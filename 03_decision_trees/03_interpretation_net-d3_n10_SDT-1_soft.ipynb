{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:34.618741Z",
     "iopub.status.busy": "2021-12-11T19:35:34.618145Z",
     "iopub.status.idle": "2021-12-11T19:35:34.647465Z",
     "shell.execute_reply": "2021-12-11T19:35:34.646511Z",
     "shell.execute_reply.started": "2021-12-11T19:35:34.618622Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 3,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': -1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'SDT', #'SDT', 'SDT'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 10, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [0,1,2],\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': None, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'random_decision_tree_trained',# 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [2048, 1024],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.2, 0.2],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.001,\n",
    "        'loss': 'soft_binary_crossentropy', #mse; soft_mse; binary_crossentropy; soft_binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['binary_crossentropy', 'binary_accuracy'],\n",
    "        \n",
    "        'epochs': 200, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 512,\n",
    "\n",
    "        'interpretation_dataset_size': 10000,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 1, # 1=standard representation; 2=sparse representation with classification for variables\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "        'soft_labels': False,\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 50,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': True,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "            \n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 10,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:34.650243Z",
     "iopub.status.busy": "2021-12-11T19:35:34.649688Z",
     "iopub.status.idle": "2021-12-11T19:35:34.657052Z",
     "shell.execute_reply": "2021-12-11T19:35:34.656145Z",
     "shell.execute_reply.started": "2021-12-11T19:35:34.650194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:34.659232Z",
     "iopub.status.busy": "2021-12-11T19:35:34.658695Z",
     "iopub.status.idle": "2021-12-11T19:35:37.740488Z",
     "shell.execute_reply": "2021-12-11T19:35:37.739872Z",
     "shell.execute_reply.started": "2021-12-11T19:35:34.659185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:37.742204Z",
     "iopub.status.busy": "2021-12-11T19:35:37.741918Z",
     "iopub.status.idle": "2021-12-11T19:35:37.748075Z",
     "shell.execute_reply": "2021-12-11T19:35:37.747548Z",
     "shell.execute_reply.started": "2021-12-11T19:35:37.742179Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:37.749259Z",
     "iopub.status.busy": "2021-12-11T19:35:37.748986Z",
     "iopub.status.idle": "2021-12-11T19:35:37.757647Z",
     "shell.execute_reply": "2021-12-11T19:35:37.757085Z",
     "shell.execute_reply.started": "2021-12-11T19:35:37.749231Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:37.758675Z",
     "iopub.status.busy": "2021-12-11T19:35:37.758432Z",
     "iopub.status.idle": "2021-12-11T19:35:37.762624Z",
     "shell.execute_reply": "2021-12-11T19:35:37.762037Z",
     "shell.execute_reply.started": "2021-12-11T19:35:37.758651Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:37.763738Z",
     "iopub.status.busy": "2021-12-11T19:35:37.763468Z",
     "iopub.status.idle": "2021-12-11T19:35:39.911844Z",
     "shell.execute_reply": "2021-12-11T19:35:39.911207Z",
     "shell.execute_reply.started": "2021-12-11T19:35:37.763713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type == 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:39.913449Z",
     "iopub.status.busy": "2021-12-11T19:35:39.913146Z",
     "iopub.status.idle": "2021-12-11T19:35:39.917659Z",
     "shell.execute_reply": "2021-12-11T19:35:39.916871Z",
     "shell.execute_reply.started": "2021-12-11T19:35:39.913424Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets10000_var10_class2_random_decision_tree_trained_xMax1_xMin0_xDistuniform_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense2048-1024_drop0.2-0.2e200b512_adam\n",
      "lNetSize5000_numLNets10000_var10_class2_random_decision_tree_trained_xMax1_xMin0_xDistuniform_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:39.918717Z",
     "iopub.status.busy": "2021-12-11T19:35:39.918481Z",
     "iopub.status.idle": "2021-12-11T19:35:39.940755Z",
     "shell.execute_reply": "2021-12-11T19:35:39.939867Z",
     "shell.execute_reply.started": "2021-12-11T19:35:39.918693Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:39.943524Z",
     "iopub.status.busy": "2021-12-11T19:35:39.943259Z",
     "iopub.status.idle": "2021-12-11T19:35:39.950291Z",
     "shell.execute_reply": "2021-12-11T19:35:39.949736Z",
     "shell.execute_reply.started": "2021-12-11T19:35:39.943500Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "       \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              config) for network_parameters_row in network_parameters.values)          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    #def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "    #    lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "    \n",
    "    #def initialize_target_function_wrapper(config, lambda_net):\n",
    "    #    lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:39.951574Z",
     "iopub.status.busy": "2021-12-11T19:35:39.951323Z",
     "iopub.status.idle": "2021-12-11T19:35:54.347040Z",
     "shell.execute_reply": "2021-12-11T19:35:54.346330Z",
     "shell.execute_reply.started": "2021-12-11T19:35:39.951550Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=10)]: Done 244 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=10)]: Done 8212 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=10)]: Done 10000 out of 10000 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "    if False:\n",
    "        lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_train_with_valid = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)   \n",
    "        \n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:54.348384Z",
     "iopub.status.busy": "2021-12-11T19:35:54.348071Z",
     "iopub.status.idle": "2021-12-11T19:35:54.352835Z",
     "shell.execute_reply": "2021-12-11T19:35:54.352370Z",
     "shell.execute_reply.started": "2021-12-11T19:35:54.348354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 1632)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:54.353824Z",
     "iopub.status.busy": "2021-12-11T19:35:54.353580Z",
     "iopub.status.idle": "2021-12-11T19:35:54.357570Z",
     "shell.execute_reply": "2021-12-11T19:35:54.357114Z",
     "shell.execute_reply.started": "2021-12-11T19:35:54.353800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1632)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:54.358523Z",
     "iopub.status.busy": "2021-12-11T19:35:54.358285Z",
     "iopub.status.idle": "2021-12-11T19:35:54.362315Z",
     "shell.execute_reply": "2021-12-11T19:35:54.361821Z",
     "shell.execute_reply.started": "2021-12-11T19:35:54.358500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1632)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-11T19:35:54.363292Z",
     "iopub.status.busy": "2021-12-11T19:35:54.363052Z",
     "iopub.status.idle": "2021-12-11T19:36:00.222793Z",
     "shell.execute_reply": "2021-12-11T19:36:00.222233Z",
     "shell.execute_reply.started": "2021-12-11T19:35:54.363263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f6v9</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>lp4c0</th>\n",
       "      <th>lp4c1</th>\n",
       "      <th>lp5c0</th>\n",
       "      <th>lp5c1</th>\n",
       "      <th>lp6c0</th>\n",
       "      <th>lp6c1</th>\n",
       "      <th>lp7c0</th>\n",
       "      <th>lp7c1</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1437</th>\n",
       "      <th>wb_1438</th>\n",
       "      <th>wb_1439</th>\n",
       "      <th>wb_1440</th>\n",
       "      <th>wb_1441</th>\n",
       "      <th>wb_1442</th>\n",
       "      <th>wb_1443</th>\n",
       "      <th>wb_1444</th>\n",
       "      <th>wb_1445</th>\n",
       "      <th>wb_1446</th>\n",
       "      <th>wb_1447</th>\n",
       "      <th>wb_1448</th>\n",
       "      <th>wb_1449</th>\n",
       "      <th>wb_1450</th>\n",
       "      <th>wb_1451</th>\n",
       "      <th>wb_1452</th>\n",
       "      <th>wb_1453</th>\n",
       "      <th>wb_1454</th>\n",
       "      <th>wb_1455</th>\n",
       "      <th>wb_1456</th>\n",
       "      <th>wb_1457</th>\n",
       "      <th>wb_1458</th>\n",
       "      <th>wb_1459</th>\n",
       "      <th>wb_1460</th>\n",
       "      <th>wb_1461</th>\n",
       "      <th>wb_1462</th>\n",
       "      <th>wb_1463</th>\n",
       "      <th>wb_1464</th>\n",
       "      <th>wb_1465</th>\n",
       "      <th>wb_1466</th>\n",
       "      <th>wb_1467</th>\n",
       "      <th>wb_1468</th>\n",
       "      <th>wb_1469</th>\n",
       "      <th>wb_1470</th>\n",
       "      <th>wb_1471</th>\n",
       "      <th>wb_1472</th>\n",
       "      <th>wb_1473</th>\n",
       "      <th>wb_1474</th>\n",
       "      <th>wb_1475</th>\n",
       "      <th>wb_1476</th>\n",
       "      <th>wb_1477</th>\n",
       "      <th>wb_1478</th>\n",
       "      <th>wb_1479</th>\n",
       "      <th>wb_1480</th>\n",
       "      <th>wb_1481</th>\n",
       "      <th>wb_1482</th>\n",
       "      <th>wb_1483</th>\n",
       "      <th>wb_1484</th>\n",
       "      <th>wb_1485</th>\n",
       "      <th>wb_1486</th>\n",
       "      <th>wb_1487</th>\n",
       "      <th>wb_1488</th>\n",
       "      <th>wb_1489</th>\n",
       "      <th>wb_1490</th>\n",
       "      <th>wb_1491</th>\n",
       "      <th>wb_1492</th>\n",
       "      <th>wb_1493</th>\n",
       "      <th>wb_1494</th>\n",
       "      <th>wb_1495</th>\n",
       "      <th>wb_1496</th>\n",
       "      <th>wb_1497</th>\n",
       "      <th>wb_1498</th>\n",
       "      <th>wb_1499</th>\n",
       "      <th>wb_1500</th>\n",
       "      <th>wb_1501</th>\n",
       "      <th>wb_1502</th>\n",
       "      <th>wb_1503</th>\n",
       "      <th>wb_1504</th>\n",
       "      <th>wb_1505</th>\n",
       "      <th>wb_1506</th>\n",
       "      <th>wb_1507</th>\n",
       "      <th>wb_1508</th>\n",
       "      <th>wb_1509</th>\n",
       "      <th>wb_1510</th>\n",
       "      <th>wb_1511</th>\n",
       "      <th>wb_1512</th>\n",
       "      <th>wb_1513</th>\n",
       "      <th>wb_1514</th>\n",
       "      <th>wb_1515</th>\n",
       "      <th>wb_1516</th>\n",
       "      <th>wb_1517</th>\n",
       "      <th>wb_1518</th>\n",
       "      <th>wb_1519</th>\n",
       "      <th>wb_1520</th>\n",
       "      <th>wb_1521</th>\n",
       "      <th>wb_1522</th>\n",
       "      <th>wb_1523</th>\n",
       "      <th>wb_1524</th>\n",
       "      <th>wb_1525</th>\n",
       "      <th>wb_1526</th>\n",
       "      <th>wb_1527</th>\n",
       "      <th>wb_1528</th>\n",
       "      <th>wb_1529</th>\n",
       "      <th>wb_1530</th>\n",
       "      <th>wb_1531</th>\n",
       "      <th>wb_1532</th>\n",
       "      <th>wb_1533</th>\n",
       "      <th>wb_1534</th>\n",
       "      <th>wb_1535</th>\n",
       "      <th>wb_1536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>3289.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.877</td>\n",
       "      <td>2.399</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>2.093</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.560</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-1.673</td>\n",
       "      <td>1.517</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-1.102</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.255</td>\n",
       "      <td>-1.036</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>2.563</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.934</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-1.203</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.255</td>\n",
       "      <td>1.922</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>2.116</td>\n",
       "      <td>2.012</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1.963</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>-0.501</td>\n",
       "      <td>0.424</td>\n",
       "      <td>2.358</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>2.034</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.293</td>\n",
       "      <td>1.194</td>\n",
       "      <td>1.510</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>1.736</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>-0.738</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.432</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.557</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.796</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>2.024</td>\n",
       "      <td>0.451</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.788</td>\n",
       "      <td>-0.608</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.469</td>\n",
       "      <td>2.215</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>2.045</td>\n",
       "      <td>0.288</td>\n",
       "      <td>-0.573</td>\n",
       "      <td>-0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>7460.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.367</td>\n",
       "      <td>1.290</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-1.358</td>\n",
       "      <td>1.613</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-1.223</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>2.304</td>\n",
       "      <td>2.055</td>\n",
       "      <td>1.961</td>\n",
       "      <td>1.972</td>\n",
       "      <td>2.012</td>\n",
       "      <td>0.319</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>1.040</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>1.644</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>1.649</td>\n",
       "      <td>1.931</td>\n",
       "      <td>1.144</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.964</td>\n",
       "      <td>1.233</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>1.731</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>1.128</td>\n",
       "      <td>1.407</td>\n",
       "      <td>-0.479</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>-1.058</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.617</td>\n",
       "      <td>1.850</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>2.040</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>1.740</td>\n",
       "      <td>1.703</td>\n",
       "      <td>1.073</td>\n",
       "      <td>0.987</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.661</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>1.520</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>1.892</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.115</td>\n",
       "      <td>1.224</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>2.229</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6043.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>...</td>\n",
       "      <td>1.393</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>1.459</td>\n",
       "      <td>-1.778</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.755</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.926</td>\n",
       "      <td>1.221</td>\n",
       "      <td>1.650</td>\n",
       "      <td>1.127</td>\n",
       "      <td>2.939</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.902</td>\n",
       "      <td>-1.867</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-2.143</td>\n",
       "      <td>-1.087</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.779</td>\n",
       "      <td>-2.414</td>\n",
       "      <td>-1.897</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>1.330</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-2.522</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-2.388</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>1.747</td>\n",
       "      <td>2.288</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-1.352</td>\n",
       "      <td>2.458</td>\n",
       "      <td>2.493</td>\n",
       "      <td>1.362</td>\n",
       "      <td>-2.542</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.984</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-2.335</td>\n",
       "      <td>1.549</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>0.986</td>\n",
       "      <td>-1.123</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.316</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-1.172</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.058</td>\n",
       "      <td>0.989</td>\n",
       "      <td>-1.793</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.688</td>\n",
       "      <td>1.929</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>1.110</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>2.629</td>\n",
       "      <td>0.883</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>9699.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>3.707</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>4.006</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>1.685</td>\n",
       "      <td>1.315</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.352</td>\n",
       "      <td>-1.850</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1.781</td>\n",
       "      <td>4.022</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>1.591</td>\n",
       "      <td>-3.233</td>\n",
       "      <td>1.047</td>\n",
       "      <td>-2.396</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.319</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>4.009</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>2.471</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.860</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1.283</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-1.264</td>\n",
       "      <td>1.529</td>\n",
       "      <td>1.063</td>\n",
       "      <td>-3.314</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>1.012</td>\n",
       "      <td>-1.355</td>\n",
       "      <td>1.613</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-1.030</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.623</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>2.084</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.128</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-1.379</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.134</td>\n",
       "      <td>1.324</td>\n",
       "      <td>1.834</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>-1.752</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>1.816</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-2.140</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.473</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.539</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>1.317</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>1.310</td>\n",
       "      <td>1.177</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.741</td>\n",
       "      <td>-1.129</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.163</td>\n",
       "      <td>1.269</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-1.980</td>\n",
       "      <td>0.497</td>\n",
       "      <td>-2.025</td>\n",
       "      <td>0.757</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>1.220</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-1.107</td>\n",
       "      <td>-1.134</td>\n",
       "      <td>2.862</td>\n",
       "      <td>-1.207</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>1.162</td>\n",
       "      <td>1.740</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-1.885</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>1.448</td>\n",
       "      <td>0.723</td>\n",
       "      <td>-1.422</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-2.042</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>1.078</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-2.337</td>\n",
       "      <td>0.661</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>-2.056</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.552</td>\n",
       "      <td>1.163</td>\n",
       "      <td>-1.307</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-1.568</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.676</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.549</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.432</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.286</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>2.781</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "3289 3289.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460 7460.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043 6043.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699 9699.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5       5.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  f2v0  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f3v0  f3v1  f3v2  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f3v3  f3v4  f3v5  f3v6  f3v7  f3v8  f3v9  f4v0  f4v1  f4v2  f4v3  f4v4  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f4v5  f4v6  f4v7  f4v8  f4v9  f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f5v7  f5v8  f5v9  f6v0  f6v1  f6v2  f6v3  f6v4  f6v5  f6v6  f6v7  f6v8  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f6v9    b0    b1    b2    b3    b4    b5    b6  lp0c0  lp0c1  lp1c0  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "\n",
       "      lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  lp4c0  lp4c1  lp5c0  lp5c1  lp6c0  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      lp6c1  lp7c0  lp7c1   wb_0   wb_1   wb_2   wb_3   wb_4  ...  wb_1437  \\\n",
       "3289  0.000  0.000  0.000  0.124  0.205 -0.256 -0.483  0.008  ...    1.901   \n",
       "7460  0.000  0.000  0.000 -0.112  0.173 -0.034 -0.170 -0.066  ...    1.757   \n",
       "6043  0.000  0.000  0.000  0.115 -0.166 -0.049 -0.473 -0.024  ...    1.393   \n",
       "9699  0.000  0.000  0.000 -0.001  0.268  0.174 -0.096  0.016  ...    3.707   \n",
       "5     0.000  0.000  0.000 -0.046 -0.051 -0.064 -0.120 -0.020  ...    0.750   \n",
       "\n",
       "      wb_1438  wb_1439  wb_1440  wb_1441  wb_1442  wb_1443  wb_1444  wb_1445  \\\n",
       "3289   -0.078    0.877    2.399    1.347   -0.056    0.052   -0.258    0.626   \n",
       "7460   -0.085    0.367    1.290    0.055   -1.358    1.613    0.328    0.384   \n",
       "6043   -0.085    0.920    0.885    0.258   -0.022    1.459   -1.778    0.517   \n",
       "9699   -0.076    4.006    0.143    0.249   -0.838    1.685    1.315    0.849   \n",
       "5      -0.072    0.314    0.621    0.202   -0.036    1.310    1.177    0.369   \n",
       "\n",
       "      wb_1446  wb_1447  wb_1448  wb_1449  wb_1450  wb_1451  wb_1452  wb_1453  \\\n",
       "3289    0.247   -0.490   -0.638    2.093    0.682    0.637    0.560    2.309   \n",
       "7460    0.336   -1.223   -0.222    2.304    2.055    1.961    1.972    2.012   \n",
       "6043    0.755   -0.828    0.169    0.926    1.221    1.650    1.127    2.939   \n",
       "9699    1.352   -1.850    0.356    0.044    1.034    0.480    0.745    1.781   \n",
       "5       0.741   -1.129    0.255    0.746    0.694    0.703    1.163    1.269   \n",
       "\n",
       "      wb_1454  wb_1455  wb_1456  wb_1457  wb_1458  wb_1459  wb_1460  wb_1461  \\\n",
       "3289    0.458   -1.673    1.517   -0.803    0.285   -0.115   -1.102   -0.113   \n",
       "7460    0.319   -0.577    1.040   -0.506    1.644   -0.112   -0.492   -0.113   \n",
       "6043    0.341   -0.168    0.902   -1.867    0.075   -2.143   -1.087   -0.113   \n",
       "9699    4.022   -0.425    1.591   -3.233    1.047   -2.396   -0.838   -0.113   \n",
       "5       0.227   -1.980    0.497   -2.025    0.757   -0.123   -0.577   -0.113   \n",
       "\n",
       "      wb_1462  wb_1463  wb_1464  wb_1465  wb_1466  wb_1467  wb_1468  wb_1469  \\\n",
       "3289   -0.246    0.422    1.255   -1.036   -0.665    2.563   -0.054    0.934   \n",
       "7460    1.649    1.931    1.144   -0.078   -0.572    0.414   -0.070    0.478   \n",
       "6043   -0.277    0.989    1.779   -2.414   -1.897    0.100   -0.055    0.961   \n",
       "9699   -0.423    0.242    0.061   -2.319   -0.354    4.009   -0.056    2.471   \n",
       "5       1.220    0.311    0.291   -1.107   -1.134    2.862   -1.207    0.625   \n",
       "\n",
       "      wb_1470  wb_1471  wb_1472  wb_1473  wb_1474  wb_1475  wb_1476  wb_1477  \\\n",
       "3289   -0.324    0.998   -1.203   -0.124    0.255    1.922   -0.438   -0.058   \n",
       "7460   -0.317    0.964    1.233   -0.112    1.731   -0.406   -0.395   -0.089   \n",
       "6043   -0.490    1.330   -0.161   -2.522    0.502    0.333   -0.211   -2.388   \n",
       "9699   -0.272    1.860    0.683   -0.104    0.578    1.283   -0.223   -0.096   \n",
       "5      -0.523    1.162    1.740   -0.088    0.904    0.431   -0.430   -0.091   \n",
       "\n",
       "      wb_1478  wb_1479  wb_1480  wb_1481  wb_1482  wb_1483  wb_1484  wb_1485  \\\n",
       "3289   -0.865    2.116    2.012   -0.309   -0.214    1.094    1.963    0.367   \n",
       "7460   -0.358    1.128    1.407   -0.479   -0.255   -0.362   -1.058    0.391   \n",
       "6043   -0.311    1.747    2.288   -0.560    0.077   -1.352    2.458    2.493   \n",
       "9699   -1.264    1.529    1.063   -3.314   -0.139    1.012   -1.355    1.613   \n",
       "5      -0.409    0.536    0.336   -0.401   -0.500   -1.885   -0.967    1.448   \n",
       "\n",
       "      wb_1486  wb_1487  wb_1488  wb_1489  wb_1490  wb_1491  wb_1492  wb_1493  \\\n",
       "3289    0.135   -0.124   -0.510   -0.830   -0.501    0.424    2.358   -0.493   \n",
       "7460    0.457   -0.123   -0.303   -0.441   -0.248    0.093    1.617    1.850   \n",
       "6043    1.362   -2.542   -0.197   -0.305   -0.311    0.984   -0.217   -0.267   \n",
       "9699    0.970   -1.030   -0.190   -0.316   -0.374    1.645    0.739   -0.216   \n",
       "5       0.723   -1.422   -0.357   -2.042   -0.104    1.078   -1.052   -1.173   \n",
       "\n",
       "      wb_1494  wb_1495  wb_1496  wb_1497  wb_1498  wb_1499  wb_1500  wb_1501  \\\n",
       "3289   -0.432    2.034   -0.162   -0.274    0.510   -0.457   -0.065    0.293   \n",
       "7460   -0.572    0.514   -0.260   -0.365    2.040   -0.505   -0.377   -0.165   \n",
       "6043   -2.335    1.549   -0.018   -0.930    0.986   -1.123   -0.905    0.174   \n",
       "9699   -0.134   -0.261   -0.110   -0.381    0.623   -0.377    2.084    1.003   \n",
       "5      -2.337    0.661   -0.416    0.778    0.406   -0.665   -2.056    0.082   \n",
       "\n",
       "      wb_1502  wb_1503  wb_1504  wb_1505  wb_1506  wb_1507  wb_1508  wb_1509  \\\n",
       "3289    1.194    1.510   -0.587    1.736    0.428   -0.213   -0.421   -0.738   \n",
       "7460    1.740    1.703    1.073    0.987   -0.010   -0.281   -0.843   -0.178   \n",
       "6043    1.316   -2.186   -0.324    0.502    0.283   -0.964   -1.172   -0.529   \n",
       "9699    1.128   -0.649    0.291    0.721    0.099   -0.534   -1.379   -0.173   \n",
       "5       0.552    1.163   -1.307    0.207    0.122   -0.535   -0.500   -1.568   \n",
       "\n",
       "      wb_1510  wb_1511  wb_1512  wb_1513  wb_1514  wb_1515  wb_1516  wb_1517  \\\n",
       "3289   -0.672   -0.101    0.563    0.432    2.187    1.557   -0.550   -0.796   \n",
       "7460   -0.468   -0.097    0.201    1.661    0.435    0.387   -0.117    0.552   \n",
       "6043   -0.204   -0.106    0.589    0.864    1.058    0.989   -1.793   -0.368   \n",
       "9699   -0.399   -0.096    0.134    1.324    1.834    0.059   -0.793   -1.752   \n",
       "5      -0.761   -0.100    0.319    0.714    0.683    0.676   -0.579   -0.963   \n",
       "\n",
       "      wb_1518  wb_1519  wb_1520  wb_1521  wb_1522  wb_1523  wb_1524  wb_1525  \\\n",
       "3289    0.067   -0.413    2.024    0.451   -0.279   -0.788   -0.608    0.417   \n",
       "7460    0.067   -0.383   -0.285    1.520   -0.212   -0.164   -0.577    1.892   \n",
       "6043    0.067   -0.198    0.787    0.765   -0.202   -0.560   -0.603    1.005   \n",
       "9699    0.067   -0.234   -0.588    1.816   -0.111   -0.166   -2.140    1.333   \n",
       "5       0.067   -0.787   -0.409    0.549   -0.395   -0.168   -0.531    0.831   \n",
       "\n",
       "      wb_1526  wb_1527  wb_1528  wb_1529  wb_1530  wb_1531  wb_1532  wb_1533  \\\n",
       "3289    0.469    2.215    0.185    0.107   -0.092    0.300   -0.343    2.045   \n",
       "7460    2.240    2.115    1.224    0.427   -0.151    0.350   -0.383    2.229   \n",
       "6043    0.240    0.301    0.688    1.929   -0.083    1.110   -0.067    2.629   \n",
       "9699    1.473    0.127   -0.237    0.539   -0.129    0.173   -0.071    1.317   \n",
       "5       1.432    0.807    0.375    1.286   -0.766   -0.470   -0.556    2.781   \n",
       "\n",
       "      wb_1534  wb_1535  wb_1536  \n",
       "3289    0.288   -0.573   -0.341  \n",
       "7460   -0.366   -0.749    0.054  \n",
       "6043    0.883   -0.133   -0.086  \n",
       "9699    0.185   -0.201   -0.179  \n",
       "5      -0.403    0.395    0.314  \n",
       "\n",
       "[5 rows x 1632 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-11T19:36:00.223906Z",
     "iopub.status.busy": "2021-12-11T19:36:00.223726Z",
     "iopub.status.idle": "2021-12-11T19:36:00.954921Z",
     "shell.execute_reply": "2021-12-11T19:36:00.954400Z",
     "shell.execute_reply.started": "2021-12-11T19:36:00.223882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f6v9</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>lp4c0</th>\n",
       "      <th>lp4c1</th>\n",
       "      <th>lp5c0</th>\n",
       "      <th>lp5c1</th>\n",
       "      <th>lp6c0</th>\n",
       "      <th>lp6c1</th>\n",
       "      <th>lp7c0</th>\n",
       "      <th>lp7c1</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1437</th>\n",
       "      <th>wb_1438</th>\n",
       "      <th>wb_1439</th>\n",
       "      <th>wb_1440</th>\n",
       "      <th>wb_1441</th>\n",
       "      <th>wb_1442</th>\n",
       "      <th>wb_1443</th>\n",
       "      <th>wb_1444</th>\n",
       "      <th>wb_1445</th>\n",
       "      <th>wb_1446</th>\n",
       "      <th>wb_1447</th>\n",
       "      <th>wb_1448</th>\n",
       "      <th>wb_1449</th>\n",
       "      <th>wb_1450</th>\n",
       "      <th>wb_1451</th>\n",
       "      <th>wb_1452</th>\n",
       "      <th>wb_1453</th>\n",
       "      <th>wb_1454</th>\n",
       "      <th>wb_1455</th>\n",
       "      <th>wb_1456</th>\n",
       "      <th>wb_1457</th>\n",
       "      <th>wb_1458</th>\n",
       "      <th>wb_1459</th>\n",
       "      <th>wb_1460</th>\n",
       "      <th>wb_1461</th>\n",
       "      <th>wb_1462</th>\n",
       "      <th>wb_1463</th>\n",
       "      <th>wb_1464</th>\n",
       "      <th>wb_1465</th>\n",
       "      <th>wb_1466</th>\n",
       "      <th>wb_1467</th>\n",
       "      <th>wb_1468</th>\n",
       "      <th>wb_1469</th>\n",
       "      <th>wb_1470</th>\n",
       "      <th>wb_1471</th>\n",
       "      <th>wb_1472</th>\n",
       "      <th>wb_1473</th>\n",
       "      <th>wb_1474</th>\n",
       "      <th>wb_1475</th>\n",
       "      <th>wb_1476</th>\n",
       "      <th>wb_1477</th>\n",
       "      <th>wb_1478</th>\n",
       "      <th>wb_1479</th>\n",
       "      <th>wb_1480</th>\n",
       "      <th>wb_1481</th>\n",
       "      <th>wb_1482</th>\n",
       "      <th>wb_1483</th>\n",
       "      <th>wb_1484</th>\n",
       "      <th>wb_1485</th>\n",
       "      <th>wb_1486</th>\n",
       "      <th>wb_1487</th>\n",
       "      <th>wb_1488</th>\n",
       "      <th>wb_1489</th>\n",
       "      <th>wb_1490</th>\n",
       "      <th>wb_1491</th>\n",
       "      <th>wb_1492</th>\n",
       "      <th>wb_1493</th>\n",
       "      <th>wb_1494</th>\n",
       "      <th>wb_1495</th>\n",
       "      <th>wb_1496</th>\n",
       "      <th>wb_1497</th>\n",
       "      <th>wb_1498</th>\n",
       "      <th>wb_1499</th>\n",
       "      <th>wb_1500</th>\n",
       "      <th>wb_1501</th>\n",
       "      <th>wb_1502</th>\n",
       "      <th>wb_1503</th>\n",
       "      <th>wb_1504</th>\n",
       "      <th>wb_1505</th>\n",
       "      <th>wb_1506</th>\n",
       "      <th>wb_1507</th>\n",
       "      <th>wb_1508</th>\n",
       "      <th>wb_1509</th>\n",
       "      <th>wb_1510</th>\n",
       "      <th>wb_1511</th>\n",
       "      <th>wb_1512</th>\n",
       "      <th>wb_1513</th>\n",
       "      <th>wb_1514</th>\n",
       "      <th>wb_1515</th>\n",
       "      <th>wb_1516</th>\n",
       "      <th>wb_1517</th>\n",
       "      <th>wb_1518</th>\n",
       "      <th>wb_1519</th>\n",
       "      <th>wb_1520</th>\n",
       "      <th>wb_1521</th>\n",
       "      <th>wb_1522</th>\n",
       "      <th>wb_1523</th>\n",
       "      <th>wb_1524</th>\n",
       "      <th>wb_1525</th>\n",
       "      <th>wb_1526</th>\n",
       "      <th>wb_1527</th>\n",
       "      <th>wb_1528</th>\n",
       "      <th>wb_1529</th>\n",
       "      <th>wb_1530</th>\n",
       "      <th>wb_1531</th>\n",
       "      <th>wb_1532</th>\n",
       "      <th>wb_1533</th>\n",
       "      <th>wb_1534</th>\n",
       "      <th>wb_1535</th>\n",
       "      <th>wb_1536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7217.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.663</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>1.152</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>1.029</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-1.084</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.120</td>\n",
       "      <td>2.227</td>\n",
       "      <td>1.188</td>\n",
       "      <td>1.253</td>\n",
       "      <td>1.029</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-1.505</td>\n",
       "      <td>1.253</td>\n",
       "      <td>-1.553</td>\n",
       "      <td>1.294</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-1.258</td>\n",
       "      <td>1.085</td>\n",
       "      <td>-0.810</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>1.528</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>0.957</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.357</td>\n",
       "      <td>1.452</td>\n",
       "      <td>-1.605</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-1.386</td>\n",
       "      <td>-1.130</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>1.217</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-1.673</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.403</td>\n",
       "      <td>-1.848</td>\n",
       "      <td>-1.076</td>\n",
       "      <td>1.786</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>1.025</td>\n",
       "      <td>-1.031</td>\n",
       "      <td>-1.730</td>\n",
       "      <td>-1.371</td>\n",
       "      <td>0.229</td>\n",
       "      <td>1.090</td>\n",
       "      <td>1.123</td>\n",
       "      <td>0.140</td>\n",
       "      <td>1.207</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>-1.036</td>\n",
       "      <td>1.695</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>8291.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.035</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.445</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.694</td>\n",
       "      <td>2.565</td>\n",
       "      <td>1.548</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>0.051</td>\n",
       "      <td>2.571</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.727</td>\n",
       "      <td>0.199</td>\n",
       "      <td>2.914</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>2.541</td>\n",
       "      <td>0.082</td>\n",
       "      <td>1.224</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-1.403</td>\n",
       "      <td>2.181</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>0.227</td>\n",
       "      <td>1.016</td>\n",
       "      <td>-1.017</td>\n",
       "      <td>-0.743</td>\n",
       "      <td>1.847</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>2.584</td>\n",
       "      <td>1.953</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>-2.979</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-1.287</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-2.685</td>\n",
       "      <td>2.209</td>\n",
       "      <td>1.418</td>\n",
       "      <td>2.695</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.864</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-1.025</td>\n",
       "      <td>-1.189</td>\n",
       "      <td>-1.487</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-1.003</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-1.260</td>\n",
       "      <td>0.113</td>\n",
       "      <td>2.393</td>\n",
       "      <td>1.854</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>1.157</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-1.226</td>\n",
       "      <td>-1.539</td>\n",
       "      <td>-1.140</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.179</td>\n",
       "      <td>2.423</td>\n",
       "      <td>-1.310</td>\n",
       "      <td>-1.161</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.073</td>\n",
       "      <td>-1.014</td>\n",
       "      <td>-1.397</td>\n",
       "      <td>-1.170</td>\n",
       "      <td>0.192</td>\n",
       "      <td>2.547</td>\n",
       "      <td>2.551</td>\n",
       "      <td>0.191</td>\n",
       "      <td>1.977</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-1.129</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.399</td>\n",
       "      <td>1.175</td>\n",
       "      <td>0.657</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>1.866</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.462</td>\n",
       "      <td>2.638</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>3.309</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.507</td>\n",
       "      <td>1.425</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.507</td>\n",
       "      <td>2.340</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>2.375</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>1.259</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>2.231</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.549</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>2.482</td>\n",
       "      <td>0.486</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.229</td>\n",
       "      <td>1.841</td>\n",
       "      <td>-0.496</td>\n",
       "      <td>1.194</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.235</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.687</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>1.451</td>\n",
       "      <td>0.831</td>\n",
       "      <td>2.743</td>\n",
       "      <td>2.412</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>1.259</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>1.609</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>1.236</td>\n",
       "      <td>2.920</td>\n",
       "      <td>3.249</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.699</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>1.486</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>0.926</td>\n",
       "      <td>-0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>5114.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.503</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.569</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>-0.557</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.658</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.666</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>0.486</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>0.620</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-0.629</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>0.546</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.873</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.523</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.025</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>1.126</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.518</td>\n",
       "      <td>-2.509</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-2.394</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>2.470</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.061</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.558</td>\n",
       "      <td>-1.359</td>\n",
       "      <td>2.679</td>\n",
       "      <td>-1.150</td>\n",
       "      <td>-1.088</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-2.813</td>\n",
       "      <td>1.413</td>\n",
       "      <td>-0.675</td>\n",
       "      <td>0.560</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>-1.009</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-1.012</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-1.145</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>1.044</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-2.466</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-1.299</td>\n",
       "      <td>-2.515</td>\n",
       "      <td>0.904</td>\n",
       "      <td>2.145</td>\n",
       "      <td>-1.540</td>\n",
       "      <td>-0.932</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>0.572</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.495</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-1.019</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-2.172</td>\n",
       "      <td>-1.939</td>\n",
       "      <td>-1.034</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.426</td>\n",
       "      <td>2.872</td>\n",
       "      <td>1.596</td>\n",
       "      <td>-1.264</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.896</td>\n",
       "      <td>-1.069</td>\n",
       "      <td>0.957</td>\n",
       "      <td>-0.551</td>\n",
       "      <td>-1.051</td>\n",
       "      <td>-1.005</td>\n",
       "      <td>0.477</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.748</td>\n",
       "      <td>1.293</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.349</td>\n",
       "      <td>-1.561</td>\n",
       "      <td>2.688</td>\n",
       "      <td>0.476</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "7217 7217.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 8291.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 4607.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 5114.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 1859.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  f2v0  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f3v0  f3v1  f3v2  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f3v3  f3v4  f3v5  f3v6  f3v7  f3v8  f3v9  f4v0  f4v1  f4v2  f4v3  f4v4  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f4v5  f4v6  f4v7  f4v8  f4v9  f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f5v7  f5v8  f5v9  f6v0  f6v1  f6v2  f6v3  f6v4  f6v5  f6v6  f6v7  f6v8  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f6v9    b0    b1    b2    b3    b4    b5    b6  lp0c0  lp0c1  lp1c0  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000   \n",
       "\n",
       "      lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  lp4c0  lp4c1  lp5c0  lp5c1  lp6c0  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      lp6c1  lp7c0  lp7c1   wb_0   wb_1   wb_2   wb_3   wb_4  ...  wb_1437  \\\n",
       "7217  0.000  0.000  0.000  0.072 -0.075 -0.134 -0.280 -0.162  ...   -1.663   \n",
       "8291  0.000  0.000  0.000 -0.071  0.045 -0.147 -0.011  0.035  ...   -1.445   \n",
       "4607  0.000  0.000  0.000 -0.102  0.171  0.001  0.082 -0.019  ...    0.350   \n",
       "5114  0.000  0.000  0.000  0.052 -0.076  0.008 -0.499 -0.213  ...   -0.645   \n",
       "1859  0.000  0.000  0.000  0.023 -0.034  0.006 -0.069 -0.171  ...   -1.025   \n",
       "\n",
       "      wb_1438  wb_1439  wb_1440  wb_1441  wb_1442  wb_1443  wb_1444  wb_1445  \\\n",
       "7217   -0.078    1.152    0.126    0.209   -0.057    1.029    0.327    0.791   \n",
       "8291   -0.085    0.694    2.565    1.548   -1.220    0.051    2.571    0.570   \n",
       "4607   -0.085    0.399    1.175    0.657   -0.048    1.866    0.340    0.462   \n",
       "5114   -0.085    0.544    0.141    0.393   -0.655    0.545    0.495    0.494   \n",
       "1859   -0.085    1.126    0.158    0.518   -2.509    0.405    0.406    0.366   \n",
       "\n",
       "      wb_1446  wb_1447  wb_1448  wb_1449  wb_1450  wb_1451  wb_1452  wb_1453  \\\n",
       "7217    0.094   -1.084    0.999    1.120    2.227    1.188    1.253    1.029   \n",
       "8291    0.290   -1.343   -0.727    0.199    2.914   -0.473    2.541    0.082   \n",
       "4607    2.638   -0.143   -0.097    3.309    0.465    0.504    0.938    0.507   \n",
       "5114    0.503   -0.157    0.409    0.186    0.112    0.086    0.647    0.648   \n",
       "1859    0.328   -2.394    0.333   -0.926    2.470    1.037    0.558    0.473   \n",
       "\n",
       "      wb_1454  wb_1455  wb_1456  wb_1457  wb_1458  wb_1459  wb_1460  wb_1461  \\\n",
       "7217    0.998   -1.505    1.253   -1.553    1.294   -0.816   -0.523   -0.113   \n",
       "8291    1.224   -1.035    0.811   -1.403    2.181   -0.119   -0.593   -0.113   \n",
       "4607    1.425   -0.559    0.847   -0.470    0.468   -0.106   -0.464   -0.113   \n",
       "5114    0.569   -0.749    0.117   -0.883    0.090   -0.837   -0.557   -0.113   \n",
       "1859    1.061   -0.158    0.558   -1.359    2.679   -1.150   -1.088   -0.113   \n",
       "\n",
       "      wb_1462  wb_1463  wb_1464  wb_1465  wb_1466  wb_1467  wb_1468  wb_1469  \\\n",
       "7217    0.199    0.249    0.127   -0.385   -0.194    0.104   -0.607    0.123   \n",
       "8291   -0.899    0.227    1.016   -1.017   -0.743    1.847   -0.062    0.304   \n",
       "4607    0.231    0.174    0.256   -0.096   -0.507    2.340   -0.046    2.375   \n",
       "5114    0.417    0.543    0.440   -0.744   -0.538    0.109   -0.047    0.658   \n",
       "1859    0.913    0.531    0.246   -0.474   -0.439    0.102   -2.813    1.413   \n",
       "\n",
       "      wb_1470  wb_1471  wb_1472  wb_1473  wb_1474  wb_1475  wb_1476  wb_1477  \\\n",
       "7217   -1.258    1.085   -0.810   -0.353    0.187   -0.117   -0.254   -0.097   \n",
       "8291   -0.950    2.584    1.953   -0.114    0.147    0.145   -0.690   -2.979   \n",
       "4607   -0.347    1.259    0.263   -0.110    2.231   -0.307   -0.235   -0.087   \n",
       "5114   -0.420    0.666   -0.450   -0.811    0.486   -0.571   -0.444   -0.762   \n",
       "1859   -0.675    0.560   -0.530   -1.009    0.301   -1.012   -0.885   -1.145   \n",
       "\n",
       "      wb_1478  wb_1479  wb_1480  wb_1481  wb_1482  wb_1483  wb_1484  wb_1485  \\\n",
       "7217   -0.410    1.528    0.538   -0.953    0.957   -0.442   -0.474    0.357   \n",
       "8291   -0.874    1.034    0.827   -1.287   -0.994   -2.685    2.209    1.418   \n",
       "4607   -0.255    0.708    0.549   -0.331   -0.201   -0.408   -0.395    2.482   \n",
       "5114   -0.540    0.136   -0.245   -0.341    0.412   -0.468   -0.259    0.564   \n",
       "1859   -0.951    1.044   -0.300   -2.466    0.703   -1.299   -2.515    0.904   \n",
       "\n",
       "      wb_1486  wb_1487  wb_1488  wb_1489  wb_1490  wb_1491  wb_1492  wb_1493  \\\n",
       "7217    1.452   -1.605   -0.188   -0.252   -1.006    0.232   -1.386   -1.130   \n",
       "8291    2.695   -0.127   -0.154   -0.864   -1.099    0.256   -1.025   -1.189   \n",
       "4607    0.486   -0.117   -0.221   -0.336   -0.217    0.694    0.229    1.841   \n",
       "5114    0.129   -0.740   -0.503   -0.543   -0.579    0.620   -0.543   -0.480   \n",
       "1859    2.145   -1.540   -0.932   -0.994   -0.912    0.572   -0.475   -0.454   \n",
       "\n",
       "      wb_1494  wb_1495  wb_1496  wb_1497  wb_1498  wb_1499  wb_1500  wb_1501  \\\n",
       "7217   -0.515    1.217   -0.073    0.669    0.208   -0.756   -0.963    0.090   \n",
       "8291   -1.487    0.259   -0.158   -1.003    0.297   -0.311   -1.260    0.113   \n",
       "4607   -0.496    1.194   -0.239   -0.197    0.187   -0.460   -0.434   -0.138   \n",
       "5114   -0.629   -0.260   -0.058    0.462    0.570   -0.350   -0.627    0.383   \n",
       "1859   -0.137   -0.427    0.276    0.806    0.495   -0.858   -1.019    0.395   \n",
       "\n",
       "      wb_1502  wb_1503  wb_1504  wb_1505  wb_1506  wb_1507  wb_1508  wb_1509  \\\n",
       "7217    0.137    0.120   -0.025    0.279    0.158   -1.079   -0.283   -1.673   \n",
       "8291    2.393    1.854   -0.704    1.157    0.313   -0.155   -1.226   -1.539   \n",
       "4607    2.013    2.235    0.176    0.365    0.687   -0.305   -0.607   -0.179   \n",
       "5114    0.562    0.536   -0.220    0.531    0.452   -0.051   -0.456   -0.893   \n",
       "1859    0.308   -1.342   -0.181    0.415    0.309   -2.172   -1.939   -1.034   \n",
       "\n",
       "      wb_1510  wb_1511  wb_1512  wb_1513  wb_1514  wb_1515  wb_1516  wb_1517  \\\n",
       "7217   -0.107   -0.436    0.244    0.276    0.080    1.403   -1.848   -1.076   \n",
       "8291   -1.140   -0.098    0.282    0.252    0.179    2.423   -1.310   -1.161   \n",
       "4607   -0.324   -0.100    1.451    0.831    2.743    2.412   -0.481    1.259   \n",
       "5114   -0.334   -0.091    0.480    0.545    0.076    0.117   -0.766   -0.631   \n",
       "1859   -0.328   -0.092    0.422    0.426    2.872    1.596   -1.264   -0.800   \n",
       "\n",
       "      wb_1518  wb_1519  wb_1520  wb_1521  wb_1522  wb_1523  wb_1524  wb_1525  \\\n",
       "7217    1.786   -0.173   -0.298    1.025   -1.031   -1.730   -1.371    0.229   \n",
       "8291    0.067   -0.022    0.040    1.073   -1.014   -1.397   -1.170    0.192   \n",
       "4607    0.067   -0.269   -0.396    1.609   -0.123   -0.898   -0.317    1.236   \n",
       "5114    0.067   -0.494   -0.568    0.546   -0.369   -0.873   -0.587    0.612   \n",
       "1859    0.067   -0.896   -1.069    0.957   -0.551   -1.051   -1.005    0.477   \n",
       "\n",
       "      wb_1526  wb_1527  wb_1528  wb_1529  wb_1530  wb_1531  wb_1532  wb_1533  \\\n",
       "7217    1.090    1.123    0.140    1.207   -0.058   -0.621   -1.036    1.695   \n",
       "8291    2.547    2.551    0.191    1.977   -0.041    0.226   -1.129    0.250   \n",
       "4607    2.920    3.249    1.769    1.699   -0.184   -0.320   -0.423    1.486   \n",
       "5114    0.606    0.123    0.390    0.616    0.028    0.523   -0.531    0.088   \n",
       "1859    1.306    0.100    0.748    1.293    0.490    0.349   -1.561    2.688   \n",
       "\n",
       "      wb_1534  wb_1535  wb_1536  \n",
       "7217    0.158   -0.952   -0.118  \n",
       "8291    0.380   -0.921   -0.076  \n",
       "4607   -0.323    0.926   -0.189  \n",
       "5114    0.456   -0.366   -0.231  \n",
       "1859    0.476   -0.292   -0.078  \n",
       "\n",
       "[5 rows x 1632 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-11T19:36:00.956013Z",
     "iopub.status.busy": "2021-12-11T19:36:00.955738Z",
     "iopub.status.idle": "2021-12-11T19:36:01.118807Z",
     "shell.execute_reply": "2021-12-11T19:36:01.118340Z",
     "shell.execute_reply.started": "2021-12-11T19:36:00.955989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f6v9</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>lp4c0</th>\n",
       "      <th>lp4c1</th>\n",
       "      <th>lp5c0</th>\n",
       "      <th>lp5c1</th>\n",
       "      <th>lp6c0</th>\n",
       "      <th>lp6c1</th>\n",
       "      <th>lp7c0</th>\n",
       "      <th>lp7c1</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1437</th>\n",
       "      <th>wb_1438</th>\n",
       "      <th>wb_1439</th>\n",
       "      <th>wb_1440</th>\n",
       "      <th>wb_1441</th>\n",
       "      <th>wb_1442</th>\n",
       "      <th>wb_1443</th>\n",
       "      <th>wb_1444</th>\n",
       "      <th>wb_1445</th>\n",
       "      <th>wb_1446</th>\n",
       "      <th>wb_1447</th>\n",
       "      <th>wb_1448</th>\n",
       "      <th>wb_1449</th>\n",
       "      <th>wb_1450</th>\n",
       "      <th>wb_1451</th>\n",
       "      <th>wb_1452</th>\n",
       "      <th>wb_1453</th>\n",
       "      <th>wb_1454</th>\n",
       "      <th>wb_1455</th>\n",
       "      <th>wb_1456</th>\n",
       "      <th>wb_1457</th>\n",
       "      <th>wb_1458</th>\n",
       "      <th>wb_1459</th>\n",
       "      <th>wb_1460</th>\n",
       "      <th>wb_1461</th>\n",
       "      <th>wb_1462</th>\n",
       "      <th>wb_1463</th>\n",
       "      <th>wb_1464</th>\n",
       "      <th>wb_1465</th>\n",
       "      <th>wb_1466</th>\n",
       "      <th>wb_1467</th>\n",
       "      <th>wb_1468</th>\n",
       "      <th>wb_1469</th>\n",
       "      <th>wb_1470</th>\n",
       "      <th>wb_1471</th>\n",
       "      <th>wb_1472</th>\n",
       "      <th>wb_1473</th>\n",
       "      <th>wb_1474</th>\n",
       "      <th>wb_1475</th>\n",
       "      <th>wb_1476</th>\n",
       "      <th>wb_1477</th>\n",
       "      <th>wb_1478</th>\n",
       "      <th>wb_1479</th>\n",
       "      <th>wb_1480</th>\n",
       "      <th>wb_1481</th>\n",
       "      <th>wb_1482</th>\n",
       "      <th>wb_1483</th>\n",
       "      <th>wb_1484</th>\n",
       "      <th>wb_1485</th>\n",
       "      <th>wb_1486</th>\n",
       "      <th>wb_1487</th>\n",
       "      <th>wb_1488</th>\n",
       "      <th>wb_1489</th>\n",
       "      <th>wb_1490</th>\n",
       "      <th>wb_1491</th>\n",
       "      <th>wb_1492</th>\n",
       "      <th>wb_1493</th>\n",
       "      <th>wb_1494</th>\n",
       "      <th>wb_1495</th>\n",
       "      <th>wb_1496</th>\n",
       "      <th>wb_1497</th>\n",
       "      <th>wb_1498</th>\n",
       "      <th>wb_1499</th>\n",
       "      <th>wb_1500</th>\n",
       "      <th>wb_1501</th>\n",
       "      <th>wb_1502</th>\n",
       "      <th>wb_1503</th>\n",
       "      <th>wb_1504</th>\n",
       "      <th>wb_1505</th>\n",
       "      <th>wb_1506</th>\n",
       "      <th>wb_1507</th>\n",
       "      <th>wb_1508</th>\n",
       "      <th>wb_1509</th>\n",
       "      <th>wb_1510</th>\n",
       "      <th>wb_1511</th>\n",
       "      <th>wb_1512</th>\n",
       "      <th>wb_1513</th>\n",
       "      <th>wb_1514</th>\n",
       "      <th>wb_1515</th>\n",
       "      <th>wb_1516</th>\n",
       "      <th>wb_1517</th>\n",
       "      <th>wb_1518</th>\n",
       "      <th>wb_1519</th>\n",
       "      <th>wb_1520</th>\n",
       "      <th>wb_1521</th>\n",
       "      <th>wb_1522</th>\n",
       "      <th>wb_1523</th>\n",
       "      <th>wb_1524</th>\n",
       "      <th>wb_1525</th>\n",
       "      <th>wb_1526</th>\n",
       "      <th>wb_1527</th>\n",
       "      <th>wb_1528</th>\n",
       "      <th>wb_1529</th>\n",
       "      <th>wb_1530</th>\n",
       "      <th>wb_1531</th>\n",
       "      <th>wb_1532</th>\n",
       "      <th>wb_1533</th>\n",
       "      <th>wb_1534</th>\n",
       "      <th>wb_1535</th>\n",
       "      <th>wb_1536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.391</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>1.596</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>1.621</td>\n",
       "      <td>1.063</td>\n",
       "      <td>1.262</td>\n",
       "      <td>0.943</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>1.439</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.417</td>\n",
       "      <td>1.340</td>\n",
       "      <td>1.241</td>\n",
       "      <td>1.406</td>\n",
       "      <td>-3.520</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-3.313</td>\n",
       "      <td>1.012</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>1.290</td>\n",
       "      <td>0.829</td>\n",
       "      <td>-3.079</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.525</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>1.702</td>\n",
       "      <td>1.076</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>1.483</td>\n",
       "      <td>1.103</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.479</td>\n",
       "      <td>1.433</td>\n",
       "      <td>1.679</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.287</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>2.090</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>2.272</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.990</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>1.098</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.468</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.557</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.085</td>\n",
       "      <td>-0.659</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.742</td>\n",
       "      <td>-1.617</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.232</td>\n",
       "      <td>1.668</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1.419</td>\n",
       "      <td>-3.962</td>\n",
       "      <td>-3.354</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>1.143</td>\n",
       "      <td>-0.536</td>\n",
       "      <td>-3.078</td>\n",
       "      <td>-2.476</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.582</td>\n",
       "      <td>1.622</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>1.670</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>1.207</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-3.366</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.929</td>\n",
       "      <td>-4.932</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.774</td>\n",
       "      <td>1.344</td>\n",
       "      <td>4.432</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1.070</td>\n",
       "      <td>-1.352</td>\n",
       "      <td>3.091</td>\n",
       "      <td>-3.127</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.227</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-3.489</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>1.224</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>1.914</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>4.979</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.963</td>\n",
       "      <td>1.649</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-2.306</td>\n",
       "      <td>1.732</td>\n",
       "      <td>3.435</td>\n",
       "      <td>-1.057</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-1.202</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-1.428</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-4.736</td>\n",
       "      <td>-3.437</td>\n",
       "      <td>-1.649</td>\n",
       "      <td>1.921</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.502</td>\n",
       "      <td>1.632</td>\n",
       "      <td>-1.585</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>1.803</td>\n",
       "      <td>-2.652</td>\n",
       "      <td>-1.668</td>\n",
       "      <td>0.775</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>-2.834</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.873</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-1.424</td>\n",
       "      <td>1.499</td>\n",
       "      <td>-1.234</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>0.687</td>\n",
       "      <td>1.679</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-1.482</td>\n",
       "      <td>1.590</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-1.627</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>1.956</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.264</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>1.439</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>1.357</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-1.192</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>1.408</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.006</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-1.268</td>\n",
       "      <td>1.688</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>0.596</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-1.188</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.658</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>1.958</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.416</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.088</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-1.057</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.541</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.508</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>0.497</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.340</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-3.178</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-1.494</td>\n",
       "      <td>-0.507</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-1.758</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.068</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.144</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.429</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.206</td>\n",
       "      <td>1.832</td>\n",
       "      <td>3.574</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.818</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>1.462</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-4.896</td>\n",
       "      <td>-3.029</td>\n",
       "      <td>5.047</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>3.845</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>0.198</td>\n",
       "      <td>2.393</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-1.642</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.744</td>\n",
       "      <td>2.152</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-1.215</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-1.541</td>\n",
       "      <td>-1.415</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-3.436</td>\n",
       "      <td>-1.738</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-1.349</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>1.866</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-1.429</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.448</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>1.720</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>-2.630</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-2.947</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.095</td>\n",
       "      <td>5.019</td>\n",
       "      <td>-1.077</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-1.272</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.711</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-2.290</td>\n",
       "      <td>2.041</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.927</td>\n",
       "      <td>-1.699</td>\n",
       "      <td>-1.351</td>\n",
       "      <td>2.241</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  f0v9  \\\n",
       "29 29.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38 38.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79 79.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19 19.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27 27.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  f2v0  f2v1  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f3v0  f3v1  f3v2  f3v3  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f3v4  f3v5  f3v6  f3v7  f3v8  f3v9  f4v0  f4v1  f4v2  f4v3  f4v4  f4v5  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f4v6  f4v7  f4v8  f4v9  f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  f5v7  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f5v8  f5v9  f6v0  f6v1  f6v2  f6v3  f6v4  f6v5  f6v6  f6v7  f6v8  f6v9  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      b0    b1    b2    b3    b4    b5    b6  lp0c0  lp0c1  lp1c0  lp1c1  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    lp2c0  lp2c1  lp3c0  lp3c1  lp4c0  lp4c1  lp5c0  lp5c1  lp6c0  lp6c1  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    lp7c0  lp7c1   wb_0   wb_1   wb_2   wb_3   wb_4  ...  wb_1437  wb_1438  \\\n",
       "29  0.000  0.000 -0.017 -0.038  0.036 -0.117 -0.110  ...    0.016   -0.085   \n",
       "38  0.000  0.000  0.242  0.494  0.008  0.119  0.106  ...    1.014   -0.085   \n",
       "79  0.000  0.000 -0.115  0.137 -0.034  0.059  0.127  ...    0.832   -0.085   \n",
       "19  0.000  0.000  0.139  0.264 -0.042 -0.217  0.049  ...    0.541   -0.085   \n",
       "27  0.000  0.000 -0.074  0.179 -0.075 -0.207 -0.040  ...    0.579   -0.085   \n",
       "\n",
       "    wb_1439  wb_1440  wb_1441  wb_1442  wb_1443  wb_1444  wb_1445  wb_1446  \\\n",
       "29    0.322    0.182    0.087   -0.080    0.073   -0.428    0.391   -0.042   \n",
       "38    1.596    0.170    0.629   -0.080    1.621    1.063    1.262    0.943   \n",
       "79    1.207    1.005    0.178   -0.080    0.053   -3.366    0.202    0.929   \n",
       "19    1.439    0.377    0.348   -0.080    1.357   -0.725    0.469    0.471   \n",
       "27    0.241    0.170    0.205   -0.072    0.068    1.690    1.144    0.272   \n",
       "\n",
       "    wb_1447  wb_1448  wb_1449  wb_1450  wb_1451  wb_1452  wb_1453  wb_1454  \\\n",
       "29   -0.453    0.243    0.063    0.132    0.114    0.452    0.106    0.337   \n",
       "38   -0.172    1.439    0.059    0.131    0.417    1.340    1.241    1.406   \n",
       "79   -4.932    0.101    0.897    0.774    1.344    4.432    1.094    1.070   \n",
       "19   -1.192   -0.347    1.408    0.459    0.864    1.006    0.873    0.357   \n",
       "27   -0.165   -1.429    0.963    0.269    0.206    1.832    3.574    0.295   \n",
       "\n",
       "    wb_1455  wb_1456  wb_1457  wb_1458  wb_1459  wb_1460  wb_1461  wb_1462  \\\n",
       "29   -0.433    0.080   -0.420    0.364   -0.133   -0.384   -0.113   -0.225   \n",
       "38   -3.520    0.088   -3.313    1.012   -0.133   -0.150   -0.113   -0.552   \n",
       "79   -1.352    3.091   -3.127    0.101   -0.133   -1.227   -0.113   -3.489   \n",
       "19   -1.268    1.688   -0.673    0.596   -0.133   -0.470   -0.113   -0.570   \n",
       "27   -0.168    0.818   -0.190    1.462   -0.133   -0.482   -0.113    0.114   \n",
       "\n",
       "    wb_1463  wb_1464  wb_1465  wb_1466  wb_1467  wb_1468  wb_1469  wb_1470  \\\n",
       "29    0.328    0.233   -0.123   -0.132    0.427   -0.092    0.153   -0.369   \n",
       "38    1.290    0.829   -3.079   -0.108    0.115   -0.092    1.525   -0.497   \n",
       "79    0.291    0.199   -0.102   -0.157    1.224   -0.076    1.914   -0.681   \n",
       "19    0.534    0.347   -0.123   -1.188    0.124   -0.087    0.658   -0.940   \n",
       "27    0.816    0.132   -4.896   -3.029    5.047   -0.092    3.845   -0.876   \n",
       "\n",
       "    wb_1471  wb_1472  wb_1473  wb_1474  wb_1475  wb_1476  wb_1477  wb_1478  \\\n",
       "29    0.189    0.231   -0.133    0.257    0.246   -0.197   -0.107   -0.268   \n",
       "38    1.702    1.076   -0.129    1.483    1.103   -0.417   -0.107   -0.479   \n",
       "79    4.979    0.496   -0.126    0.963    1.649   -0.129   -0.107   -2.306   \n",
       "19    1.958    0.475   -0.133    0.462    0.416   -0.437   -0.107   -0.671   \n",
       "27    0.198    2.393   -0.133    0.191   -1.642   -0.838   -0.107   -1.744   \n",
       "\n",
       "    wb_1479  wb_1480  wb_1481  wb_1482  wb_1483  wb_1484  wb_1485  wb_1486  \\\n",
       "29    0.114    0.263   -0.306   -0.228   -0.066   -0.019    0.000    0.380   \n",
       "38    1.433    1.679   -0.505   -0.393   -0.017   -0.011    0.000    1.287   \n",
       "79    1.732    3.435   -1.057    0.013   -0.187   -1.202    0.772    0.129   \n",
       "19    1.488    1.088   -0.423   -0.770   -1.057    0.728    0.000    0.541   \n",
       "27    2.152    0.536   -1.215    0.739   -1.541   -1.415    0.000    0.315   \n",
       "\n",
       "    wb_1487  wb_1488  wb_1489  wb_1490  wb_1491  wb_1492  wb_1493  wb_1494  \\\n",
       "29   -0.145   -0.178   -0.315   -0.266    0.072    0.227   -0.020   -0.436   \n",
       "38   -0.145    2.090   -0.490   -0.072    2.272    1.012    1.990   -0.156   \n",
       "79   -0.145   -0.191   -1.428   -0.837    0.739   -4.736   -3.437   -1.649   \n",
       "19   -0.145   -0.503   -0.694   -0.600    0.477    0.508   -0.438   -0.837   \n",
       "27   -0.145    0.754   -3.436   -1.738    0.393   -0.984   -0.265   -1.349   \n",
       "\n",
       "    wb_1495  wb_1496  wb_1497  wb_1498  wb_1499  wb_1500  wb_1501  wb_1502  \\\n",
       "29    0.242    0.060   -0.206    0.223   -0.402   -0.092    0.197    0.299   \n",
       "38    1.098   -0.446    0.999    1.468   -0.379   -0.072    0.557    1.749   \n",
       "79    1.921   -0.101    0.502    1.632   -1.585   -0.061   -0.061    1.803   \n",
       "19    0.497   -0.360   -0.481    0.411   -0.840   -0.074    0.249    0.490   \n",
       "27    0.166   -0.405    1.866    0.255   -0.960   -1.429    0.180    1.448   \n",
       "\n",
       "    wb_1503  wb_1504  wb_1505  wb_1506  wb_1507  wb_1508  wb_1509  wb_1510  \\\n",
       "29    0.005   -0.078    0.320    0.210   -0.058   -0.403   -0.462   -0.088   \n",
       "38    1.085   -0.659    0.938    0.742   -1.617   -0.160   -0.203   -0.587   \n",
       "79   -2.652   -1.668    0.775   -0.062   -0.848   -2.834   -0.197   -0.592   \n",
       "19    0.506    0.194    0.448    0.340   -0.465   -0.616   -0.193   -0.097   \n",
       "27   -1.222    1.720    0.583    0.151   -0.449   -2.630   -0.203   -2.947   \n",
       "\n",
       "    wb_1511  wb_1512  wb_1513  wb_1514  wb_1515  wb_1516  wb_1517  wb_1518  \\\n",
       "29   -0.106    0.320    0.059    0.108    0.081   -0.474   -0.318    0.067   \n",
       "38   -0.106    0.232    1.668    1.300    1.419   -3.962   -3.354    0.067   \n",
       "79   -0.106    0.081    0.433    0.093    1.873   -0.164   -0.050    0.067   \n",
       "19   -0.106    0.460    0.387    0.642    0.084   -0.876   -0.044    0.067   \n",
       "27   -0.106    0.249    0.477    0.095    5.019   -1.077   -0.047    0.067   \n",
       "\n",
       "    wb_1519  wb_1520  wb_1521  wb_1522  wb_1523  wb_1524  wb_1525  wb_1526  \\\n",
       "29   -0.058   -0.006    0.374    0.196   -0.465   -0.365    0.077    0.078   \n",
       "38   -0.587   -0.006    1.143   -0.536   -3.078   -2.476    0.070    0.074   \n",
       "79   -0.139   -1.424    1.499   -1.234   -0.208   -2.628    0.687    1.679   \n",
       "19   -0.673   -0.006    0.422   -0.326   -3.178   -0.502    0.596    0.547   \n",
       "27   -1.272   -0.006    0.711   -0.635   -0.191   -2.290    2.041    0.975   \n",
       "\n",
       "    wb_1527  wb_1528  wb_1529  wb_1530  wb_1531  wb_1532  wb_1533  wb_1534  \\\n",
       "29    0.149    0.221    0.356    0.123   -0.264   -0.151    0.127   -0.237   \n",
       "38    0.144    0.582    1.622   -0.478   -0.596   -0.119    1.670   -0.440   \n",
       "79    0.139   -1.482    1.590   -0.098   -1.627   -0.939    1.956    0.530   \n",
       "19    0.149    0.719    0.125   -0.175   -1.494   -0.507    0.110   -1.758   \n",
       "27    0.144    0.674    0.127    0.927   -1.699   -1.351    2.241   -0.934   \n",
       "\n",
       "    wb_1535  wb_1536  \n",
       "29    0.216   -0.100  \n",
       "38   -0.604    0.117  \n",
       "79    0.036    0.086  \n",
       "19   -0.419   -0.033  \n",
       "27   -0.717    0.116  \n",
       "\n",
       "[5 rows x 1632 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:36:01.119784Z",
     "iopub.status.busy": "2021-12-11T19:36:01.119538Z",
     "iopub.status.idle": "2021-12-11T19:36:01.122133Z",
     "shell.execute_reply": "2021-12-11T19:36:01.121642Z",
     "shell.execute_reply.started": "2021-12-11T19:36:01.119760Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir data/logging/ --port=8811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:36:01.123097Z",
     "iopub.status.busy": "2021-12-11T19:36:01.122925Z",
     "iopub.status.idle": "2021-12-11T19:36:01.125882Z",
     "shell.execute_reply": "2021-12-11T19:36:01.125353Z",
     "shell.execute_reply.started": "2021-12-11T19:36:01.123075Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:36:01.126823Z",
     "iopub.status.busy": "2021-12-11T19:36:01.126653Z",
     "iopub.status.idle": "2021-12-11T20:04:01.134507Z",
     "shell.execute_reply": "2021-12-11T20:04:01.133921Z",
     "shell.execute_reply.started": "2021-12-11T19:36:01.126801Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 24s 832ms/step - loss: 0.6983 - binary_crossentropy_inet_decision_function_fv_metric: 0.7854 - binary_accuracy_inet_decision_function_fv_metric: 0.5378 - val_loss: 0.6693 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7840 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5981\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 9s 513ms/step - loss: 0.6626 - binary_crossentropy_inet_decision_function_fv_metric: 0.7904 - binary_accuracy_inet_decision_function_fv_metric: 0.6140 - val_loss: 0.6597 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.8145 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6178\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 9s 490ms/step - loss: 0.6562 - binary_crossentropy_inet_decision_function_fv_metric: 0.7374 - binary_accuracy_inet_decision_function_fv_metric: 0.6218 - val_loss: 0.6565 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7483 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6192\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 9s 484ms/step - loss: 0.6508 - binary_crossentropy_inet_decision_function_fv_metric: 0.7407 - binary_accuracy_inet_decision_function_fv_metric: 0.6283 - val_loss: 0.6441 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7358 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6429\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 9s 479ms/step - loss: 0.6339 - binary_crossentropy_inet_decision_function_fv_metric: 0.7728 - binary_accuracy_inet_decision_function_fv_metric: 0.6519 - val_loss: 0.6202 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6955 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6669\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 465ms/step - loss: 0.6001 - binary_crossentropy_inet_decision_function_fv_metric: 0.7386 - binary_accuracy_inet_decision_function_fv_metric: 0.6950 - val_loss: 0.5719 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7294 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7319\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 465ms/step - loss: 0.5557 - binary_crossentropy_inet_decision_function_fv_metric: 0.7960 - binary_accuracy_inet_decision_function_fv_metric: 0.7536 - val_loss: 0.5187 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6838 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7968\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 470ms/step - loss: 0.5142 - binary_crossentropy_inet_decision_function_fv_metric: 0.7663 - binary_accuracy_inet_decision_function_fv_metric: 0.8027 - val_loss: 0.4928 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6313 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8273\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 9s 478ms/step - loss: 0.4955 - binary_crossentropy_inet_decision_function_fv_metric: 0.7309 - binary_accuracy_inet_decision_function_fv_metric: 0.8243 - val_loss: 0.4822 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6423 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8403\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 9s 476ms/step - loss: 0.4872 - binary_crossentropy_inet_decision_function_fv_metric: 0.7506 - binary_accuracy_inet_decision_function_fv_metric: 0.8342 - val_loss: 0.4755 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6505 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8487\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 8s 462ms/step - loss: 0.4883 - binary_crossentropy_inet_decision_function_fv_metric: 0.7893 - binary_accuracy_inet_decision_function_fv_metric: 0.8334 - val_loss: 0.4811 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7131 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8421\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 8s 476ms/step - loss: 0.4839 - binary_crossentropy_inet_decision_function_fv_metric: 0.8153 - binary_accuracy_inet_decision_function_fv_metric: 0.8389 - val_loss: 0.4726 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7142 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8519\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 9s 495ms/step - loss: 0.4767 - binary_crossentropy_inet_decision_function_fv_metric: 0.7977 - binary_accuracy_inet_decision_function_fv_metric: 0.8467 - val_loss: 0.4669 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6427 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8589\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.4726 - binary_crossentropy_inet_decision_function_fv_metric: 0.7890 - binary_accuracy_inet_decision_function_fv_metric: 0.8515 - val_loss: 0.4651 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6673 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8609\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 464ms/step - loss: 0.4697 - binary_crossentropy_inet_decision_function_fv_metric: 0.7803 - binary_accuracy_inet_decision_function_fv_metric: 0.8550 - val_loss: 0.4664 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6663 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8591\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 9s 476ms/step - loss: 0.4691 - binary_crossentropy_inet_decision_function_fv_metric: 0.7885 - binary_accuracy_inet_decision_function_fv_metric: 0.8557 - val_loss: 0.4626 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6666 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8640\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 8s 474ms/step - loss: 0.4661 - binary_crossentropy_inet_decision_function_fv_metric: 0.7715 - binary_accuracy_inet_decision_function_fv_metric: 0.8593 - val_loss: 0.4619 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6668 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8645\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 8s 455ms/step - loss: 0.4648 - binary_crossentropy_inet_decision_function_fv_metric: 0.7669 - binary_accuracy_inet_decision_function_fv_metric: 0.8609 - val_loss: 0.4603 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6806 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8665\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 9s 481ms/step - loss: 0.4635 - binary_crossentropy_inet_decision_function_fv_metric: 0.7615 - binary_accuracy_inet_decision_function_fv_metric: 0.8621 - val_loss: 0.4590 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6581 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8677\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 9s 480ms/step - loss: 0.4627 - binary_crossentropy_inet_decision_function_fv_metric: 0.7776 - binary_accuracy_inet_decision_function_fv_metric: 0.8631 - val_loss: 0.4589 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6547 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8681\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 8s 452ms/step - loss: 0.4610 - binary_crossentropy_inet_decision_function_fv_metric: 0.7509 - binary_accuracy_inet_decision_function_fv_metric: 0.8652 - val_loss: 0.4580 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6231 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8692\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 8s 471ms/step - loss: 0.4599 - binary_crossentropy_inet_decision_function_fv_metric: 0.7493 - binary_accuracy_inet_decision_function_fv_metric: 0.8665 - val_loss: 0.4572 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6486 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8703\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 8s 472ms/step - loss: 0.4588 - binary_crossentropy_inet_decision_function_fv_metric: 0.7425 - binary_accuracy_inet_decision_function_fv_metric: 0.8676 - val_loss: 0.4573 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6405 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8700\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 8s 451ms/step - loss: 0.4577 - binary_crossentropy_inet_decision_function_fv_metric: 0.7302 - binary_accuracy_inet_decision_function_fv_metric: 0.8690 - val_loss: 0.4565 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6542 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8710\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4572 - binary_crossentropy_inet_decision_function_fv_metric: 0.7325 - binary_accuracy_inet_decision_function_fv_metric: 0.8695 - val_loss: 0.4558 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6509 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8715\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 8s 425ms/step - loss: 0.4569 - binary_crossentropy_inet_decision_function_fv_metric: 0.7374 - binary_accuracy_inet_decision_function_fv_metric: 0.8700 - val_loss: 0.4561 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6544 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8714\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 8s 451ms/step - loss: 0.4566 - binary_crossentropy_inet_decision_function_fv_metric: 0.7310 - binary_accuracy_inet_decision_function_fv_metric: 0.8701 - val_loss: 0.4573 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6194 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8698\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 8s 466ms/step - loss: 0.4574 - binary_crossentropy_inet_decision_function_fv_metric: 0.7427 - binary_accuracy_inet_decision_function_fv_metric: 0.8694 - val_loss: 0.4562 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6958 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8713\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 8s 463ms/step - loss: 0.4552 - binary_crossentropy_inet_decision_function_fv_metric: 0.7367 - binary_accuracy_inet_decision_function_fv_metric: 0.8720 - val_loss: 0.4539 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6288 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8747\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 8s 452ms/step - loss: 0.4540 - binary_crossentropy_inet_decision_function_fv_metric: 0.7195 - binary_accuracy_inet_decision_function_fv_metric: 0.8733 - val_loss: 0.4542 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6174 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8738\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 8s 470ms/step - loss: 0.4534 - binary_crossentropy_inet_decision_function_fv_metric: 0.7242 - binary_accuracy_inet_decision_function_fv_metric: 0.8741 - val_loss: 0.4545 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6158 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8734\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 9s 484ms/step - loss: 0.4530 - binary_crossentropy_inet_decision_function_fv_metric: 0.7203 - binary_accuracy_inet_decision_function_fv_metric: 0.8745 - val_loss: 0.4539 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6226 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8742\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 8s 454ms/step - loss: 0.4530 - binary_crossentropy_inet_decision_function_fv_metric: 0.7112 - binary_accuracy_inet_decision_function_fv_metric: 0.8744 - val_loss: 0.4541 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6162 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8746\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 8s 473ms/step - loss: 0.4532 - binary_crossentropy_inet_decision_function_fv_metric: 0.7159 - binary_accuracy_inet_decision_function_fv_metric: 0.8740 - val_loss: 0.4546 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6692 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8743\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 9s 476ms/step - loss: 0.4531 - binary_crossentropy_inet_decision_function_fv_metric: 0.7284 - binary_accuracy_inet_decision_function_fv_metric: 0.8743 - val_loss: 0.4544 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6362 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8737\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.4527 - binary_crossentropy_inet_decision_function_fv_metric: 0.7205 - binary_accuracy_inet_decision_function_fv_metric: 0.8748 - val_loss: 0.4546 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6392 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8739\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4520 - binary_crossentropy_inet_decision_function_fv_metric: 0.7222 - binary_accuracy_inet_decision_function_fv_metric: 0.8756 - val_loss: 0.4536 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6438 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8756\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 8s 451ms/step - loss: 0.4514 - binary_crossentropy_inet_decision_function_fv_metric: 0.7128 - binary_accuracy_inet_decision_function_fv_metric: 0.8763 - val_loss: 0.4530 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6236 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8755\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 8s 461ms/step - loss: 0.4508 - binary_crossentropy_inet_decision_function_fv_metric: 0.7244 - binary_accuracy_inet_decision_function_fv_metric: 0.8771 - val_loss: 0.4528 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6105 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8757\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.4501 - binary_crossentropy_inet_decision_function_fv_metric: 0.7049 - binary_accuracy_inet_decision_function_fv_metric: 0.8778 - val_loss: 0.4524 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6382 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8764\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 8s 471ms/step - loss: 0.4496 - binary_crossentropy_inet_decision_function_fv_metric: 0.7115 - binary_accuracy_inet_decision_function_fv_metric: 0.8784 - val_loss: 0.4520 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6299 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8767\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4490 - binary_crossentropy_inet_decision_function_fv_metric: 0.6885 - binary_accuracy_inet_decision_function_fv_metric: 0.8792 - val_loss: 0.4528 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6258 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8759\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4489 - binary_crossentropy_inet_decision_function_fv_metric: 0.6904 - binary_accuracy_inet_decision_function_fv_metric: 0.8793 - val_loss: 0.4511 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6557 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8784\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4481 - binary_crossentropy_inet_decision_function_fv_metric: 0.6856 - binary_accuracy_inet_decision_function_fv_metric: 0.8803 - val_loss: 0.4519 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6180 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8771\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.4481 - binary_crossentropy_inet_decision_function_fv_metric: 0.6956 - binary_accuracy_inet_decision_function_fv_metric: 0.8803 - val_loss: 0.4517 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6638 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8770\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 8s 454ms/step - loss: 0.4476 - binary_crossentropy_inet_decision_function_fv_metric: 0.6820 - binary_accuracy_inet_decision_function_fv_metric: 0.8809 - val_loss: 0.4516 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6329 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8771\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4470 - binary_crossentropy_inet_decision_function_fv_metric: 0.6917 - binary_accuracy_inet_decision_function_fv_metric: 0.8816 - val_loss: 0.4502 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6143 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8789\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 9s 478ms/step - loss: 0.4460 - binary_crossentropy_inet_decision_function_fv_metric: 0.6904 - binary_accuracy_inet_decision_function_fv_metric: 0.8829 - val_loss: 0.4501 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6183 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8787\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 8s 458ms/step - loss: 0.4456 - binary_crossentropy_inet_decision_function_fv_metric: 0.6774 - binary_accuracy_inet_decision_function_fv_metric: 0.8833 - val_loss: 0.4499 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6465 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8798\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 8s 463ms/step - loss: 0.4454 - binary_crossentropy_inet_decision_function_fv_metric: 0.6703 - binary_accuracy_inet_decision_function_fv_metric: 0.8834 - val_loss: 0.4493 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6120 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8797\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 8s 466ms/step - loss: 0.4457 - binary_crossentropy_inet_decision_function_fv_metric: 0.6750 - binary_accuracy_inet_decision_function_fv_metric: 0.8833 - val_loss: 0.4494 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6081 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8802\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 8s 463ms/step - loss: 0.4454 - binary_crossentropy_inet_decision_function_fv_metric: 0.6699 - binary_accuracy_inet_decision_function_fv_metric: 0.8836 - val_loss: 0.4506 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6655 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8778\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.4448 - binary_crossentropy_inet_decision_function_fv_metric: 0.6732 - binary_accuracy_inet_decision_function_fv_metric: 0.8843 - val_loss: 0.4499 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6020 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8788\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 8s 468ms/step - loss: 0.4445 - binary_crossentropy_inet_decision_function_fv_metric: 0.6661 - binary_accuracy_inet_decision_function_fv_metric: 0.8846 - val_loss: 0.4490 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5980 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8799\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 8s 458ms/step - loss: 0.4440 - binary_crossentropy_inet_decision_function_fv_metric: 0.6549 - binary_accuracy_inet_decision_function_fv_metric: 0.8850 - val_loss: 0.4492 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6241 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8795\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4446 - binary_crossentropy_inet_decision_function_fv_metric: 0.6808 - binary_accuracy_inet_decision_function_fv_metric: 0.8846 - val_loss: 0.4492 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6084 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8795\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 8s 459ms/step - loss: 0.4434 - binary_crossentropy_inet_decision_function_fv_metric: 0.6555 - binary_accuracy_inet_decision_function_fv_metric: 0.8860 - val_loss: 0.4482 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5985 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8811\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4433 - binary_crossentropy_inet_decision_function_fv_metric: 0.6548 - binary_accuracy_inet_decision_function_fv_metric: 0.8861 - val_loss: 0.4509 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6296 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8777\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4429 - binary_crossentropy_inet_decision_function_fv_metric: 0.6584 - binary_accuracy_inet_decision_function_fv_metric: 0.8867 - val_loss: 0.4490 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6225 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8798\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.4427 - binary_crossentropy_inet_decision_function_fv_metric: 0.6622 - binary_accuracy_inet_decision_function_fv_metric: 0.8867 - val_loss: 0.4483 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6240 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8812\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4427 - binary_crossentropy_inet_decision_function_fv_metric: 0.6583 - binary_accuracy_inet_decision_function_fv_metric: 0.8867 - val_loss: 0.4486 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6405 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8804\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.4425 - binary_crossentropy_inet_decision_function_fv_metric: 0.6732 - binary_accuracy_inet_decision_function_fv_metric: 0.8871 - val_loss: 0.4482 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6363 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8812\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.4422 - binary_crossentropy_inet_decision_function_fv_metric: 0.6665 - binary_accuracy_inet_decision_function_fv_metric: 0.8875 - val_loss: 0.4494 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6152 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8793\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.4418 - binary_crossentropy_inet_decision_function_fv_metric: 0.6682 - binary_accuracy_inet_decision_function_fv_metric: 0.8876 - val_loss: 0.4486 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6258 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8812\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 8s 462ms/step - loss: 0.4413 - binary_crossentropy_inet_decision_function_fv_metric: 0.6549 - binary_accuracy_inet_decision_function_fv_metric: 0.8885 - val_loss: 0.4476 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6295 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8820\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 8s 454ms/step - loss: 0.4410 - binary_crossentropy_inet_decision_function_fv_metric: 0.6583 - binary_accuracy_inet_decision_function_fv_metric: 0.8890 - val_loss: 0.4480 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6300 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8814\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 8s 455ms/step - loss: 0.4406 - binary_crossentropy_inet_decision_function_fv_metric: 0.6634 - binary_accuracy_inet_decision_function_fv_metric: 0.8894 - val_loss: 0.4485 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6320 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8809\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 8s 459ms/step - loss: 0.4419 - binary_crossentropy_inet_decision_function_fv_metric: 0.6923 - binary_accuracy_inet_decision_function_fv_metric: 0.8879 - val_loss: 0.4489 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8808\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4426 - binary_crossentropy_inet_decision_function_fv_metric: 0.7226 - binary_accuracy_inet_decision_function_fv_metric: 0.8870 - val_loss: 0.4480 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8816\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 8s 455ms/step - loss: 0.4422 - binary_crossentropy_inet_decision_function_fv_metric: 0.7246 - binary_accuracy_inet_decision_function_fv_metric: 0.8876 - val_loss: 0.4483 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6612 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8809\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 8s 459ms/step - loss: 0.4420 - binary_crossentropy_inet_decision_function_fv_metric: 0.7098 - binary_accuracy_inet_decision_function_fv_metric: 0.8877 - val_loss: 0.4489 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6107 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8805\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.4414 - binary_crossentropy_inet_decision_function_fv_metric: 0.6866 - binary_accuracy_inet_decision_function_fv_metric: 0.8884 - val_loss: 0.4493 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6725 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8798\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 8s 463ms/step - loss: 0.4415 - binary_crossentropy_inet_decision_function_fv_metric: 0.6968 - binary_accuracy_inet_decision_function_fv_metric: 0.8883 - val_loss: 0.4478 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6300 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8817\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4414 - binary_crossentropy_inet_decision_function_fv_metric: 0.6996 - binary_accuracy_inet_decision_function_fv_metric: 0.8882 - val_loss: 0.4472 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6426 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8824\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.4402 - binary_crossentropy_inet_decision_function_fv_metric: 0.6873 - binary_accuracy_inet_decision_function_fv_metric: 0.8897 - val_loss: 0.4467 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6317 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8828\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 8s 448ms/step - loss: 0.4398 - binary_crossentropy_inet_decision_function_fv_metric: 0.6803 - binary_accuracy_inet_decision_function_fv_metric: 0.8905 - val_loss: 0.4471 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5947 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8823\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.4396 - binary_crossentropy_inet_decision_function_fv_metric: 0.6913 - binary_accuracy_inet_decision_function_fv_metric: 0.8905 - val_loss: 0.4464 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6107 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8834\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.4389 - binary_crossentropy_inet_decision_function_fv_metric: 0.6753 - binary_accuracy_inet_decision_function_fv_metric: 0.8914 - val_loss: 0.4469 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6331 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8830\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4389 - binary_crossentropy_inet_decision_function_fv_metric: 0.6924 - binary_accuracy_inet_decision_function_fv_metric: 0.8913 - val_loss: 0.4469 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6332 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8827\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.4385 - binary_crossentropy_inet_decision_function_fv_metric: 0.6750 - binary_accuracy_inet_decision_function_fv_metric: 0.8918 - val_loss: 0.4472 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6490 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8829\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.4380 - binary_crossentropy_inet_decision_function_fv_metric: 0.6775 - binary_accuracy_inet_decision_function_fv_metric: 0.8925 - val_loss: 0.4468 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6256 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8826\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 8s 428ms/step - loss: 0.4382 - binary_crossentropy_inet_decision_function_fv_metric: 0.6871 - binary_accuracy_inet_decision_function_fv_metric: 0.8921 - val_loss: 0.4474 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6262 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8819\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4417 - binary_crossentropy_inet_decision_function_fv_metric: 0.7161 - binary_accuracy_inet_decision_function_fv_metric: 0.8885 - val_loss: 0.4459 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5930 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8845\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 8s 426ms/step - loss: 0.4386 - binary_crossentropy_inet_decision_function_fv_metric: 0.6757 - binary_accuracy_inet_decision_function_fv_metric: 0.8919 - val_loss: 0.4468 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6095 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8832\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 8s 429ms/step - loss: 0.4391 - binary_crossentropy_inet_decision_function_fv_metric: 0.6953 - binary_accuracy_inet_decision_function_fv_metric: 0.8913 - val_loss: 0.4465 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6514 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8831\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.4381 - binary_crossentropy_inet_decision_function_fv_metric: 0.6737 - binary_accuracy_inet_decision_function_fv_metric: 0.8924 - val_loss: 0.4484 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6784 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8802\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.4383 - binary_crossentropy_inet_decision_function_fv_metric: 0.6973 - binary_accuracy_inet_decision_function_fv_metric: 0.8921 - val_loss: 0.4462 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6463 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8837\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.4371 - binary_crossentropy_inet_decision_function_fv_metric: 0.6775 - binary_accuracy_inet_decision_function_fv_metric: 0.8938 - val_loss: 0.4460 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6177 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8842\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4374 - binary_crossentropy_inet_decision_function_fv_metric: 0.6885 - binary_accuracy_inet_decision_function_fv_metric: 0.8932 - val_loss: 0.4463 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6313 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8837\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.4492 - binary_crossentropy_inet_decision_function_fv_metric: 1.0506 - binary_accuracy_inet_decision_function_fv_metric: 0.8796 - val_loss: 0.4602 - val_binary_crossentropy_inet_decision_function_fv_metric: 1.3207 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8664\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 8s 464ms/step - loss: 0.4550 - binary_crossentropy_inet_decision_function_fv_metric: 1.3060 - binary_accuracy_inet_decision_function_fv_metric: 0.8721 - val_loss: 0.4600 - val_binary_crossentropy_inet_decision_function_fv_metric: 1.2350 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8662\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4554 - binary_crossentropy_inet_decision_function_fv_metric: 1.2571 - binary_accuracy_inet_decision_function_fv_metric: 0.8721 - val_loss: 0.4565 - val_binary_crossentropy_inet_decision_function_fv_metric: 1.0885 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8703\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4499 - binary_crossentropy_inet_decision_function_fv_metric: 1.1209 - binary_accuracy_inet_decision_function_fv_metric: 0.8785 - val_loss: 0.4557 - val_binary_crossentropy_inet_decision_function_fv_metric: 1.0137 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8713\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.4475 - binary_crossentropy_inet_decision_function_fv_metric: 1.0534 - binary_accuracy_inet_decision_function_fv_metric: 0.8809 - val_loss: 0.4525 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.9731 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8757\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.4459 - binary_crossentropy_inet_decision_function_fv_metric: 1.0172 - binary_accuracy_inet_decision_function_fv_metric: 0.8831 - val_loss: 0.4520 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.8694 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8764\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4453 - binary_crossentropy_inet_decision_function_fv_metric: 0.9687 - binary_accuracy_inet_decision_function_fv_metric: 0.8839 - val_loss: 0.4514 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.8266 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8767\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.4440 - binary_crossentropy_inet_decision_function_fv_metric: 0.9211 - binary_accuracy_inet_decision_function_fv_metric: 0.8851 - val_loss: 0.4500 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.8195 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8784\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4436 - binary_crossentropy_inet_decision_function_fv_metric: 0.9002 - binary_accuracy_inet_decision_function_fv_metric: 0.8857 - val_loss: 0.4495 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7431 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8788\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4423 - binary_crossentropy_inet_decision_function_fv_metric: 0.8792 - binary_accuracy_inet_decision_function_fv_metric: 0.8872 - val_loss: 0.4487 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.8134 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8803\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4412 - binary_crossentropy_inet_decision_function_fv_metric: 0.8415 - binary_accuracy_inet_decision_function_fv_metric: 0.8885 - val_loss: 0.4476 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7378 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8809\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 8s 464ms/step - loss: 0.4398 - binary_crossentropy_inet_decision_function_fv_metric: 0.8123 - binary_accuracy_inet_decision_function_fv_metric: 0.8904 - val_loss: 0.4476 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7596 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8813\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4397 - binary_crossentropy_inet_decision_function_fv_metric: 0.8107 - binary_accuracy_inet_decision_function_fv_metric: 0.8905 - val_loss: 0.4471 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7223 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8818\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.4393 - binary_crossentropy_inet_decision_function_fv_metric: 0.8289 - binary_accuracy_inet_decision_function_fv_metric: 0.8910 - val_loss: 0.4466 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7122 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8826\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4393 - binary_crossentropy_inet_decision_function_fv_metric: 0.7852 - binary_accuracy_inet_decision_function_fv_metric: 0.8908 - val_loss: 0.4471 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7274 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8823\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4385 - binary_crossentropy_inet_decision_function_fv_metric: 0.7854 - binary_accuracy_inet_decision_function_fv_metric: 0.8920 - val_loss: 0.4482 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6937 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8807\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 8s 448ms/step - loss: 0.4379 - binary_crossentropy_inet_decision_function_fv_metric: 0.7527 - binary_accuracy_inet_decision_function_fv_metric: 0.8926 - val_loss: 0.4460 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6818 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8836\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4379 - binary_crossentropy_inet_decision_function_fv_metric: 0.7618 - binary_accuracy_inet_decision_function_fv_metric: 0.8924 - val_loss: 0.4457 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6590 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8841\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.4372 - binary_crossentropy_inet_decision_function_fv_metric: 0.7279 - binary_accuracy_inet_decision_function_fv_metric: 0.8935 - val_loss: 0.4454 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6631 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8842\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4364 - binary_crossentropy_inet_decision_function_fv_metric: 0.7086 - binary_accuracy_inet_decision_function_fv_metric: 0.8944 - val_loss: 0.4458 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6716 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8839\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.4361 - binary_crossentropy_inet_decision_function_fv_metric: 0.7120 - binary_accuracy_inet_decision_function_fv_metric: 0.8948 - val_loss: 0.4458 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6310 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8838\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.4362 - binary_crossentropy_inet_decision_function_fv_metric: 0.7049 - binary_accuracy_inet_decision_function_fv_metric: 0.8947 - val_loss: 0.4456 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6316 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8838\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4365 - binary_crossentropy_inet_decision_function_fv_metric: 0.7129 - binary_accuracy_inet_decision_function_fv_metric: 0.8941 - val_loss: 0.4457 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6340 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8841\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.4358 - binary_crossentropy_inet_decision_function_fv_metric: 0.7090 - binary_accuracy_inet_decision_function_fv_metric: 0.8951 - val_loss: 0.4450 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6356 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8855\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.4355 - binary_crossentropy_inet_decision_function_fv_metric: 0.7003 - binary_accuracy_inet_decision_function_fv_metric: 0.8955 - val_loss: 0.4458 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6635 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8841\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4351 - binary_crossentropy_inet_decision_function_fv_metric: 0.6955 - binary_accuracy_inet_decision_function_fv_metric: 0.8961 - val_loss: 0.4454 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6425 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8841\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 8s 425ms/step - loss: 0.4351 - binary_crossentropy_inet_decision_function_fv_metric: 0.6994 - binary_accuracy_inet_decision_function_fv_metric: 0.8960 - val_loss: 0.4453 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6309 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8843\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4347 - binary_crossentropy_inet_decision_function_fv_metric: 0.6763 - binary_accuracy_inet_decision_function_fv_metric: 0.8965 - val_loss: 0.4446 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6291 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8852\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4345 - binary_crossentropy_inet_decision_function_fv_metric: 0.6915 - binary_accuracy_inet_decision_function_fv_metric: 0.8968 - val_loss: 0.4455 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6725 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8842\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.4344 - binary_crossentropy_inet_decision_function_fv_metric: 0.6914 - binary_accuracy_inet_decision_function_fv_metric: 0.8969 - val_loss: 0.4445 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6235 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8857\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.4346 - binary_crossentropy_inet_decision_function_fv_metric: 0.6821 - binary_accuracy_inet_decision_function_fv_metric: 0.8965 - val_loss: 0.4460 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6533 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8835\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 8s 464ms/step - loss: 0.4346 - binary_crossentropy_inet_decision_function_fv_metric: 0.6856 - binary_accuracy_inet_decision_function_fv_metric: 0.8968 - val_loss: 0.4456 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6515 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8840\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.4344 - binary_crossentropy_inet_decision_function_fv_metric: 0.6951 - binary_accuracy_inet_decision_function_fv_metric: 0.8968 - val_loss: 0.4458 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6504 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8837\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4341 - binary_crossentropy_inet_decision_function_fv_metric: 0.6836 - binary_accuracy_inet_decision_function_fv_metric: 0.8972 - val_loss: 0.4458 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6415 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8839\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 8s 429ms/step - loss: 0.4340 - binary_crossentropy_inet_decision_function_fv_metric: 0.6843 - binary_accuracy_inet_decision_function_fv_metric: 0.8975 - val_loss: 0.4449 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6412 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8853\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4334 - binary_crossentropy_inet_decision_function_fv_metric: 0.6775 - binary_accuracy_inet_decision_function_fv_metric: 0.8981 - val_loss: 0.4442 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6235 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8862\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 8s 432ms/step - loss: 0.4332 - binary_crossentropy_inet_decision_function_fv_metric: 0.6700 - binary_accuracy_inet_decision_function_fv_metric: 0.8984 - val_loss: 0.4443 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6250 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8860\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.4330 - binary_crossentropy_inet_decision_function_fv_metric: 0.6657 - binary_accuracy_inet_decision_function_fv_metric: 0.8986 - val_loss: 0.4449 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6582 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8851\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4334 - binary_crossentropy_inet_decision_function_fv_metric: 0.6951 - binary_accuracy_inet_decision_function_fv_metric: 0.8983 - val_loss: 0.4444 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6380 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8856\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4332 - binary_crossentropy_inet_decision_function_fv_metric: 0.6611 - binary_accuracy_inet_decision_function_fv_metric: 0.8985 - val_loss: 0.4443 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6095 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8862\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4331 - binary_crossentropy_inet_decision_function_fv_metric: 0.6762 - binary_accuracy_inet_decision_function_fv_metric: 0.8986 - val_loss: 0.4436 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6290 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8868\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4327 - binary_crossentropy_inet_decision_function_fv_metric: 0.6732 - binary_accuracy_inet_decision_function_fv_metric: 0.8990 - val_loss: 0.4447 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6412 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8851\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4330 - binary_crossentropy_inet_decision_function_fv_metric: 0.6650 - binary_accuracy_inet_decision_function_fv_metric: 0.8989 - val_loss: 0.4450 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6244 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8848\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.4329 - binary_crossentropy_inet_decision_function_fv_metric: 0.6706 - binary_accuracy_inet_decision_function_fv_metric: 0.8988 - val_loss: 0.4448 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6260 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8856\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4331 - binary_crossentropy_inet_decision_function_fv_metric: 0.6748 - binary_accuracy_inet_decision_function_fv_metric: 0.8985 - val_loss: 0.4446 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6351 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8855\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.4327 - binary_crossentropy_inet_decision_function_fv_metric: 0.6636 - binary_accuracy_inet_decision_function_fv_metric: 0.8989 - val_loss: 0.4437 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6190 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8871\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.4327 - binary_crossentropy_inet_decision_function_fv_metric: 0.6767 - binary_accuracy_inet_decision_function_fv_metric: 0.8990 - val_loss: 0.4442 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6235 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8863\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4323 - binary_crossentropy_inet_decision_function_fv_metric: 0.6801 - binary_accuracy_inet_decision_function_fv_metric: 0.8996 - val_loss: 0.4438 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6248 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8866\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4322 - binary_crossentropy_inet_decision_function_fv_metric: 0.6683 - binary_accuracy_inet_decision_function_fv_metric: 0.8995 - val_loss: 0.4438 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6375 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8866\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.4321 - binary_crossentropy_inet_decision_function_fv_metric: 0.6569 - binary_accuracy_inet_decision_function_fv_metric: 0.8997 - val_loss: 0.4440 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6191 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8865\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.4320 - binary_crossentropy_inet_decision_function_fv_metric: 0.6707 - binary_accuracy_inet_decision_function_fv_metric: 0.9001 - val_loss: 0.4443 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6214 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8860\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 8s 432ms/step - loss: 0.4318 - binary_crossentropy_inet_decision_function_fv_metric: 0.6594 - binary_accuracy_inet_decision_function_fv_metric: 0.9003 - val_loss: 0.4445 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6112 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8854\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.4317 - binary_crossentropy_inet_decision_function_fv_metric: 0.6673 - binary_accuracy_inet_decision_function_fv_metric: 0.9003 - val_loss: 0.4440 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6244 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8862\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 8s 455ms/step - loss: 0.4320 - binary_crossentropy_inet_decision_function_fv_metric: 0.6633 - binary_accuracy_inet_decision_function_fv_metric: 0.9000 - val_loss: 0.4442 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6469 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8862\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.4317 - binary_crossentropy_inet_decision_function_fv_metric: 0.6705 - binary_accuracy_inet_decision_function_fv_metric: 0.9003 - val_loss: 0.4451 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6350 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8845\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4313 - binary_crossentropy_inet_decision_function_fv_metric: 0.6669 - binary_accuracy_inet_decision_function_fv_metric: 0.9009 - val_loss: 0.4443 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6428 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8855\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.4312 - binary_crossentropy_inet_decision_function_fv_metric: 0.6564 - binary_accuracy_inet_decision_function_fv_metric: 0.9010 - val_loss: 0.4440 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6200 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8862\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.4307 - binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - binary_accuracy_inet_decision_function_fv_metric: 0.9014 - val_loss: 0.4437 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6377 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8871\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4307 - binary_crossentropy_inet_decision_function_fv_metric: 0.6596 - binary_accuracy_inet_decision_function_fv_metric: 0.9015 - val_loss: 0.4434 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5983 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8871\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.4307 - binary_crossentropy_inet_decision_function_fv_metric: 0.6578 - binary_accuracy_inet_decision_function_fv_metric: 0.9016 - val_loss: 0.4442 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6109 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8862\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.4312 - binary_crossentropy_inet_decision_function_fv_metric: 0.6515 - binary_accuracy_inet_decision_function_fv_metric: 0.9007 - val_loss: 0.4437 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6178 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8872\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.4310 - binary_crossentropy_inet_decision_function_fv_metric: 0.6559 - binary_accuracy_inet_decision_function_fv_metric: 0.9010 - val_loss: 0.4441 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6132 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8861\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4310 - binary_crossentropy_inet_decision_function_fv_metric: 0.6745 - binary_accuracy_inet_decision_function_fv_metric: 0.9011 - val_loss: 0.4441 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6525 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8865\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.4310 - binary_crossentropy_inet_decision_function_fv_metric: 0.6609 - binary_accuracy_inet_decision_function_fv_metric: 0.9013 - val_loss: 0.4427 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6242 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8880\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.4303 - binary_crossentropy_inet_decision_function_fv_metric: 0.6511 - binary_accuracy_inet_decision_function_fv_metric: 0.9021 - val_loss: 0.4433 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6259 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8876\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4304 - binary_crossentropy_inet_decision_function_fv_metric: 0.6662 - binary_accuracy_inet_decision_function_fv_metric: 0.9020 - val_loss: 0.4426 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6214 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8885\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4299 - binary_crossentropy_inet_decision_function_fv_metric: 0.6452 - binary_accuracy_inet_decision_function_fv_metric: 0.9024 - val_loss: 0.4426 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5965 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8884\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.4300 - binary_crossentropy_inet_decision_function_fv_metric: 0.6504 - binary_accuracy_inet_decision_function_fv_metric: 0.9024 - val_loss: 0.4433 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5974 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8876\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.4301 - binary_crossentropy_inet_decision_function_fv_metric: 0.6595 - binary_accuracy_inet_decision_function_fv_metric: 0.9022 - val_loss: 0.4434 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6115 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8872\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4299 - binary_crossentropy_inet_decision_function_fv_metric: 0.6594 - binary_accuracy_inet_decision_function_fv_metric: 0.9026 - val_loss: 0.4438 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6054 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8864\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 8s 454ms/step - loss: 0.4301 - binary_crossentropy_inet_decision_function_fv_metric: 0.6427 - binary_accuracy_inet_decision_function_fv_metric: 0.9021 - val_loss: 0.4438 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6237 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8863\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.4298 - binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - binary_accuracy_inet_decision_function_fv_metric: 0.9026 - val_loss: 0.4437 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6162 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8867\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 8s 462ms/step - loss: 0.4301 - binary_crossentropy_inet_decision_function_fv_metric: 0.6648 - binary_accuracy_inet_decision_function_fv_metric: 0.9022 - val_loss: 0.4434 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6164 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8867\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.4298 - binary_crossentropy_inet_decision_function_fv_metric: 0.6557 - binary_accuracy_inet_decision_function_fv_metric: 0.9028 - val_loss: 0.4437 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6305 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8867\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.4295 - binary_crossentropy_inet_decision_function_fv_metric: 0.6630 - binary_accuracy_inet_decision_function_fv_metric: 0.9028 - val_loss: 0.4434 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6445 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8870\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4296 - binary_crossentropy_inet_decision_function_fv_metric: 0.6383 - binary_accuracy_inet_decision_function_fv_metric: 0.9031 - val_loss: 0.4430 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6184 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8877\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 8s 457ms/step - loss: 0.4298 - binary_crossentropy_inet_decision_function_fv_metric: 0.6728 - binary_accuracy_inet_decision_function_fv_metric: 0.9026 - val_loss: 0.4430 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6230 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8876\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 8s 428ms/step - loss: 0.4293 - binary_crossentropy_inet_decision_function_fv_metric: 0.6401 - binary_accuracy_inet_decision_function_fv_metric: 0.9034 - val_loss: 0.4430 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6320 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8874\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4292 - binary_crossentropy_inet_decision_function_fv_metric: 0.6463 - binary_accuracy_inet_decision_function_fv_metric: 0.9035 - val_loss: 0.4433 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6255 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8875\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.4293 - binary_crossentropy_inet_decision_function_fv_metric: 0.6489 - binary_accuracy_inet_decision_function_fv_metric: 0.9032 - val_loss: 0.4436 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6555 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8870\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 8s 432ms/step - loss: 0.4295 - binary_crossentropy_inet_decision_function_fv_metric: 0.6629 - binary_accuracy_inet_decision_function_fv_metric: 0.9030 - val_loss: 0.4431 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6473 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8871\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4291 - binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - binary_accuracy_inet_decision_function_fv_metric: 0.9038 - val_loss: 0.4425 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6316 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8884\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4288 - binary_crossentropy_inet_decision_function_fv_metric: 0.6502 - binary_accuracy_inet_decision_function_fv_metric: 0.9038 - val_loss: 0.4423 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6096 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8881\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4289 - binary_crossentropy_inet_decision_function_fv_metric: 0.6525 - binary_accuracy_inet_decision_function_fv_metric: 0.9038 - val_loss: 0.4424 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6153 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8886\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4291 - binary_crossentropy_inet_decision_function_fv_metric: 0.6485 - binary_accuracy_inet_decision_function_fv_metric: 0.9035 - val_loss: 0.4423 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6262 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8887\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4287 - binary_crossentropy_inet_decision_function_fv_metric: 0.6487 - binary_accuracy_inet_decision_function_fv_metric: 0.9040 - val_loss: 0.4424 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6172 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8885\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 8s 426ms/step - loss: 0.4288 - binary_crossentropy_inet_decision_function_fv_metric: 0.6462 - binary_accuracy_inet_decision_function_fv_metric: 0.9038 - val_loss: 0.4432 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6403 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8876\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.4288 - binary_crossentropy_inet_decision_function_fv_metric: 0.6544 - binary_accuracy_inet_decision_function_fv_metric: 0.9040 - val_loss: 0.4437 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6498 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8861\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.4286 - binary_crossentropy_inet_decision_function_fv_metric: 0.6506 - binary_accuracy_inet_decision_function_fv_metric: 0.9042 - val_loss: 0.4436 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6326 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8866\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.4285 - binary_crossentropy_inet_decision_function_fv_metric: 0.6429 - binary_accuracy_inet_decision_function_fv_metric: 0.9043 - val_loss: 0.4425 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6119 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8881\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.4282 - binary_crossentropy_inet_decision_function_fv_metric: 0.6385 - binary_accuracy_inet_decision_function_fv_metric: 0.9045 - val_loss: 0.4430 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6124 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8877\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.4284 - binary_crossentropy_inet_decision_function_fv_metric: 0.6446 - binary_accuracy_inet_decision_function_fv_metric: 0.9045 - val_loss: 0.4429 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6383 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8881\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 6s 352ms/step - loss: 0.4288 - binary_crossentropy_inet_decision_function_fv_metric: 0.6573 - binary_accuracy_inet_decision_function_fv_metric: 0.9040 - val_loss: 0.4419 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6023 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8889\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.4286 - binary_crossentropy_inet_decision_function_fv_metric: 0.6477 - binary_accuracy_inet_decision_function_fv_metric: 0.9042 - val_loss: 0.4429 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.5993 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8879\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.4284 - binary_crossentropy_inet_decision_function_fv_metric: 0.6410 - binary_accuracy_inet_decision_function_fv_metric: 0.9045 - val_loss: 0.4428 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6034 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8873\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.4284 - binary_crossentropy_inet_decision_function_fv_metric: 0.6484 - binary_accuracy_inet_decision_function_fv_metric: 0.9044 - val_loss: 0.4431 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6317 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8876\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.4281 - binary_crossentropy_inet_decision_function_fv_metric: 0.6430 - binary_accuracy_inet_decision_function_fv_metric: 0.9046 - val_loss: 0.4435 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6140 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8869\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 6s 353ms/step - loss: 0.4287 - binary_crossentropy_inet_decision_function_fv_metric: 0.6476 - binary_accuracy_inet_decision_function_fv_metric: 0.9040 - val_loss: 0.4435 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6247 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8868\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.4280 - binary_crossentropy_inet_decision_function_fv_metric: 0.6374 - binary_accuracy_inet_decision_function_fv_metric: 0.9048 - val_loss: 0.4433 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6016 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8878\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.4280 - binary_crossentropy_inet_decision_function_fv_metric: 0.6462 - binary_accuracy_inet_decision_function_fv_metric: 0.9047 - val_loss: 0.4426 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6062 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8885\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.4281 - binary_crossentropy_inet_decision_function_fv_metric: 0.6466 - binary_accuracy_inet_decision_function_fv_metric: 0.9047 - val_loss: 0.4427 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6156 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8889\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 6s 355ms/step - loss: 0.4288 - binary_crossentropy_inet_decision_function_fv_metric: 0.6766 - binary_accuracy_inet_decision_function_fv_metric: 0.9040 - val_loss: 0.4464 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.7362 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8838\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.4289 - binary_crossentropy_inet_decision_function_fv_metric: 0.6634 - binary_accuracy_inet_decision_function_fv_metric: 0.9038 - val_loss: 0.4432 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6251 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8879\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.4282 - binary_crossentropy_inet_decision_function_fv_metric: 0.6561 - binary_accuracy_inet_decision_function_fv_metric: 0.9047 - val_loss: 0.4433 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6163 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8872\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.4279 - binary_crossentropy_inet_decision_function_fv_metric: 0.6476 - binary_accuracy_inet_decision_function_fv_metric: 0.9051 - val_loss: 0.4431 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6213 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8875\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.4276 - binary_crossentropy_inet_decision_function_fv_metric: 0.6463 - binary_accuracy_inet_decision_function_fv_metric: 0.9054 - val_loss: 0.4424 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6198 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8886\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.4275 - binary_crossentropy_inet_decision_function_fv_metric: 0.6426 - binary_accuracy_inet_decision_function_fv_metric: 0.9056 - val_loss: 0.4420 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6159 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8889\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.4275 - binary_crossentropy_inet_decision_function_fv_metric: 0.6402 - binary_accuracy_inet_decision_function_fv_metric: 0.9056 - val_loss: 0.4426 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6300 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8886\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.4275 - binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - binary_accuracy_inet_decision_function_fv_metric: 0.9056 - val_loss: 0.4430 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6195 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8876\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.4273 - binary_crossentropy_inet_decision_function_fv_metric: 0.6316 - binary_accuracy_inet_decision_function_fv_metric: 0.9059 - val_loss: 0.4425 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6124 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8884\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 6s 355ms/step - loss: 0.4271 - binary_crossentropy_inet_decision_function_fv_metric: 0.6434 - binary_accuracy_inet_decision_function_fv_metric: 0.9059 - val_loss: 0.4432 - val_binary_crossentropy_inet_decision_function_fv_metric: 0.6284 - val_binary_accuracy_inet_decision_function_fv_metric: 0.8877\n",
      "Training Time: 0:27:59\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      callback_names=['tensorboard'] #plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T20:04:01.136157Z",
     "iopub.status.busy": "2021-12-11T20:04:01.135845Z",
     "iopub.status.idle": "2021-12-11T20:04:01.397803Z",
     "shell.execute_reply": "2021-12-11T20:04:01.396958Z",
     "shell.execute_reply.started": "2021-12-11T20:04:01.136121Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T20:04:01.399201Z",
     "iopub.status.busy": "2021-12-11T20:04:01.398894Z",
     "iopub.status.idle": "2021-12-11T20:04:02.541170Z",
     "shell.execute_reply": "2021-12-11T20:04:02.540036Z",
     "shell.execute_reply.started": "2021-12-11T20:04:01.399176Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 3\n",
    "network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "if (config['i_net']['convolution_layers'] != None or config['i_net']['lstm_layers'] != None or (config['i_net']['nas'] and config['i_net']['nas_type'] != 'SEQUENTIAL')) and config['i_net']['data_reshape_version'] is not None:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T20:04:02.543413Z",
     "iopub.status.busy": "2021-12-11T20:04:02.542990Z",
     "iopub.status.idle": "2021-12-11T20:04:02.555560Z",
     "shell.execute_reply": "2021-12-11T20:04:02.554866Z",
     "shell.execute_reply.started": "2021-12-11T20:04:02.543365Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1537)]            0         \n",
      "_________________________________________________________________\n",
      "hidden1_2048 (Dense)         (None, 2048)              3149824   \n",
      "_________________________________________________________________\n",
      "activation1_relu (Activation (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout1_0.2 (Dropout)       (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "hidden2_1024 (Dense)         (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "activation2_relu (Activation (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout2_0.2 (Dropout)       (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "output_93 (Dense)            (None, 93)                95325     \n",
      "=================================================================\n",
      "Total params: 5,343,325\n",
      "Trainable params: 5,343,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T20:04:02.556984Z",
     "iopub.status.busy": "2021-12-11T20:04:02.556688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "WARNING:tensorflow:From /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=10)]: Done  41 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=10)]: Done  52 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=10)]: Done  65 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=10)]: Done  78 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=10)]: Done  93 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=10)]: Done 108 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=10)]: Done 125 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=10)]: Done 142 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=10)]: Done 161 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=10)]: Done 201 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=10)]: Done 222 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=10)]: Done 245 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=10)]: Done 268 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=10)]: Done 293 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=10)]: Done 318 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=10)]: Done 345 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=10)]: Done 372 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=10)]: Done 401 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=10)]: Done 461 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=10)]: Done 492 tasks      | elapsed: 42.8min\n",
      "[Parallel(n_jobs=10)]: Done 525 tasks      | elapsed: 45.1min\n",
      "[Parallel(n_jobs=10)]: Done 558 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=10)]: Done 593 tasks      | elapsed: 49.7min\n",
      "[Parallel(n_jobs=10)]: Done 628 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=10)]: Done 665 tasks      | elapsed: 54.6min\n",
      "[Parallel(n_jobs=10)]: Done 702 tasks      | elapsed: 57.0min\n",
      "[Parallel(n_jobs=10)]: Done 741 tasks      | elapsed: 59.7min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 62.3min\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = lambda_net_dataset_train.X_test_lambda_array.shape[0]#10\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_train.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "    \n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=10, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_train.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_train.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('TRAIN DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_valid.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_valid.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_valid.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_valid.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('VALID DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = lambda_net_dataset_test.X_test_lambda_array.shape[0]#10\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_test.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_test.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_test.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('TEST DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file: \n",
    "        if different_eval_data:\n",
    "            flat_config = flatten_dict(config_train)\n",
    "        else:\n",
    "            flat_config = flatten_dict(config)\n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key)\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_binary_crossentropy_' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_accuracy' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_f1_score' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_runtime_' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_binary_crossentropy_' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_accuracy' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_score' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_runtime_' + str(i))\n",
    "            text_file.write(';')      \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file: \n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['dt_scores']['binary_crossentropy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['dt_scores']['accuracy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['dt_scores']['f1_score']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['dt_scores']['runtime']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['inet_scores']['binary_crossentropy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['inet_scores']['accuracy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['inet_scores']['f1_score']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['inet_scores']['runtime']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATA EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "\n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 #\"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 #\"Marital Status\", #5\n",
    "                 #\"Occupation\",  #6\n",
    "                 #\"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 'capital_gain'\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = ['Sex', 'Race', 'Workclass', 'capital_gain']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(adult_data)\n",
    "\n",
    "adult_data = transformer.transform(adult_data)\n",
    "adult_data = pd.DataFrame(adult_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    adult_data[ordinal_feature] = OrdinalEncoder().fit_transform(adult_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "adult_data = adult_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "y_data_adult = adult_data['capital_gain']\n",
    "#le = LabelEncoder()\n",
    "#le.fit(y_data_adult)\n",
    "#y_data_adult = le.transform(y_data_adult)\n",
    "#class_names = le.classes_\n",
    "\n",
    "\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data['capital_gain'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_adult.shape[1] > number_of_variables:\n",
    "    X_data_adult = X_data_adult.sample(n=number_of_variables,axis='columns')\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_adult.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_adult[column_name] = np.zeros(X_data_adult.shape[0])\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_adult:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_adult[column_name].values.reshape(-1, 1))\n",
    "    X_data_adult[column_name] = scaler.transform(X_data_adult[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_adult_with_valid, X_test_adult, y_train_adult_with_valid, y_test_adult = train_test_split(X_data_adult, y_data_adult, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_adult, X_valid_adult, y_train_adult, y_valid_adult = train_test_split(X_train_adult_with_valid, y_train_adult_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_adult.shape, y_train_adult.shape)\n",
    "print(X_valid_adult.shape, y_valid_adult.shape)\n",
    "print(X_test_adult.shape, y_test_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_adult, y_train_adult = oversample.fit_resample(X_train_adult, y_train_adult)\n",
    "\n",
    "    true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "    false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_adult = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_adult.fit(X_train_adult,\n",
    "                                      y_train_adult, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_adult, y_valid_adult),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.get_weights()[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult_parameters = shaped_network_parameters_to_array(test_network_adult.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_adult_dt_inet = model.predict(np.array([test_network_adult_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_adult = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_adult = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "    \n",
    "results_adult_list = []\n",
    "dt_distilled_adult_list = []\n",
    "for dataset_size in dataset_size_list_adult:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_adult.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_adult['inet_scores']['runtime'] = inet_runtime\n",
    "    results_adult_list.append(results_adult)\n",
    "    dt_distilled_adult_list.append(dt_distilled_adult)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy',  np.round(results_adult['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_adult['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy',  np.round(results_adult['dt_scores']['binary_crossentropy'], 3), np.round(results_adult['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_adult['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy',  np.round(results_adult['dt_scores']['accuracy'], 3), np.round(results_adult['dt_scores']['accuracy_data_random'], 3), np.round(results_adult['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score',  np.round(results_adult['dt_scores']['f1_score'], 3), np.round(results_adult['dt_scores']['f1_score_data_random'], 3), np.round(results_adult['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n",
    "        \n",
    "adult_evaluation_result_dict = None\n",
    "for some_dict in results_adult_list:\n",
    "    if adult_evaluation_result_dict == None:\n",
    "        adult_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        adult_evaluation_result_dict = mergeDict(adult_evaluation_result_dict, some_dict)\n",
    "\n",
    "adult_evaluation_result_dict['dataset_size'] = dataset_size_list_adult\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_adult_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_adult_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_adult, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_adult.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.drop([\n",
    "                                    'Cabin', \n",
    "                                    'Ticket', \n",
    "                                    'Name', \n",
    "                                    'PassengerId'\n",
    "                                ], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "#titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "categorical_features = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features = ['Sex']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(titanic_data)\n",
    "\n",
    "titanic_data = transformer.transform(titanic_data)\n",
    "titanic_data = pd.DataFrame(titanic_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    titanic_data[ordinal_feature] = OrdinalEncoder().fit_transform(titanic_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "titanic_data = titanic_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_titanic.shape[1] > number_of_variables:\n",
    "    X_data_titanic = X_data_titanic.sample(n=number_of_variables,axis='columns')\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_titanic.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_titanic[column_name] = np.zeros(X_data_titanic.shape[0])\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_titanic:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_titanic[column_name].values.reshape(-1, 1))\n",
    "    X_data_titanic[column_name] = scaler.transform(X_data_titanic[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_titanic_with_valid, X_test_titanic, y_train_titanic_with_valid, y_test_titanic = train_test_split(X_data_titanic, y_data_titanic, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_titanic, X_valid_titanic, y_train_titanic, y_valid_titanic = train_test_split(X_train_titanic_with_valid, y_train_titanic_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_titanic.shape, y_train_titanic.shape)\n",
    "print(X_valid_titanic.shape, y_valid_titanic.shape)\n",
    "print(X_test_titanic.shape, y_test_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_titanic, y_train_titanic = oversample.fit_resample(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "    false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_titanic = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_titanic.fit(X_train_titanic,\n",
    "                                          y_train_titanic, \n",
    "                                          epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                          batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                          callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                          validation_data=(X_valid_titanic, y_valid_titanic),\n",
    "                                          verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic_parameters = shaped_network_parameters_to_array(test_network_titanic.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_titanic_dt_inet = model.predict(np.array([test_network_titanic_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.get_weights()[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_titanic = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_titanic = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "    \n",
    "results_titanic_list = []\n",
    "dt_distilled_titanic_list = []\n",
    "for dataset_size in dataset_size_list_titanic:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_titanic.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_titanic['inet_scores']['runtime'] = inet_runtime\n",
    "    results_titanic_list.append(results_titanic)\n",
    "    dt_distilled_titanic_list.append(dt_distilled_titanic)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy',  np.round(results_titanic['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_titanic['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy',  np.round(results_titanic['dt_scores']['binary_crossentropy'], 3), np.round(results_titanic['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy',  np.round(results_titanic['dt_scores']['accuracy'], 3), np.round(results_titanic['dt_scores']['accuracy_data_random'], 3), np.round(results_titanic['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score',  np.round(results_titanic['dt_scores']['f1_score'], 3), np.round(results_titanic['dt_scores']['f1_score_data_random'], 3), np.round(results_titanic['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "titanic_evaluation_result_dict = None\n",
    "for some_dict in results_titanic_list:\n",
    "    if titanic_evaluation_result_dict == None:\n",
    "        titanic_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        titanic_evaluation_result_dict = mergeDict(titanic_evaluation_result_dict, some_dict)\n",
    "\n",
    "titanic_evaluation_result_dict['dataset_size'] = dataset_size_list_titanic\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_data_titanic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_titanic_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_titanic_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_titanic, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_titanic.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "absenteeism_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           #'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           #'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           #'Weight', \n",
    "                           #'Height', \n",
    "                           #'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = []\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(absenteeism_data)\n",
    "\n",
    "absenteeism_data = transformer.transform(absenteeism_data)\n",
    "absenteeism_data = pd.DataFrame(absenteeism_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    absenteeism_data[ordinal_feature] = OrdinalEncoder().fit_transform(absenteeism_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "absenteeism_data = absenteeism_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n",
    "\n",
    "print(X_data_absenteeism.shape)\n",
    "\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_absenteeism.shape[1] > number_of_variables:\n",
    "    X_data_absenteeism = X_data_absenteeism.sample(n=number_of_variables,axis='columns')\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_absenteeism.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_absenteeism[column_name] = np.zeros(X_data_absenteeism.shape[0])\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_absenteeism:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_absenteeism[column_name].values.reshape(-1, 1))\n",
    "    X_data_absenteeism[column_name] = scaler.transform(X_data_absenteeism[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_absenteeism_with_valid, X_test_absenteeism, y_train_absenteeism_with_valid, y_test_absenteeism = train_test_split(X_data_absenteeism, y_data_absenteeism, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_absenteeism, X_valid_absenteeism, y_train_absenteeism, y_valid_absenteeism = train_test_split(X_train_absenteeism_with_valid, y_train_absenteeism_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_absenteeism.shape, y_train_absenteeism.shape)\n",
    "print(X_valid_absenteeism.shape, y_valid_absenteeism.shape)\n",
    "print(X_test_absenteeism.shape, y_test_absenteeism.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_absenteeism, y_train_absenteeism = oversample.fit_resample(X_train_absenteeism, y_train_absenteeism)\n",
    "\n",
    "    true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "    false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_absenteeism = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_absenteeism.fit(X_train_absenteeism,\n",
    "                                      y_train_absenteeism, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_absenteeism, y_valid_absenteeism),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.get_weights()[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism_parameters = shaped_network_parameters_to_array(test_network_absenteeism.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_absenteeism_dt_inet = model.predict(np.array([test_network_absenteeism_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_absenteeism = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_absenteeism = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "\n",
    "results_absenteeism_list = []\n",
    "dt_distilled_absenteeism_list = []\n",
    "for dataset_size in dataset_size_list_absenteeism:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_absenteeism.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_absenteeism['inet_scores']['runtime'] = inet_runtime\n",
    "    results_absenteeism_list.append(results_absenteeism)\n",
    "    dt_distilled_absenteeism_list.append(dt_distilled_absenteeism)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy',  np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_absenteeism['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy',  np.round(results_absenteeism['dt_scores']['binary_crossentropy'], 3), np.round(results_absenteeism['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_absenteeism['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy',  np.round(results_absenteeism['dt_scores']['accuracy'], 3), np.round(results_absenteeism['dt_scores']['accuracy_data_random'], 3), np.round(results_absenteeism['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score',  np.round(results_absenteeism['dt_scores']['f1_score'], 3), np.round(results_absenteeism['dt_scores']['f1_score_data_random'], 3), np.round(results_absenteeism['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "absenteeism_evaluation_result_dict = None\n",
    "for some_dict in results_absenteeism_list:\n",
    "    if absenteeism_evaluation_result_dict == None:\n",
    "        absenteeism_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        absenteeism_evaluation_result_dict = mergeDict(absenteeism_evaluation_result_dict, some_dict)\n",
    "\n",
    "absenteeism_evaluation_result_dict['dataset_size'] = dataset_size_list_absenteeism\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_absenteeism_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_absenteeism_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_absenteeism, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_absenteeism.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "        if different_eval_data:\n",
    "            flat_config = flatten_dict(config_train)\n",
    "        else:\n",
    "            flat_config = flatten_dict(config)\n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key + ';')\n",
    "            \n",
    "        text_file.write('dt_scores_binary_crossentropy_artificial_mean' + ';')\n",
    "        text_file.write('dt_scores_accuracy_artificial_mean' + ';')\n",
    "        text_file.write('dt_f1_score_artificial_mean' + ';')\n",
    "        text_file.write('dt_scores_runtime_artificial_mean' + ';')\n",
    "        text_file.write('inet_binary_crossentropy_artificial_mean' + ';')\n",
    "        text_file.write('inet_accuracy_artificial_mean' + ';')\n",
    "        text_file.write('inet_score_artificial_mean' + ';')\n",
    "        text_file.write('inet_runtime_artificial_mean' + ';')\n",
    "        \n",
    "        \n",
    "        for dataset_size in dataset_size_list_adult:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_adult_' + str(dataset_size) + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list_titanic:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_titanic_' + str(dataset_size) + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list_adult:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_absenteeism_' + str(dataset_size) + ';')        \n",
    "    \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['runtime']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['runtime']) + ';')\n",
    "    \n",
    "    \n",
    "    for i in range(len(dataset_size_list_adult)):\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "    \n",
    "    for i in range(len(dataset_size_list_titanic)):\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "    \n",
    "    for i in range(len(dataset_size_list_absenteeism)):\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "        \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import gc\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "test_network = generate_lambda_net_from_config(config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network = generate_lambda_net_from_config(config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
