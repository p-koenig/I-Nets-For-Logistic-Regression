{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7413b1-5b9f-472e-9045-ee14068be971",
   "metadata": {},
   "source": [
    "# Config & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d269d23f-33f7-456b-b4fc-a457414ed778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 19:09:25.925317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 19:09:25.925360: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import utilities_LR\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ef29c7-245e-4770-b29d-0045b6b0b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data': {\n",
    "        'n_datasets': 45_000, # the number of datasets\n",
    "        \n",
    "        'n_samples': 5_000, # the number of samples per dataset\n",
    "        \n",
    "        'n_features': 20, \n",
    "        # The total number of features. \n",
    "        # These comprise n_informative informative features, n_redundant redundant features, n_repeated duplicated features and \n",
    "        # n_features-n_informative-n_redundant-n_repeated useless features drawn at random.\n",
    "        \n",
    "        #'n_informative': random.randint(2, 10),\n",
    "        'n_informative': 'random',\n",
    "        # The number of informative features. Each class is composed of a number of gaussian clusters each located around the vertices \n",
    "        # of a hypercube in a subspace of dimension n_informative. For each cluster, informative features are drawn independently \n",
    "        # from N(0, 1) and then randomly linearly combined within each cluster in order to add covariance. The clusters are then \n",
    "        # placed on the vertices of the hypercube.\n",
    "        ### int or 'random'\n",
    "        \n",
    "        'n_targets': 1,\n",
    "        # The number of targets (or labels) of the classification problem.\n",
    "    \n",
    "        'n_clusters_per_class': 1,\n",
    "        # The number of clusters per class.\n",
    "        \n",
    "        'class_sep': 1.0,\n",
    "        # class_sepfloat, default=1.0\n",
    "        # The factor multiplying the hypercube size. Larger values spread out the clusters/classes and make the classification task \n",
    "        # easier.\n",
    "        \n",
    "        'shuffle': True,\n",
    "        # Shuffle the samples and the features.\n",
    "        \n",
    "        'random_state': 46,\n",
    "        # Determines random number generation for dataset creation. Pass an int for reproducible output across multiple function calls.\n",
    "    },\n",
    "    'lambda': {\n",
    "        'data_prep': {\n",
    "            'train_test_val_split': { # refer to sklearn doc\n",
    "                'test_size': 0.1,\n",
    "                'val_size': 0.15,\n",
    "                'random_state': None,\n",
    "                'shuffle': False, # should be always false\n",
    "                'stratify': None\n",
    "            }\n",
    "        },\n",
    "        'model_compile': {\n",
    "            'optimizer_lambda': 'adam',\n",
    "            'loss': 'mae',# keras.losses.BinaryCrossentropy(from_logits=False), #tf.keras.losses.get(config['lambda_net']['loss_lambda']), # 'mae'\n",
    "            'metrics': [], #'mae', keras.losses.BinaryCrossentropy(from_logits=False)]\n",
    "        },\n",
    "        'model_fit': { # refer to keras API\n",
    "            'batch_size': 64,\n",
    "            'epochs': 500,\n",
    "            'verbose': 0,\n",
    "            'callbacks': None,\n",
    "            'shuffle': True, # usually true\n",
    "            'class_weight': None,\n",
    "            'sample_weight': None,\n",
    "            'initial_epoch': 0,\n",
    "            'steps_per_epoch': None,\n",
    "            'validation_steps': None,\n",
    "            'validation_batch_size': None,\n",
    "            'validation_freq': 1\n",
    "        }\n",
    "    },\n",
    "    'computation':{\n",
    "        'n_jobs': 100,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '4',\n",
    "        'RANDOM_SEED': 1,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8c0cc-8b52-4637-aaeb-e16a16634b89",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9518e9f9-6a5d-45e8-9bea-95333bb436d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config['computation']['gpu_numbers'] if config['computation']['use_gpu'] else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if config['computation']['use_gpu'] else ''\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if config['computation']['use_gpu'] else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if config['computation']['use_gpu'] else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d525d7-df11-4db7-bd88-211471e5a29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 19:09:30.121707: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-08 19:09:30.121744: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-08 19:09:30.121775: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dws-11): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae09b938-bfec-4ac3-b5cd-a33ce494c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76077315-f3bc-495f-92b9-df69649f3eed",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91501bce-140a-4c6c-89c4-94317079c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_datasets_list = np.zeros([config['data']['n_datasets'], config['data']['n_samples'], config['data']['n_features']])\n",
    "\n",
    "if  config['data']['n_targets'] < 2:\n",
    "    y_datasets_list = np.zeros([config['data']['n_datasets'], config['data']['n_samples'], ])\n",
    "else:\n",
    "    y_datasets_list = np.zeros([config['data']['n_datasets'], config['data']['n_samples'], config['data']['n_targets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f258543-80c3-4faa-a6f8-04f4a48e09cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = utilities_LR.data_path_LR(config)\n",
    "\n",
    "with open(directory + '/X.npy', \"rb\") as f:\n",
    "    X_datasets_list = np.load(f, allow_pickle=True)\n",
    "with open(directory + '/y.npy', \"rb\") as f:\n",
    "    y_datasets_list = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65510a-d70f-4277-800b-75ed4df35315",
   "metadata": {},
   "source": [
    "# Save Model & Metrics (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5754bd-00ae-472c-827e-fc2f807f93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models_predictions(weights_list, y_pred_list):\n",
    "    directory = utilities_LR.lambda_path_LR(config)\n",
    "    \n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    np.save(directory + '/lambda_weights_list.npy', weights_list, allow_pickle=True)\n",
    "    np.save(directory + '/lambda_preds_list.npy', y_pred_list, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77189e30-fcd7-4410-a593-dfc50360347f",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf1bd26-92b3-4826-9601-e8c4b6b77654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X, y, index):\n",
    "    # Data Prep\n",
    "    X_train, _, y_train, _ = train_test_split(X, y, \n",
    "                                                        test_size=config['lambda']['data_prep']['train_test_val_split']['test_size'],\n",
    "                                                        train_size=None,\n",
    "                                                        random_state=None,\n",
    "                                                        shuffle=config['lambda']['data_prep']['train_test_val_split']['shuffle'],\n",
    "                                                        stratify=None,\n",
    "                                                       )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Model Def\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                min_delta=0.001,\n",
    "                                patience=15,\n",
    "                                verbose=0,\n",
    "                                mode='auto',\n",
    "                                baseline=None,\n",
    "                                restore_best_weights=True)\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_dim=config['data']['n_features']))\n",
    "    model.add(Dense(100, activation='swish'))\n",
    "    #model.add(Dense(60, activation='relu'))\n",
    "    model.add(Dense(config['data']['n_targets'], activation='sigmoid'))\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=config['lambda']['model_compile']['optimizer_lambda'],\n",
    "                  loss=config['lambda']['model_compile']['loss'],\n",
    "                  metrics=config['lambda']['model_compile']['metrics']\n",
    "                 )\n",
    "    \n",
    "    #print(model.summary())\n",
    "    \n",
    "    # Model fit\n",
    "    _ = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        batch_size=config['lambda']['model_fit']['batch_size'],\n",
    "                        epochs=config['lambda']['model_fit']['epochs'],\n",
    "                        verbose=config['lambda']['model_fit']['verbose'],\n",
    "                        callbacks=[early_stopping],\n",
    "                        #validation_data=(X_val, y_val),\n",
    "                        validation_split=config['lambda']['data_prep']['train_test_val_split']['val_size'],\n",
    "                        shuffle=config['lambda']['model_fit']['shuffle'],\n",
    "                        class_weight=config['lambda']['model_fit']['class_weight'],\n",
    "                        sample_weight=config['lambda']['model_fit']['sample_weight'],\n",
    "                        initial_epoch=config['lambda']['model_fit']['initial_epoch'],\n",
    "                        steps_per_epoch=config['lambda']['model_fit']['steps_per_epoch'],\n",
    "                        validation_steps=config['lambda']['model_fit']['validation_steps'],\n",
    "                        validation_batch_size=config['lambda']['model_fit']['validation_batch_size'],\n",
    "                        validation_freq=config['lambda']['model_fit']['validation_freq'],\n",
    "                       )\n",
    "    \n",
    "    lambda_weights = np.concatenate([x.flatten() for x in model.get_weights()])\n",
    "    \n",
    "    y_pred = model.predict(X, verbose=0)\n",
    "    \n",
    "    return lambda_weights, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8ab4a7a-cae7-4fe8-b9a4-277357c64c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=100)]: Using backend LokyBackend with 100 concurrent workers.\n",
      "[Parallel(n_jobs=100)]: Done  21 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=100)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=100)]: Done  65 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=100)]: Done  88 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=100)]: Done 113 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=100)]: Done 138 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=100)]: Done 165 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=100)]: Done 192 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=100)]: Done 221 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=100)]: Done 250 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=100)]: Done 281 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=100)]: Done 312 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=100)]: Done 345 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=100)]: Done 378 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=100)]: Done 413 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=100)]: Done 448 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=100)]: Done 485 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=100)]: Done 522 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=100)]: Done 561 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=100)]: Done 600 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=100)]: Done 641 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=100)]: Done 682 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=100)]: Done 725 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=100)]: Done 768 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=100)]: Done 813 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=100)]: Done 858 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=100)]: Done 905 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=100)]: Done 952 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=100)]: Done 1001 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=100)]: Done 1050 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=100)]: Done 1101 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=100)]: Done 1152 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=100)]: Done 1205 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=100)]: Done 1258 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=100)]: Done 1313 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=100)]: Done 1368 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=100)]: Done 1425 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=100)]: Done 1482 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=100)]: Done 1541 tasks      | elapsed: 30.7min\n",
      "[Parallel(n_jobs=100)]: Done 1600 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=100)]: Done 1661 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=100)]: Done 1722 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=100)]: Done 1785 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=100)]: Done 1848 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=100)]: Done 1913 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=100)]: Done 1978 tasks      | elapsed: 38.8min\n",
      "[Parallel(n_jobs=100)]: Done 2045 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=100)]: Done 2112 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=100)]: Done 2181 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=100)]: Done 2250 tasks      | elapsed: 43.8min\n",
      "[Parallel(n_jobs=100)]: Done 2321 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=100)]: Done 2392 tasks      | elapsed: 46.6min\n",
      "[Parallel(n_jobs=100)]: Done 2465 tasks      | elapsed: 47.9min\n",
      "[Parallel(n_jobs=100)]: Done 2538 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=100)]: Done 2613 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=100)]: Done 2688 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=100)]: Done 2765 tasks      | elapsed: 53.6min\n",
      "[Parallel(n_jobs=100)]: Done 2842 tasks      | elapsed: 55.0min\n",
      "[Parallel(n_jobs=100)]: Done 2921 tasks      | elapsed: 56.5min\n",
      "[Parallel(n_jobs=100)]: Done 3000 tasks      | elapsed: 58.1min\n",
      "[Parallel(n_jobs=100)]: Done 3081 tasks      | elapsed: 59.5min\n",
      "[Parallel(n_jobs=100)]: Done 3162 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=100)]: Done 3245 tasks      | elapsed: 62.6min\n",
      "[Parallel(n_jobs=100)]: Done 3328 tasks      | elapsed: 64.2min\n",
      "[Parallel(n_jobs=100)]: Done 3413 tasks      | elapsed: 65.8min\n",
      "[Parallel(n_jobs=100)]: Done 3498 tasks      | elapsed: 67.6min\n",
      "[Parallel(n_jobs=100)]: Done 3585 tasks      | elapsed: 69.2min\n",
      "[Parallel(n_jobs=100)]: Done 3672 tasks      | elapsed: 71.0min\n",
      "[Parallel(n_jobs=100)]: Done 3761 tasks      | elapsed: 72.5min\n",
      "[Parallel(n_jobs=100)]: Done 3850 tasks      | elapsed: 74.4min\n",
      "[Parallel(n_jobs=100)]: Done 3941 tasks      | elapsed: 76.2min\n",
      "[Parallel(n_jobs=100)]: Done 4032 tasks      | elapsed: 78.1min\n",
      "[Parallel(n_jobs=100)]: Done 4125 tasks      | elapsed: 79.8min\n",
      "[Parallel(n_jobs=100)]: Done 4218 tasks      | elapsed: 81.7min\n",
      "[Parallel(n_jobs=100)]: Done 4313 tasks      | elapsed: 83.4min\n",
      "[Parallel(n_jobs=100)]: Done 4408 tasks      | elapsed: 85.1min\n",
      "[Parallel(n_jobs=100)]: Done 4505 tasks      | elapsed: 87.0min\n",
      "[Parallel(n_jobs=100)]: Done 4602 tasks      | elapsed: 88.8min\n",
      "[Parallel(n_jobs=100)]: Done 4701 tasks      | elapsed: 90.7min\n",
      "[Parallel(n_jobs=100)]: Done 4800 tasks      | elapsed: 92.5min\n",
      "[Parallel(n_jobs=100)]: Done 4901 tasks      | elapsed: 94.6min\n",
      "[Parallel(n_jobs=100)]: Done 5002 tasks      | elapsed: 96.6min\n",
      "[Parallel(n_jobs=100)]: Done 5105 tasks      | elapsed: 98.6min\n",
      "[Parallel(n_jobs=100)]: Done 5208 tasks      | elapsed: 100.5min\n",
      "[Parallel(n_jobs=100)]: Done 5313 tasks      | elapsed: 102.5min\n",
      "[Parallel(n_jobs=100)]: Done 5418 tasks      | elapsed: 104.6min\n",
      "[Parallel(n_jobs=100)]: Done 5525 tasks      | elapsed: 106.7min\n",
      "[Parallel(n_jobs=100)]: Done 5632 tasks      | elapsed: 108.7min\n",
      "[Parallel(n_jobs=100)]: Done 5741 tasks      | elapsed: 110.8min\n",
      "[Parallel(n_jobs=100)]: Done 5850 tasks      | elapsed: 112.8min\n",
      "[Parallel(n_jobs=100)]: Done 5961 tasks      | elapsed: 115.0min\n",
      "[Parallel(n_jobs=100)]: Done 6072 tasks      | elapsed: 117.2min\n",
      "[Parallel(n_jobs=100)]: Done 6185 tasks      | elapsed: 119.4min\n",
      "[Parallel(n_jobs=100)]: Done 6298 tasks      | elapsed: 121.5min\n",
      "[Parallel(n_jobs=100)]: Done 6413 tasks      | elapsed: 123.7min\n",
      "[Parallel(n_jobs=100)]: Done 6528 tasks      | elapsed: 126.0min\n",
      "[Parallel(n_jobs=100)]: Done 6645 tasks      | elapsed: 128.2min\n",
      "[Parallel(n_jobs=100)]: Done 6762 tasks      | elapsed: 130.5min\n",
      "[Parallel(n_jobs=100)]: Done 6881 tasks      | elapsed: 132.9min\n",
      "[Parallel(n_jobs=100)]: Done 7000 tasks      | elapsed: 135.2min\n",
      "[Parallel(n_jobs=100)]: Done 7121 tasks      | elapsed: 137.6min\n",
      "[Parallel(n_jobs=100)]: Done 7242 tasks      | elapsed: 139.9min\n",
      "[Parallel(n_jobs=100)]: Done 7365 tasks      | elapsed: 142.2min\n",
      "[Parallel(n_jobs=100)]: Done 7488 tasks      | elapsed: 144.6min\n",
      "[Parallel(n_jobs=100)]: Done 7613 tasks      | elapsed: 147.1min\n",
      "[Parallel(n_jobs=100)]: Done 7738 tasks      | elapsed: 149.4min\n",
      "[Parallel(n_jobs=100)]: Done 7865 tasks      | elapsed: 152.0min\n",
      "[Parallel(n_jobs=100)]: Done 7992 tasks      | elapsed: 154.4min\n",
      "[Parallel(n_jobs=100)]: Done 8121 tasks      | elapsed: 157.0min\n",
      "[Parallel(n_jobs=100)]: Done 8250 tasks      | elapsed: 159.2min\n",
      "[Parallel(n_jobs=100)]: Done 8381 tasks      | elapsed: 162.0min\n",
      "[Parallel(n_jobs=100)]: Done 8512 tasks      | elapsed: 164.6min\n",
      "[Parallel(n_jobs=100)]: Done 8645 tasks      | elapsed: 167.1min\n",
      "[Parallel(n_jobs=100)]: Done 8778 tasks      | elapsed: 169.8min\n",
      "[Parallel(n_jobs=100)]: Done 8913 tasks      | elapsed: 172.7min\n",
      "[Parallel(n_jobs=100)]: Done 9048 tasks      | elapsed: 175.1min\n",
      "[Parallel(n_jobs=100)]: Done 9185 tasks      | elapsed: 177.9min\n",
      "[Parallel(n_jobs=100)]: Done 9322 tasks      | elapsed: 180.4min\n",
      "[Parallel(n_jobs=100)]: Done 9461 tasks      | elapsed: 183.2min\n",
      "[Parallel(n_jobs=100)]: Done 9600 tasks      | elapsed: 185.7min\n",
      "[Parallel(n_jobs=100)]: Done 9741 tasks      | elapsed: 188.6min\n",
      "[Parallel(n_jobs=100)]: Done 9882 tasks      | elapsed: 191.1min\n",
      "[Parallel(n_jobs=100)]: Done 10025 tasks      | elapsed: 194.0min\n",
      "[Parallel(n_jobs=100)]: Done 10168 tasks      | elapsed: 196.7min\n",
      "[Parallel(n_jobs=100)]: Done 10313 tasks      | elapsed: 199.4min\n",
      "[Parallel(n_jobs=100)]: Done 10458 tasks      | elapsed: 202.2min\n",
      "[Parallel(n_jobs=100)]: Done 10605 tasks      | elapsed: 204.9min\n",
      "[Parallel(n_jobs=100)]: Done 10752 tasks      | elapsed: 207.8min\n",
      "[Parallel(n_jobs=100)]: Done 10901 tasks      | elapsed: 210.4min\n",
      "[Parallel(n_jobs=100)]: Done 11050 tasks      | elapsed: 213.2min\n",
      "[Parallel(n_jobs=100)]: Done 11201 tasks      | elapsed: 216.0min\n",
      "[Parallel(n_jobs=100)]: Done 11352 tasks      | elapsed: 218.8min\n",
      "[Parallel(n_jobs=100)]: Done 11505 tasks      | elapsed: 221.7min\n",
      "[Parallel(n_jobs=100)]: Done 11658 tasks      | elapsed: 224.7min\n",
      "[Parallel(n_jobs=100)]: Done 11813 tasks      | elapsed: 227.7min\n",
      "[Parallel(n_jobs=100)]: Done 11968 tasks      | elapsed: 230.5min\n",
      "[Parallel(n_jobs=100)]: Done 12125 tasks      | elapsed: 233.5min\n",
      "[Parallel(n_jobs=100)]: Done 12282 tasks      | elapsed: 236.7min\n",
      "[Parallel(n_jobs=100)]: Done 12441 tasks      | elapsed: 239.5min\n",
      "[Parallel(n_jobs=100)]: Done 12600 tasks      | elapsed: 242.4min\n",
      "[Parallel(n_jobs=100)]: Done 12761 tasks      | elapsed: 245.5min\n",
      "[Parallel(n_jobs=100)]: Done 12922 tasks      | elapsed: 248.7min\n",
      "[Parallel(n_jobs=100)]: Done 13085 tasks      | elapsed: 251.8min\n",
      "[Parallel(n_jobs=100)]: Done 13248 tasks      | elapsed: 255.0min\n",
      "[Parallel(n_jobs=100)]: Done 13413 tasks      | elapsed: 258.0min\n",
      "[Parallel(n_jobs=100)]: Done 13578 tasks      | elapsed: 261.2min\n",
      "[Parallel(n_jobs=100)]: Done 13745 tasks      | elapsed: 264.3min\n",
      "[Parallel(n_jobs=100)]: Done 13912 tasks      | elapsed: 267.5min\n",
      "[Parallel(n_jobs=100)]: Done 14081 tasks      | elapsed: 270.8min\n",
      "[Parallel(n_jobs=100)]: Done 14250 tasks      | elapsed: 274.0min\n",
      "[Parallel(n_jobs=100)]: Done 14421 tasks      | elapsed: 277.2min\n",
      "[Parallel(n_jobs=100)]: Done 14592 tasks      | elapsed: 280.5min\n",
      "[Parallel(n_jobs=100)]: Done 14765 tasks      | elapsed: 283.7min\n",
      "[Parallel(n_jobs=100)]: Done 14938 tasks      | elapsed: 287.0min\n",
      "[Parallel(n_jobs=100)]: Done 15113 tasks      | elapsed: 290.4min\n",
      "[Parallel(n_jobs=100)]: Done 15288 tasks      | elapsed: 293.8min\n",
      "[Parallel(n_jobs=100)]: Done 15465 tasks      | elapsed: 296.9min\n",
      "[Parallel(n_jobs=100)]: Done 15642 tasks      | elapsed: 300.4min\n",
      "[Parallel(n_jobs=100)]: Done 15821 tasks      | elapsed: 303.7min\n",
      "[Parallel(n_jobs=100)]: Done 16000 tasks      | elapsed: 307.3min\n",
      "[Parallel(n_jobs=100)]: Done 16181 tasks      | elapsed: 310.7min\n",
      "[Parallel(n_jobs=100)]: Done 16362 tasks      | elapsed: 314.1min\n",
      "[Parallel(n_jobs=100)]: Done 16545 tasks      | elapsed: 317.6min\n",
      "[Parallel(n_jobs=100)]: Done 16728 tasks      | elapsed: 321.0min\n",
      "[Parallel(n_jobs=100)]: Done 16913 tasks      | elapsed: 324.5min\n",
      "[Parallel(n_jobs=100)]: Done 17098 tasks      | elapsed: 327.9min\n",
      "[Parallel(n_jobs=100)]: Done 17285 tasks      | elapsed: 331.5min\n",
      "[Parallel(n_jobs=100)]: Done 17472 tasks      | elapsed: 335.1min\n",
      "[Parallel(n_jobs=100)]: Done 17661 tasks      | elapsed: 338.7min\n",
      "[Parallel(n_jobs=100)]: Done 17850 tasks      | elapsed: 342.4min\n",
      "[Parallel(n_jobs=100)]: Done 18041 tasks      | elapsed: 346.2min\n",
      "[Parallel(n_jobs=100)]: Done 18232 tasks      | elapsed: 350.0min\n",
      "[Parallel(n_jobs=100)]: Done 18425 tasks      | elapsed: 353.8min\n",
      "[Parallel(n_jobs=100)]: Done 18618 tasks      | elapsed: 357.6min\n",
      "[Parallel(n_jobs=100)]: Done 18813 tasks      | elapsed: 361.4min\n",
      "[Parallel(n_jobs=100)]: Done 19008 tasks      | elapsed: 365.2min\n",
      "[Parallel(n_jobs=100)]: Done 19205 tasks      | elapsed: 369.1min\n",
      "[Parallel(n_jobs=100)]: Done 19402 tasks      | elapsed: 372.9min\n",
      "[Parallel(n_jobs=100)]: Done 19601 tasks      | elapsed: 376.7min\n",
      "[Parallel(n_jobs=100)]: Done 19800 tasks      | elapsed: 380.6min\n",
      "[Parallel(n_jobs=100)]: Done 20001 tasks      | elapsed: 384.5min\n",
      "[Parallel(n_jobs=100)]: Done 20202 tasks      | elapsed: 388.2min\n",
      "[Parallel(n_jobs=100)]: Done 20405 tasks      | elapsed: 392.0min\n",
      "[Parallel(n_jobs=100)]: Done 20608 tasks      | elapsed: 395.9min\n",
      "[Parallel(n_jobs=100)]: Done 20813 tasks      | elapsed: 399.7min\n",
      "[Parallel(n_jobs=100)]: Done 21018 tasks      | elapsed: 403.7min\n",
      "[Parallel(n_jobs=100)]: Done 21225 tasks      | elapsed: 407.6min\n",
      "[Parallel(n_jobs=100)]: Done 21432 tasks      | elapsed: 411.4min\n",
      "[Parallel(n_jobs=100)]: Done 21641 tasks      | elapsed: 415.4min\n",
      "[Parallel(n_jobs=100)]: Done 21850 tasks      | elapsed: 419.3min\n",
      "[Parallel(n_jobs=100)]: Done 22061 tasks      | elapsed: 423.4min\n",
      "[Parallel(n_jobs=100)]: Done 22272 tasks      | elapsed: 427.4min\n",
      "[Parallel(n_jobs=100)]: Done 22485 tasks      | elapsed: 431.4min\n",
      "[Parallel(n_jobs=100)]: Done 22698 tasks      | elapsed: 435.3min\n",
      "[Parallel(n_jobs=100)]: Done 22913 tasks      | elapsed: 439.5min\n",
      "[Parallel(n_jobs=100)]: Done 23128 tasks      | elapsed: 443.4min\n",
      "[Parallel(n_jobs=100)]: Done 23345 tasks      | elapsed: 447.6min\n",
      "[Parallel(n_jobs=100)]: Done 23562 tasks      | elapsed: 451.8min\n",
      "[Parallel(n_jobs=100)]: Done 23781 tasks      | elapsed: 455.7min\n",
      "[Parallel(n_jobs=100)]: Done 24000 tasks      | elapsed: 460.1min\n",
      "[Parallel(n_jobs=100)]: Done 24221 tasks      | elapsed: 464.2min\n",
      "[Parallel(n_jobs=100)]: Done 24442 tasks      | elapsed: 468.4min\n",
      "[Parallel(n_jobs=100)]: Done 24665 tasks      | elapsed: 472.8min\n",
      "[Parallel(n_jobs=100)]: Done 24888 tasks      | elapsed: 477.0min\n",
      "[Parallel(n_jobs=100)]: Done 25113 tasks      | elapsed: 481.3min\n",
      "[Parallel(n_jobs=100)]: Done 25338 tasks      | elapsed: 485.6min\n",
      "[Parallel(n_jobs=100)]: Done 25565 tasks      | elapsed: 489.9min\n",
      "[Parallel(n_jobs=100)]: Done 25792 tasks      | elapsed: 494.3min\n",
      "[Parallel(n_jobs=100)]: Done 26021 tasks      | elapsed: 498.9min\n",
      "[Parallel(n_jobs=100)]: Done 26250 tasks      | elapsed: 503.2min\n",
      "[Parallel(n_jobs=100)]: Done 26481 tasks      | elapsed: 507.6min\n",
      "[Parallel(n_jobs=100)]: Done 26712 tasks      | elapsed: 511.9min\n",
      "[Parallel(n_jobs=100)]: Done 26945 tasks      | elapsed: 516.4min\n",
      "[Parallel(n_jobs=100)]: Done 27178 tasks      | elapsed: 521.0min\n",
      "[Parallel(n_jobs=100)]: Done 27413 tasks      | elapsed: 525.6min\n",
      "[Parallel(n_jobs=100)]: Done 27648 tasks      | elapsed: 530.1min\n",
      "[Parallel(n_jobs=100)]: Done 27885 tasks      | elapsed: 534.8min\n",
      "[Parallel(n_jobs=100)]: Done 28122 tasks      | elapsed: 539.4min\n",
      "[Parallel(n_jobs=100)]: Done 28361 tasks      | elapsed: 544.0min\n",
      "[Parallel(n_jobs=100)]: Done 28600 tasks      | elapsed: 548.7min\n",
      "[Parallel(n_jobs=100)]: Done 28841 tasks      | elapsed: 553.2min\n",
      "[Parallel(n_jobs=100)]: Done 29082 tasks      | elapsed: 557.7min\n",
      "[Parallel(n_jobs=100)]: Done 29325 tasks      | elapsed: 562.3min\n",
      "[Parallel(n_jobs=100)]: Done 29568 tasks      | elapsed: 566.8min\n",
      "[Parallel(n_jobs=100)]: Done 29813 tasks      | elapsed: 571.5min\n",
      "[Parallel(n_jobs=100)]: Done 30058 tasks      | elapsed: 576.1min\n",
      "[Parallel(n_jobs=100)]: Done 30305 tasks      | elapsed: 580.7min\n",
      "[Parallel(n_jobs=100)]: Done 30552 tasks      | elapsed: 585.3min\n",
      "[Parallel(n_jobs=100)]: Done 30801 tasks      | elapsed: 590.3min\n",
      "[Parallel(n_jobs=100)]: Done 31050 tasks      | elapsed: 594.9min\n",
      "[Parallel(n_jobs=100)]: Done 31301 tasks      | elapsed: 599.6min\n",
      "[Parallel(n_jobs=100)]: Done 31552 tasks      | elapsed: 604.3min\n",
      "[Parallel(n_jobs=100)]: Done 31805 tasks      | elapsed: 609.0min\n",
      "[Parallel(n_jobs=100)]: Done 32058 tasks      | elapsed: 613.6min\n",
      "[Parallel(n_jobs=100)]: Done 32313 tasks      | elapsed: 618.4min\n",
      "[Parallel(n_jobs=100)]: Done 32568 tasks      | elapsed: 623.2min\n",
      "[Parallel(n_jobs=100)]: Done 32825 tasks      | elapsed: 628.1min\n",
      "[Parallel(n_jobs=100)]: Done 33082 tasks      | elapsed: 632.9min\n",
      "[Parallel(n_jobs=100)]: Done 33341 tasks      | elapsed: 637.9min\n",
      "[Parallel(n_jobs=100)]: Done 33600 tasks      | elapsed: 642.9min\n",
      "[Parallel(n_jobs=100)]: Done 33861 tasks      | elapsed: 647.7min\n",
      "[Parallel(n_jobs=100)]: Done 34122 tasks      | elapsed: 652.7min\n",
      "[Parallel(n_jobs=100)]: Done 34385 tasks      | elapsed: 657.9min\n",
      "[Parallel(n_jobs=100)]: Done 34648 tasks      | elapsed: 663.0min\n",
      "[Parallel(n_jobs=100)]: Done 34913 tasks      | elapsed: 667.9min\n",
      "[Parallel(n_jobs=100)]: Done 35178 tasks      | elapsed: 673.2min\n",
      "[Parallel(n_jobs=100)]: Done 35445 tasks      | elapsed: 678.4min\n",
      "[Parallel(n_jobs=100)]: Done 35712 tasks      | elapsed: 683.7min\n",
      "[Parallel(n_jobs=100)]: Done 35981 tasks      | elapsed: 688.9min\n",
      "[Parallel(n_jobs=100)]: Done 36250 tasks      | elapsed: 694.3min\n",
      "[Parallel(n_jobs=100)]: Done 36521 tasks      | elapsed: 699.8min\n",
      "[Parallel(n_jobs=100)]: Done 36792 tasks      | elapsed: 705.3min\n",
      "[Parallel(n_jobs=100)]: Done 37065 tasks      | elapsed: 710.6min\n",
      "[Parallel(n_jobs=100)]: Done 37338 tasks      | elapsed: 715.8min\n",
      "[Parallel(n_jobs=100)]: Done 37613 tasks      | elapsed: 721.3min\n",
      "[Parallel(n_jobs=100)]: Done 37888 tasks      | elapsed: 726.4min\n",
      "[Parallel(n_jobs=100)]: Done 38165 tasks      | elapsed: 731.9min\n",
      "[Parallel(n_jobs=100)]: Done 38442 tasks      | elapsed: 737.3min\n",
      "[Parallel(n_jobs=100)]: Done 38721 tasks      | elapsed: 742.5min\n",
      "[Parallel(n_jobs=100)]: Done 39000 tasks      | elapsed: 747.8min\n",
      "[Parallel(n_jobs=100)]: Done 39281 tasks      | elapsed: 753.2min\n",
      "[Parallel(n_jobs=100)]: Done 39562 tasks      | elapsed: 758.4min\n",
      "[Parallel(n_jobs=100)]: Done 39845 tasks      | elapsed: 764.0min\n",
      "[Parallel(n_jobs=100)]: Done 40128 tasks      | elapsed: 769.3min\n",
      "[Parallel(n_jobs=100)]: Done 40413 tasks      | elapsed: 774.6min\n",
      "[Parallel(n_jobs=100)]: Done 40698 tasks      | elapsed: 780.2min\n",
      "[Parallel(n_jobs=100)]: Done 40985 tasks      | elapsed: 785.5min\n",
      "[Parallel(n_jobs=100)]: Done 41272 tasks      | elapsed: 790.8min\n",
      "[Parallel(n_jobs=100)]: Done 41561 tasks      | elapsed: 796.4min\n",
      "[Parallel(n_jobs=100)]: Done 41850 tasks      | elapsed: 801.9min\n",
      "[Parallel(n_jobs=100)]: Done 42141 tasks      | elapsed: 807.4min\n",
      "[Parallel(n_jobs=100)]: Done 42432 tasks      | elapsed: 813.0min\n",
      "[Parallel(n_jobs=100)]: Done 42725 tasks      | elapsed: 818.6min\n",
      "[Parallel(n_jobs=100)]: Done 43018 tasks      | elapsed: 824.1min\n",
      "[Parallel(n_jobs=100)]: Done 43313 tasks      | elapsed: 829.7min\n",
      "[Parallel(n_jobs=100)]: Done 43608 tasks      | elapsed: 835.5min\n",
      "[Parallel(n_jobs=100)]: Done 43905 tasks      | elapsed: 841.0min\n",
      "[Parallel(n_jobs=100)]: Done 44202 tasks      | elapsed: 846.9min\n",
      "[Parallel(n_jobs=100)]: Done 44501 tasks      | elapsed: 852.8min\n",
      "[Parallel(n_jobs=100)]: Done 44800 tasks      | elapsed: 858.5min\n",
      "[Parallel(n_jobs=100)]: Done 45000 out of 45000 | elapsed: 861.7min finished\n"
     ]
    }
   ],
   "source": [
    "parallel = Parallel(n_jobs=config['computation']['n_jobs'], verbose=10, backend='loky') #loky\n",
    "\n",
    "weights_ypred_list = parallel(delayed(train_nn)(X_data, y_data, index) for index, (X_data, y_data) in enumerate(zip(X_datasets_list, y_datasets_list)))\n",
    "#weights_ypred_list = parallel(delayed(train_nn)(X_data, y_data, index) for index, (X_data, y_data) in enumerate(zip(X_datasets_list[:5], y_datasets_list[:5])))\n",
    "                                  \n",
    "del parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c847f21-dd63-423c-95fc-5627f8b2e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_list = np.stack([np.array(x[0]) for x in weights_ypred_list])\n",
    "y_pred_list = np.stack([x[1] for x in weights_ypred_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eaf4b1e-1013-40ac-9d3c-93f6a24c1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = y_pred_list.reshape([config['data']['n_datasets'], config['data']['n_samples']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778c426-b6e2-421c-aa06-17507dfa3a32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inspect Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcd173a-cba2-440d-a63d-ebd1f8b8579e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 2281)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92e041fd-5704-498f-9a40-489636bf503c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e440930-b8ca-4b24-bbdd-56c8a5ed1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a2f702f-483b-4f55-8141-e4167eac7117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.999962e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.138527e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.691417e-12</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>8.473344e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473599e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.476363e-05</td>\n",
       "      <td>8.923207e-01</td>\n",
       "      <td>6.114637e-09</td>\n",
       "      <td>3.915742e-09</td>\n",
       "      <td>1.046712e-12</td>\n",
       "      <td>9.975100e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999994e-01</td>\n",
       "      <td>2.286794e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.942850e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.430906e-06</td>\n",
       "      <td>1.617538e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.631763e-12</td>\n",
       "      <td>6.959830e-15</td>\n",
       "      <td>2.689273e-12</td>\n",
       "      <td>9.999990e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.578691e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.124277e-05</td>\n",
       "      <td>9.976035e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.017615e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.793100e-30</td>\n",
       "      <td>4.044016e-18</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.638189e-23</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.895738e-07</td>\n",
       "      <td>2.164144e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.008530e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.608814e-21</td>\n",
       "      <td>4.042871e-12</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.999983e-01</td>\n",
       "      <td>2.809809e-04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.619053e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.769570e-07</td>\n",
       "      <td>9.999960e-01</td>\n",
       "      <td>1.479902e-04</td>\n",
       "      <td>5.253218e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999979e-01</td>\n",
       "      <td>9.999946e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.640541e-09</td>\n",
       "      <td>9.999997e-01</td>\n",
       "      <td>2.296707e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.997872e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.550677e-07</td>\n",
       "      <td>9.938993e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.646212e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999982e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.706445e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.282193e-07</td>\n",
       "      <td>3.215503e-08</td>\n",
       "      <td>2.011468e-04</td>\n",
       "      <td>3.064805e-04</td>\n",
       "      <td>6.523809e-07</td>\n",
       "      <td>1.184045e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.402515e-17</td>\n",
       "      <td>5.543542e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.456075e-08</td>\n",
       "      <td>7.482244e-12</td>\n",
       "      <td>1.958541e-10</td>\n",
       "      <td>8.700747e-10</td>\n",
       "      <td>9.999967e-01</td>\n",
       "      <td>2.023470e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999977e-01</td>\n",
       "      <td>2.422380e-07</td>\n",
       "      <td>6.209589e-13</td>\n",
       "      <td>2.724104e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.975051e-01</td>\n",
       "      <td>2.286279e-05</td>\n",
       "      <td>3.689187e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.980575e-01</td>\n",
       "      <td>4.346909e-07</td>\n",
       "      <td>2.332441e-07</td>\n",
       "      <td>9.999734e-01</td>\n",
       "      <td>9.998739e-01</td>\n",
       "      <td>9.997934e-01</td>\n",
       "      <td>7.784935e-06</td>\n",
       "      <td>1.354322e-04</td>\n",
       "      <td>9.999295e-01</td>\n",
       "      <td>8.806789e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.230794e-04</td>\n",
       "      <td>9.993427e-01</td>\n",
       "      <td>3.445297e-06</td>\n",
       "      <td>9.999983e-01</td>\n",
       "      <td>8.130342e-04</td>\n",
       "      <td>2.895789e-03</td>\n",
       "      <td>9.999972e-01</td>\n",
       "      <td>9.998887e-01</td>\n",
       "      <td>3.699810e-05</td>\n",
       "      <td>9.999873e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.999235e-01</td>\n",
       "      <td>9.999724e-01</td>\n",
       "      <td>3.998061e-04</td>\n",
       "      <td>1.867596e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.170942e-04</td>\n",
       "      <td>1.526337e-15</td>\n",
       "      <td>2.911810e-08</td>\n",
       "      <td>1.155214e-03</td>\n",
       "      <td>9.880936e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.063271e-08</td>\n",
       "      <td>7.934025e-13</td>\n",
       "      <td>1.255124e-02</td>\n",
       "      <td>9.999990e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999994e-01</td>\n",
       "      <td>6.022833e-10</td>\n",
       "      <td>1.006256e-06</td>\n",
       "      <td>9.189248e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.328889e-08</td>\n",
       "      <td>7.525453e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.695145e-10</td>\n",
       "      <td>4.717558e-07</td>\n",
       "      <td>1.205683e-10</td>\n",
       "      <td>9.999977e-01</td>\n",
       "      <td>1.278498e-14</td>\n",
       "      <td>5.679117e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.998423e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.265351e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.029898e-10</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.985750e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999973e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.284993e-07</td>\n",
       "      <td>9.993867e-01</td>\n",
       "      <td>8.589901e-11</td>\n",
       "      <td>9.999997e-01</td>\n",
       "      <td>1.730399e-14</td>\n",
       "      <td>1.068417e-10</td>\n",
       "      <td>1.433693e-07</td>\n",
       "      <td>6.932717e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.652960e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.043868e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>9.999977e-01</td>\n",
       "      <td>5.957645e-07</td>\n",
       "      <td>6.663851e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999989e-01</td>\n",
       "      <td>1.292809e-05</td>\n",
       "      <td>9.999996e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.027293e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.467205e-11</td>\n",
       "      <td>1.626354e-03</td>\n",
       "      <td>2.133268e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.123682e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.785798e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999995e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.999468e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999785e-01</td>\n",
       "      <td>6.259650e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.136644e-08</td>\n",
       "      <td>2.048680e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>4.254474e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.922548e-02</td>\n",
       "      <td>4.084671e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.547943e-08</td>\n",
       "      <td>1.145987e-05</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>7.157972e-05</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.498789e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.272145e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.335219e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.193259e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.647079e-09</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>3.555714e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.410776e-08</td>\n",
       "      <td>1.425410e-12</td>\n",
       "      <td>5.564583e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.888838e-01</td>\n",
       "      <td>5.791265e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.998384e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.998025e-01</td>\n",
       "      <td>1.568740e-20</td>\n",
       "      <td>9.005655e-08</td>\n",
       "      <td>2.791726e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>4.962438e-04</td>\n",
       "      <td>6.283450e-19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>4.110014e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.984776e-01</td>\n",
       "      <td>5.993988e-10</td>\n",
       "      <td>1.757756e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.458869e-06</td>\n",
       "      <td>3.823031e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.401726e-14</td>\n",
       "      <td>1.175448e-08</td>\n",
       "      <td>9.999976e-01</td>\n",
       "      <td>5.131776e-05</td>\n",
       "      <td>5.159607e-10</td>\n",
       "      <td>3.830566e-04</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>9.999993e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.190524e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999991e-01</td>\n",
       "      <td>9.782575e-09</td>\n",
       "      <td>8.394966e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.922747e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.996095e-01</td>\n",
       "      <td>1.702416e-09</td>\n",
       "      <td>9.999586e-01</td>\n",
       "      <td>5.880003e-14</td>\n",
       "      <td>9.999429e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999692e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999977e-01</td>\n",
       "      <td>5.033026e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.860009e-08</td>\n",
       "      <td>3.666788e-08</td>\n",
       "      <td>2.244149e-08</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>9.997857e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999855e-01</td>\n",
       "      <td>7.968872e-06</td>\n",
       "      <td>9.999971e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.384464e-07</td>\n",
       "      <td>9.388072e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.240284e-04</td>\n",
       "      <td>2.021665e-09</td>\n",
       "      <td>1.304631e-06</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.527376e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.022436e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.989448e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.926485e-06</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.091173e-13</td>\n",
       "      <td>2.101491e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.596345e-14</td>\n",
       "      <td>5.070477e-07</td>\n",
       "      <td>8.447885e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999111e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.085084e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999626e-01</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>6.194756e-05</td>\n",
       "      <td>6.132869e-05</td>\n",
       "      <td>1.926563e-06</td>\n",
       "      <td>1.903232e-10</td>\n",
       "      <td>3.629048e-05</td>\n",
       "      <td>3.849123e-04</td>\n",
       "      <td>9.999979e-01</td>\n",
       "      <td>9.987815e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.782235e-06</td>\n",
       "      <td>2.509307e-04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.008067e-11</td>\n",
       "      <td>4.839368e-11</td>\n",
       "      <td>9.999993e-01</td>\n",
       "      <td>6.765356e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999737e-01</td>\n",
       "      <td>1.057991e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>9.992868e-01</td>\n",
       "      <td>6.696980e-07</td>\n",
       "      <td>4.658732e-09</td>\n",
       "      <td>2.876503e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.108070e-06</td>\n",
       "      <td>6.862539e-10</td>\n",
       "      <td>9.250821e-15</td>\n",
       "      <td>5.566646e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.894473e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999550e-01</td>\n",
       "      <td>2.661423e-03</td>\n",
       "      <td>2.298120e-09</td>\n",
       "      <td>4.139090e-05</td>\n",
       "      <td>9.884048e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.453056e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.186128e-06</td>\n",
       "      <td>9.980833e-01</td>\n",
       "      <td>5.984226e-07</td>\n",
       "      <td>1.235399e-06</td>\n",
       "      <td>1.613285e-06</td>\n",
       "      <td>1.415900e-04</td>\n",
       "      <td>9.999945e-01</td>\n",
       "      <td>1.036181e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2             3             4     \\\n",
       "0   9.999962e-01  9.999999e-01  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "1   1.000000e+00  9.999999e-01  1.000000e+00  1.000000e+00  9.999998e-01   \n",
       "2   2.124277e-05  9.976035e-01  1.000000e+00  1.017615e-03  1.000000e+00   \n",
       "3   9.999983e-01  2.809809e-04  1.000000e+00  1.000000e+00  9.619053e-01   \n",
       "4   9.999999e-01  1.000000e+00  1.550677e-07  9.938993e-01  1.000000e+00   \n",
       "5   1.402515e-17  5.543542e-07  1.000000e+00  7.456075e-08  7.482244e-12   \n",
       "6   9.980575e-01  4.346909e-07  2.332441e-07  9.999734e-01  9.998739e-01   \n",
       "7   9.999235e-01  9.999724e-01  3.998061e-04  1.867596e-09  1.000000e+00   \n",
       "8   1.328889e-08  7.525453e-07  1.000000e+00  2.695145e-10  4.717558e-07   \n",
       "9   7.284993e-07  9.993867e-01  8.589901e-11  9.999997e-01  1.730399e-14   \n",
       "10  1.000000e+00  1.027293e-03  1.000000e+00  1.000000e+00  2.467205e-11   \n",
       "11  9.999468e-01  1.000000e+00  1.000000e+00  9.999785e-01  6.259650e-10   \n",
       "12  1.000000e+00  1.272145e-09  1.000000e+00  2.335219e-06  1.000000e+00   \n",
       "13  1.000000e+00  9.998025e-01  1.568740e-20  9.005655e-08  2.791726e-13   \n",
       "14  1.000000e+00  7.401726e-14  1.175448e-08  9.999976e-01  5.131776e-05   \n",
       "15  9.996095e-01  1.702416e-09  9.999586e-01  5.880003e-14  9.999429e-01   \n",
       "16  1.000000e+00  1.384464e-07  9.388072e-06  1.000000e+00  2.240284e-04   \n",
       "17  1.596345e-14  5.070477e-07  8.447885e-09  1.000000e+00  1.000000e+00   \n",
       "18  1.782235e-06  2.509307e-04  1.000000e+00  2.008067e-11  4.839368e-11   \n",
       "19  5.894473e-05  1.000000e+00  9.999550e-01  2.661423e-03  2.298120e-09   \n",
       "\n",
       "            5             6             7             8             9     ...  \\\n",
       "0   6.138527e-11  1.000000e+00  8.691417e-12  9.999999e-01  8.473344e-14  ...   \n",
       "1   1.000000e+00  9.999994e-01  2.286794e-10  1.000000e+00  8.942850e-09  ...   \n",
       "2   1.793100e-30  4.044016e-18  9.999999e-01  2.638189e-23  1.000000e+00  ...   \n",
       "3   1.000000e+00  2.769570e-07  9.999960e-01  1.479902e-04  5.253218e-10  ...   \n",
       "4   1.000000e+00  3.646212e-05  1.000000e+00  9.999982e-01  9.999999e-01  ...   \n",
       "5   1.958541e-10  8.700747e-10  9.999967e-01  2.023470e-02  1.000000e+00  ...   \n",
       "6   9.997934e-01  7.784935e-06  1.354322e-04  9.999295e-01  8.806789e-05  ...   \n",
       "7   8.170942e-04  1.526337e-15  2.911810e-08  1.155214e-03  9.880936e-01  ...   \n",
       "8   1.205683e-10  9.999977e-01  1.278498e-14  5.679117e-18  1.000000e+00  ...   \n",
       "9   1.068417e-10  1.433693e-07  6.932717e-09  1.000000e+00  8.652960e-06  ...   \n",
       "10  1.626354e-03  2.133268e-07  1.000000e+00  1.000000e+00  1.000000e+00  ...   \n",
       "11  1.000000e+00  5.136644e-08  2.048680e-07  9.999995e-01  4.254474e-08  ...   \n",
       "12  4.193259e-17  1.000000e+00  1.647079e-09  9.999998e-01  3.555714e-09  ...   \n",
       "13  1.000000e+00  1.000000e+00  9.999999e-01  4.962438e-04  6.283450e-19  ...   \n",
       "14  5.159607e-10  3.830566e-04  9.999995e-01  9.999993e-01  1.000000e+00  ...   \n",
       "15  1.000000e+00  9.999692e-01  1.000000e+00  9.999977e-01  5.033026e-09  ...   \n",
       "16  2.021665e-09  1.304631e-06  9.999999e-01  6.527376e-05  1.000000e+00  ...   \n",
       "17  1.000000e+00  9.999111e-01  1.000000e+00  1.000000e+00  3.085084e-06  ...   \n",
       "18  9.999993e-01  6.765356e-09  1.000000e+00  9.999737e-01  1.057991e-07  ...   \n",
       "19  4.139090e-05  9.884048e-01  1.000000e+00  5.453056e-07  1.000000e+00  ...   \n",
       "\n",
       "            4990          4991          4992          4993          4994  \\\n",
       "0   1.473599e-05  1.000000e+00  1.000000e+00  2.476363e-05  8.923207e-01   \n",
       "1   2.430906e-06  1.617538e-01  1.000000e+00  1.000000e+00  3.631763e-12   \n",
       "2   1.895738e-07  2.164144e-07  1.000000e+00  5.008530e-09  1.000000e+00   \n",
       "3   9.999979e-01  9.999946e-01  1.000000e+00  1.000000e+00  9.999999e-01   \n",
       "4   4.706445e-08  1.000000e+00  1.000000e+00  1.000000e+00  1.282193e-07   \n",
       "5   9.999977e-01  2.422380e-07  6.209589e-13  2.724104e-12  1.000000e+00   \n",
       "6   4.230794e-04  9.993427e-01  3.445297e-06  9.999983e-01  8.130342e-04   \n",
       "7   1.000000e+00  5.063271e-08  7.934025e-13  1.255124e-02  9.999990e-01   \n",
       "8   9.998423e-01  1.000000e+00  1.000000e+00  5.265351e-08  1.000000e+00   \n",
       "9   2.043868e-14  1.000000e+00  9.999996e-01  9.999977e-01  5.957645e-07   \n",
       "10  1.000000e+00  1.000000e+00  1.123682e-09  1.000000e+00  1.000000e+00   \n",
       "11  1.922548e-02  4.084671e-09  1.000000e+00  8.547943e-08  1.145987e-05   \n",
       "12  1.000000e+00  1.000000e+00  3.410776e-08  1.425410e-12  5.564583e-13   \n",
       "13  1.000000e+00  9.999995e-01  4.110014e-13  1.000000e+00  9.984776e-01   \n",
       "14  1.000000e+00  1.000000e+00  1.190524e-14  1.000000e+00  9.999991e-01   \n",
       "15  2.860009e-08  3.666788e-08  2.244149e-08  9.999996e-01  9.997857e-01   \n",
       "16  8.022436e-13  1.000000e+00  2.989448e-15  1.000000e+00  9.926485e-06   \n",
       "17  9.999626e-01  9.999998e-01  6.194756e-05  6.132869e-05  1.926563e-06   \n",
       "18  9.992868e-01  6.696980e-07  4.658732e-09  2.876503e-08  1.000000e+00   \n",
       "19  3.186128e-06  9.980833e-01  5.984226e-07  1.235399e-06  1.613285e-06   \n",
       "\n",
       "            4995          4996          4997          4998          4999  \n",
       "0   6.114637e-09  3.915742e-09  1.046712e-12  9.975100e-01  9.999999e-01  \n",
       "1   6.959830e-15  2.689273e-12  9.999990e-01  1.000000e+00  2.578691e-07  \n",
       "2   9.608814e-21  4.042871e-12  9.999999e-01  1.000000e+00  1.000000e+00  \n",
       "3   6.640541e-09  9.999997e-01  2.296707e-05  1.000000e+00  9.997872e-01  \n",
       "4   3.215503e-08  2.011468e-04  3.064805e-04  6.523809e-07  1.184045e-04  \n",
       "5   1.000000e+00  1.000000e+00  9.975051e-01  2.286279e-05  3.689187e-12  \n",
       "6   2.895789e-03  9.999972e-01  9.998887e-01  3.699810e-05  9.999873e-01  \n",
       "7   1.000000e+00  9.999994e-01  6.022833e-10  1.006256e-06  9.189248e-09  \n",
       "8   3.029898e-10  9.999999e-01  9.985750e-01  1.000000e+00  9.999973e-01  \n",
       "9   6.663851e-02  1.000000e+00  9.999989e-01  1.292809e-05  9.999996e-01  \n",
       "10  9.785798e-01  1.000000e+00  1.000000e+00  1.000000e+00  9.999995e-01  \n",
       "11  9.999999e-01  7.157972e-05  9.999999e-01  9.498789e-01  1.000000e+00  \n",
       "12  1.000000e+00  8.888838e-01  5.791265e-09  1.000000e+00  9.998384e-01  \n",
       "13  5.993988e-10  1.757756e-10  1.000000e+00  4.458869e-06  3.823031e-11  \n",
       "14  9.782575e-09  8.394966e-02  1.000000e+00  3.922747e-03  1.000000e+00  \n",
       "15  1.000000e+00  9.999855e-01  7.968872e-06  9.999971e-01  1.000000e+00  \n",
       "16  9.999995e-01  1.000000e+00  1.000000e+00  8.091173e-13  2.101491e-26  \n",
       "17  1.903232e-10  3.629048e-05  3.849123e-04  9.999979e-01  9.987815e-01  \n",
       "18  1.000000e+00  5.108070e-06  6.862539e-10  9.250821e-15  5.566646e-07  \n",
       "19  1.415900e-04  9.999945e-01  1.036181e-07  1.000000e+00  1.000000e+00  \n",
       "\n",
       "[20 rows x 5000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred_list).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4dbf02a-2f09-40ee-a620-51aa1822d3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2271</th>\n",
       "      <th>2272</th>\n",
       "      <th>2273</th>\n",
       "      <th>2274</th>\n",
       "      <th>2275</th>\n",
       "      <th>2276</th>\n",
       "      <th>2277</th>\n",
       "      <th>2278</th>\n",
       "      <th>2279</th>\n",
       "      <th>2280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.273227</td>\n",
       "      <td>1.456176</td>\n",
       "      <td>1.714342</td>\n",
       "      <td>1.167481</td>\n",
       "      <td>1.291423</td>\n",
       "      <td>1.314084</td>\n",
       "      <td>1.478568</td>\n",
       "      <td>1.341347</td>\n",
       "      <td>1.867055</td>\n",
       "      <td>1.218742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387057</td>\n",
       "      <td>0.617674</td>\n",
       "      <td>0.485932</td>\n",
       "      <td>-0.735704</td>\n",
       "      <td>-0.275552</td>\n",
       "      <td>0.716748</td>\n",
       "      <td>-0.403787</td>\n",
       "      <td>-0.365568</td>\n",
       "      <td>-0.695516</td>\n",
       "      <td>-0.020497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.634331</td>\n",
       "      <td>1.709461</td>\n",
       "      <td>1.313607</td>\n",
       "      <td>1.399012</td>\n",
       "      <td>1.978154</td>\n",
       "      <td>1.488322</td>\n",
       "      <td>1.506199</td>\n",
       "      <td>1.558690</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>1.548079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490861</td>\n",
       "      <td>0.677688</td>\n",
       "      <td>0.405649</td>\n",
       "      <td>0.571978</td>\n",
       "      <td>0.397829</td>\n",
       "      <td>0.622126</td>\n",
       "      <td>0.780143</td>\n",
       "      <td>-0.562525</td>\n",
       "      <td>0.507592</td>\n",
       "      <td>0.008390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.308087</td>\n",
       "      <td>1.545860</td>\n",
       "      <td>1.570379</td>\n",
       "      <td>1.837858</td>\n",
       "      <td>1.582708</td>\n",
       "      <td>1.463777</td>\n",
       "      <td>1.472044</td>\n",
       "      <td>1.886343</td>\n",
       "      <td>1.327492</td>\n",
       "      <td>1.787939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362005</td>\n",
       "      <td>-0.610704</td>\n",
       "      <td>0.512364</td>\n",
       "      <td>0.264245</td>\n",
       "      <td>-0.504969</td>\n",
       "      <td>-0.093688</td>\n",
       "      <td>-0.323620</td>\n",
       "      <td>-0.561719</td>\n",
       "      <td>-0.442283</td>\n",
       "      <td>-0.005410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.448570</td>\n",
       "      <td>1.513339</td>\n",
       "      <td>1.374404</td>\n",
       "      <td>1.130764</td>\n",
       "      <td>1.329992</td>\n",
       "      <td>1.798237</td>\n",
       "      <td>1.195872</td>\n",
       "      <td>1.451789</td>\n",
       "      <td>1.149218</td>\n",
       "      <td>1.790473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521757</td>\n",
       "      <td>-0.382411</td>\n",
       "      <td>0.489943</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>0.575427</td>\n",
       "      <td>0.234203</td>\n",
       "      <td>0.454195</td>\n",
       "      <td>-0.310278</td>\n",
       "      <td>-0.510932</td>\n",
       "      <td>-0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.369443</td>\n",
       "      <td>1.265511</td>\n",
       "      <td>1.327023</td>\n",
       "      <td>1.326311</td>\n",
       "      <td>1.251862</td>\n",
       "      <td>1.635917</td>\n",
       "      <td>1.545733</td>\n",
       "      <td>1.274655</td>\n",
       "      <td>1.463871</td>\n",
       "      <td>1.375490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286706</td>\n",
       "      <td>0.415688</td>\n",
       "      <td>-0.305275</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>-0.063645</td>\n",
       "      <td>-0.169689</td>\n",
       "      <td>0.369789</td>\n",
       "      <td>-0.298626</td>\n",
       "      <td>0.323180</td>\n",
       "      <td>-0.010952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.461969</td>\n",
       "      <td>1.720233</td>\n",
       "      <td>1.537704</td>\n",
       "      <td>1.797598</td>\n",
       "      <td>1.412351</td>\n",
       "      <td>1.749615</td>\n",
       "      <td>1.409657</td>\n",
       "      <td>1.762415</td>\n",
       "      <td>1.479785</td>\n",
       "      <td>1.499247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.611237</td>\n",
       "      <td>-0.896081</td>\n",
       "      <td>0.610535</td>\n",
       "      <td>0.402509</td>\n",
       "      <td>0.417682</td>\n",
       "      <td>0.249992</td>\n",
       "      <td>-0.673877</td>\n",
       "      <td>0.267124</td>\n",
       "      <td>0.228789</td>\n",
       "      <td>-0.029592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.276650</td>\n",
       "      <td>1.013818</td>\n",
       "      <td>1.250898</td>\n",
       "      <td>1.314274</td>\n",
       "      <td>1.151043</td>\n",
       "      <td>1.106136</td>\n",
       "      <td>1.216790</td>\n",
       "      <td>1.246972</td>\n",
       "      <td>1.202147</td>\n",
       "      <td>1.125733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264400</td>\n",
       "      <td>0.232520</td>\n",
       "      <td>-0.236806</td>\n",
       "      <td>-0.236197</td>\n",
       "      <td>-0.346603</td>\n",
       "      <td>-0.074671</td>\n",
       "      <td>0.188674</td>\n",
       "      <td>0.371697</td>\n",
       "      <td>0.367823</td>\n",
       "      <td>0.009762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.587411</td>\n",
       "      <td>1.365236</td>\n",
       "      <td>1.999340</td>\n",
       "      <td>1.280902</td>\n",
       "      <td>1.472057</td>\n",
       "      <td>1.595768</td>\n",
       "      <td>1.455997</td>\n",
       "      <td>1.807051</td>\n",
       "      <td>1.417556</td>\n",
       "      <td>1.392983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766232</td>\n",
       "      <td>0.425392</td>\n",
       "      <td>-0.462283</td>\n",
       "      <td>0.402090</td>\n",
       "      <td>-0.536250</td>\n",
       "      <td>-0.479621</td>\n",
       "      <td>0.458906</td>\n",
       "      <td>-0.424887</td>\n",
       "      <td>0.471068</td>\n",
       "      <td>0.006290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.700307</td>\n",
       "      <td>1.677092</td>\n",
       "      <td>1.444550</td>\n",
       "      <td>1.377154</td>\n",
       "      <td>1.543291</td>\n",
       "      <td>1.429593</td>\n",
       "      <td>1.714550</td>\n",
       "      <td>1.602946</td>\n",
       "      <td>1.690839</td>\n",
       "      <td>1.846873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276569</td>\n",
       "      <td>-0.477766</td>\n",
       "      <td>-0.443003</td>\n",
       "      <td>0.528952</td>\n",
       "      <td>-0.840266</td>\n",
       "      <td>-0.478490</td>\n",
       "      <td>-0.058660</td>\n",
       "      <td>-0.643963</td>\n",
       "      <td>-0.801707</td>\n",
       "      <td>-0.000342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.421675</td>\n",
       "      <td>1.486324</td>\n",
       "      <td>1.242986</td>\n",
       "      <td>1.327877</td>\n",
       "      <td>1.194204</td>\n",
       "      <td>1.303395</td>\n",
       "      <td>1.670265</td>\n",
       "      <td>1.255335</td>\n",
       "      <td>1.376114</td>\n",
       "      <td>1.306573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284370</td>\n",
       "      <td>0.438770</td>\n",
       "      <td>0.380937</td>\n",
       "      <td>0.027612</td>\n",
       "      <td>0.452854</td>\n",
       "      <td>-0.393547</td>\n",
       "      <td>0.273923</td>\n",
       "      <td>-0.470944</td>\n",
       "      <td>0.172919</td>\n",
       "      <td>-0.036892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.580051</td>\n",
       "      <td>1.689077</td>\n",
       "      <td>1.583287</td>\n",
       "      <td>1.403570</td>\n",
       "      <td>1.563843</td>\n",
       "      <td>1.242344</td>\n",
       "      <td>1.633323</td>\n",
       "      <td>1.643067</td>\n",
       "      <td>1.485363</td>\n",
       "      <td>1.343517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.531214</td>\n",
       "      <td>-0.344257</td>\n",
       "      <td>-0.371489</td>\n",
       "      <td>-0.426873</td>\n",
       "      <td>0.497356</td>\n",
       "      <td>-0.220933</td>\n",
       "      <td>-0.386810</td>\n",
       "      <td>-0.447070</td>\n",
       "      <td>0.504636</td>\n",
       "      <td>-0.026681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.453268</td>\n",
       "      <td>1.749976</td>\n",
       "      <td>1.164000</td>\n",
       "      <td>1.417603</td>\n",
       "      <td>1.403816</td>\n",
       "      <td>1.773374</td>\n",
       "      <td>1.872750</td>\n",
       "      <td>1.641924</td>\n",
       "      <td>1.537451</td>\n",
       "      <td>1.670267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.491961</td>\n",
       "      <td>-0.498585</td>\n",
       "      <td>0.452627</td>\n",
       "      <td>0.336649</td>\n",
       "      <td>-0.625415</td>\n",
       "      <td>0.317801</td>\n",
       "      <td>-0.402708</td>\n",
       "      <td>-0.362181</td>\n",
       "      <td>0.300011</td>\n",
       "      <td>0.014595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.360483</td>\n",
       "      <td>1.480302</td>\n",
       "      <td>1.945223</td>\n",
       "      <td>1.459941</td>\n",
       "      <td>1.857001</td>\n",
       "      <td>1.673883</td>\n",
       "      <td>1.504753</td>\n",
       "      <td>1.602401</td>\n",
       "      <td>1.553182</td>\n",
       "      <td>1.911662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.599338</td>\n",
       "      <td>0.547487</td>\n",
       "      <td>-0.637832</td>\n",
       "      <td>0.561931</td>\n",
       "      <td>0.540708</td>\n",
       "      <td>-0.415512</td>\n",
       "      <td>-0.354037</td>\n",
       "      <td>-0.150797</td>\n",
       "      <td>0.392478</td>\n",
       "      <td>-0.011856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.319602</td>\n",
       "      <td>1.347438</td>\n",
       "      <td>1.541109</td>\n",
       "      <td>1.406957</td>\n",
       "      <td>1.225519</td>\n",
       "      <td>1.733951</td>\n",
       "      <td>1.406998</td>\n",
       "      <td>1.811859</td>\n",
       "      <td>2.088979</td>\n",
       "      <td>1.678082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334814</td>\n",
       "      <td>-0.391755</td>\n",
       "      <td>0.672867</td>\n",
       "      <td>0.479418</td>\n",
       "      <td>-0.332473</td>\n",
       "      <td>-0.328192</td>\n",
       "      <td>-0.395568</td>\n",
       "      <td>0.527840</td>\n",
       "      <td>-0.559489</td>\n",
       "      <td>-0.015078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.861394</td>\n",
       "      <td>1.215766</td>\n",
       "      <td>2.018729</td>\n",
       "      <td>1.355580</td>\n",
       "      <td>2.075874</td>\n",
       "      <td>1.515850</td>\n",
       "      <td>1.631849</td>\n",
       "      <td>1.388765</td>\n",
       "      <td>1.472106</td>\n",
       "      <td>1.988045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399157</td>\n",
       "      <td>0.635978</td>\n",
       "      <td>-0.187053</td>\n",
       "      <td>-0.575125</td>\n",
       "      <td>-0.697636</td>\n",
       "      <td>0.597432</td>\n",
       "      <td>0.431338</td>\n",
       "      <td>-0.458829</td>\n",
       "      <td>-0.506309</td>\n",
       "      <td>-0.038329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.526959</td>\n",
       "      <td>1.100469</td>\n",
       "      <td>1.104694</td>\n",
       "      <td>1.424305</td>\n",
       "      <td>1.517485</td>\n",
       "      <td>1.442641</td>\n",
       "      <td>1.419628</td>\n",
       "      <td>0.965907</td>\n",
       "      <td>1.402957</td>\n",
       "      <td>1.092704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331705</td>\n",
       "      <td>0.271088</td>\n",
       "      <td>-0.439825</td>\n",
       "      <td>-0.279989</td>\n",
       "      <td>-0.369878</td>\n",
       "      <td>0.310426</td>\n",
       "      <td>-0.338984</td>\n",
       "      <td>-0.095388</td>\n",
       "      <td>0.050582</td>\n",
       "      <td>-0.022118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.032374</td>\n",
       "      <td>1.628997</td>\n",
       "      <td>1.492254</td>\n",
       "      <td>1.312752</td>\n",
       "      <td>1.426947</td>\n",
       "      <td>1.694266</td>\n",
       "      <td>1.879384</td>\n",
       "      <td>2.007204</td>\n",
       "      <td>1.264665</td>\n",
       "      <td>1.339373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391947</td>\n",
       "      <td>0.603151</td>\n",
       "      <td>-0.379708</td>\n",
       "      <td>0.685926</td>\n",
       "      <td>0.512143</td>\n",
       "      <td>0.494793</td>\n",
       "      <td>-0.474546</td>\n",
       "      <td>-0.498098</td>\n",
       "      <td>0.755344</td>\n",
       "      <td>0.015539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.272590</td>\n",
       "      <td>1.864939</td>\n",
       "      <td>1.436486</td>\n",
       "      <td>1.362193</td>\n",
       "      <td>1.264216</td>\n",
       "      <td>1.451387</td>\n",
       "      <td>1.719966</td>\n",
       "      <td>1.311872</td>\n",
       "      <td>1.353081</td>\n",
       "      <td>1.399268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466371</td>\n",
       "      <td>0.497846</td>\n",
       "      <td>-0.464061</td>\n",
       "      <td>0.474795</td>\n",
       "      <td>-0.572525</td>\n",
       "      <td>-0.616272</td>\n",
       "      <td>0.456123</td>\n",
       "      <td>0.268169</td>\n",
       "      <td>-0.530397</td>\n",
       "      <td>0.016195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.328591</td>\n",
       "      <td>1.396890</td>\n",
       "      <td>1.578116</td>\n",
       "      <td>1.930361</td>\n",
       "      <td>1.956344</td>\n",
       "      <td>1.617549</td>\n",
       "      <td>1.604243</td>\n",
       "      <td>1.635098</td>\n",
       "      <td>1.435315</td>\n",
       "      <td>1.708827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380048</td>\n",
       "      <td>-0.252863</td>\n",
       "      <td>-0.379151</td>\n",
       "      <td>-0.364112</td>\n",
       "      <td>-0.274907</td>\n",
       "      <td>-0.185798</td>\n",
       "      <td>0.387862</td>\n",
       "      <td>-0.227268</td>\n",
       "      <td>0.854561</td>\n",
       "      <td>-0.049803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.405273</td>\n",
       "      <td>1.228139</td>\n",
       "      <td>1.180900</td>\n",
       "      <td>1.305109</td>\n",
       "      <td>1.169616</td>\n",
       "      <td>1.193897</td>\n",
       "      <td>1.250865</td>\n",
       "      <td>1.405355</td>\n",
       "      <td>1.285070</td>\n",
       "      <td>1.287494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322512</td>\n",
       "      <td>-0.417577</td>\n",
       "      <td>0.120519</td>\n",
       "      <td>0.271821</td>\n",
       "      <td>0.361118</td>\n",
       "      <td>0.200699</td>\n",
       "      <td>0.374089</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>0.288593</td>\n",
       "      <td>-0.008372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  2281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "0   1.273227  1.456176  1.714342  1.167481  1.291423  1.314084  1.478568   \n",
       "1   1.634331  1.709461  1.313607  1.399012  1.978154  1.488322  1.506199   \n",
       "2   1.308087  1.545860  1.570379  1.837858  1.582708  1.463777  1.472044   \n",
       "3   1.448570  1.513339  1.374404  1.130764  1.329992  1.798237  1.195872   \n",
       "4   1.369443  1.265511  1.327023  1.326311  1.251862  1.635917  1.545733   \n",
       "5   1.461969  1.720233  1.537704  1.797598  1.412351  1.749615  1.409657   \n",
       "6   1.276650  1.013818  1.250898  1.314274  1.151043  1.106136  1.216790   \n",
       "7   1.587411  1.365236  1.999340  1.280902  1.472057  1.595768  1.455997   \n",
       "8   1.700307  1.677092  1.444550  1.377154  1.543291  1.429593  1.714550   \n",
       "9   1.421675  1.486324  1.242986  1.327877  1.194204  1.303395  1.670265   \n",
       "10  1.580051  1.689077  1.583287  1.403570  1.563843  1.242344  1.633323   \n",
       "11  1.453268  1.749976  1.164000  1.417603  1.403816  1.773374  1.872750   \n",
       "12  1.360483  1.480302  1.945223  1.459941  1.857001  1.673883  1.504753   \n",
       "13  1.319602  1.347438  1.541109  1.406957  1.225519  1.733951  1.406998   \n",
       "14  1.861394  1.215766  2.018729  1.355580  2.075874  1.515850  1.631849   \n",
       "15  1.526959  1.100469  1.104694  1.424305  1.517485  1.442641  1.419628   \n",
       "16  2.032374  1.628997  1.492254  1.312752  1.426947  1.694266  1.879384   \n",
       "17  1.272590  1.864939  1.436486  1.362193  1.264216  1.451387  1.719966   \n",
       "18  1.328591  1.396890  1.578116  1.930361  1.956344  1.617549  1.604243   \n",
       "19  1.405273  1.228139  1.180900  1.305109  1.169616  1.193897  1.250865   \n",
       "\n",
       "        7         8         9     ...      2271      2272      2273      2274  \\\n",
       "0   1.341347  1.867055  1.218742  ... -0.387057  0.617674  0.485932 -0.735704   \n",
       "1   1.558690  1.309333  1.548079  ... -0.490861  0.677688  0.405649  0.571978   \n",
       "2   1.886343  1.327492  1.787939  ... -0.362005 -0.610704  0.512364  0.264245   \n",
       "3   1.451789  1.149218  1.790473  ...  0.521757 -0.382411  0.489943  0.205914   \n",
       "4   1.274655  1.463871  1.375490  ... -0.286706  0.415688 -0.305275  0.260771   \n",
       "5   1.762415  1.479785  1.499247  ... -0.611237 -0.896081  0.610535  0.402509   \n",
       "6   1.246972  1.202147  1.125733  ... -0.264400  0.232520 -0.236806 -0.236197   \n",
       "7   1.807051  1.417556  1.392983  ...  0.766232  0.425392 -0.462283  0.402090   \n",
       "8   1.602946  1.690839  1.846873  ... -0.276569 -0.477766 -0.443003  0.528952   \n",
       "9   1.255335  1.376114  1.306573  ... -0.284370  0.438770  0.380937  0.027612   \n",
       "10  1.643067  1.485363  1.343517  ... -0.531214 -0.344257 -0.371489 -0.426873   \n",
       "11  1.641924  1.537451  1.670267  ... -0.491961 -0.498585  0.452627  0.336649   \n",
       "12  1.602401  1.553182  1.911662  ... -0.599338  0.547487 -0.637832  0.561931   \n",
       "13  1.811859  2.088979  1.678082  ... -0.334814 -0.391755  0.672867  0.479418   \n",
       "14  1.388765  1.472106  1.988045  ...  0.399157  0.635978 -0.187053 -0.575125   \n",
       "15  0.965907  1.402957  1.092704  ...  0.331705  0.271088 -0.439825 -0.279989   \n",
       "16  2.007204  1.264665  1.339373  ... -0.391947  0.603151 -0.379708  0.685926   \n",
       "17  1.311872  1.353081  1.399268  ...  0.466371  0.497846 -0.464061  0.474795   \n",
       "18  1.635098  1.435315  1.708827  ... -0.380048 -0.252863 -0.379151 -0.364112   \n",
       "19  1.405355  1.285070  1.287494  ... -0.322512 -0.417577  0.120519  0.271821   \n",
       "\n",
       "        2275      2276      2277      2278      2279      2280  \n",
       "0  -0.275552  0.716748 -0.403787 -0.365568 -0.695516 -0.020497  \n",
       "1   0.397829  0.622126  0.780143 -0.562525  0.507592  0.008390  \n",
       "2  -0.504969 -0.093688 -0.323620 -0.561719 -0.442283 -0.005410  \n",
       "3   0.575427  0.234203  0.454195 -0.310278 -0.510932 -0.002442  \n",
       "4  -0.063645 -0.169689  0.369789 -0.298626  0.323180 -0.010952  \n",
       "5   0.417682  0.249992 -0.673877  0.267124  0.228789 -0.029592  \n",
       "6  -0.346603 -0.074671  0.188674  0.371697  0.367823  0.009762  \n",
       "7  -0.536250 -0.479621  0.458906 -0.424887  0.471068  0.006290  \n",
       "8  -0.840266 -0.478490 -0.058660 -0.643963 -0.801707 -0.000342  \n",
       "9   0.452854 -0.393547  0.273923 -0.470944  0.172919 -0.036892  \n",
       "10  0.497356 -0.220933 -0.386810 -0.447070  0.504636 -0.026681  \n",
       "11 -0.625415  0.317801 -0.402708 -0.362181  0.300011  0.014595  \n",
       "12  0.540708 -0.415512 -0.354037 -0.150797  0.392478 -0.011856  \n",
       "13 -0.332473 -0.328192 -0.395568  0.527840 -0.559489 -0.015078  \n",
       "14 -0.697636  0.597432  0.431338 -0.458829 -0.506309 -0.038329  \n",
       "15 -0.369878  0.310426 -0.338984 -0.095388  0.050582 -0.022118  \n",
       "16  0.512143  0.494793 -0.474546 -0.498098  0.755344  0.015539  \n",
       "17 -0.572525 -0.616272  0.456123  0.268169 -0.530397  0.016195  \n",
       "18 -0.274907 -0.185798  0.387862 -0.227268  0.854561 -0.049803  \n",
       "19  0.361118  0.200699  0.374089 -0.244372  0.288593 -0.008372  \n",
       "\n",
       "[20 rows x 2281 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(weights_list).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334925c3-84fb-4005-a6c5-da5915a5708a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32ac9b49-0daa-4851-8f77-56354ff8d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_predictions(weights_list, y_pred_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myBA",
   "language": "python",
   "name": "myba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
