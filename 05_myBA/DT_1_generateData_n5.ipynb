{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Generation for the Training of λ-Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:26:49.061308Z",
     "start_time": "2020-09-16T12:26:49.055692Z"
    }
   },
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnpassen: \\n\\nnumber_of_variables --> anzahl variablen\\nlambda_dataset_size --> datensatz größe für training von lambda-nets\\nnumber_of_generated_datasets --> anzahl der lambda-nets\\n\\nANMERKUNG: Hier werden die daten von make_classification nach dem generieren in [0,1] skaliert (das wäre evtl sinnvoll bei dir auch zu machen)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Anpassen: \n",
    "\n",
    "number_of_variables --> anzahl variablen\n",
    "lambda_dataset_size --> datensatz größe für training von lambda-nets\n",
    "number_of_generated_datasets --> anzahl der lambda-nets\n",
    "\n",
    "ANMERKUNG: Hier werden die daten von make_classification nach dem generieren in [0,1] skaliert (das wäre evtl sinnvoll bei dir auch zu machen)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 3,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,          \n",
    "        'dt_type': 'vanilla', #'vanilla', 'SDT'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 5, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [],\n",
    "        'random_parameters_distribution': True, ##MAKEPATH DIFFERENT FILES\n",
    "        'max_distributions_per_class': 1, # None; 0; int >= 1\n",
    "        'exclude_linearly_seperable': False,\n",
    "        'data_generation_filtering': False,\n",
    "        'fixed_class_probability': False,\n",
    "        'balanced_data': True,\n",
    "        'weighted_data_generation': False,\n",
    "        'shift_distrib': False,\n",
    "        \n",
    "        'function_generation_type': 'make_classification' ,#'distribution', 'distribution_trained' 'make_classification_distribution', 'make_classification_distribution_trained', 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'distribution_list': ['uniform', 'normal', 'gamma', 'beta', 'poisson'],#['uniform', 'normal', 'gamma', 'beta', 'poisson', 'lognormal', 'exponential', 'f', 'logistic', 'weibull'],#['uniform', 'normal', 'gamma', 'exponential', 'beta', 'binomial', 'poisson'], \n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        'number_of_generated_datasets': 45_000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "        \n",
    "        'data_noise': 0, #None or float\n",
    "        'distrib_param_max': 5,\n",
    "    }, \n",
    "    'computation':{\n",
    "        'n_jobs': 100,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '7',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:26:58.879427Z",
     "start_time": "2020-09-16T12:26:58.874894Z"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T21:12:40.476681Z",
     "start_time": "2021-01-13T21:12:38.298249Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from itertools import product       # forms cartesian products\n",
    "from more_itertools import random_product \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import random \n",
    "from random import sample \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sympy import Symbol, sympify\n",
    "\n",
    "        \n",
    "import seaborn as sns\n",
    "        \n",
    "import random \n",
    "\n",
    "import warnings\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from utilities.DecisionTree_BASIC import SDT\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.utility_functions import *\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='data_creation'))\n",
    "generate_directory_structure()\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numDatasets45000_var5_class2_make_classification_xMax1_xMin0_xDistuniform_dNoise0_randParamDist_maxDistClass1_distribParamMax5_randClassProb\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_function_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T12:28:46.853042Z",
     "start_time": "2020-09-16T12:28:46.848346Z"
    }
   },
   "source": [
    "# Function Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=100)]: Using backend LokyBackend with 100 concurrent workers.\n",
      "[Parallel(n_jobs=100)]: Done  88 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=100)]: Done 318 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=100)]: Done 1073 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=100)]: Done 3369 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=100)]: Done 6396 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=100)]: Done 9984 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=100)]: Done 14336 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=100)]: Done 19200 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=100)]: Done 24576 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=100)]: Done 30464 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=100)]: Done 36864 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=100)]: Done 43776 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=100)]: Done 45000 out of 45000 | elapsed:   35.6s finished\n"
     ]
    }
   ],
   "source": [
    "if function_generation_type == 'random_decision_tree':\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    result_list = parallel(delayed(generate_data_random_decision_tree)(config, seed=RANDOM_SEED+i) for i in range(number_of_generated_datasets))\n",
    "elif function_generation_type == 'random_decision_tree_trained':\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    result_list = parallel(delayed(generate_data_random_decision_tree_trained)(config, seed=RANDOM_SEED+i) for i in range(number_of_generated_datasets))  \n",
    "elif function_generation_type == 'make_classification':\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    result_list = parallel(delayed(generate_data_make_classification)(config, seed=RANDOM_SEED+i) for i in range(number_of_generated_datasets)) \n",
    "elif function_generation_type == 'make_classification_trained':\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    result_list = parallel(delayed(generate_data_make_classification_decision_tree_trained)(config, seed=RANDOM_SEED+i) for i in range(number_of_generated_datasets))    \n",
    "elif function_generation_type == 'make_classification_distribution':\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    result_list = parallel(delayed(generate_data_make_classification_distribution)(config, seed=RANDOM_SEED+i) for i in range(number_of_generated_datasets)) \n",
    "elif function_generation_type == 'make_classification_distribution_trained':\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    result_list = parallel(delayed(generate_data_make_classification_distribution_decision_tree_trained)(config, seed=RANDOM_SEED+i) for i in range(number_of_generated_datasets))    \n",
    "elif function_generation_type == 'distribution':\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #sequential\n",
    "    result_list = parallel(delayed(generate_data_distribution)(config, \n",
    "                                                              seed=RANDOM_SEED+i, \n",
    "                                                              max_distributions_per_class=max_distributions_per_class, \n",
    "                                                              random_parameters=random_parameters_distribution,\n",
    "                                                              data_noise=data_noise) for i in range(number_of_generated_datasets))    #, distribution_list = ['uniform']\n",
    "elif function_generation_type == 'distribution_trained':\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky')\n",
    "    result_list = parallel(delayed(generate_data_distribution_trained)(config, \n",
    "                                                                      seed=RANDOM_SEED+i, \n",
    "                                                                      max_distributions_per_class=max_distributions_per_class, \n",
    "                                                                      random_parameters=random_parameters_distribution,\n",
    "                                                                      data_noise=data_noise) for i in range(number_of_generated_datasets))    #, distribution_list = ['uniform']\n",
    "    \n",
    "    \n",
    "function_identifier_list = generate_decision_tree_identifier(config)  \n",
    "identifier_series_list = [pd.Series(result[0],  index=function_identifier_list) for result in result_list]\n",
    "\n",
    "function_df = pd.DataFrame(data=np.array([result[0] for result in result_list]), columns=function_identifier_list)\n",
    "\n",
    "X_data_list = [[identifier_series, pd.DataFrame(result[1], columns=['x' + str(i) for i in range(number_of_variables)])] for identifier_series, result in zip(identifier_series_list, result_list)]\n",
    "y_data_list = [[identifier_series, pd.DataFrame(result[2], columns=['result'])] for identifier_series, result in zip(identifier_series_list, result_list)]\n",
    "y_data_raw_list = [[identifier_series, pd.DataFrame(result[3], columns=['result_raw'])] for identifier_series, result in zip(identifier_series_list, result_list)]\n",
    "try:\n",
    "    distribution_parameter_list_list =[[identifier_series, result[4]] for identifier_series, result in zip(identifier_series_list, result_list)]\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T12:59:22.156778Z",
     "start_time": "2021-01-14T12:57:34.187753Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_functions = './data/saved_function_lists/functions_' + path_identifier_function_data + '.csv'\n",
    "function_df.to_csv(path_functions, index=False)\n",
    "\n",
    "path_X_data = './data/saved_function_lists/X_data_' + path_identifier_function_data + '.pkl'\n",
    "with open(path_X_data, 'wb') as f:\n",
    "    pickle.dump(X_data_list, f)\n",
    "    \n",
    "path_y_data = './data/saved_function_lists/y_data_' + path_identifier_function_data + '.pkl'\n",
    "with open(path_y_data, 'wb') as f:\n",
    "    pickle.dump(y_data_list, f)\n",
    "\n",
    "try:\n",
    "    path_distribution = './data/saved_function_lists/distribution_parameter_list_list_' + path_identifier_function_data + '.pkl'\n",
    "    with open(path_distribution, 'wb') as f:\n",
    "        pickle.dump(distribution_parameter_list_list, f)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myBA",
   "language": "python",
   "name": "myba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
