{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.6 (default, Aug 18 2021, 19:38:01) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 4,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'vanilla', #'vanilla', 'SDT'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 66, \n",
    "        'num_classes': 2,\n",
    "        \n",
    "        'function_generation_type': 'make_classification_vanilla_decision_tree_trained', # 'make_classification' 'random_decision_tree' 'random_decision_tree_trained' 'random_vanilla_decision_tree_trained' 'make_classification_vanilla_decision_tree_trained'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [256],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [512, 1024],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.5, 0],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.001,\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': ['binary_accuracy'],\n",
    "        \n",
    "        'epochs': 200, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 64,\n",
    "\n",
    "        'interpretation_dataset_size': 10000,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 2, # 1=standard representation; 2=sparse representation\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "                      \n",
    "        'data_reshape_version': 0, #default to 2 options:(None, 0,1 2)\n",
    "        \n",
    "        'nas': True,\n",
    "        'nas_type': 'CNN', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 25,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 1000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 500,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 500,\n",
    "            \n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        \n",
    "        'n_jobs': -3,\n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '0',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 11:46:23.363140: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "#from prettytable import PrettyTable\n",
    "#import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "\n",
    "#from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import random \n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/lib/cuda-10.1'\n",
    "\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = (2 ** maximum_depth - 1) * number_of_variables + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else None\n",
    "                                                            )\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets10000_var66_class2_make_classification_vanilla_decision_tree_trained_xMax1_xMin0_xDistuniform_depth4_beta1_decisionSpars1_fullyGrown/256_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense512-1024_drop0.5-0e200b64_adam\n",
      "lNetSize5000_numLNets10000_var66_class2_make_classification_vanilla_decision_tree_trained_xMax1_xMin0_xDistuniform_depth4_beta1_decisionSpars1_fullyGrown/256_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 11:46:27.075967: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    path_X_data = directory + 'X_test_lambda.txt'\n",
    "    path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    \n",
    "    X_test_lambda = pd.read_csv(path_X_data, sep=\",\", header=None)\n",
    "    X_test_lambda = X_test_lambda.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        X_test_lambda = X_test_lambda.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    \n",
    "    y_test_lambda = pd.read_csv(path_y_data, sep=\",\", header=None)\n",
    "    y_test_lambda = y_test_lambda.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        y_test_lambda = y_test_lambda.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "        \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              X_test_lambda_row, \n",
    "                                              y_test_lambda_row, \n",
    "                                              config) for network_parameters_row, X_test_lambda_row, y_test_lambda_row in zip(network_parameters.values, X_test_lambda.values, y_test_lambda.values))          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "        lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    _ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    del parallel\n",
    "    \n",
    "    def initialize_target_function_wrapper(config, lambda_net):\n",
    "        lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    _ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    del parallel\n",
    "        \n",
    "    \n",
    "    #lambda_nets = [None] * network_parameters.shape[0]\n",
    "    #for i, (network_parameters_row, X_test_lambda_row, y_test_lambda_row) in tqdm(enumerate(zip(network_parameters.values, X_test_lambda.values, y_test_lambda.values)), total=network_parameters.values.shape[0]):        \n",
    "    #    lambda_net = LambdaNet(network_parameters_row, X_test_lambda_row, y_test_lambda_row, config)\n",
    "    #    lambda_nets[i] = lambda_net\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 11:46:27.145204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-09-13 11:46:27.145244: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 11:46:27.153336: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-13 11:46:27.153387: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-13 11:46:27.155064: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-13 11:46:27.156026: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-13 11:46:27.157413: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-09-13 11:46:27.159132: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-13 11:46:27.159286: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-13 11:46:27.160954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 78 concurrent workers.\n",
      "2021-09-13 12:15:39.438168: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.439423: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.439580: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.439967: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.441705: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.442310: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.449644: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.454703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.454869: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.455391: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.455644: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.457190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.457366: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.458064: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.463411: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.463409: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.477051: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.483625: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.518173: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.541370: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.561722: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.561751: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.561756: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.561849: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.561852: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.573382: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.573526: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.573620: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.573683: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.573720: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.573763: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.573937: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.573953: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.574307: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.574556: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.575256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.575831: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576118: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576208: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576233: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576277: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576305: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576435: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576638: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576764: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576876: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576887: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576936: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.576960: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577026: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577149: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577275: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577323: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577476: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577659: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577688: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577739: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.577974: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.578231: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.578371: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.578384: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.578497: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.578679: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.579275: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.579787: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.580419: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.581725: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.581813: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.582674: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.583459: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.584197: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.586120: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.590787: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.609131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.609135: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.609273: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.627911: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:15:39.700841: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "[Parallel(n_jobs=-3)]: Done 132 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-3)]: Done 356 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-3)]: Done 644 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-3)]: Done 996 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-3)]: Done 1412 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-3)]: Done 1892 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-3)]: Done 2436 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-3)]: Done 3044 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-3)]: Done 3716 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-3)]: Done 4452 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-3)]: Done 5252 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-3)]: Done 6116 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-3)]: Done 7044 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-3)]: Done 8036 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-3)]: Done 9092 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-3)]: Done 10000 out of 10000 | elapsed:  1.8min finished\n",
      "2021-09-13 12:16:40.688417: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[Parallel(n_jobs=-3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "2021-09-13 12:16:40.697397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-09-13 12:16:40.699387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-09-13 12:16:40.699472: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:16:41.270478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-13 12:16:41.270517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-09-13 12:16:41.270524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-09-13 12:16:41.273053: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth sett[Parallel(n_jobs=-3)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "ing because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-09-13 12:16:41.273088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9658 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 10000 out of 10000 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=-3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 10000 out of 10000 | elapsed:   22.7s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "\n",
    "    lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "    lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)    \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8955, 18448)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 18448)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18448)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f0v30</th>\n",
       "      <th>f0v31</th>\n",
       "      <th>f0v32</th>\n",
       "      <th>f0v33</th>\n",
       "      <th>f0v34</th>\n",
       "      <th>f0v35</th>\n",
       "      <th>f0v36</th>\n",
       "      <th>f0v37</th>\n",
       "      <th>f0v38</th>\n",
       "      <th>f0v39</th>\n",
       "      <th>f0v40</th>\n",
       "      <th>f0v41</th>\n",
       "      <th>f0v42</th>\n",
       "      <th>f0v43</th>\n",
       "      <th>f0v44</th>\n",
       "      <th>f0v45</th>\n",
       "      <th>f0v46</th>\n",
       "      <th>f0v47</th>\n",
       "      <th>f0v48</th>\n",
       "      <th>f0v49</th>\n",
       "      <th>f0v50</th>\n",
       "      <th>f0v51</th>\n",
       "      <th>f0v52</th>\n",
       "      <th>f0v53</th>\n",
       "      <th>f0v54</th>\n",
       "      <th>f0v55</th>\n",
       "      <th>f0v56</th>\n",
       "      <th>f0v57</th>\n",
       "      <th>f0v58</th>\n",
       "      <th>f0v59</th>\n",
       "      <th>f0v60</th>\n",
       "      <th>f0v61</th>\n",
       "      <th>f0v62</th>\n",
       "      <th>f0v63</th>\n",
       "      <th>f0v64</th>\n",
       "      <th>f0v65</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f1v30</th>\n",
       "      <th>f1v31</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_17309</th>\n",
       "      <th>wb_17310</th>\n",
       "      <th>wb_17311</th>\n",
       "      <th>wb_17312</th>\n",
       "      <th>wb_17313</th>\n",
       "      <th>wb_17314</th>\n",
       "      <th>wb_17315</th>\n",
       "      <th>wb_17316</th>\n",
       "      <th>wb_17317</th>\n",
       "      <th>wb_17318</th>\n",
       "      <th>wb_17319</th>\n",
       "      <th>wb_17320</th>\n",
       "      <th>wb_17321</th>\n",
       "      <th>wb_17322</th>\n",
       "      <th>wb_17323</th>\n",
       "      <th>wb_17324</th>\n",
       "      <th>wb_17325</th>\n",
       "      <th>wb_17326</th>\n",
       "      <th>wb_17327</th>\n",
       "      <th>wb_17328</th>\n",
       "      <th>wb_17329</th>\n",
       "      <th>wb_17330</th>\n",
       "      <th>wb_17331</th>\n",
       "      <th>wb_17332</th>\n",
       "      <th>wb_17333</th>\n",
       "      <th>wb_17334</th>\n",
       "      <th>wb_17335</th>\n",
       "      <th>wb_17336</th>\n",
       "      <th>wb_17337</th>\n",
       "      <th>wb_17338</th>\n",
       "      <th>wb_17339</th>\n",
       "      <th>wb_17340</th>\n",
       "      <th>wb_17341</th>\n",
       "      <th>wb_17342</th>\n",
       "      <th>wb_17343</th>\n",
       "      <th>wb_17344</th>\n",
       "      <th>wb_17345</th>\n",
       "      <th>wb_17346</th>\n",
       "      <th>wb_17347</th>\n",
       "      <th>wb_17348</th>\n",
       "      <th>wb_17349</th>\n",
       "      <th>wb_17350</th>\n",
       "      <th>wb_17351</th>\n",
       "      <th>wb_17352</th>\n",
       "      <th>wb_17353</th>\n",
       "      <th>wb_17354</th>\n",
       "      <th>wb_17355</th>\n",
       "      <th>wb_17356</th>\n",
       "      <th>wb_17357</th>\n",
       "      <th>wb_17358</th>\n",
       "      <th>wb_17359</th>\n",
       "      <th>wb_17360</th>\n",
       "      <th>wb_17361</th>\n",
       "      <th>wb_17362</th>\n",
       "      <th>wb_17363</th>\n",
       "      <th>wb_17364</th>\n",
       "      <th>wb_17365</th>\n",
       "      <th>wb_17366</th>\n",
       "      <th>wb_17367</th>\n",
       "      <th>wb_17368</th>\n",
       "      <th>wb_17369</th>\n",
       "      <th>wb_17370</th>\n",
       "      <th>wb_17371</th>\n",
       "      <th>wb_17372</th>\n",
       "      <th>wb_17373</th>\n",
       "      <th>wb_17374</th>\n",
       "      <th>wb_17375</th>\n",
       "      <th>wb_17376</th>\n",
       "      <th>wb_17377</th>\n",
       "      <th>wb_17378</th>\n",
       "      <th>wb_17379</th>\n",
       "      <th>wb_17380</th>\n",
       "      <th>wb_17381</th>\n",
       "      <th>wb_17382</th>\n",
       "      <th>wb_17383</th>\n",
       "      <th>wb_17384</th>\n",
       "      <th>wb_17385</th>\n",
       "      <th>wb_17386</th>\n",
       "      <th>wb_17387</th>\n",
       "      <th>wb_17388</th>\n",
       "      <th>wb_17389</th>\n",
       "      <th>wb_17390</th>\n",
       "      <th>wb_17391</th>\n",
       "      <th>wb_17392</th>\n",
       "      <th>wb_17393</th>\n",
       "      <th>wb_17394</th>\n",
       "      <th>wb_17395</th>\n",
       "      <th>wb_17396</th>\n",
       "      <th>wb_17397</th>\n",
       "      <th>wb_17398</th>\n",
       "      <th>wb_17399</th>\n",
       "      <th>wb_17400</th>\n",
       "      <th>wb_17401</th>\n",
       "      <th>wb_17402</th>\n",
       "      <th>wb_17403</th>\n",
       "      <th>wb_17404</th>\n",
       "      <th>wb_17405</th>\n",
       "      <th>wb_17406</th>\n",
       "      <th>wb_17407</th>\n",
       "      <th>wb_17408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>6671.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>3274.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>3095.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>8379.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>3043.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  18448 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "6671 6671.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 3274.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 3095.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 8379.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 3043.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  \\\n",
       "6671 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v19  f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  \\\n",
       "6671  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v29  f0v30  f0v31  f0v32  f0v33  f0v34  f0v35  f0v36  f0v37  f0v38  \\\n",
       "6671  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v39  f0v40  f0v41  f0v42  f0v43  f0v44  f0v45  f0v46  f0v47  f0v48  \\\n",
       "6671  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v49  f0v50  f0v51  f0v52  f0v53  f0v54  f0v55  f0v56  f0v57  f0v58  \\\n",
       "6671  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v59  f0v60  f0v61  f0v62  f0v63  f0v64  f0v65  f1v0  f1v1  f1v2  f1v3  \\\n",
       "6671  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "3274  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "3095  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "8379  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "3043  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  f1v10  f1v11  f1v12  f1v13  f1v14  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v15  f1v16  f1v17  f1v18  f1v19  f1v20  f1v21  f1v22  f1v23  f1v24  \\\n",
       "6671  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v25  f1v26  f1v27  f1v28  f1v29  f1v30  f1v31  ...  wb_17309  \\\n",
       "6671  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.253   \n",
       "3274  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.130   \n",
       "3095  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.257   \n",
       "8379  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.127   \n",
       "3043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.316   \n",
       "\n",
       "      wb_17310  wb_17311  wb_17312  wb_17313  wb_17314  wb_17315  wb_17316  \\\n",
       "6671    -0.069    -0.146    -0.072    -0.074    -0.142     0.070     0.025   \n",
       "3274    -0.286    -0.143    -0.173    -0.315    -0.142     0.070     0.025   \n",
       "3095    -0.213    -0.142    -0.199    -0.074    -0.142     0.070     0.025   \n",
       "8379     0.005    -0.138    -0.102    -0.074    -0.142     0.070     0.105   \n",
       "3043    -0.244    -0.225    -0.073    -0.074    -0.142     0.070     0.023   \n",
       "\n",
       "      wb_17317  wb_17318  wb_17319  wb_17320  wb_17321  wb_17322  wb_17323  \\\n",
       "6671     0.124    -0.108    -0.090     0.106    -0.115    -0.093    -0.147   \n",
       "3274     0.200    -0.108    -0.209     0.148    -0.111    -0.099    -0.046   \n",
       "3095     0.223    -0.108    -0.077     0.262    -0.121    -0.258    -0.130   \n",
       "8379     0.177    -0.309    -0.173     0.093    -0.035    -0.092    -0.205   \n",
       "3043     0.207    -0.108    -0.204     0.164    -0.113    -0.111    -0.064   \n",
       "\n",
       "      wb_17324  wb_17325  wb_17326  wb_17327  wb_17328  wb_17329  wb_17330  \\\n",
       "6671     0.025    -0.068    -0.166    -0.105    -0.137    -0.108     0.248   \n",
       "3274     0.025    -0.258    -0.171    -0.107    -0.137    -0.073     0.329   \n",
       "3095     0.029    -0.204    -0.143    -0.293    -0.137    -0.099     0.279   \n",
       "8379     0.184    -0.122    -0.062    -0.273    -0.137    -0.076     0.144   \n",
       "3043     0.033    -0.166    -0.131    -0.105    -0.137    -0.155     0.141   \n",
       "\n",
       "      wb_17331  wb_17332  wb_17333  wb_17334  wb_17335  wb_17336  wb_17337  \\\n",
       "6671    -0.143    -0.039    -0.121    -0.116     0.121     0.215    -0.151   \n",
       "3274    -0.134    -0.039    -0.119    -0.164     0.121     0.177    -0.152   \n",
       "3095    -0.298    -0.039    -0.121    -0.122     0.086     0.151    -0.330   \n",
       "8379    -0.288    -0.039    -0.121    -0.057     0.203     0.096    -0.270   \n",
       "3043    -0.141    -0.039    -0.119    -0.110     0.206     0.050    -0.144   \n",
       "\n",
       "      wb_17338  wb_17339  wb_17340  wb_17341  wb_17342  wb_17343  wb_17344  \\\n",
       "6671     0.255    -0.042    -0.141    -0.159    -0.162    -0.014     0.262   \n",
       "3274     0.300    -0.042    -0.006    -0.213     0.144    -0.014     0.069   \n",
       "3095     0.139    -0.042    -0.003    -0.129    -0.179    -0.014     0.069   \n",
       "8379     0.301    -0.042     0.166    -0.073     0.162    -0.014     0.071   \n",
       "3043     0.309    -0.042     0.162    -0.217    -0.143    -0.014     0.069   \n",
       "\n",
       "      wb_17345  wb_17346  wb_17347  wb_17348  wb_17349  wb_17350  wb_17351  \\\n",
       "6671    -0.091    -0.058     0.085     0.052     0.014    -0.042    -0.025   \n",
       "3274    -0.091    -0.058     0.162     0.244     0.014    -0.042    -0.171   \n",
       "3095    -0.091    -0.058     0.084     0.112     0.014    -0.193    -0.189   \n",
       "8379    -0.091    -0.058     0.078     0.187     0.014    -0.248    -0.253   \n",
       "3043    -0.091    -0.058     0.211     0.229     0.014    -0.053    -0.023   \n",
       "\n",
       "      wb_17352  wb_17353  wb_17354  wb_17355  wb_17356  wb_17357  wb_17358  \\\n",
       "6671     0.181    -0.151    -0.019     0.135     0.196    -0.193     0.111   \n",
       "3274     0.160    -0.304    -0.159     0.135     0.236    -0.183     0.111   \n",
       "3095     0.114     0.177    -0.187     0.135     0.126    -0.162     0.114   \n",
       "8379     0.141     0.123    -0.014     0.135     0.245    -0.168     0.274   \n",
       "3043     0.281    -0.258    -0.016     0.135     0.098    -0.105     0.109   \n",
       "\n",
       "      wb_17359  wb_17360  wb_17361  wb_17362  wb_17363  wb_17364  wb_17365  \\\n",
       "6671     0.118     0.149    -0.158     0.174    -0.032     0.111     0.144   \n",
       "3274    -0.195     0.221    -0.172     0.180    -0.032     0.120     0.350   \n",
       "3095     0.210     0.166    -0.018     0.105    -0.032     0.107     0.138   \n",
       "8379    -0.221     0.206     0.090     0.313    -0.032     0.125     0.141   \n",
       "3043     0.141     0.156    -0.179     0.248    -0.032     0.297     0.139   \n",
       "\n",
       "      wb_17366  wb_17367  wb_17368  wb_17369  wb_17370  wb_17371  wb_17372  \\\n",
       "6671     0.009     0.094     0.229    -0.167    -0.128    -0.157     0.186   \n",
       "3274     0.143     0.229     0.332    -0.215    -0.170    -0.255     0.223   \n",
       "3095     0.010     0.091     0.341    -0.176    -0.094    -0.197     0.235   \n",
       "8379     0.137     0.109     0.127    -0.127    -0.050    -0.169     0.173   \n",
       "3043     0.007     0.086     0.236    -0.176    -0.124    -0.229     0.169   \n",
       "\n",
       "      wb_17373  wb_17374  wb_17375  wb_17376  wb_17377  wb_17378  wb_17379  \\\n",
       "6671     0.131     0.164     0.008     0.017     0.109     0.094     0.071   \n",
       "3274     0.131    -0.092     0.011     0.017     0.083     0.170     0.076   \n",
       "3095     0.131     0.003     0.005     0.017     0.054     0.020     0.067   \n",
       "8379     0.131    -0.142     0.150     0.017     0.002     0.107     0.234   \n",
       "3043     0.131    -0.227     0.008     0.017     0.215     0.201     0.241   \n",
       "\n",
       "      wb_17380  wb_17381  wb_17382  wb_17383  wb_17384  wb_17385  wb_17386  \\\n",
       "6671    -0.061    -0.193     0.189    -0.156     0.209    -0.174     0.190   \n",
       "3274    -0.060    -0.051     0.148    -0.144     0.238    -0.169     0.062   \n",
       "3095    -0.240    -0.055     0.192    -0.291     0.188    -0.024     0.261   \n",
       "8379    -0.066    -0.053     0.168    -0.141     0.135    -0.024     0.067   \n",
       "3043    -0.064    -0.053     0.152    -0.141     0.062    -0.125     0.149   \n",
       "\n",
       "      wb_17387  wb_17388  wb_17389  wb_17390  wb_17391  wb_17392  wb_17393  \\\n",
       "6671     0.041    -0.143    -0.075    -0.012     0.205     0.204     0.050   \n",
       "3274     0.041    -0.196    -0.081    -0.012     0.083     0.010     0.050   \n",
       "3095     0.041    -0.219    -0.072    -0.012     0.075     0.024     0.050   \n",
       "8379     0.041    -0.199    -0.180    -0.012     0.200     0.006     0.043   \n",
       "3043     0.041    -0.172    -0.202    -0.012     0.182     0.010     0.050   \n",
       "\n",
       "      wb_17394  wb_17395  wb_17396  wb_17397  wb_17398  wb_17399  wb_17400  \\\n",
       "6671     0.130    -0.097    -0.046    -0.218    -0.116    -0.105     0.191   \n",
       "3274     0.140    -0.105    -0.046    -0.231    -0.109    -0.107     0.222   \n",
       "3095     0.269    -0.208    -0.046    -0.125    -0.117    -0.106     0.215   \n",
       "8379     0.248    -0.227    -0.046    -0.305    -0.104    -0.106     0.255   \n",
       "3043     0.122    -0.104    -0.046    -0.129    -0.149    -0.104     0.148   \n",
       "\n",
       "      wb_17401  wb_17402  wb_17403  wb_17404  wb_17405  wb_17406  wb_17407  \\\n",
       "6671     0.129     0.238    -0.098     0.120    -0.164    -0.124     0.217   \n",
       "3274     0.277     0.239    -0.135     0.215    -0.161    -0.125     0.131   \n",
       "3095     0.192     0.107    -0.155     0.266    -0.126    -0.125     0.251   \n",
       "8379    -0.176     0.096    -0.154     0.066    -0.144    -0.125     0.231   \n",
       "3043    -0.187     0.291    -0.113     0.205    -0.126    -0.125     0.123   \n",
       "\n",
       "      wb_17408  \n",
       "6671     0.011  \n",
       "3274    -0.021  \n",
       "3095     0.007  \n",
       "8379    -0.022  \n",
       "3043    -0.008  \n",
       "\n",
       "[5 rows x 18448 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f0v30</th>\n",
       "      <th>f0v31</th>\n",
       "      <th>f0v32</th>\n",
       "      <th>f0v33</th>\n",
       "      <th>f0v34</th>\n",
       "      <th>f0v35</th>\n",
       "      <th>f0v36</th>\n",
       "      <th>f0v37</th>\n",
       "      <th>f0v38</th>\n",
       "      <th>f0v39</th>\n",
       "      <th>f0v40</th>\n",
       "      <th>f0v41</th>\n",
       "      <th>f0v42</th>\n",
       "      <th>f0v43</th>\n",
       "      <th>f0v44</th>\n",
       "      <th>f0v45</th>\n",
       "      <th>f0v46</th>\n",
       "      <th>f0v47</th>\n",
       "      <th>f0v48</th>\n",
       "      <th>f0v49</th>\n",
       "      <th>f0v50</th>\n",
       "      <th>f0v51</th>\n",
       "      <th>f0v52</th>\n",
       "      <th>f0v53</th>\n",
       "      <th>f0v54</th>\n",
       "      <th>f0v55</th>\n",
       "      <th>f0v56</th>\n",
       "      <th>f0v57</th>\n",
       "      <th>f0v58</th>\n",
       "      <th>f0v59</th>\n",
       "      <th>f0v60</th>\n",
       "      <th>f0v61</th>\n",
       "      <th>f0v62</th>\n",
       "      <th>f0v63</th>\n",
       "      <th>f0v64</th>\n",
       "      <th>f0v65</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f1v30</th>\n",
       "      <th>f1v31</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_17309</th>\n",
       "      <th>wb_17310</th>\n",
       "      <th>wb_17311</th>\n",
       "      <th>wb_17312</th>\n",
       "      <th>wb_17313</th>\n",
       "      <th>wb_17314</th>\n",
       "      <th>wb_17315</th>\n",
       "      <th>wb_17316</th>\n",
       "      <th>wb_17317</th>\n",
       "      <th>wb_17318</th>\n",
       "      <th>wb_17319</th>\n",
       "      <th>wb_17320</th>\n",
       "      <th>wb_17321</th>\n",
       "      <th>wb_17322</th>\n",
       "      <th>wb_17323</th>\n",
       "      <th>wb_17324</th>\n",
       "      <th>wb_17325</th>\n",
       "      <th>wb_17326</th>\n",
       "      <th>wb_17327</th>\n",
       "      <th>wb_17328</th>\n",
       "      <th>wb_17329</th>\n",
       "      <th>wb_17330</th>\n",
       "      <th>wb_17331</th>\n",
       "      <th>wb_17332</th>\n",
       "      <th>wb_17333</th>\n",
       "      <th>wb_17334</th>\n",
       "      <th>wb_17335</th>\n",
       "      <th>wb_17336</th>\n",
       "      <th>wb_17337</th>\n",
       "      <th>wb_17338</th>\n",
       "      <th>wb_17339</th>\n",
       "      <th>wb_17340</th>\n",
       "      <th>wb_17341</th>\n",
       "      <th>wb_17342</th>\n",
       "      <th>wb_17343</th>\n",
       "      <th>wb_17344</th>\n",
       "      <th>wb_17345</th>\n",
       "      <th>wb_17346</th>\n",
       "      <th>wb_17347</th>\n",
       "      <th>wb_17348</th>\n",
       "      <th>wb_17349</th>\n",
       "      <th>wb_17350</th>\n",
       "      <th>wb_17351</th>\n",
       "      <th>wb_17352</th>\n",
       "      <th>wb_17353</th>\n",
       "      <th>wb_17354</th>\n",
       "      <th>wb_17355</th>\n",
       "      <th>wb_17356</th>\n",
       "      <th>wb_17357</th>\n",
       "      <th>wb_17358</th>\n",
       "      <th>wb_17359</th>\n",
       "      <th>wb_17360</th>\n",
       "      <th>wb_17361</th>\n",
       "      <th>wb_17362</th>\n",
       "      <th>wb_17363</th>\n",
       "      <th>wb_17364</th>\n",
       "      <th>wb_17365</th>\n",
       "      <th>wb_17366</th>\n",
       "      <th>wb_17367</th>\n",
       "      <th>wb_17368</th>\n",
       "      <th>wb_17369</th>\n",
       "      <th>wb_17370</th>\n",
       "      <th>wb_17371</th>\n",
       "      <th>wb_17372</th>\n",
       "      <th>wb_17373</th>\n",
       "      <th>wb_17374</th>\n",
       "      <th>wb_17375</th>\n",
       "      <th>wb_17376</th>\n",
       "      <th>wb_17377</th>\n",
       "      <th>wb_17378</th>\n",
       "      <th>wb_17379</th>\n",
       "      <th>wb_17380</th>\n",
       "      <th>wb_17381</th>\n",
       "      <th>wb_17382</th>\n",
       "      <th>wb_17383</th>\n",
       "      <th>wb_17384</th>\n",
       "      <th>wb_17385</th>\n",
       "      <th>wb_17386</th>\n",
       "      <th>wb_17387</th>\n",
       "      <th>wb_17388</th>\n",
       "      <th>wb_17389</th>\n",
       "      <th>wb_17390</th>\n",
       "      <th>wb_17391</th>\n",
       "      <th>wb_17392</th>\n",
       "      <th>wb_17393</th>\n",
       "      <th>wb_17394</th>\n",
       "      <th>wb_17395</th>\n",
       "      <th>wb_17396</th>\n",
       "      <th>wb_17397</th>\n",
       "      <th>wb_17398</th>\n",
       "      <th>wb_17399</th>\n",
       "      <th>wb_17400</th>\n",
       "      <th>wb_17401</th>\n",
       "      <th>wb_17402</th>\n",
       "      <th>wb_17403</th>\n",
       "      <th>wb_17404</th>\n",
       "      <th>wb_17405</th>\n",
       "      <th>wb_17406</th>\n",
       "      <th>wb_17407</th>\n",
       "      <th>wb_17408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>3466.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.264</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.268</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.268</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4148.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.380</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.634</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.589</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>1.977</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-0.581</td>\n",
       "      <td>1.905</td>\n",
       "      <td>-0.821</td>\n",
       "      <td>0.416</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.526</td>\n",
       "      <td>0.082</td>\n",
       "      <td>1.408</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-1.247</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.859</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.050</td>\n",
       "      <td>1.180</td>\n",
       "      <td>-2.020</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-1.643</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>2815.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.902</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1.108</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.746</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185</th>\n",
       "      <td>5185.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  18448 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "3466 3466.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689   689.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 4148.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 2815.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 5185.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  \\\n",
       "3466 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v19  f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  \\\n",
       "3466  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v29  f0v30  f0v31  f0v32  f0v33  f0v34  f0v35  f0v36  f0v37  f0v38  \\\n",
       "3466  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v39  f0v40  f0v41  f0v42  f0v43  f0v44  f0v45  f0v46  f0v47  f0v48  \\\n",
       "3466  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v49  f0v50  f0v51  f0v52  f0v53  f0v54  f0v55  f0v56  f0v57  f0v58  \\\n",
       "3466  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v59  f0v60  f0v61  f0v62  f0v63  f0v64  f0v65  f1v0  f1v1  f1v2  f1v3  \\\n",
       "3466  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "689   0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "4148  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "2815  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "5185  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  f1v10  f1v11  f1v12  f1v13  f1v14  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v15  f1v16  f1v17  f1v18  f1v19  f1v20  f1v21  f1v22  f1v23  f1v24  \\\n",
       "3466  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v25  f1v26  f1v27  f1v28  f1v29  f1v30  f1v31  ...  wb_17309  \\\n",
       "3466  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.142   \n",
       "689   0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.130   \n",
       "4148  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.204   \n",
       "2815  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.134   \n",
       "5185  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.139   \n",
       "\n",
       "      wb_17310  wb_17311  wb_17312  wb_17313  wb_17314  wb_17315  wb_17316  \\\n",
       "3466     0.164    -0.139    -0.071    -0.074    -0.142     0.070     0.025   \n",
       "689     -0.002    -0.126    -0.076    -0.074    -0.142     0.070     0.027   \n",
       "4148    -0.016    -0.089    -0.013    -0.030    -0.142     0.070     1.380   \n",
       "2815    -0.000    -0.161    -0.172    -0.074    -0.142     0.070     0.025   \n",
       "5185     0.001    -0.237    -0.069    -0.212    -0.142     0.070     0.025   \n",
       "\n",
       "      wb_17317  wb_17318  wb_17319  wb_17320  wb_17321  wb_17322  wb_17323  \\\n",
       "3466     0.100    -0.103    -0.181     0.264    -0.123    -0.245    -0.220   \n",
       "689      0.190    -0.108    -0.182     0.260     0.003    -0.086    -0.060   \n",
       "4148     0.092    -0.108    -0.106     0.634    -0.008    -0.094     0.042   \n",
       "2815     0.232    -0.108    -0.067     0.107    -0.164    -0.087    -0.231   \n",
       "5185     0.189    -0.108    -0.179     0.119    -0.156    -0.246    -0.233   \n",
       "\n",
       "      wb_17324  wb_17325  wb_17326  wb_17327  wb_17328  wb_17329  wb_17330  \\\n",
       "3466     0.027    -0.219    -0.232    -0.105    -0.137    -0.114     0.268   \n",
       "689      0.173    -0.145    -0.163    -0.103    -0.137    -0.178     0.142   \n",
       "4148     0.027    -0.029    -0.306    -0.129    -0.137    -0.516     0.141   \n",
       "2815     0.902    -0.627    -0.103    -0.410    -0.137    -0.091     0.143   \n",
       "5185     0.040    -0.220    -0.189    -0.109    -0.137    -0.137     0.145   \n",
       "\n",
       "      wb_17331  wb_17332  wb_17333  wb_17334  wb_17335  wb_17336  wb_17337  \\\n",
       "3466    -0.190    -0.039    -0.120    -0.091     0.265     0.268    -0.150   \n",
       "689     -0.224    -0.039    -0.121    -0.136     0.096     0.060    -0.252   \n",
       "4148    -0.134    -0.039    -0.121    -0.048     0.067     0.589    -0.839   \n",
       "2815    -0.300    -0.039    -0.122    -0.057     0.085     0.378    -0.146   \n",
       "5185    -0.162    -0.039    -0.126    -0.121     0.294     0.137    -0.341   \n",
       "\n",
       "      wb_17338  wb_17339  wb_17340  wb_17341  wb_17342  wb_17343  wb_17344  \\\n",
       "3466     0.144    -0.042    -0.160    -0.034     0.142    -0.009     0.249   \n",
       "689      0.291    -0.042    -0.196    -0.144     0.145    -0.014     0.069   \n",
       "4148     1.977    -0.042    -0.097    -0.265    -0.192    -0.014     0.068   \n",
       "2815     0.139    -0.042    -0.183    -0.165    -0.196    -0.014     0.068   \n",
       "5185     0.141    -0.042    -0.009    -0.141     0.203    -0.014     0.239   \n",
       "\n",
       "      wb_17345  wb_17346  wb_17347  wb_17348  wb_17349  wb_17350  wb_17351  \\\n",
       "3466    -0.091    -0.058     0.090     0.054     0.014    -0.040    -0.024   \n",
       "689     -0.091    -0.058     0.257     0.217     0.014    -0.040    -0.031   \n",
       "4148    -0.091    -0.058     0.091     0.001     0.014    -0.042    -0.033   \n",
       "2815    -0.091    -0.058     0.229     0.548     0.014    -0.049    -0.027   \n",
       "5185    -0.091    -0.058     0.091     0.186     0.014    -0.042    -0.028   \n",
       "\n",
       "      wb_17352  wb_17353  wb_17354  wb_17355  wb_17356  wb_17357  wb_17358  \\\n",
       "3466     0.226    -0.200    -0.013     0.127     0.105    -0.189     0.211   \n",
       "689      0.155    -0.140    -0.013     0.135     0.150    -0.238     0.193   \n",
       "4148     0.040    -0.177    -0.022     0.135     0.200    -0.560     0.709   \n",
       "2815     0.228    -0.081    -0.128     0.135     0.174    -0.385     0.111   \n",
       "5185     0.216    -0.215    -0.209     0.135     0.381    -0.206     0.258   \n",
       "\n",
       "      wb_17359  wb_17360  wb_17361  wb_17362  wb_17363  wb_17364  wb_17365  \\\n",
       "3466     0.003     0.180    -0.057     0.213    -0.032     0.110     0.144   \n",
       "689      0.176     0.055    -0.126     0.131    -0.032     0.111     0.208   \n",
       "4148    -0.581     1.905    -0.821     0.416    -0.032     0.531     0.703   \n",
       "2815    -0.163     0.264     0.552     0.129    -0.032     0.113     0.440   \n",
       "5185     0.170     0.060    -0.149     0.245    -0.032     0.111     0.285   \n",
       "\n",
       "      wb_17366  wb_17367  wb_17368  wb_17369  wb_17370  wb_17371  wb_17372  \\\n",
       "3466     0.195     0.167     0.275    -0.187    -0.063    -0.242     0.252   \n",
       "689      0.006     0.229     0.146    -0.108    -0.121    -0.009     0.176   \n",
       "4148     1.526     0.082     1.408    -0.059    -1.247    -0.098     0.023   \n",
       "2815     0.020     1.108     0.214    -0.119    -0.259    -0.278     0.234   \n",
       "5185     0.169     0.248     0.257    -0.150    -0.049    -0.220     0.173   \n",
       "\n",
       "      wb_17373  wb_17374  wb_17375  wb_17376  wb_17377  wb_17378  wb_17379  \\\n",
       "3466     0.131    -0.100     0.211     0.017     0.131     0.030     0.072   \n",
       "689      0.131    -0.112     0.015     0.017     0.099     0.014     0.075   \n",
       "4148     0.131    -0.005     0.008     0.017     0.049     0.077     0.070   \n",
       "2815     0.131    -0.137     0.008     0.017     0.148     0.126     0.211   \n",
       "5185     0.131    -0.144     0.202     0.017     0.093     0.027     0.076   \n",
       "\n",
       "      wb_17380  wb_17381  wb_17382  wb_17383  wb_17384  wb_17385  wb_17386  \\\n",
       "3466    -0.057    -0.442     0.093    -0.289     0.130    -0.108     0.172   \n",
       "689     -0.061    -0.203     0.129    -0.279     0.157    -0.178     0.128   \n",
       "4148    -0.057    -0.048     0.110    -0.144     0.070    -0.001     0.104   \n",
       "2815    -0.150    -0.192     0.128    -0.139     0.071    -0.116     0.081   \n",
       "5185    -0.057    -0.071     0.206    -0.146     0.260    -0.097     0.062   \n",
       "\n",
       "      wb_17387  wb_17388  wb_17389  wb_17390  wb_17391  wb_17392  wb_17393  \\\n",
       "3466     0.041    -0.169    -0.077    -0.203     0.115     0.011     0.050   \n",
       "689      0.041    -0.139    -0.083    -0.012     0.080     0.006     0.050   \n",
       "4148     0.041    -0.089    -0.579     0.006     1.859     0.009     0.050   \n",
       "2815     0.041    -0.216    -0.210    -0.009     0.186     0.014     0.050   \n",
       "5185     0.041    -0.174    -0.256    -0.012     0.079     0.008     0.050   \n",
       "\n",
       "      wb_17394  wb_17395  wb_17396  wb_17397  wb_17398  wb_17399  wb_17400  \\\n",
       "3466     0.306    -0.093    -0.046    -0.240    -0.148    -0.334     0.227   \n",
       "689      0.124    -0.190    -0.046    -0.135    -0.180    -0.230     0.173   \n",
       "4148     1.180    -2.020    -0.046    -1.643    -0.122    -0.105     0.016   \n",
       "2815     0.277    -0.304    -0.046    -0.218    -0.130    -0.107     0.203   \n",
       "5185     0.123    -0.223    -0.046    -0.255    -0.192    -0.110     0.235   \n",
       "\n",
       "      wb_17401  wb_17402  wb_17403  wb_17404  wb_17405  wb_17406  wb_17407  \\\n",
       "3466     0.256     0.219    -0.139     0.129    -0.098    -0.262     0.204   \n",
       "689      0.170     0.217    -0.163     0.116    -0.173    -0.130     0.289   \n",
       "4148     0.326     0.078    -0.003     0.254    -0.406    -0.130     0.124   \n",
       "2815     0.418     0.746    -0.037     0.321    -0.161    -0.120     0.216   \n",
       "5185    -0.014     0.377    -0.153     0.074    -0.116    -0.125     0.235   \n",
       "\n",
       "      wb_17408  \n",
       "3466     0.012  \n",
       "689      0.001  \n",
       "4148    -0.021  \n",
       "2815    -0.023  \n",
       "5185     0.012  \n",
       "\n",
       "[5 rows x 18448 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f0v30</th>\n",
       "      <th>f0v31</th>\n",
       "      <th>f0v32</th>\n",
       "      <th>f0v33</th>\n",
       "      <th>f0v34</th>\n",
       "      <th>f0v35</th>\n",
       "      <th>f0v36</th>\n",
       "      <th>f0v37</th>\n",
       "      <th>f0v38</th>\n",
       "      <th>f0v39</th>\n",
       "      <th>f0v40</th>\n",
       "      <th>f0v41</th>\n",
       "      <th>f0v42</th>\n",
       "      <th>f0v43</th>\n",
       "      <th>f0v44</th>\n",
       "      <th>f0v45</th>\n",
       "      <th>f0v46</th>\n",
       "      <th>f0v47</th>\n",
       "      <th>f0v48</th>\n",
       "      <th>f0v49</th>\n",
       "      <th>f0v50</th>\n",
       "      <th>f0v51</th>\n",
       "      <th>f0v52</th>\n",
       "      <th>f0v53</th>\n",
       "      <th>f0v54</th>\n",
       "      <th>f0v55</th>\n",
       "      <th>f0v56</th>\n",
       "      <th>f0v57</th>\n",
       "      <th>f0v58</th>\n",
       "      <th>f0v59</th>\n",
       "      <th>f0v60</th>\n",
       "      <th>f0v61</th>\n",
       "      <th>f0v62</th>\n",
       "      <th>f0v63</th>\n",
       "      <th>f0v64</th>\n",
       "      <th>f0v65</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f1v30</th>\n",
       "      <th>f1v31</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_17309</th>\n",
       "      <th>wb_17310</th>\n",
       "      <th>wb_17311</th>\n",
       "      <th>wb_17312</th>\n",
       "      <th>wb_17313</th>\n",
       "      <th>wb_17314</th>\n",
       "      <th>wb_17315</th>\n",
       "      <th>wb_17316</th>\n",
       "      <th>wb_17317</th>\n",
       "      <th>wb_17318</th>\n",
       "      <th>wb_17319</th>\n",
       "      <th>wb_17320</th>\n",
       "      <th>wb_17321</th>\n",
       "      <th>wb_17322</th>\n",
       "      <th>wb_17323</th>\n",
       "      <th>wb_17324</th>\n",
       "      <th>wb_17325</th>\n",
       "      <th>wb_17326</th>\n",
       "      <th>wb_17327</th>\n",
       "      <th>wb_17328</th>\n",
       "      <th>wb_17329</th>\n",
       "      <th>wb_17330</th>\n",
       "      <th>wb_17331</th>\n",
       "      <th>wb_17332</th>\n",
       "      <th>wb_17333</th>\n",
       "      <th>wb_17334</th>\n",
       "      <th>wb_17335</th>\n",
       "      <th>wb_17336</th>\n",
       "      <th>wb_17337</th>\n",
       "      <th>wb_17338</th>\n",
       "      <th>wb_17339</th>\n",
       "      <th>wb_17340</th>\n",
       "      <th>wb_17341</th>\n",
       "      <th>wb_17342</th>\n",
       "      <th>wb_17343</th>\n",
       "      <th>wb_17344</th>\n",
       "      <th>wb_17345</th>\n",
       "      <th>wb_17346</th>\n",
       "      <th>wb_17347</th>\n",
       "      <th>wb_17348</th>\n",
       "      <th>wb_17349</th>\n",
       "      <th>wb_17350</th>\n",
       "      <th>wb_17351</th>\n",
       "      <th>wb_17352</th>\n",
       "      <th>wb_17353</th>\n",
       "      <th>wb_17354</th>\n",
       "      <th>wb_17355</th>\n",
       "      <th>wb_17356</th>\n",
       "      <th>wb_17357</th>\n",
       "      <th>wb_17358</th>\n",
       "      <th>wb_17359</th>\n",
       "      <th>wb_17360</th>\n",
       "      <th>wb_17361</th>\n",
       "      <th>wb_17362</th>\n",
       "      <th>wb_17363</th>\n",
       "      <th>wb_17364</th>\n",
       "      <th>wb_17365</th>\n",
       "      <th>wb_17366</th>\n",
       "      <th>wb_17367</th>\n",
       "      <th>wb_17368</th>\n",
       "      <th>wb_17369</th>\n",
       "      <th>wb_17370</th>\n",
       "      <th>wb_17371</th>\n",
       "      <th>wb_17372</th>\n",
       "      <th>wb_17373</th>\n",
       "      <th>wb_17374</th>\n",
       "      <th>wb_17375</th>\n",
       "      <th>wb_17376</th>\n",
       "      <th>wb_17377</th>\n",
       "      <th>wb_17378</th>\n",
       "      <th>wb_17379</th>\n",
       "      <th>wb_17380</th>\n",
       "      <th>wb_17381</th>\n",
       "      <th>wb_17382</th>\n",
       "      <th>wb_17383</th>\n",
       "      <th>wb_17384</th>\n",
       "      <th>wb_17385</th>\n",
       "      <th>wb_17386</th>\n",
       "      <th>wb_17387</th>\n",
       "      <th>wb_17388</th>\n",
       "      <th>wb_17389</th>\n",
       "      <th>wb_17390</th>\n",
       "      <th>wb_17391</th>\n",
       "      <th>wb_17392</th>\n",
       "      <th>wb_17393</th>\n",
       "      <th>wb_17394</th>\n",
       "      <th>wb_17395</th>\n",
       "      <th>wb_17396</th>\n",
       "      <th>wb_17397</th>\n",
       "      <th>wb_17398</th>\n",
       "      <th>wb_17399</th>\n",
       "      <th>wb_17400</th>\n",
       "      <th>wb_17401</th>\n",
       "      <th>wb_17402</th>\n",
       "      <th>wb_17403</th>\n",
       "      <th>wb_17404</th>\n",
       "      <th>wb_17405</th>\n",
       "      <th>wb_17406</th>\n",
       "      <th>wb_17407</th>\n",
       "      <th>wb_17408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7217.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.311</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>8291.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.288</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.288</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>5114.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.486</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  18448 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "7217 7217.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 8291.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 4607.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 5114.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 1859.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  \\\n",
       "7217 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v19  f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v29  f0v30  f0v31  f0v32  f0v33  f0v34  f0v35  f0v36  f0v37  f0v38  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v39  f0v40  f0v41  f0v42  f0v43  f0v44  f0v45  f0v46  f0v47  f0v48  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v49  f0v50  f0v51  f0v52  f0v53  f0v54  f0v55  f0v56  f0v57  f0v58  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v59  f0v60  f0v61  f0v62  f0v63  f0v64  f0v65  f1v0  f1v1  f1v2  f1v3  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  f1v10  f1v11  f1v12  f1v13  f1v14  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v15  f1v16  f1v17  f1v18  f1v19  f1v20  f1v21  f1v22  f1v23  f1v24  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v25  f1v26  f1v27  f1v28  f1v29  f1v30  f1v31  ...  wb_17309  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.172   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.298   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.237   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.199   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...    -0.136   \n",
       "\n",
       "      wb_17310  wb_17311  wb_17312  wb_17313  wb_17314  wb_17315  wb_17316  \\\n",
       "7217     0.258    -0.139    -0.077    -0.068    -0.142     0.070     0.025   \n",
       "8291    -0.131    -0.126    -0.225    -0.074    -0.142     0.070     0.025   \n",
       "4607     0.005    -0.190    -0.221    -0.074    -0.142     0.070     0.025   \n",
       "5114     0.077    -0.036    -0.076    -0.074    -0.142     0.070     0.025   \n",
       "1859    -0.207    -0.091    -0.073    -0.074    -0.142     0.070     0.025   \n",
       "\n",
       "      wb_17317  wb_17318  wb_17319  wb_17320  wb_17321  wb_17322  wb_17323  \\\n",
       "7217     0.166    -0.108    -0.212     0.225    -0.055    -0.072    -0.036   \n",
       "8291     0.163    -0.107    -0.174     0.234    -0.049    -0.087    -0.051   \n",
       "4607     0.136    -0.111    -0.081     0.256    -0.120    -0.091    -0.046   \n",
       "5114     0.140    -0.108    -0.084     0.245    -0.072    -0.112    -0.179   \n",
       "1859     0.150    -0.108    -0.128     0.201    -0.117    -0.404    -0.185   \n",
       "\n",
       "      wb_17324  wb_17325  wb_17326  wb_17327  wb_17328  wb_17329  wb_17330  \\\n",
       "7217     0.030    -0.111     0.010    -0.315    -0.258    -0.162     0.143   \n",
       "8291     0.203    -0.026    -0.102    -0.096    -0.137    -0.064     0.143   \n",
       "4607     0.210    -0.178    -0.061    -0.111    -0.136    -0.166     0.143   \n",
       "5114     0.155    -0.113    -0.037    -0.103    -0.137    -0.067     0.143   \n",
       "1859     0.018    -0.165    -0.062    -0.290    -0.137    -0.134     0.143   \n",
       "\n",
       "      wb_17331  wb_17332  wb_17333  wb_17334  wb_17335  wb_17336  wb_17337  \\\n",
       "7217    -0.285    -0.039    -0.143    -0.101     0.084     0.119    -0.152   \n",
       "8291    -0.244    -0.039    -0.121    -0.081     0.085     0.152    -0.152   \n",
       "4607    -0.180    -0.039    -0.121    -0.088     0.200     0.195    -0.146   \n",
       "5114    -0.223    -0.039    -0.122    -0.108     0.250     0.138    -0.145   \n",
       "1859    -0.185    -0.039    -0.111    -0.080     0.084     0.163    -0.143   \n",
       "\n",
       "      wb_17338  wb_17339  wb_17340  wb_17341  wb_17342  wb_17343  wb_17344  \\\n",
       "7217     0.139    -0.042     0.006    -0.127     0.197    -0.014     0.245   \n",
       "8291     0.288    -0.042     0.004    -0.103    -0.066    -0.014     0.071   \n",
       "4607     0.306    -0.042    -0.204    -0.220    -0.200    -0.014     0.070   \n",
       "5114     0.226    -0.042    -0.125    -0.130    -0.126    -0.014     0.070   \n",
       "1859     0.486    -0.042     0.004    -0.102     0.045    -0.014     0.071   \n",
       "\n",
       "      wb_17345  wb_17346  wb_17347  wb_17348  wb_17349  wb_17350  wb_17351  \\\n",
       "7217    -0.091    -0.058     0.392     0.035     0.014    -0.042    -0.191   \n",
       "8291    -0.091    -0.058     0.092     0.043     0.014    -0.042    -0.031   \n",
       "4607    -0.091    -0.058     0.086     0.162     0.014    -0.042    -0.022   \n",
       "5114    -0.091    -0.058     0.235     0.135     0.014    -0.046    -0.023   \n",
       "1859    -0.091    -0.058     0.248     0.224     0.014    -0.045    -0.024   \n",
       "\n",
       "      wb_17352  wb_17353  wb_17354  wb_17355  wb_17356  wb_17357  wb_17358  \\\n",
       "7217     0.104    -0.005    -0.066     0.135     0.136    -0.254     0.113   \n",
       "8291     0.130    -0.159    -0.014     0.135     0.099    -0.218     0.111   \n",
       "4607     0.094     0.249    -0.015     0.135     0.175    -0.308     0.106   \n",
       "5114     0.166    -0.118    -0.014     0.135     0.229    -0.161     0.160   \n",
       "1859     0.186    -0.184    -0.014     0.135     0.197    -0.216     0.118   \n",
       "\n",
       "      wb_17359  wb_17360  wb_17361  wb_17362  wb_17363  wb_17364  wb_17365  \\\n",
       "7217    -0.259     0.311    -0.181     0.302    -0.032     0.353     0.272   \n",
       "8291    -0.175     0.177    -0.068     0.233    -0.032     0.137     0.141   \n",
       "4607    -0.128     0.210    -0.154     0.227    -0.032     0.243     0.319   \n",
       "5114    -0.092     0.172    -0.095     0.147    -0.032     0.111     0.142   \n",
       "1859    -0.170     0.323    -0.099     0.197    -0.032     0.280     0.215   \n",
       "\n",
       "      wb_17366  wb_17367  wb_17368  wb_17369  wb_17370  wb_17371  wb_17372  \\\n",
       "7217     0.264     0.282     0.140    -0.130    -0.121    -0.110     0.195   \n",
       "8291     0.008     0.093     0.194    -0.116    -0.091    -0.137     0.209   \n",
       "4607     0.011     0.227     0.139    -0.127    -0.173    -0.098     0.190   \n",
       "5114    -0.013     0.154     0.216    -0.147    -0.120    -0.124     0.245   \n",
       "1859     0.136     0.095     0.150    -0.215    -0.046    -0.224     0.197   \n",
       "\n",
       "      wb_17373  wb_17374  wb_17375  wb_17376  wb_17377  wb_17378  wb_17379  \\\n",
       "7217     0.131    -0.163     0.008     0.017     0.146     0.036     0.076   \n",
       "8291     0.131     0.150     0.005     0.017     0.014     0.165     0.071   \n",
       "4607     0.131     0.157     0.008     0.017     0.066     0.049     0.074   \n",
       "5114     0.131     0.137     0.009     0.017     0.125     0.160     0.234   \n",
       "1859     0.131    -0.007     0.009     0.017     0.164     0.028     0.076   \n",
       "\n",
       "      wb_17380  wb_17381  wb_17382  wb_17383  wb_17384  wb_17385  wb_17386  \\\n",
       "7217    -0.060    -0.053     0.194    -0.355     0.133    -0.011     0.268   \n",
       "8291    -0.054    -0.243     0.157    -0.285     0.167    -0.160     0.060   \n",
       "4607    -0.067    -0.251     0.239    -0.149     0.260    -0.004     0.190   \n",
       "5114    -0.063    -0.193     0.137    -0.142     0.061    -0.026     0.061   \n",
       "1859    -0.221    -0.045     0.158    -0.144     0.069    -0.122     0.061   \n",
       "\n",
       "      wb_17387  wb_17388  wb_17389  wb_17390  wb_17391  wb_17392  wb_17393  \\\n",
       "7217     0.041    -0.205    -0.088    -0.012     0.238     0.010     0.050   \n",
       "8291     0.041    -0.154    -0.216    -0.033     0.079     0.011     0.050   \n",
       "4607     0.041    -0.192    -0.074    -0.012     0.082     0.006     0.050   \n",
       "5114     0.041    -0.141    -0.073    -0.012     0.214     0.122     0.050   \n",
       "1859     0.041    -0.139    -0.079    -0.012     0.081     0.186     0.050   \n",
       "\n",
       "      wb_17394  wb_17395  wb_17396  wb_17397  wb_17398  wb_17399  wb_17400  \\\n",
       "7217     0.122    -0.308    -0.046    -0.277    -0.131    -0.104     0.253   \n",
       "8291     0.131    -0.103    -0.046    -0.241    -0.106    -0.114     0.149   \n",
       "4607     0.126    -0.250    -0.046    -0.231    -0.212    -0.296     0.235   \n",
       "5114     0.124    -0.235    -0.046    -0.128    -0.148    -0.104     0.070   \n",
       "1859     0.122    -0.222    -0.046    -0.143    -0.109    -0.243     0.174   \n",
       "\n",
       "      wb_17401  wb_17402  wb_17403  wb_17404  wb_17405  wb_17406  wb_17407  \\\n",
       "7217    -0.197     0.228    -0.185     0.162    -0.165    -0.129     0.313   \n",
       "8291     0.178     0.260    -0.109     0.073    -0.136    -0.125     0.125   \n",
       "4607     0.261     0.090    -0.177     0.159    -0.149    -0.126     0.288   \n",
       "5114    -0.007     0.083    -0.117     0.177    -0.145    -0.125     0.261   \n",
       "1859     0.085     0.181    -0.148     0.245    -0.094    -0.128     0.168   \n",
       "\n",
       "      wb_17408  \n",
       "7217    -0.013  \n",
       "8291    -0.011  \n",
       "4607    -0.035  \n",
       "5114     0.001  \n",
       "1859     0.003  \n",
       "\n",
       "[5 rows x 18448 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "RESTRUCTURING DATA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defd5fa7bf3740f6835b92da1bc1c988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=75)]: Using backend LokyBackend with 75 concurrent workers.\n",
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "2021-09-13 12:23:15.854863: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:15.862631: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:15.864482: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.201955: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.337575: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.493257: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.589293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.589349: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.643733: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.647891: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.647900: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.647938: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.647993: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.689029: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.711306: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.711381: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.720099: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.810190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.857288: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.892263: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:17.929103: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.112895: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.507140: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.513851: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.566324: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.566324: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.596994: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.610249: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.615453: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.626373: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.629719: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.658073: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.664762: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.664762: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.666356: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.677277: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.677281: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.677682: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.678331: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.679642: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.679742: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.679924: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.682654: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.685666: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.689775: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.690441: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.699187: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.699718: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.699777: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.701324: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.701542: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.701641: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.703712: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.715521: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.722221: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.722324: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.722485: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.724259: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.726122: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.726597: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.727038: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.727759: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.731832: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.732184: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:18.950796: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:39.747251: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:40.380131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:40.553190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:40.925825: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:42.069657: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "[Parallel(n_jobs=75)]: Done  50 tasks      | elapsed:  1.0min\n",
      "2021-09-13 12:23:43.641249: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:44.214253: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:44.382740: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 12:23:44.544805: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "[Parallel(n_jobs=75)]: Done 300 tasks      | elapsed:  1.0min\n",
      "2021-09-13 12:23:45.873613: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "[Parallel(n_jobs=75)]: Done 650 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=75)]: Done 1100 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=75)]: Done 1650 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=75)]: Done 2300 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=75)]: Done 3050 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=75)]: Done 3900 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=75)]: Done 4850 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=75)]: Done 5900 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=75)]: Done 7050 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=75)]: Done 8300 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=75)]: Done 8955 out of 8955 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8955, 324, 256)\n",
      "(8955, 17409)\n",
      "(8955, 1037)\n",
      "RESTRUCTURING DATA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e34837f7c8b47a48c8e062f632e4260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=69)]: Using backend LokyBackend with 69 concurrent workers.\n",
      "[Parallel(n_jobs=69)]: Done  62 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=69)]: Done 312 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=69)]: Done 662 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=69)]: Done 995 out of 995 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 324, 256)\n",
      "(995, 17409)\n",
      "(995, 1037)\n",
      "RESTRUCTURING DATA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e200a8f0f3499498a503355e9c29fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=73)]: Using backend LokyBackend with 73 concurrent workers.\n",
      "[Parallel(n_jobs=73)]: Done   7 out of  50 | elapsed:    0.5s remaining:    2.9s\n",
      "[Parallel(n_jobs=73)]: Done  50 out of  50 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 324, 256)\n",
      "(50, 17409)\n",
      "(50, 1037)\n",
      "(8955, 324, 256)\n",
      "(8955, 17409)\n",
      "(8955, 1037)\n",
      "TRAIN DATAS SHAPE:  (8955, 324, 256)\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "conv_block_1/ke...|3                 |?                 \n",
      "conv_block_1/se...|False             |?                 \n",
      "conv_block_1/ma...|True              |?                 \n",
      "conv_block_1/dr...|0                 |?                 \n",
      "conv_block_1/nu...|2                 |?                 \n",
      "conv_block_1/nu...|2                 |?                 \n",
      "conv_block_1/fi...|512               |?                 \n",
      "conv_block_1/fi...|32                |?                 \n",
      "conv_block_1/fi...|32                |?                 \n",
      "conv_block_1/fi...|32                |?                 \n",
      "dense_block_1/u...|False             |?                 \n",
      "dense_block_1/n...|2                 |?                 \n",
      "dense_block_1/u...|32                |?                 \n",
      "dense_block_1/d...|0                 |?                 \n",
      "dense_block_1/u...|32                |?                 \n",
      "optimizer         |adam              |?                 \n",
      "learning_rate     |0.001             |?                 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 12:25:16.074913: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-13 12:25:16.094932: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2197530000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/binary_crossentropy_inet_decision_function_fv_loss/loop_body/GatherV2_1/pfor/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/binary_crossentropy_inet_decision_function_fv_loss/loop_body/GatherV2_1/pfor/Reshape:0\", shape=(None, 500), dtype=float32), dense_shape=Tensor(\"gradient_tape/binary_crossentropy_inet_decision_function_fv_loss/loop_body/GatherV2_1/pfor/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2021-09-13 12:25:29.404593: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-13 12:25:29.841830: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 8.0.4 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2021-09-13 12:25:29.844043: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 8.0.4 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2021-09-13 12:25:29.845265: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-13 12:25:30.751387: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1d/conv1d (defined at home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/utils/utils.py:88) ]]\n\t [[binary_crossentropy_inet_decision_function_fv_loss/map_1/while/body/_45/binary_crossentropy_inet_decision_function_fv_loss/map_1/while/ExpandDims_1/_166]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1d/conv1d (defined at home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/utils/utils.py:88) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_975382]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3023/3888185687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m  \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpretation_net_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                       \u001b[0mlambda_net_dataset_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                       \u001b[0mlambda_net_dataset_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work-ceph/smarton/InES_XAI/03_decision_trees/utilities/InterpretationNet.py\u001b[0m in \u001b[0;36minterpretation_net_training\u001b[0;34m(lambda_net_train_dataset, lambda_net_valid_dataset, lambda_net_test_dataset, config, callback_names)\u001b[0m\n\u001b[1;32m    138\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m      \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m      \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_inet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_net_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                         \u001b[0mlambda_net_valid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                         \u001b[0mlambda_net_test_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work-ceph/smarton/InES_XAI/03_decision_trees/utilities/InterpretationNet.py\u001b[0m in \u001b[0;36mtrain_inet\u001b[0;34m(lambda_net_train_dataset, lambda_net_valid_dataset, lambda_net_test_dataset, config, callback_names)\u001b[0m\n\u001b[1;32m    417\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i_net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i_net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_callbacks_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'early_stopping'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         history = self.tuner.search(\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         super().search(\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         _, history = utils.fit_with_adaptive_batch_size(\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36mfit_with_adaptive_batch_size\u001b[0;34m(model, batch_size, **fit_kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_adaptive_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     history = run_with_adaptive_batch_size(\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36mrun_with_adaptive_batch_size\u001b[0;34m(batch_size, func, **fit_kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceExhaustedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_adaptive_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     history = run_with_adaptive_batch_size(\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/XAI/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1d/conv1d (defined at home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/utils/utils.py:88) ]]\n\t [[binary_crossentropy_inet_decision_function_fv_loss/map_1/while/body/_45/binary_crossentropy_inet_decision_function_fv_loss/map_1/while/ExpandDims_1/_166]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1d/conv1d (defined at home/smarton/anaconda3/envs/XAI/lib/python3.9/site-packages/autokeras/utils/utils.py:88) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_975382]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " history,\n",
    "\n",
    " model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=['plot_losses']\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['i_net']['data_reshape_version'] = 0\n",
    "data_reshape_version = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['i_net']['batch_size'] = 32\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nas:\n",
    "    for trial in history_list[-1]: \n",
    "        print(trial.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_inet_dt_list = []\n",
    "y_test_distilled_sklearn_dt_list = []\n",
    "\n",
    "binary_crossentropy_distilled_sklearn_dt_list =[]\n",
    "accuracy_distilled_sklearn_dt_list = []\n",
    "f1_score_distilled_sklearn_dt_list = []\n",
    "\n",
    "binary_crossentropy_inet_dt_list =[]\n",
    "accuracy_inet_dt_list = []\n",
    "f1_score_inet_dt_list = []\n",
    "\n",
    "#inet_metric_function_list = []\n",
    "\n",
    "number = lambda_net_dataset_test.y_test_lambda_array.shape[0]#10\n",
    "\n",
    "for lambda_net_parameters, lambda_net, X_test_lambda, y_test_lambda in tqdm(zip(lambda_net_dataset_test.network_parameters_array[:number], lambda_net_dataset_test.network_list[:number], lambda_net_dataset_test.X_test_lambda_array[:number], lambda_net_dataset_test.y_test_lambda_array[:number]), total=lambda_net_dataset_test.y_test_lambda_array[:number].shape[0]):\n",
    "    dt_inet = model.predict(np.array([lambda_net_parameters]))[0]\n",
    "    if nas:\n",
    "        dt_inet = dt_inet[:function_representation_length]\n",
    "\n",
    "    \n",
    "    X_data_random = generate_random_data_points_custom(config['data']['x_min'], config['data']['x_max'], config['evaluation']['random_evaluation_dataset_size'], config['data']['number_of_variables'])\n",
    "    y_data_random_lambda_pred = lambda_net.predict(X_data_random)\n",
    "    y_data_random_lambda_pred = np.round(y_data_random_lambda_pred).astype(np.int64)\n",
    "    \n",
    "    dt_sklearn_distilled = DecisionTreeClassifier(max_depth=config['function_family']['maximum_depth'])\n",
    "    dt_sklearn_distilled.fit(X_data_random, y_data_random_lambda_pred)\n",
    "    \n",
    "    \n",
    "    if dt_type == 'SDT':\n",
    "        y_test_inet_dt  = calculate_function_value_from_decision_tree_parameters_wrapper(X_test_lambda, config)(dt_inet).numpy()\n",
    "    elif dt_type == 'vanilla':\n",
    "        y_test_inet_dt  = calculate_function_value_from_vanilla_decision_tree_parameters_wrapper(X_test_lambda, config)(dt_inet).numpy()\n",
    "    y_test_distilled_sklearn_dt = dt_sklearn_distilled.predict(X_test_lambda)\n",
    "    \n",
    "    y_test_lambda_pred = lambda_net.predict(X_test_lambda)\n",
    "    y_test_lambda_pred = np.round(y_test_lambda_pred)\n",
    "    \n",
    "    \n",
    "    #random_model = generate_base_model(config)        \n",
    "    #random_network_parameters = random_model.get_weights()\n",
    "    #network_parameters_structure = [network_parameter.shape for network_parameter in random_network_parameters]         \n",
    "    \n",
    "    #function_true_placeholder = np.array([0 for i in range(basic_function_representation_length)])\n",
    "    #function_true_with_network_parameters = np.concatenate([function_true_placeholder, lambda_net_parameters])\n",
    "    #inet_metric_function = inet_decision_function_fv_metric_wrapper(X_test_lambda, \n",
    "    #                                                                 random_model, \n",
    "    #                                                                 network_parameters_structure, \n",
    "    #                                                                 config, \n",
    "    #                                                                 'binary_accuracy')(np.array([function_true_with_network_parameters]), \n",
    "    #                                                                                     np.array([dt_inet]))    \n",
    "    #inet_metric_function_list.append(inet_metric_function)\n",
    "        \n",
    "    \n",
    "    \n",
    "    binary_crossentropy_distilled_sklearn_dt = log_loss(y_test_lambda_pred, y_test_distilled_sklearn_dt)\n",
    "    accuracy_distilled_sklearn_dt = accuracy_score(y_test_lambda_pred, np.round(y_test_distilled_sklearn_dt))\n",
    "    f1_score_distilled_sklearn_dt = f1_score(y_test_lambda_pred, np.round(y_test_distilled_sklearn_dt))\n",
    "    \n",
    "    binary_crossentropy_inet_dt = log_loss(y_test_lambda_pred, y_test_inet_dt)\n",
    "    accuracy_inet_dt = accuracy_score(y_test_lambda_pred, np.round(y_test_inet_dt))\n",
    "    f1_score_inet_dt = f1_score(y_test_lambda_pred, np.round(y_test_inet_dt))\n",
    "    \n",
    "    \n",
    "    y_test_inet_dt_list.append(y_test_inet_dt)\n",
    "    y_test_distilled_sklearn_dt_list.append(y_test_distilled_sklearn_dt)    \n",
    "\n",
    "    binary_crossentropy_distilled_sklearn_dt_list.append(np.nan_to_num(binary_crossentropy_distilled_sklearn_dt))\n",
    "    accuracy_distilled_sklearn_dt_list.append(np.nan_to_num(accuracy_distilled_sklearn_dt))\n",
    "    f1_score_distilled_sklearn_dt_list.append(np.nan_to_num(f1_score_distilled_sklearn_dt))\n",
    "\n",
    "    binary_crossentropy_inet_dt_list.append(np.nan_to_num(binary_crossentropy_inet_dt))\n",
    "    accuracy_inet_dt_list.append(np.nan_to_num(accuracy_inet_dt))\n",
    "    f1_score_inet_dt_list.append(np.nan_to_num(f1_score_inet_dt))\n",
    "    \n",
    "y_test_inet_dt_list = np.array(y_test_inet_dt_list)\n",
    "y_test_distilled_sklearn_dt_list = np.array(y_test_distilled_sklearn_dt_list)\n",
    "\n",
    "binary_crossentropy_distilled_sklearn_dt_list = np.array(binary_crossentropy_distilled_sklearn_dt_list)\n",
    "accuracy_distilled_sklearn_dt_list = np.array(accuracy_distilled_sklearn_dt_list)\n",
    "f1_score_distilled_sklearn_dt_list = np.array(f1_score_distilled_sklearn_dt_list)\n",
    "\n",
    "binary_crossentropy_inet_dt_list = np.array(binary_crossentropy_inet_dt_list)\n",
    "accuracy_inet_dt_list = np.array(accuracy_inet_dt_list)\n",
    "f1_score_inet_dt_list = np.array(f1_score_inet_dt_list)    \n",
    "\n",
    "    \n",
    "print('Binary Crossentropy:\\t\\t', np.round(np.mean(binary_crossentropy_distilled_sklearn_dt_list), 3), '(Sklearn DT)' , '\\t', np.round(np.mean(binary_crossentropy_inet_dt_list), 3), '(I-Net DT)')\n",
    "print('Accuracy:\\t\\t', np.round(np.mean(accuracy_distilled_sklearn_dt_list), 3), '(Sklearn DT)' , '\\t', np.round(np.mean(accuracy_inet_dt_list), 3), '(I-Net DT)')\n",
    "print('F1 Score:\\t\\t', np.round(np.mean(f1_score_distilled_sklearn_dt_list), 3), '(Sklearn DT)' , '\\t', np.round(np.mean(f1_score_inet_dt_list), 3), '(I-Net DT)')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATA EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "dataframe = dataframe.drop([\n",
    "                             #\"Age\", #0\n",
    "                             \"Workclass\",  #1\n",
    "                             \"fnlwgt\",  #2\n",
    "                             \"Education\",  #3\n",
    "                             \"Education-Num\",  #4\n",
    "                             \"Marital Status\", #5\n",
    "                             \"Occupation\",  #6\n",
    "                             \"Relationship\",  #7\n",
    "                             \"Race\",  #8\n",
    "                             #\"Sex\",  #9 \n",
    "                             #\"Capital Gain\",  #10\n",
    "                             #\"Capital Loss\", #11\n",
    "                             \"Hours per week\",  #12\n",
    "                             \"Country\", #13\n",
    "                            ] , axis=1)\n",
    "#dataframe = dataframe.drop(['Country'], axis=1)\n",
    "\n",
    "categorical_features = [\n",
    "                        1, #\"Workclass\"\n",
    "                        3, #\"Education\"\n",
    "                        5, #\"Marital Status\"\n",
    "                        6, #\"Occupation\"\n",
    "                        7, #\"Relationship\"\n",
    "                        8, #\"Race\"\n",
    "                        9, #\"Sex\"\n",
    "                        #13, #\"Country\n",
    "                       ] \n",
    "\n",
    "categorical_features = [1]\n",
    "\n",
    "\n",
    "data = dataframe.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['capital_gain'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,data.shape[1]-1]\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "class_names = le.classes_\n",
    "data = data[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough')\n",
    "transformer.fit(data)\n",
    "\n",
    "data = transformer.transform(data)\n",
    "data = data#.toarray()\n",
    "data = data.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose = data.transpose()\n",
    "normalizer_list = []\n",
    "transpose_normalized = []\n",
    "for column in transpose:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(column.reshape(-1, 1))\n",
    "    column_new = scaler.transform(column.reshape(-1, 1)).ravel()\n",
    "    transpose_normalized.append(column_new)\n",
    "    normalizer_list.append(scaler)\n",
    "data = np.array(transpose_normalized).transpose()\n",
    "\n",
    "#data = data / data.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_valid, test, labels_train_with_valid, labels_test = train_test_split(data, labels, train_size=0.8)\n",
    "train, valid, labels_train, labels_valid = train_test_split(train_with_valid, labels_train_with_valid, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_network = generate_lambda_net_from_config(config)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                  patience=50, \n",
    "                                                  min_delta=0.001, \n",
    "                                                  verbose=0, \n",
    "                                                  mode='min', \n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "model_history = test_network.fit(train,\n",
    "                                  labels_train, \n",
    "                                  epochs=1000, \n",
    "                                  batch_size=256, \n",
    "                                  callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                  validation_data=(valid, labels_valid),\n",
    "                                  verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_network_parameters = shaped_network_parameters_to_array(test_network.get_weights(), config)\n",
    "test_network_dt_inet = model.predict(np.array([test_network_parameters]))[0]\n",
    "\n",
    "if nas:\n",
    "    test_network_dt_inet = test_network_dt_inet[:function_representation_length]\n",
    "\n",
    "X_data_random = generate_random_data_points_custom(config['data']['x_min'], config['data']['x_max'], config['evaluation']['random_evaluation_dataset_size'], config['data']['number_of_variables'])\n",
    "y_data_random_test_network_pred = test_network.predict(X_data_random)\n",
    "y_data_random_test_network_pred = np.round(y_data_random_test_network_pred).astype(np.int64)\n",
    "\n",
    "dt_sklearn_distilled = DecisionTreeClassifier(max_depth=config['function_family']['maximum_depth'])\n",
    "dt_sklearn_distilled.fit(X_data_random, y_data_random_test_network_pred)\n",
    "\n",
    "\n",
    "if dt_type == 'SDT':\n",
    "    y_test_inet_dt  = calculate_function_value_from_decision_tree_parameters_wrapper(test, config)(test_network_dt_inet).numpy()\n",
    "elif dt_type == 'vanilla':\n",
    "    y_test_inet_dt  = calculate_function_value_from_vanilla_decision_tree_parameters_wrapper(test, config)(test_network_dt_inet).numpy()\n",
    "y_test_distilled_sklearn_dt = dt_sklearn_distilled.predict(test)\n",
    "\n",
    "y_test_test_network_pred = test_network.predict(test)\n",
    "y_test_test_network_pred = np.round(y_test_test_network_pred)\n",
    "\n",
    "binary_crossentropy_distilled_sklearn_dt = log_loss(y_test_test_network_pred, y_test_distilled_sklearn_dt)\n",
    "accuracy_distilled_sklearn_dt = accuracy_score(y_test_test_network_pred, np.round(y_test_distilled_sklearn_dt))\n",
    "f1_score_distilled_sklearn_dt = f1_score(y_test_test_network_pred, np.round(y_test_distilled_sklearn_dt))\n",
    "\n",
    "binary_crossentropy_inet_dt = log_loss(y_test_test_network_pred, y_test_inet_dt)\n",
    "accuracy_inet_dt = accuracy_score(y_test_test_network_pred, np.round(y_test_inet_dt))\n",
    "f1_score_inet_dt = f1_score(y_test_test_network_pred, np.round(y_test_inet_dt))\n",
    "\n",
    "\n",
    "print('Binary Crossentropy:\\t\\t', np.round(binary_crossentropy_distilled_sklearn_dt, 3), '(Sklearn DT)' , '\\t', np.round(binary_crossentropy_inet_dt, 3), '(I-Net DT)')\n",
    "print('Accuracy:\\t\\t', np.round(accuracy_distilled_sklearn_dt, 3), '(Sklearn DT)' , '\\t', np.round(accuracy_inet_dt, 3), '(I-Net DT)')\n",
    "print('F1 Score:\\t\\t', np.round(f1_score_distilled_sklearn_dt, 3), '(Sklearn DT)' , '\\t', np.round(f1_score_inet_dt, 3), '(I-Net DT)')\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, leaf_classes = get_shaped_parameters_for_decision_tree(test_network_dt_inet, config)\n",
    "print(splits, leaf_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "image, nodes = anytree_decision_tree_from_parameters(test_network_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "image\n",
    "#tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = treelib_decision_tree_from_parameters(test_network_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "#tree = treelib_decision_tree_from_parameters(test_network_dt_inet, config=config)\n",
    "\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree = treelib_decision_tree_from_parameters(test_network_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "tree = treelib_decision_tree_from_parameters(test_network_dt_inet, config=config)\n",
    "\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "plot_tree(dt_sklearn_distilled, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
