{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:19.952761Z",
     "iopub.status.busy": "2021-12-17T08:41:19.952439Z",
     "iopub.status.idle": "2021-12-17T08:41:19.974619Z",
     "shell.execute_reply": "2021-12-17T08:41:19.973548Z",
     "shell.execute_reply.started": "2021-12-17T08:41:19.952697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 3,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': -1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'SDT', #'SDT', 'SDT'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 30, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [],\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': None, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'random_decision_tree_trained',# 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [2048, 1024, 256, 128],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.1, 0.1, 0.1, 0],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.001,\n",
    "        'loss': 'binary_crossentropy', #mse; soft_mse; binary_crossentropy; soft_binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['binary_crossentropy', 'binary_accuracy'],\n",
    "        \n",
    "        'epochs': 200, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 1024,\n",
    "\n",
    "        'interpretation_dataset_size': 10000,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 1, # 1=standard representation; 2=sparse representation with classification for variables\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "        'soft_labels': False,\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2);\n",
    "        \n",
    "        'nas': True,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 2,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': True,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "            \n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 10,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '3',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:20.006830Z",
     "iopub.status.busy": "2021-12-17T08:41:20.006496Z",
     "iopub.status.idle": "2021-12-17T08:41:20.012731Z",
     "shell.execute_reply": "2021-12-17T08:41:20.011980Z",
     "shell.execute_reply.started": "2021-12-17T08:41:20.006794Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:20.014825Z",
     "iopub.status.busy": "2021-12-17T08:41:20.014309Z",
     "iopub.status.idle": "2021-12-17T08:41:23.799096Z",
     "shell.execute_reply": "2021-12-17T08:41:23.798506Z",
     "shell.execute_reply.started": "2021-12-17T08:41:20.014790Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:23.800246Z",
     "iopub.status.busy": "2021-12-17T08:41:23.800063Z",
     "iopub.status.idle": "2021-12-17T08:41:23.806838Z",
     "shell.execute_reply": "2021-12-17T08:41:23.806200Z",
     "shell.execute_reply.started": "2021-12-17T08:41:23.800220Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:23.808216Z",
     "iopub.status.busy": "2021-12-17T08:41:23.807920Z",
     "iopub.status.idle": "2021-12-17T08:41:23.821282Z",
     "shell.execute_reply": "2021-12-17T08:41:23.820691Z",
     "shell.execute_reply.started": "2021-12-17T08:41:23.808182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:23.823650Z",
     "iopub.status.busy": "2021-12-17T08:41:23.823367Z",
     "iopub.status.idle": "2021-12-17T08:41:23.828498Z",
     "shell.execute_reply": "2021-12-17T08:41:23.827944Z",
     "shell.execute_reply.started": "2021-12-17T08:41:23.823617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:23.829826Z",
     "iopub.status.busy": "2021-12-17T08:41:23.829539Z",
     "iopub.status.idle": "2021-12-17T08:41:26.547686Z",
     "shell.execute_reply": "2021-12-17T08:41:26.547082Z",
     "shell.execute_reply.started": "2021-12-17T08:41:23.829792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type == 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:26.548872Z",
     "iopub.status.busy": "2021-12-17T08:41:26.548643Z",
     "iopub.status.idle": "2021-12-17T08:41:26.553711Z",
     "shell.execute_reply": "2021-12-17T08:41:26.553025Z",
     "shell.execute_reply.started": "2021-12-17T08:41:26.548847Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets10000_var30_class2_random_decision_tree_trained_xMax1_xMin0_xDistuniform_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense2048-1024-256-128_drop0.1-0.1-0.1-0e200b1024_adam\n",
      "lNetSize5000_numLNets10000_var30_class2_random_decision_tree_trained_xMax1_xMin0_xDistuniform_depth3_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:26.554804Z",
     "iopub.status.busy": "2021-12-17T08:41:26.554570Z",
     "iopub.status.idle": "2021-12-17T08:41:26.579336Z",
     "shell.execute_reply": "2021-12-17T08:41:26.578632Z",
     "shell.execute_reply.started": "2021-12-17T08:41:26.554781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:26.580697Z",
     "iopub.status.busy": "2021-12-17T08:41:26.580443Z",
     "iopub.status.idle": "2021-12-17T08:41:26.588045Z",
     "shell.execute_reply": "2021-12-17T08:41:26.587307Z",
     "shell.execute_reply.started": "2021-12-17T08:41:26.580673Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "       \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              config) for network_parameters_row in network_parameters.values)          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    #def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "    #    lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "    \n",
    "    #def initialize_target_function_wrapper(config, lambda_net):\n",
    "    #    lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:26.589221Z",
     "iopub.status.busy": "2021-12-17T08:41:26.588968Z",
     "iopub.status.idle": "2021-12-17T08:41:58.416945Z",
     "shell.execute_reply": "2021-12-17T08:41:58.416175Z",
     "shell.execute_reply.started": "2021-12-17T08:41:26.589198Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=10)]: Done 328 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=10)]: Done 5066 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=10)]: Done 10000 out of 10000 | elapsed:   15.2s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "    if False:\n",
    "        lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_train_with_valid = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)   \n",
    "        \n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:58.418834Z",
     "iopub.status.busy": "2021-12-17T08:41:58.418537Z",
     "iopub.status.idle": "2021-12-17T08:41:58.423989Z",
     "shell.execute_reply": "2021-12-17T08:41:58.423500Z",
     "shell.execute_reply.started": "2021-12-17T08:41:58.418804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 4332)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:58.424911Z",
     "iopub.status.busy": "2021-12-17T08:41:58.424739Z",
     "iopub.status.idle": "2021-12-17T08:41:58.431346Z",
     "shell.execute_reply": "2021-12-17T08:41:58.430754Z",
     "shell.execute_reply.started": "2021-12-17T08:41:58.424888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4332)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:58.432324Z",
     "iopub.status.busy": "2021-12-17T08:41:58.432117Z",
     "iopub.status.idle": "2021-12-17T08:41:58.436358Z",
     "shell.execute_reply": "2021-12-17T08:41:58.435766Z",
     "shell.execute_reply.started": "2021-12-17T08:41:58.432301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4332)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:41:58.439618Z",
     "iopub.status.busy": "2021-12-17T08:41:58.439390Z",
     "iopub.status.idle": "2021-12-17T08:42:13.618881Z",
     "shell.execute_reply": "2021-12-17T08:42:13.618198Z",
     "shell.execute_reply.started": "2021-12-17T08:41:58.439594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f2v15</th>\n",
       "      <th>f2v16</th>\n",
       "      <th>f2v17</th>\n",
       "      <th>f2v18</th>\n",
       "      <th>f2v19</th>\n",
       "      <th>f2v20</th>\n",
       "      <th>f2v21</th>\n",
       "      <th>f2v22</th>\n",
       "      <th>f2v23</th>\n",
       "      <th>f2v24</th>\n",
       "      <th>f2v25</th>\n",
       "      <th>f2v26</th>\n",
       "      <th>f2v27</th>\n",
       "      <th>f2v28</th>\n",
       "      <th>f2v29</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_3997</th>\n",
       "      <th>wb_3998</th>\n",
       "      <th>wb_3999</th>\n",
       "      <th>wb_4000</th>\n",
       "      <th>wb_4001</th>\n",
       "      <th>wb_4002</th>\n",
       "      <th>wb_4003</th>\n",
       "      <th>wb_4004</th>\n",
       "      <th>wb_4005</th>\n",
       "      <th>wb_4006</th>\n",
       "      <th>wb_4007</th>\n",
       "      <th>wb_4008</th>\n",
       "      <th>wb_4009</th>\n",
       "      <th>wb_4010</th>\n",
       "      <th>wb_4011</th>\n",
       "      <th>wb_4012</th>\n",
       "      <th>wb_4013</th>\n",
       "      <th>wb_4014</th>\n",
       "      <th>wb_4015</th>\n",
       "      <th>wb_4016</th>\n",
       "      <th>wb_4017</th>\n",
       "      <th>wb_4018</th>\n",
       "      <th>wb_4019</th>\n",
       "      <th>wb_4020</th>\n",
       "      <th>wb_4021</th>\n",
       "      <th>wb_4022</th>\n",
       "      <th>wb_4023</th>\n",
       "      <th>wb_4024</th>\n",
       "      <th>wb_4025</th>\n",
       "      <th>wb_4026</th>\n",
       "      <th>wb_4027</th>\n",
       "      <th>wb_4028</th>\n",
       "      <th>wb_4029</th>\n",
       "      <th>wb_4030</th>\n",
       "      <th>wb_4031</th>\n",
       "      <th>wb_4032</th>\n",
       "      <th>wb_4033</th>\n",
       "      <th>wb_4034</th>\n",
       "      <th>wb_4035</th>\n",
       "      <th>wb_4036</th>\n",
       "      <th>wb_4037</th>\n",
       "      <th>wb_4038</th>\n",
       "      <th>wb_4039</th>\n",
       "      <th>wb_4040</th>\n",
       "      <th>wb_4041</th>\n",
       "      <th>wb_4042</th>\n",
       "      <th>wb_4043</th>\n",
       "      <th>wb_4044</th>\n",
       "      <th>wb_4045</th>\n",
       "      <th>wb_4046</th>\n",
       "      <th>wb_4047</th>\n",
       "      <th>wb_4048</th>\n",
       "      <th>wb_4049</th>\n",
       "      <th>wb_4050</th>\n",
       "      <th>wb_4051</th>\n",
       "      <th>wb_4052</th>\n",
       "      <th>wb_4053</th>\n",
       "      <th>wb_4054</th>\n",
       "      <th>wb_4055</th>\n",
       "      <th>wb_4056</th>\n",
       "      <th>wb_4057</th>\n",
       "      <th>wb_4058</th>\n",
       "      <th>wb_4059</th>\n",
       "      <th>wb_4060</th>\n",
       "      <th>wb_4061</th>\n",
       "      <th>wb_4062</th>\n",
       "      <th>wb_4063</th>\n",
       "      <th>wb_4064</th>\n",
       "      <th>wb_4065</th>\n",
       "      <th>wb_4066</th>\n",
       "      <th>wb_4067</th>\n",
       "      <th>wb_4068</th>\n",
       "      <th>wb_4069</th>\n",
       "      <th>wb_4070</th>\n",
       "      <th>wb_4071</th>\n",
       "      <th>wb_4072</th>\n",
       "      <th>wb_4073</th>\n",
       "      <th>wb_4074</th>\n",
       "      <th>wb_4075</th>\n",
       "      <th>wb_4076</th>\n",
       "      <th>wb_4077</th>\n",
       "      <th>wb_4078</th>\n",
       "      <th>wb_4079</th>\n",
       "      <th>wb_4080</th>\n",
       "      <th>wb_4081</th>\n",
       "      <th>wb_4082</th>\n",
       "      <th>wb_4083</th>\n",
       "      <th>wb_4084</th>\n",
       "      <th>wb_4085</th>\n",
       "      <th>wb_4086</th>\n",
       "      <th>wb_4087</th>\n",
       "      <th>wb_4088</th>\n",
       "      <th>wb_4089</th>\n",
       "      <th>wb_4090</th>\n",
       "      <th>wb_4091</th>\n",
       "      <th>wb_4092</th>\n",
       "      <th>wb_4093</th>\n",
       "      <th>wb_4094</th>\n",
       "      <th>wb_4095</th>\n",
       "      <th>wb_4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>3289.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.714</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.453</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.086</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.860</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>1.078</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>0.869</td>\n",
       "      <td>-1.153</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.801</td>\n",
       "      <td>-0.911</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.443</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-1.058</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-1.060</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>1.326</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-1.009</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.573</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.235</td>\n",
       "      <td>1.146</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-0.810</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>7460.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.313</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-2.226</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-2.323</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-1.238</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.489</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-1.663</td>\n",
       "      <td>1.252</td>\n",
       "      <td>-1.363</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-1.425</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.268</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-1.412</td>\n",
       "      <td>1.797</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.453</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>0.522</td>\n",
       "      <td>1.536</td>\n",
       "      <td>-1.767</td>\n",
       "      <td>-1.312</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.285</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-1.379</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-1.376</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-1.444</td>\n",
       "      <td>-1.614</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-2.175</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-1.857</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>-2.207</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.221</td>\n",
       "      <td>1.858</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>0.293</td>\n",
       "      <td>1.531</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-1.432</td>\n",
       "      <td>-1.458</td>\n",
       "      <td>-1.449</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.268</td>\n",
       "      <td>1.262</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>-1.363</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>-1.779</td>\n",
       "      <td>0.401</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>-1.434</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6043.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.621</td>\n",
       "      <td>1.480</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>1.526</td>\n",
       "      <td>-1.043</td>\n",
       "      <td>0.573</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.502</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.619</td>\n",
       "      <td>1.472</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.417</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>1.529</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>1.263</td>\n",
       "      <td>0.431</td>\n",
       "      <td>1.133</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-1.163</td>\n",
       "      <td>1.613</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.848</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.395</td>\n",
       "      <td>1.120</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>9699.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.476</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.734</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.529</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.664</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.288</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.523</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-1.042</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>0.424</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.536</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>-0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>1.868</td>\n",
       "      <td>1.430</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.606</td>\n",
       "      <td>1.216</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.119</td>\n",
       "      <td>1.162</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>1.337</td>\n",
       "      <td>-1.626</td>\n",
       "      <td>1.613</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>1.540</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-1.493</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-1.053</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-1.323</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-1.329</td>\n",
       "      <td>-1.586</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1.460</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.383</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-1.443</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>-1.815</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  4332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "3289 3289.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460 7460.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043 6043.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699 9699.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5       5.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  \\\n",
       "3289 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5    0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v19  f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v29  f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  \\\n",
       "3289  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "7460  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "6043  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "9699  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5     0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v10  f1v11  f1v12  f1v13  f1v14  f1v15  f1v16  f1v17  f1v18  f1v19  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v20  f1v21  f1v22  f1v23  f1v24  f1v25  f1v26  f1v27  f1v28  f1v29  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f2v0  f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "\n",
       "      f2v11  f2v12  f2v13  f2v14  f2v15  f2v16  f2v17  f2v18  f2v19  f2v20  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f2v21  f2v22  f2v23  f2v24  f2v25  f2v26  f2v27  f2v28  f2v29  f3v0  \\\n",
       "3289  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "7460  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "6043  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "9699  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "5     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "      f3v1  f3v2  f3v3  f3v4  f3v5  f3v6  f3v7  ...  wb_3997  wb_3998  \\\n",
       "3289 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.897   -0.895   \n",
       "7460 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.207   -0.176   \n",
       "6043 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.472   -0.317   \n",
       "9699 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.394   -0.067   \n",
       "5    0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.296   -0.469   \n",
       "\n",
       "      wb_3999  wb_4000  wb_4001  wb_4002  wb_4003  wb_4004  wb_4005  wb_4006  \\\n",
       "3289    0.190    0.423    0.714   -0.513    0.286    0.007    0.169    0.110   \n",
       "7460    0.313    1.306    0.172   -2.226    0.068   -2.323    0.317    0.283   \n",
       "6043    0.348    0.688    0.362   -0.321    0.067    0.399    0.326    0.460   \n",
       "9699    0.426    0.172    0.260   -0.560    0.064    0.433    0.447    0.456   \n",
       "5       0.208    0.431    0.106   -0.592    1.868    1.430    0.370    0.181   \n",
       "\n",
       "      wb_4007  wb_4008  wb_4009  wb_4010  wb_4011  wb_4012  wb_4013  wb_4014  \\\n",
       "3289   -0.265    0.016    0.218    0.453    1.378    1.086    0.982    0.860   \n",
       "7460   -1.238    0.297    0.519    0.384    0.489    1.099    0.416    0.140   \n",
       "6043   -0.174    0.485    0.445    0.454    0.579    0.461    0.621    1.480   \n",
       "9699   -0.637    0.375    0.696    0.157    0.522    0.321    0.121    0.128   \n",
       "5      -0.182    0.269    1.606    1.216    0.128    0.461    0.119    1.162   \n",
       "\n",
       "      wb_4015  wb_4016  wb_4017  wb_4018  wb_4019  wb_4020  wb_4021  wb_4022  \\\n",
       "3289   -0.357    1.078   -0.667    0.869   -1.153   -0.174   -0.899   -0.478   \n",
       "7460   -0.183    0.442   -1.663    1.252   -1.363   -0.529   -0.104   -1.425   \n",
       "6043   -0.404    1.526   -1.043    0.573   -0.093   -0.176   -0.106   -0.200   \n",
       "9699   -0.467    0.476   -0.745    0.536   -0.521   -0.178   -0.105   -0.300   \n",
       "5      -0.472    1.337   -1.626    1.613   -0.419   -0.176   -0.104   -0.253   \n",
       "\n",
       "      wb_4023  wb_4024  wb_4025  wb_4026  wb_4027  wb_4028  wb_4029  wb_4030  \\\n",
       "3289    0.279    0.127   -0.108   -0.665    0.405   -0.765    0.801   -0.911   \n",
       "7460    0.282    0.268   -0.438   -1.412    1.797   -0.371    0.453   -0.401   \n",
       "6043    0.369    0.024   -0.094   -0.389    0.505   -0.065    0.502   -0.430   \n",
       "9699    0.451    0.369   -0.734   -0.138    0.406   -0.483    0.529   -0.125   \n",
       "5       0.475    0.224   -0.462   -0.474    0.099   -0.425    1.540   -0.359   \n",
       "\n",
       "      wb_4031  wb_4032  wb_4033  wb_4034  wb_4035  wb_4036  wb_4037  wb_4038  \\\n",
       "3289    0.324    0.443   -0.117    0.343    0.176   -1.058   -0.107   -0.214   \n",
       "7460    0.522    1.536   -1.767   -1.312    0.377   -0.499   -0.107   -1.285   \n",
       "6043    0.619    1.472   -0.115    0.428    0.417   -0.311   -0.107   -0.284   \n",
       "9699    0.536    0.397   -0.664    0.411    0.131   -0.526   -0.107   -0.230   \n",
       "5       0.392    0.974   -0.115   -0.499   -1.493   -0.684   -0.107   -0.323   \n",
       "\n",
       "      wb_4039  wb_4040  wb_4041  wb_4042  wb_4043  wb_4044  wb_4045  wb_4046  \\\n",
       "3289    0.341    0.179    0.008    0.403   -1.060   -0.568   -0.207    1.326   \n",
       "7460    0.499    0.301   -0.207   -0.257   -1.379   -0.282    0.397    0.158   \n",
       "6043    1.529    0.126   -0.298   -0.275   -0.277    1.263    0.431    1.133   \n",
       "9699    0.199    0.316   -0.213    0.288   -0.228   -0.426   -0.418    0.523   \n",
       "5       1.192    0.038   -0.104   -0.354   -0.437   -1.053   -0.396    0.170   \n",
       "\n",
       "      wb_4047  wb_4048  wb_4049  wb_4050  wb_4051  wb_4052  wb_4053  wb_4054  \\\n",
       "3289   -0.257   -0.504   -0.639   -0.919    0.084    0.153   -0.985   -0.658   \n",
       "7460   -1.376   -0.296   -1.444   -1.614    0.699   -0.183   -0.426   -2.175   \n",
       "6043   -0.290    0.258   -0.247   -0.438    0.485    0.289   -0.048   -0.297   \n",
       "9699   -0.526   -0.103   -0.412   -0.575    0.309   -0.382   -1.042   -0.099   \n",
       "5      -0.412   -0.241   -0.396   -0.459    0.400    0.273   -0.531   -1.323   \n",
       "\n",
       "      wb_4055  wb_4056  wb_4057  wb_4058  wb_4059  wb_4060  wb_4061  wb_4062  \\\n",
       "3289   -0.188   -0.126   -0.713    0.271   -0.300   -0.268    0.086    0.159   \n",
       "7460    0.180   -0.586   -1.857    0.193   -1.222   -2.207    0.197    0.221   \n",
       "6043    0.294   -0.276    0.460    0.192   -0.436   -0.358    0.064    0.036   \n",
       "9699    0.333   -0.363   -0.434    0.310   -0.248   -0.066    0.220    0.121   \n",
       "5       0.270   -0.378    0.296    0.160   -0.543   -0.441    0.220    0.225   \n",
       "\n",
       "      wb_4063  wb_4064  wb_4065  wb_4066  wb_4067  wb_4068  wb_4069  wb_4070  \\\n",
       "3289   -0.252   -1.009    0.145   -0.573   -0.913   -0.309   -0.170   -0.438   \n",
       "7460    1.858   -0.413    0.293    1.531   -0.398   -1.432   -1.458   -1.449   \n",
       "6043    0.373   -1.052    0.453    0.475   -0.085   -0.485   -0.315   -0.387   \n",
       "9699   -0.486   -0.563    0.424   -0.537   -0.358   -0.561   -0.523   -0.474   \n",
       "5       0.296   -1.420    0.839    0.350   -0.446   -1.329   -1.586   -0.115   \n",
       "\n",
       "      wb_4071  wb_4072  wb_4073  wb_4074  wb_4075  wb_4076  wb_4077  wb_4078  \\\n",
       "3289   -0.106    0.155    0.224    0.721    0.242   -0.599   -1.062    0.230   \n",
       "7460   -0.106    0.268    1.262    0.394    0.459   -1.361   -1.363    0.377   \n",
       "6043   -0.106    0.191    0.428    0.417    0.765   -0.387   -1.163    1.613   \n",
       "9699   -0.106    0.381    0.439    0.082    0.077   -0.207   -0.536    0.441   \n",
       "5      -0.106    0.146    1.460    0.363    0.383   -0.174   -0.811    0.386   \n",
       "\n",
       "      wb_4079  wb_4080  wb_4081  wb_4082  wb_4083  wb_4084  wb_4085  wb_4086  \\\n",
       "3289   -0.797   -0.196    0.295   -0.196   -0.749   -0.279    0.074    0.235   \n",
       "7460   -0.803   -1.779    0.401   -0.309   -1.878   -1.434    0.253    0.650   \n",
       "6043   -0.320    0.920    0.848   -0.262   -0.749   -0.924    0.245    0.395   \n",
       "9699   -0.441   -0.463    0.168   -0.408   -0.737   -0.403    0.261    0.420   \n",
       "5      -1.443    0.349    0.452   -0.395   -0.604   -1.815    0.239    0.328   \n",
       "\n",
       "      wb_4087  wb_4088  wb_4089  wb_4090  wb_4091  wb_4092  wb_4093  wb_4094  \\\n",
       "3289    1.146    0.150    0.285   -0.043   -0.144   -0.406    0.132   -0.385   \n",
       "7460    0.430    0.196    0.347   -0.152    0.249   -0.311    0.290   -0.315   \n",
       "6043    1.120    0.331    0.365   -0.226   -0.268   -0.138    0.324    0.319   \n",
       "9699    0.177    0.279    0.333   -0.020    0.359   -0.225    0.093   -0.544   \n",
       "5       0.389    0.145    0.160   -0.335   -0.309   -0.376    0.413   -0.244   \n",
       "\n",
       "      wb_4095  wb_4096  \n",
       "3289   -0.810   -0.066  \n",
       "7460   -1.524    0.158  \n",
       "6043    0.554    0.074  \n",
       "9699   -0.623   -0.171  \n",
       "5      -0.321   -0.170  \n",
       "\n",
       "[5 rows x 4332 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:42:13.620282Z",
     "iopub.status.busy": "2021-12-17T08:42:13.619996Z",
     "iopub.status.idle": "2021-12-17T08:42:15.535024Z",
     "shell.execute_reply": "2021-12-17T08:42:15.534452Z",
     "shell.execute_reply.started": "2021-12-17T08:42:13.620255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f2v15</th>\n",
       "      <th>f2v16</th>\n",
       "      <th>f2v17</th>\n",
       "      <th>f2v18</th>\n",
       "      <th>f2v19</th>\n",
       "      <th>f2v20</th>\n",
       "      <th>f2v21</th>\n",
       "      <th>f2v22</th>\n",
       "      <th>f2v23</th>\n",
       "      <th>f2v24</th>\n",
       "      <th>f2v25</th>\n",
       "      <th>f2v26</th>\n",
       "      <th>f2v27</th>\n",
       "      <th>f2v28</th>\n",
       "      <th>f2v29</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_3997</th>\n",
       "      <th>wb_3998</th>\n",
       "      <th>wb_3999</th>\n",
       "      <th>wb_4000</th>\n",
       "      <th>wb_4001</th>\n",
       "      <th>wb_4002</th>\n",
       "      <th>wb_4003</th>\n",
       "      <th>wb_4004</th>\n",
       "      <th>wb_4005</th>\n",
       "      <th>wb_4006</th>\n",
       "      <th>wb_4007</th>\n",
       "      <th>wb_4008</th>\n",
       "      <th>wb_4009</th>\n",
       "      <th>wb_4010</th>\n",
       "      <th>wb_4011</th>\n",
       "      <th>wb_4012</th>\n",
       "      <th>wb_4013</th>\n",
       "      <th>wb_4014</th>\n",
       "      <th>wb_4015</th>\n",
       "      <th>wb_4016</th>\n",
       "      <th>wb_4017</th>\n",
       "      <th>wb_4018</th>\n",
       "      <th>wb_4019</th>\n",
       "      <th>wb_4020</th>\n",
       "      <th>wb_4021</th>\n",
       "      <th>wb_4022</th>\n",
       "      <th>wb_4023</th>\n",
       "      <th>wb_4024</th>\n",
       "      <th>wb_4025</th>\n",
       "      <th>wb_4026</th>\n",
       "      <th>wb_4027</th>\n",
       "      <th>wb_4028</th>\n",
       "      <th>wb_4029</th>\n",
       "      <th>wb_4030</th>\n",
       "      <th>wb_4031</th>\n",
       "      <th>wb_4032</th>\n",
       "      <th>wb_4033</th>\n",
       "      <th>wb_4034</th>\n",
       "      <th>wb_4035</th>\n",
       "      <th>wb_4036</th>\n",
       "      <th>wb_4037</th>\n",
       "      <th>wb_4038</th>\n",
       "      <th>wb_4039</th>\n",
       "      <th>wb_4040</th>\n",
       "      <th>wb_4041</th>\n",
       "      <th>wb_4042</th>\n",
       "      <th>wb_4043</th>\n",
       "      <th>wb_4044</th>\n",
       "      <th>wb_4045</th>\n",
       "      <th>wb_4046</th>\n",
       "      <th>wb_4047</th>\n",
       "      <th>wb_4048</th>\n",
       "      <th>wb_4049</th>\n",
       "      <th>wb_4050</th>\n",
       "      <th>wb_4051</th>\n",
       "      <th>wb_4052</th>\n",
       "      <th>wb_4053</th>\n",
       "      <th>wb_4054</th>\n",
       "      <th>wb_4055</th>\n",
       "      <th>wb_4056</th>\n",
       "      <th>wb_4057</th>\n",
       "      <th>wb_4058</th>\n",
       "      <th>wb_4059</th>\n",
       "      <th>wb_4060</th>\n",
       "      <th>wb_4061</th>\n",
       "      <th>wb_4062</th>\n",
       "      <th>wb_4063</th>\n",
       "      <th>wb_4064</th>\n",
       "      <th>wb_4065</th>\n",
       "      <th>wb_4066</th>\n",
       "      <th>wb_4067</th>\n",
       "      <th>wb_4068</th>\n",
       "      <th>wb_4069</th>\n",
       "      <th>wb_4070</th>\n",
       "      <th>wb_4071</th>\n",
       "      <th>wb_4072</th>\n",
       "      <th>wb_4073</th>\n",
       "      <th>wb_4074</th>\n",
       "      <th>wb_4075</th>\n",
       "      <th>wb_4076</th>\n",
       "      <th>wb_4077</th>\n",
       "      <th>wb_4078</th>\n",
       "      <th>wb_4079</th>\n",
       "      <th>wb_4080</th>\n",
       "      <th>wb_4081</th>\n",
       "      <th>wb_4082</th>\n",
       "      <th>wb_4083</th>\n",
       "      <th>wb_4084</th>\n",
       "      <th>wb_4085</th>\n",
       "      <th>wb_4086</th>\n",
       "      <th>wb_4087</th>\n",
       "      <th>wb_4088</th>\n",
       "      <th>wb_4089</th>\n",
       "      <th>wb_4090</th>\n",
       "      <th>wb_4091</th>\n",
       "      <th>wb_4092</th>\n",
       "      <th>wb_4093</th>\n",
       "      <th>wb_4094</th>\n",
       "      <th>wb_4095</th>\n",
       "      <th>wb_4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7217.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.823</td>\n",
       "      <td>1.202</td>\n",
       "      <td>1.414</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>0.255</td>\n",
       "      <td>1.189</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.306</td>\n",
       "      <td>1.468</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>1.176</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-1.661</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-1.673</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.667</td>\n",
       "      <td>-1.161</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>1.733</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>2.217</td>\n",
       "      <td>1.050</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.872</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-1.073</td>\n",
       "      <td>0.515</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-1.098</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-1.233</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-1.105</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.344</td>\n",
       "      <td>1.550</td>\n",
       "      <td>1.541</td>\n",
       "      <td>-1.015</td>\n",
       "      <td>-1.763</td>\n",
       "      <td>1.387</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>1.559</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-1.219</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.070</td>\n",
       "      <td>2.006</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1.087</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>8291.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-1.543</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-1.049</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.467</td>\n",
       "      <td>1.782</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-1.564</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>-1.059</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-1.579</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-1.393</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.030</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>-1.102</td>\n",
       "      <td>-1.605</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-1.479</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.319</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-1.106</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-1.452</td>\n",
       "      <td>-1.274</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-1.177</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1.396</td>\n",
       "      <td>0.411</td>\n",
       "      <td>1.234</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-1.139</td>\n",
       "      <td>1.443</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>1.832</td>\n",
       "      <td>-1.115</td>\n",
       "      <td>-1.784</td>\n",
       "      <td>-1.097</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.473</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>-0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-1.854</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.291</td>\n",
       "      <td>1.589</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.296</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.872</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-1.981</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.461</td>\n",
       "      <td>1.179</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>1.055</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.178</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-1.211</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.463</td>\n",
       "      <td>0.738</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>1.746</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>1.277</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-1.708</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>0.770</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.584</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1.775</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.913</td>\n",
       "      <td>1.221</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>1.205</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.836</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.709</td>\n",
       "      <td>1.067</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.244</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>5114.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-1.111</td>\n",
       "      <td>0.241</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.855</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.621</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.502</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.267</td>\n",
       "      <td>1.402</td>\n",
       "      <td>1.744</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-1.015</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-1.211</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-1.208</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>1.656</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.877</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-1.291</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>1.184</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-1.307</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.217</td>\n",
       "      <td>1.344</td>\n",
       "      <td>1.363</td>\n",
       "      <td>0.519</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-1.048</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.364</td>\n",
       "      <td>1.107</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-1.275</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.272</td>\n",
       "      <td>1.532</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.496</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.421</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.517</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>0.635</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>0.588</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.592</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>0.361</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.424</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.557</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  4332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "7217 7217.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 8291.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 4607.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 5114.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 1859.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  \\\n",
       "7217 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v19  f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f0v29  f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  \\\n",
       "7217  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v10  f1v11  f1v12  f1v13  f1v14  f1v15  f1v16  f1v17  f1v18  f1v19  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f1v20  f1v21  f1v22  f1v23  f1v24  f1v25  f1v26  f1v27  f1v28  f1v29  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f2v0  f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "\n",
       "      f2v11  f2v12  f2v13  f2v14  f2v15  f2v16  f2v17  f2v18  f2v19  f2v20  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f2v21  f2v22  f2v23  f2v24  f2v25  f2v26  f2v27  f2v28  f2v29  f3v0  \\\n",
       "7217  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "8291  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "4607  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "5114  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "1859  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "      f3v1  f3v2  f3v3  f3v4  f3v5  f3v6  f3v7  ...  wb_3997  wb_3998  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.641   -0.823   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.309   -1.543   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.269   -0.358   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.350   -1.111   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...    0.257   -0.496   \n",
       "\n",
       "      wb_3999  wb_4000  wb_4001  wb_4002  wb_4003  wb_4004  wb_4005  wb_4006  \\\n",
       "7217    1.202    1.414    0.272   -0.567    0.067   -0.783    0.255    1.189   \n",
       "8291    0.387    0.639    0.237   -0.069    0.068    0.238    0.399    0.236   \n",
       "4607    0.327    0.990    0.167   -1.854    0.534    0.014    0.291    1.589   \n",
       "5114    0.241    1.051    0.971   -0.855    0.067    1.621    0.252    0.812   \n",
       "1859    0.502    0.625    0.267   -0.519    0.066    0.521    0.274    0.421   \n",
       "\n",
       "      wb_4007  wb_4008  wb_4009  wb_4010  wb_4011  wb_4012  wb_4013  wb_4014  \\\n",
       "7217   -0.988    0.143    0.355    0.306    1.468    0.337    0.119    0.407   \n",
       "8291   -1.049   -0.904    0.357    0.467    1.782    0.435    0.105    0.406   \n",
       "4607   -0.454    0.852    1.296    0.839    0.480    0.506    0.360    0.442   \n",
       "5114   -1.095    0.180    0.067    1.502    1.089    0.267    1.402    1.744   \n",
       "1859   -0.577    0.438    0.503    0.477    0.563    0.131    0.123    0.517   \n",
       "\n",
       "      wb_4015  wb_4016  wb_4017  wb_4018  wb_4019  wb_4020  wb_4021  wb_4022  \\\n",
       "7217   -0.518    1.176   -0.591    0.440   -0.370   -0.176   -1.661   -0.198   \n",
       "8291   -0.983    0.100   -0.989    0.121   -1.564   -0.177   -0.494   -0.803   \n",
       "4607   -0.384    0.872   -0.197    0.126   -0.207   -1.981   -1.361   -0.244   \n",
       "5114   -0.798    1.705   -0.485    0.124   -1.015   -0.617   -0.103   -0.142   \n",
       "1859   -0.540    0.635   -0.620    0.588   -0.515   -0.183   -0.100   -0.401   \n",
       "\n",
       "      wb_4023  wb_4024  wb_4025  wb_4026  wb_4027  wb_4028  wb_4029  wb_4030  \\\n",
       "7217    0.455    0.176   -0.417   -0.359    0.375   -0.451    0.681   -0.340   \n",
       "8291    0.374    0.273   -1.021   -1.059    0.120   -1.579    0.442   -0.450   \n",
       "4607    0.461    1.179   -0.077   -0.219    0.313   -0.791    1.055   -0.089   \n",
       "5114    0.181    0.149   -0.526   -1.211    0.455   -0.364    0.138   -0.745   \n",
       "1859    0.301    0.159   -0.498   -0.511    0.335   -0.492    0.138   -0.508   \n",
       "\n",
       "      wb_4031  wb_4032  wb_4033  wb_4034  wb_4035  wb_4036  wb_4037  wb_4038  \\\n",
       "7217    0.362    0.275   -1.673    0.277    0.667   -1.161   -0.107   -0.318   \n",
       "8291    0.404   -1.515   -1.257    0.313   -1.393   -0.112   -0.107   -1.030   \n",
       "4607    0.317    1.178   -0.383    0.425   -1.211   -0.195   -0.101   -0.198   \n",
       "5114    0.325    0.823   -1.208   -0.566    1.656   -0.404   -0.107   -0.877   \n",
       "1859    0.171    0.592   -0.519    0.672    0.480   -0.367   -0.107   -0.241   \n",
       "\n",
       "      wb_4039  wb_4040  wb_4041  wb_4042  wb_4043  wb_4044  wb_4045  wb_4046  \\\n",
       "7217    0.364    0.343   -0.089    0.184   -0.292   -0.347   -0.652    1.733   \n",
       "8291    0.317    0.296   -0.451   -0.611   -1.102   -1.605    0.281    0.540   \n",
       "4607    1.463    0.738   -0.200    0.143   -0.316   -0.228   -0.266    1.746   \n",
       "5114    0.531    0.323   -0.079   -0.124   -0.847   -0.638   -0.179    0.168   \n",
       "1859    0.509    0.307   -0.026    0.385   -0.486   -0.295    0.473    0.171   \n",
       "\n",
       "      wb_4047  wb_4048  wb_4049  wb_4050  wb_4051  wb_4052  wb_4053  wb_4054  \\\n",
       "7217   -0.307   -0.225   -0.334   -1.295    2.217    1.050   -0.037   -0.410   \n",
       "8291   -0.472   -0.956   -0.701   -1.479    0.070    0.319   -0.974   -1.095   \n",
       "4607   -0.591   -0.223   -0.301   -0.457    1.277    0.966   -1.708   -0.392   \n",
       "5114   -1.291   -0.095   -0.301   -0.356    1.184    0.102   -0.719   -0.178   \n",
       "1859   -0.515   -0.429   -0.432   -0.487    0.081   -0.281   -0.480   -0.452   \n",
       "\n",
       "      wb_4055  wb_4056  wb_4057  wb_4058  wb_4059  wb_4060  wb_4061  wb_4062  \\\n",
       "7217    0.872   -0.473   -1.073    0.515   -0.394   -0.427   -0.447    0.160   \n",
       "8291    0.328   -1.106   -0.364    0.400   -0.432   -0.069    0.251    0.196   \n",
       "4607    0.770   -0.252    0.268    0.584   -0.164   -0.372    0.171    0.146   \n",
       "5114    0.148   -0.215   -0.776    0.294   -0.282   -0.348    0.013    0.142   \n",
       "1859    0.361   -0.347   -0.429    0.184   -0.518   -0.064    0.291    0.123   \n",
       "\n",
       "      wb_4063  wb_4064  wb_4065  wb_4066  wb_4067  wb_4068  wb_4069  wb_4070  \\\n",
       "7217   -0.332   -1.098    0.321   -1.233   -0.262   -0.422   -1.105   -0.185   \n",
       "8291   -1.452   -1.274    0.432   -1.177   -0.403   -0.535   -0.477   -0.705   \n",
       "4607    0.377   -0.374    0.608    1.775   -0.137   -0.980   -0.298   -0.360   \n",
       "5114   -1.307   -0.568    0.075    0.283   -0.164   -0.965   -0.968   -0.272   \n",
       "1859   -0.447   -0.077    0.468    0.424   -0.450   -0.176   -0.545   -0.308   \n",
       "\n",
       "      wb_4071  wb_4072  wb_4073  wb_4074  wb_4075  wb_4076  wb_4077  wb_4078  \\\n",
       "7217   -0.106    0.177    0.344    1.550    1.541   -1.015   -1.763    1.387   \n",
       "8291   -0.106    0.401    1.396    0.411    1.234   -0.765   -1.139    1.443   \n",
       "4607   -0.106    0.265    0.453    0.913    1.221   -0.187   -0.075    0.615   \n",
       "5114   -0.106    0.217    1.344    1.363    0.519   -1.524   -0.374    0.357   \n",
       "1859   -0.106    0.332    0.451    0.539    0.471   -0.543   -0.630    0.043   \n",
       "\n",
       "      wb_4079  wb_4080  wb_4081  wb_4082  wb_4083  wb_4084  wb_4085  wb_4086  \\\n",
       "7217   -0.196   -0.395    1.559   -0.400   -1.219   -0.492    0.287    0.070   \n",
       "8291   -0.039   -0.610    1.832   -1.115   -1.784   -1.097    0.252    0.430   \n",
       "4607   -0.406    1.205    0.408    0.836   -0.918   -1.032    0.533    0.487   \n",
       "5114   -0.440    0.307    0.462   -0.153   -0.465   -1.048    0.233    0.694   \n",
       "1859   -0.126   -0.446    0.557   -0.420   -0.292   -0.503    0.057    0.503   \n",
       "\n",
       "      wb_4087  wb_4088  wb_4089  wb_4090  wb_4091  wb_4092  wb_4093  wb_4094  \\\n",
       "7217    2.006    0.646    1.087   -0.141   -0.366   -0.170    0.918   -0.490   \n",
       "8291    0.313    0.413    0.473   -0.924   -0.845   -0.393    0.560    0.241   \n",
       "4607    0.965    0.709    1.067   -0.093   -0.223   -0.185    0.670    0.244   \n",
       "5114    0.364    1.107    0.291   -0.081   -1.275   -0.240    0.272    1.532   \n",
       "1859    0.582   -0.072    0.367   -0.110    0.471   -0.440    0.434   -0.413   \n",
       "\n",
       "      wb_4095  wb_4096  \n",
       "7217   -0.399   -0.153  \n",
       "8291   -0.779   -0.168  \n",
       "4607    1.031    0.088  \n",
       "5114   -0.474   -0.207  \n",
       "1859   -0.404    0.202  \n",
       "\n",
       "[5 rows x 4332 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-17T08:42:15.536136Z",
     "iopub.status.busy": "2021-12-17T08:42:15.535903Z",
     "iopub.status.idle": "2021-12-17T08:42:15.873587Z",
     "shell.execute_reply": "2021-12-17T08:42:15.872617Z",
     "shell.execute_reply.started": "2021-12-17T08:42:15.536111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f0v15</th>\n",
       "      <th>f0v16</th>\n",
       "      <th>f0v17</th>\n",
       "      <th>f0v18</th>\n",
       "      <th>f0v19</th>\n",
       "      <th>f0v20</th>\n",
       "      <th>f0v21</th>\n",
       "      <th>f0v22</th>\n",
       "      <th>f0v23</th>\n",
       "      <th>f0v24</th>\n",
       "      <th>f0v25</th>\n",
       "      <th>f0v26</th>\n",
       "      <th>f0v27</th>\n",
       "      <th>f0v28</th>\n",
       "      <th>f0v29</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f1v15</th>\n",
       "      <th>f1v16</th>\n",
       "      <th>f1v17</th>\n",
       "      <th>f1v18</th>\n",
       "      <th>f1v19</th>\n",
       "      <th>f1v20</th>\n",
       "      <th>f1v21</th>\n",
       "      <th>f1v22</th>\n",
       "      <th>f1v23</th>\n",
       "      <th>f1v24</th>\n",
       "      <th>f1v25</th>\n",
       "      <th>f1v26</th>\n",
       "      <th>f1v27</th>\n",
       "      <th>f1v28</th>\n",
       "      <th>f1v29</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f2v15</th>\n",
       "      <th>f2v16</th>\n",
       "      <th>f2v17</th>\n",
       "      <th>f2v18</th>\n",
       "      <th>f2v19</th>\n",
       "      <th>f2v20</th>\n",
       "      <th>f2v21</th>\n",
       "      <th>f2v22</th>\n",
       "      <th>f2v23</th>\n",
       "      <th>f2v24</th>\n",
       "      <th>f2v25</th>\n",
       "      <th>f2v26</th>\n",
       "      <th>f2v27</th>\n",
       "      <th>f2v28</th>\n",
       "      <th>f2v29</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_3997</th>\n",
       "      <th>wb_3998</th>\n",
       "      <th>wb_3999</th>\n",
       "      <th>wb_4000</th>\n",
       "      <th>wb_4001</th>\n",
       "      <th>wb_4002</th>\n",
       "      <th>wb_4003</th>\n",
       "      <th>wb_4004</th>\n",
       "      <th>wb_4005</th>\n",
       "      <th>wb_4006</th>\n",
       "      <th>wb_4007</th>\n",
       "      <th>wb_4008</th>\n",
       "      <th>wb_4009</th>\n",
       "      <th>wb_4010</th>\n",
       "      <th>wb_4011</th>\n",
       "      <th>wb_4012</th>\n",
       "      <th>wb_4013</th>\n",
       "      <th>wb_4014</th>\n",
       "      <th>wb_4015</th>\n",
       "      <th>wb_4016</th>\n",
       "      <th>wb_4017</th>\n",
       "      <th>wb_4018</th>\n",
       "      <th>wb_4019</th>\n",
       "      <th>wb_4020</th>\n",
       "      <th>wb_4021</th>\n",
       "      <th>wb_4022</th>\n",
       "      <th>wb_4023</th>\n",
       "      <th>wb_4024</th>\n",
       "      <th>wb_4025</th>\n",
       "      <th>wb_4026</th>\n",
       "      <th>wb_4027</th>\n",
       "      <th>wb_4028</th>\n",
       "      <th>wb_4029</th>\n",
       "      <th>wb_4030</th>\n",
       "      <th>wb_4031</th>\n",
       "      <th>wb_4032</th>\n",
       "      <th>wb_4033</th>\n",
       "      <th>wb_4034</th>\n",
       "      <th>wb_4035</th>\n",
       "      <th>wb_4036</th>\n",
       "      <th>wb_4037</th>\n",
       "      <th>wb_4038</th>\n",
       "      <th>wb_4039</th>\n",
       "      <th>wb_4040</th>\n",
       "      <th>wb_4041</th>\n",
       "      <th>wb_4042</th>\n",
       "      <th>wb_4043</th>\n",
       "      <th>wb_4044</th>\n",
       "      <th>wb_4045</th>\n",
       "      <th>wb_4046</th>\n",
       "      <th>wb_4047</th>\n",
       "      <th>wb_4048</th>\n",
       "      <th>wb_4049</th>\n",
       "      <th>wb_4050</th>\n",
       "      <th>wb_4051</th>\n",
       "      <th>wb_4052</th>\n",
       "      <th>wb_4053</th>\n",
       "      <th>wb_4054</th>\n",
       "      <th>wb_4055</th>\n",
       "      <th>wb_4056</th>\n",
       "      <th>wb_4057</th>\n",
       "      <th>wb_4058</th>\n",
       "      <th>wb_4059</th>\n",
       "      <th>wb_4060</th>\n",
       "      <th>wb_4061</th>\n",
       "      <th>wb_4062</th>\n",
       "      <th>wb_4063</th>\n",
       "      <th>wb_4064</th>\n",
       "      <th>wb_4065</th>\n",
       "      <th>wb_4066</th>\n",
       "      <th>wb_4067</th>\n",
       "      <th>wb_4068</th>\n",
       "      <th>wb_4069</th>\n",
       "      <th>wb_4070</th>\n",
       "      <th>wb_4071</th>\n",
       "      <th>wb_4072</th>\n",
       "      <th>wb_4073</th>\n",
       "      <th>wb_4074</th>\n",
       "      <th>wb_4075</th>\n",
       "      <th>wb_4076</th>\n",
       "      <th>wb_4077</th>\n",
       "      <th>wb_4078</th>\n",
       "      <th>wb_4079</th>\n",
       "      <th>wb_4080</th>\n",
       "      <th>wb_4081</th>\n",
       "      <th>wb_4082</th>\n",
       "      <th>wb_4083</th>\n",
       "      <th>wb_4084</th>\n",
       "      <th>wb_4085</th>\n",
       "      <th>wb_4086</th>\n",
       "      <th>wb_4087</th>\n",
       "      <th>wb_4088</th>\n",
       "      <th>wb_4089</th>\n",
       "      <th>wb_4090</th>\n",
       "      <th>wb_4091</th>\n",
       "      <th>wb_4092</th>\n",
       "      <th>wb_4093</th>\n",
       "      <th>wb_4094</th>\n",
       "      <th>wb_4095</th>\n",
       "      <th>wb_4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.558</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.676</td>\n",
       "      <td>-1.301</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.454</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.815</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.669</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.333</td>\n",
       "      <td>2.164</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>-0.723</td>\n",
       "      <td>-1.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>-1.690</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>-0.548</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.630</td>\n",
       "      <td>2.623</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>-1.543</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.568</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>2.521</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-2.504</td>\n",
       "      <td>-1.527</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1.562</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-0.702</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.599</td>\n",
       "      <td>-2.511</td>\n",
       "      <td>2.283</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.783</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.316</td>\n",
       "      <td>2.669</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>1.810</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.133</td>\n",
       "      <td>3.201</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-3.144</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>2.630</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.732</td>\n",
       "      <td>-2.809</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-1.753</td>\n",
       "      <td>2.408</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2.054</td>\n",
       "      <td>-2.606</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.294</td>\n",
       "      <td>3.515</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-2.566</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-2.753</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-1.444</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>2.710</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>2.601</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-3.373</td>\n",
       "      <td>-3.603</td>\n",
       "      <td>-1.407</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3.225</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-1.192</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-1.421</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.334</td>\n",
       "      <td>3.219</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-1.669</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-2.995</td>\n",
       "      <td>-0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.516</td>\n",
       "      <td>-1.512</td>\n",
       "      <td>1.290</td>\n",
       "      <td>2.585</td>\n",
       "      <td>1.281</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.059</td>\n",
       "      <td>4.009</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.533</td>\n",
       "      <td>1.741</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.133</td>\n",
       "      <td>3.576</td>\n",
       "      <td>-2.180</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-3.598</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-2.243</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>3.040</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>1.752</td>\n",
       "      <td>3.266</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.816</td>\n",
       "      <td>3.963</td>\n",
       "      <td>-2.147</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-2.674</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1.770</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-2.586</td>\n",
       "      <td>-2.326</td>\n",
       "      <td>2.180</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-3.498</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-1.337</td>\n",
       "      <td>4.513</td>\n",
       "      <td>1.806</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.545</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.483</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.253</td>\n",
       "      <td>3.337</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-2.190</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.878</td>\n",
       "      <td>2.984</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-2.133</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.690</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-1.963</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.088</td>\n",
       "      <td>2.191</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-3.174</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>2.317</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-2.190</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476</td>\n",
       "      <td>-4.002</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-3.108</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.083</td>\n",
       "      <td>2.626</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>3.453</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>3.357</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.627</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.516</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.647</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.531</td>\n",
       "      <td>2.842</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  4332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  f0v9  \\\n",
       "29 29.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38 38.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79 79.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19 19.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27 27.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f0v10  f0v11  f0v12  f0v13  f0v14  f0v15  f0v16  f0v17  f0v18  f0v19  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f0v20  f0v21  f0v22  f0v23  f0v24  f0v25  f0v26  f0v27  f0v28  f0v29  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f1v0  f1v1  f1v2  f1v3  f1v4  f1v5  f1v6  f1v7  f1v8  f1v9  f1v10  f1v11  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "    f1v12  f1v13  f1v14  f1v15  f1v16  f1v17  f1v18  f1v19  f1v20  f1v21  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f1v22  f1v23  f1v24  f1v25  f1v26  f1v27  f1v28  f1v29  f2v0  f2v1  f2v2  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  f2v11  f2v12  f2v13  \\\n",
       "29 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "38 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "79 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "19 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "27 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f2v14  f2v15  f2v16  f2v17  f2v18  f2v19  f2v20  f2v21  f2v22  f2v23  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    f2v24  f2v25  f2v26  f2v27  f2v28  f2v29  f3v0  f3v1  f3v2  f3v3  f3v4  \\\n",
       "29  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "38  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "79  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "19  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "27  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "    f3v5  f3v6  f3v7  ...  wb_3997  wb_3998  wb_3999  wb_4000  wb_4001  \\\n",
       "29 0.000 0.000 0.000  ...    0.710   -1.008    0.531    0.173    0.558   \n",
       "38 0.000 0.000 0.000  ...    0.140   -0.194    0.184    0.175    0.175   \n",
       "79 0.000 0.000 0.000  ...    2.599   -2.511    2.283    0.172    0.783   \n",
       "19 0.000 0.000 0.000  ...    1.516   -1.512    1.290    2.585    1.281   \n",
       "27 0.000 0.000 0.000  ...    0.476   -4.002    0.360    0.739    0.215   \n",
       "\n",
       "    wb_4002  wb_4003  wb_4004  wb_4005  wb_4006  wb_4007  wb_4008  wb_4009  \\\n",
       "29   -0.080    0.073    0.018    0.383    0.676   -1.301   -0.656    0.078   \n",
       "38   -0.070    0.073    0.018    0.236    0.145   -0.208    0.054    0.083   \n",
       "79   -0.080    0.073    0.018    0.316    2.669   -0.193    1.810    0.610   \n",
       "19   -0.080    0.073    0.018    0.059    4.009   -0.984    2.346    2.533   \n",
       "27   -0.080    0.073    0.018    0.404    0.440   -3.108    0.449    0.083   \n",
       "\n",
       "    wb_4010  wb_4011  wb_4012  wb_4013  wb_4014  wb_4015  wb_4016  wb_4017  \\\n",
       "29    0.606    0.137    0.704    0.133    0.161   -0.661    0.104   -0.212   \n",
       "38    0.256    0.143    0.267    0.133    0.253   -0.310    0.112   -0.212   \n",
       "79    0.315    0.143    0.298    0.133    3.201   -0.319    0.106   -0.210   \n",
       "19    1.741    0.143    0.138    0.133    3.576   -2.180    0.111   -0.212   \n",
       "27    2.626    0.138    0.383    0.133    0.162   -0.622    3.453   -0.207   \n",
       "\n",
       "    wb_4018  wb_4019  wb_4020  wb_4021  wb_4022  wb_4023  wb_4024  wb_4025  \\\n",
       "29    0.135   -0.122   -0.183   -0.113   -0.409    0.514    0.454   -0.117   \n",
       "38    0.135   -0.239   -0.183   -0.113   -0.120    0.216    0.038   -0.114   \n",
       "79    0.135   -3.144   -0.183   -0.113   -0.006    2.630    0.063   -0.732   \n",
       "19    0.135   -3.598   -0.183   -0.113   -2.243   -0.211   -0.144   -0.170   \n",
       "27    0.135   -0.127   -0.183   -0.113   -0.219    0.463    0.203   -0.717   \n",
       "\n",
       "    wb_4026  wb_4027  wb_4028  wb_4029  wb_4030  wb_4031  wb_4032  wb_4033  \\\n",
       "29   -0.803    0.145   -0.078    0.815   -0.534    0.587    0.669   -0.133   \n",
       "38   -0.276    0.241   -0.092    0.263   -0.192    0.305    0.021   -0.285   \n",
       "79   -2.809    0.132   -1.753    2.408   -0.242    0.300    2.054   -2.606   \n",
       "19    0.065    0.129   -0.084    3.040   -0.133    1.752    3.266   -0.133   \n",
       "27   -0.137    3.357   -0.082    0.627   -0.586    0.272    0.550   -0.610   \n",
       "\n",
       "    wb_4034  wb_4035  wb_4036  wb_4037  wb_4038  wb_4039  wb_4040  wb_4041  \\\n",
       "29    0.010    0.014   -0.527   -0.107    0.333    2.164    0.439   -0.492   \n",
       "38    0.008    0.012   -0.120   -0.107   -0.161    0.274    0.085   -0.172   \n",
       "79   -0.001    0.013   -0.108   -0.107   -1.294    3.515    0.148   -0.282   \n",
       "19    0.816    3.963   -2.147   -0.107   -2.674    0.123    1.770   -0.043   \n",
       "27    0.507    0.020   -0.468   -0.107   -0.388    0.593    0.178   -0.289   \n",
       "\n",
       "    wb_4042  wb_4043  wb_4044  wb_4045  wb_4046  wb_4047  wb_4048  wb_4049  \\\n",
       "29   -0.514   -0.723   -1.728    0.000    0.748   -1.690   -0.413   -0.548   \n",
       "38   -0.136   -0.177   -0.146    0.000    0.192   -0.130   -0.119   -0.239   \n",
       "79   -0.202   -0.274   -2.566    0.000    0.306   -2.753   -0.009   -1.444   \n",
       "19   -2.586   -2.326    2.180    0.000    0.169   -3.498   -0.183   -0.070   \n",
       "27   -0.478   -0.830   -0.972    0.000    3.516   -0.130   -0.279   -0.418   \n",
       "\n",
       "    wb_4050  wb_4051  wb_4052  wb_4053  wb_4054  wb_4055  wb_4056  wb_4057  \\\n",
       "29   -0.599    0.088    0.436   -0.783   -0.737    0.366   -0.662   -0.521   \n",
       "38   -0.117    0.100   -0.046   -0.060   -0.246    0.119   -0.152   -0.009   \n",
       "79   -2.710    2.710    0.137   -0.060   -0.158    0.171   -0.052    2.601   \n",
       "19   -1.337    4.513    1.806   -0.060   -0.169   -0.222   -1.656    0.137   \n",
       "27   -0.538    0.089    0.441   -0.060   -0.647    0.427   -0.354   -0.386   \n",
       "\n",
       "    wb_4058  wb_4059  wb_4060  wb_4061  wb_4062  wb_4063  wb_4064  wb_4065  \\\n",
       "29    0.455   -0.484   -0.085   -0.445    0.337    0.000   -0.084    0.630   \n",
       "38    0.233   -0.290   -0.075    0.126    0.034    0.005   -0.084    0.121   \n",
       "79    0.137   -0.281   -0.092    0.171    0.073    0.005   -0.084    0.248   \n",
       "19    0.771   -1.545   -0.092    1.483   -0.027    0.005   -0.084    0.253   \n",
       "27    0.197   -1.340   -0.092    0.225    0.051    0.005   -0.084    0.651   \n",
       "\n",
       "    wb_4066  wb_4067  wb_4068  wb_4069  wb_4070  wb_4071  wb_4072  wb_4073  \\\n",
       "29    2.623   -0.514   -0.710   -1.543   -0.658   -0.106    0.188    0.069   \n",
       "38    0.124   -0.142   -0.306   -0.286   -0.231   -0.106    0.240    0.190   \n",
       "79    0.021   -0.248   -3.373   -3.603   -1.407   -0.106    0.175    0.059   \n",
       "19    3.337   -0.124   -2.190   -0.176   -0.107   -0.106    0.878    2.984   \n",
       "27    0.017   -0.605   -0.700   -0.616   -0.435   -0.106    0.409    0.521   \n",
       "\n",
       "    wb_4074  wb_4075  wb_4076  wb_4077  wb_4078  wb_4079  wb_4080  wb_4081  \\\n",
       "29    0.134    0.093   -0.193   -0.072    0.568   -0.713   -0.001    2.521   \n",
       "38    0.102    0.209   -0.193   -0.072    0.062   -0.161   -0.006    0.322   \n",
       "79    0.094    3.225   -0.420   -0.072    0.065   -1.192    0.000    0.180   \n",
       "19   -0.043    0.090   -2.133   -0.072    0.061   -2.690    0.027    0.185   \n",
       "27    0.531    2.842   -0.635   -0.072    0.057   -0.329   -0.531    0.718   \n",
       "\n",
       "    wb_4082  wb_4083  wb_4084  wb_4085  wb_4086  wb_4087  wb_4088  wb_4089  \\\n",
       "29   -0.625   -2.504   -1.527    0.386    0.085    1.562    0.255    0.356   \n",
       "38    0.034   -0.316   -0.222    0.158    0.094    0.266    0.139    0.249   \n",
       "79   -0.219   -0.178   -1.421    0.184    0.334    3.219    0.081    0.179   \n",
       "19   -1.963   -0.188   -0.118   -0.168    0.088    2.191   -0.133    0.036   \n",
       "27   -0.435   -0.690   -0.495    0.257    0.458    0.445    0.588    0.542   \n",
       "\n",
       "    wb_4090  wb_4091  wb_4092  wb_4093  wb_4094  wb_4095  wb_4096  \n",
       "29   -0.276   -0.702   -0.439    0.573    0.683   -0.593    0.038  \n",
       "38   -0.106    0.060   -0.219    0.225    0.137    0.008   -0.052  \n",
       "79   -0.083   -0.688   -1.669    0.165   -0.321   -2.995   -0.214  \n",
       "19    0.320   -3.174   -0.146    2.317   -0.296   -2.190   -0.066  \n",
       "27   -0.210   -0.502   -0.314    2.161    0.419    0.002    0.060  \n",
       "\n",
       "[5 rows x 4332 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:42:15.874934Z",
     "iopub.status.busy": "2021-12-17T08:42:15.874687Z",
     "iopub.status.idle": "2021-12-17T08:42:15.878447Z",
     "shell.execute_reply": "2021-12-17T08:42:15.877666Z",
     "shell.execute_reply.started": "2021-12-17T08:42:15.874909Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir data/logging/ --port=8811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:42:15.880048Z",
     "iopub.status.busy": "2021-12-17T08:42:15.879655Z",
     "iopub.status.idle": "2021-12-17T08:42:15.882996Z",
     "shell.execute_reply": "2021-12-17T08:42:15.882515Z",
     "shell.execute_reply.started": "2021-12-17T08:42:15.880012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:42:15.884232Z",
     "iopub.status.busy": "2021-12-17T08:42:15.883962Z",
     "iopub.status.idle": "2021-12-17T09:21:13.977701Z",
     "shell.execute_reply": "2021-12-17T09:21:13.977100Z",
     "shell.execute_reply.started": "2021-12-17T08:42:15.884207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 07m 57s]\n",
      "val_loss: 7.779325008392334\n",
      "\n",
      "Best val_loss So Far: 0.5010059475898743\n",
      "Total elapsed time: 00h 38m 52s\n",
      "Training Time: 0:38:57\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model,\n",
    " encoder_model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      callback_names=['tensorboard'] #plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:21:13.979162Z",
     "iopub.status.busy": "2021-12-17T09:21:13.978906Z",
     "iopub.status.idle": "2021-12-17T09:21:13.987002Z",
     "shell.execute_reply": "2021-12-17T09:21:13.986449Z",
     "shell.execute_reply.started": "2021-12-17T09:21:13.979136Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_block_1/num_layers: 2\n",
      "dense_block_1/units_0: 2048\n",
      "dense_block_1/dropout: 0.0\n",
      "dense_block_1/units_1: 128\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "Score: 0.5010059475898743\n",
      "None\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_block_1/num_layers: 2\n",
      "dense_block_1/units_0: 2048\n",
      "dense_block_1/dropout: 0.0\n",
      "dense_block_1/units_1: 128\n",
      "optimizer: adam\n",
      "learning_rate: 0.1\n",
      "Score: 7.779325008392334\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:21:13.988020Z",
     "iopub.status.busy": "2021-12-17T09:21:13.987794Z",
     "iopub.status.idle": "2021-12-17T09:21:16.703680Z",
     "shell.execute_reply": "2021-12-17T09:21:16.702409Z",
     "shell.execute_reply.started": "2021-12-17T09:21:13.987997Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 3\n",
    "network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "if (config['i_net']['convolution_layers'] != None or config['i_net']['lstm_layers'] != None or (config['i_net']['nas'] and config['i_net']['nas_type'] != 'SEQUENTIAL')) and config['i_net']['data_reshape_version'] is not None:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:21:16.706385Z",
     "iopub.status.busy": "2021-12-17T09:21:16.705887Z",
     "iopub.status.idle": "2021-12-17T09:21:16.723102Z",
     "shell.execute_reply": "2021-12-17T09:21:16.722083Z",
     "shell.execute_reply.started": "2021-12-17T09:21:16.706323Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4097)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cast_to_float32 (CastToFloat32) (None, 4097)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         8392704     cast_to_float32[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 210)          27090       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            903         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           2064        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 233)          0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,685,033\n",
      "Trainable params: 8,685,033\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:21:16.725264Z",
     "iopub.status.busy": "2021-12-17T09:21:16.724773Z",
     "iopub.status.idle": "2021-12-17T09:31:01.931572Z",
     "shell.execute_reply": "2021-12-17T09:31:01.930661Z",
     "shell.execute_reply.started": "2021-12-17T09:21:16.725214Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=10)]: Done  41 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=10)]: Done  52 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=10)]: Done  65 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=10)]: Done  78 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=10)]: Done  92 out of 100 | elapsed:  9.4min remaining:   48.9s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:  9.7min finished\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_train.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_train.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "    \n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=10, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_train.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_train.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:31:01.933175Z",
     "iopub.status.busy": "2021-12-17T09:31:01.932975Z",
     "iopub.status.idle": "2021-12-17T09:31:01.952390Z",
     "shell.execute_reply": "2021-12-17T09:31:01.950886Z",
     "shell.execute_reply.started": "2021-12-17T09:31:01.933146Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA RESULTS\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|               Metric              | Distilled DT (Train/Random Data) | Distilled DT (Test Data) | I-Net DT (Test Data) |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|  Soft Binary Crossentropy (Mean)  |              0.418               |          0.419           |        0.544         |\n",
      "|     Binary Crossentropy (Mean)    |              0.141               |          0.157           |        0.444         |\n",
      "|          Accuracy (Mean)          |              0.954               |          0.948           |         0.78         |\n",
      "|          F1 Score (Mean)          |              0.951               |          0.944           |        0.738         |\n",
      "|           Runtime (Mean)          |              55.744              |          55.744          |        0.001         |\n",
      "| Soft Binary Crossentropy (Median) |              0.416               |          0.417           |        0.555         |\n",
      "|    Binary Crossentropy (Median)   |              0.135               |          0.155           |        0.471         |\n",
      "|         Accuracy (Median)         |              0.958               |           0.95           |        0.773         |\n",
      "|         F1 Score (Median)         |              0.958               |          0.953           |        0.802         |\n",
      "|          Runtime (Median)         |              55.553              |          55.553          |        0.001         |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:31:01.954755Z",
     "iopub.status.busy": "2021-12-17T09:31:01.954205Z",
     "iopub.status.idle": "2021-12-17T09:31:19.327942Z",
     "shell.execute_reply": "2021-12-17T09:31:19.327003Z",
     "shell.execute_reply.started": "2021-12-17T09:31:01.954706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbc9d34d1494da4b11ffb5da98a4939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Z-Score (Sample to Train Data):\t\t 2212.465\n",
      "Average Distance to Initialization:\t\t 379.026\n",
      "Average Mean Distance to Train Data:\t\t 539.66\n",
      "Average Distance to closest Train Data Sample:\t 0.0\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    z_score = (sample-mean)/std\n",
    "    z_score_aggregate = np.sum(np.abs(z_score))\n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "\n",
    "z_score_average_train = np.mean(z_score_aggregate_list)\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "distance_to_initialization_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    distance_to_initialization = sample - initialization_array\n",
    "    distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "\n",
    "distance_to_initialization_average_train = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "for sample1 in tqdm(lambda_net_dataset_train.network_parameters_array[:100]):\n",
    "    distance_to_sample_aggregate_list = []\n",
    "    for sample2 in lambda_net_dataset_train.network_parameters_array:\n",
    "        distance_to_sample = sample1 - sample2\n",
    "        distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "        distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "    distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "    distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "    \n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)\n",
    "    \n",
    "distance_to_sample_average_average_train = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_train = np.mean(distance_to_sample_min_list)\n",
    "    \n",
    "print('Average Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_average_train, 3))\n",
    "print('Average Distance to Initialization:\\t\\t', np.round(distance_to_initialization_average_train, 3))   \n",
    "    \n",
    "print('Average Mean Distance to Train Data:\\t\\t', np.round(distance_to_sample_average_average_train, 3))   \n",
    "print('Average Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min_average_train, 3))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:31:19.329760Z",
     "iopub.status.busy": "2021-12-17T09:31:19.329419Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  3.0min\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_valid.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_valid.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_valid.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_valid.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('VALID DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "for sample in lambda_net_dataset_valid.network_parameters_array:\n",
    "    z_score = (sample-mean)/std\n",
    "    z_score_aggregate = np.sum(np.abs(z_score))\n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "\n",
    "z_score_average = np.mean(z_score_aggregate_list)\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "distance_to_initialization_aggregate_list = []\n",
    "for sample in lambda_net_dataset_valid.network_parameters_array:\n",
    "    distance_to_initialization = sample - initialization_array\n",
    "    distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "\n",
    "distance_to_initialization_average = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "for sample1 in tqdm(lambda_net_dataset_valid.network_parameters_array[:100]):\n",
    "    distance_to_sample_aggregate_list = []\n",
    "    for sample2 in lambda_net_dataset_train.network_parameters_array:\n",
    "        distance_to_sample = sample1 - sample2\n",
    "        distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "        distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "    distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "    distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "    \n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)\n",
    "    \n",
    "distance_to_sample_average_average = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average = np.mean(distance_to_sample_min_list)\n",
    "    \n",
    "print('Average Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_average, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "print('Average Distance to Initialization:\\t\\t', np.round(distance_to_initialization_average, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')    \n",
    "\n",
    "print('Average Mean Distance to Train Data:\\t\\t', np.round(distance_to_sample_average_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Average Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min_average, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = lambda_net_dataset_test.X_test_lambda_array.shape[0]#10\n",
    "\n",
    "    start_inet = time.time() \n",
    "    dt_inet_list = model.predict(np.array(lambda_net_dataset_test.network_parameters_array[:number]))\n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    dt_inet_list = np.array(dt_inet_list)\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_test.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_test.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict == None:\n",
    "            inet_evaluation_result_dict = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    "\n",
    "    inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('TEST DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "for sample in lambda_net_dataset_test.network_parameters_array:\n",
    "    z_score = (sample-mean)/std\n",
    "    z_score_aggregate = np.sum(np.abs(z_score))\n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "\n",
    "z_score_average = np.mean(z_score_aggregate_list)\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "distance_to_initialization_aggregate_list = []\n",
    "for sample in lambda_net_dataset_test.network_parameters_array:\n",
    "    distance_to_initialization = sample - initialization_array\n",
    "    distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "\n",
    "distance_to_initialization_average = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "for sample1 in tqdm(lambda_net_dataset_test.network_parameters_array[:100]):\n",
    "    distance_to_sample_aggregate_list = []\n",
    "    for sample2 in lambda_net_dataset_train.network_parameters_array:\n",
    "        distance_to_sample = sample1 - sample2\n",
    "        distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "        distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "    distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "    distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "    \n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)\n",
    "    \n",
    "distance_to_sample_average_average = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average = np.mean(distance_to_sample_min_list)\n",
    "    \n",
    "print('Average Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_average, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "print('Average Distance to Initialization:\\t\\t', np.round(distance_to_initialization_average, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')   \n",
    "    \n",
    "print('Average Mean Distance to Train Data:\\t\\t', np.round(distance_to_sample_average_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Average Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min_average, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file: \n",
    "        if different_eval_data:\n",
    "            flat_config = flatten_dict(config_train)\n",
    "        else:\n",
    "            flat_config = flatten_dict(config)\n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key)\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_binary_crossentropy_' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_accuracy' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_f1_score' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_runtime_' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_binary_crossentropy_' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_accuracy' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_score' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_runtime_' + str(i))\n",
    "            text_file.write(';')      \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file: \n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['dt_scores']['binary_crossentropy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['dt_scores']['accuracy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['dt_scores']['f1_score']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['dt_scores']['runtime']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['inet_scores']['binary_crossentropy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['inet_scores']['accuracy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['inet_scores']['f1_score']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['inet_scores']['runtime']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATA EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "\n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "#adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "#adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 'capital_gain'\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "categorical_features = ['Race', 'Workclass', 'Education', \"Marital Status\", \"Occupation\", \"Relationship\"]#[1, 2, 7]\n",
    "ordinal_features = ['Sex', 'capital_gain']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(adult_data)\n",
    "\n",
    "adult_data = transformer.transform(adult_data)\n",
    "adult_data = pd.DataFrame(adult_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    adult_data[ordinal_feature] = OrdinalEncoder().fit_transform(adult_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "adult_data = adult_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "y_data_adult = adult_data['capital_gain']\n",
    "#le = LabelEncoder()\n",
    "#le.fit(y_data_adult)\n",
    "#y_data_adult = le.transform(y_data_adult)\n",
    "#class_names = le.classes_\n",
    "\n",
    "\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data['capital_gain'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_adult.shape[1] > number_of_variables:\n",
    "    #X_data_adult = X_data_adult.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_adult = ExtraTreesClassifier(n_estimators=100)\n",
    "    clf_adult = clf_adult.fit(X_data_adult, y_data_adult)\n",
    "\n",
    "    selector_adult = SelectFromModel(clf_adult, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_adult.get_support()   \n",
    "    X_data_adult = X_data_adult.loc[:,feature_idx]\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_adult.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_adult[column_name] = np.zeros(X_data_adult.shape[0])\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_adult:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_adult[column_name].values.reshape(-1, 1))\n",
    "    X_data_adult[column_name] = scaler.transform(X_data_adult[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_adult_with_valid, X_test_adult, y_train_adult_with_valid, y_test_adult = train_test_split(X_data_adult, y_data_adult, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_adult, X_valid_adult, y_train_adult, y_valid_adult = train_test_split(X_train_adult_with_valid, y_train_adult_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_adult.shape, y_train_adult.shape)\n",
    "print(X_valid_adult.shape, y_valid_adult.shape)\n",
    "print(X_test_adult.shape, y_test_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_adult, y_train_adult = oversample.fit_resample(X_train_adult, y_train_adult)\n",
    "\n",
    "    true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "    false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_adult = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_adult.fit(X_train_adult,\n",
    "                                      y_train_adult, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_adult, y_valid_adult),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult_parameters = shaped_network_parameters_to_array(test_network_adult.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_adult_dt_inet = model.predict(np.array([test_network_adult_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_adult = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_adult = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "    \n",
    "results_adult_list = []\n",
    "dt_distilled_adult_list = []\n",
    "for dataset_size in dataset_size_list_adult:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_adult.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_adult['inet_scores']['runtime'] = inet_runtime\n",
    "    results_adult_list.append(results_adult)\n",
    "    dt_distilled_adult_list.append(dt_distilled_adult)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_adult['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy',  np.round(results_adult['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['binary_crossentropy'], 3), np.round(results_adult['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_adult['dt_scores']['accuracy_data_random'], 3), np.round(results_adult['dt_scores']['accuracy'], 3), np.round(results_adult['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_adult['dt_scores']['f1_score_data_random'], 3), np.round(results_adult['dt_scores']['f1_score'], 3), np.round(results_adult['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n",
    "        \n",
    "adult_evaluation_result_dict = None\n",
    "for some_dict in results_adult_list:\n",
    "    if adult_evaluation_result_dict == None:\n",
    "        adult_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        adult_evaluation_result_dict = mergeDict(adult_evaluation_result_dict, some_dict)\n",
    "\n",
    "adult_evaluation_result_dict['dataset_size'] = dataset_size_list_adult\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score = (test_network_adult_parameters-mean)/std\n",
    "z_score_aggregate = np.sum(np.abs(z_score))\n",
    "\n",
    "print('Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_aggregate, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "\n",
    "distance_to_initialization = test_network_adult_parameters - initialization_array\n",
    "distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "\n",
    "print('Distance to Initialization:\\t\\t', np.round(distance_to_initialization_aggregate, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')   \n",
    "\n",
    "distance_to_sample_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    distance_to_sample = test_network_adult_parameters - sample\n",
    "    distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "    distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "\n",
    "print('Average Distance to Train Data:\\t\\t', np.round(distance_to_sample_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_adult_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_adult_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_adult, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_adult.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.drop([\n",
    "                                    'Cabin', \n",
    "                                    'Ticket', \n",
    "                                    'Name', \n",
    "                                    'PassengerId'\n",
    "                                ], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "categorical_features = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features = ['Sex']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(titanic_data)\n",
    "\n",
    "titanic_data = transformer.transform(titanic_data)\n",
    "titanic_data = pd.DataFrame(titanic_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    titanic_data[ordinal_feature] = OrdinalEncoder().fit_transform(titanic_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "titanic_data = titanic_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_titanic.shape[1] > number_of_variables:\n",
    "    #X_data_titanic = X_data_titanic.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_titanic = ExtraTreesClassifier(n_estimators=100)\n",
    "    clf_titanic = clf_titanic.fit(X_data_titanic, y_data_titanic)\n",
    "\n",
    "    selector_titanic = SelectFromModel(clf_titanic, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_titanic.get_support()   \n",
    "    X_data_titanic = X_data_titanic.loc[:,feature_idx]    \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_titanic.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_titanic[column_name] = np.zeros(X_data_titanic.shape[0])\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_titanic:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_titanic[column_name].values.reshape(-1, 1))\n",
    "    X_data_titanic[column_name] = scaler.transform(X_data_titanic[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_titanic_with_valid, X_test_titanic, y_train_titanic_with_valid, y_test_titanic = train_test_split(X_data_titanic, y_data_titanic, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_titanic, X_valid_titanic, y_train_titanic, y_valid_titanic = train_test_split(X_train_titanic_with_valid, y_train_titanic_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_titanic.shape, y_train_titanic.shape)\n",
    "print(X_valid_titanic.shape, y_valid_titanic.shape)\n",
    "print(X_test_titanic.shape, y_test_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_titanic, y_train_titanic = oversample.fit_resample(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "    false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_titanic = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_titanic.fit(X_train_titanic,\n",
    "                                          y_train_titanic, \n",
    "                                          epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                          batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                          callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                          validation_data=(X_valid_titanic, y_valid_titanic),\n",
    "                                          verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic_parameters = shaped_network_parameters_to_array(test_network_titanic.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_titanic_dt_inet = model.predict(np.array([test_network_titanic_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_titanic = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_titanic = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "    \n",
    "results_titanic_list = []\n",
    "dt_distilled_titanic_list = []\n",
    "for dataset_size in dataset_size_list_titanic:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_titanic.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_titanic['inet_scores']['runtime'] = inet_runtime\n",
    "    results_titanic_list.append(results_titanic)\n",
    "    dt_distilled_titanic_list.append(dt_distilled_titanic)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_titanic['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_titanic['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_titanic['dt_scores']['accuracy_data_random'], 3), np.round(results_titanic['dt_scores']['accuracy'], 3), np.round(results_titanic['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_titanic['dt_scores']['f1_score_data_random'], 3), np.round(results_titanic['dt_scores']['f1_score'], 3), np.round(results_titanic['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "titanic_evaluation_result_dict = None\n",
    "for some_dict in results_titanic_list:\n",
    "    if titanic_evaluation_result_dict == None:\n",
    "        titanic_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        titanic_evaluation_result_dict = mergeDict(titanic_evaluation_result_dict, some_dict)\n",
    "\n",
    "titanic_evaluation_result_dict['dataset_size'] = dataset_size_list_titanic\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score = (test_network_titanic_parameters-mean)/std\n",
    "z_score_aggregate = np.sum(np.abs(z_score))\n",
    "\n",
    "print('Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_aggregate, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "\n",
    "distance_to_initialization = test_network_titanic_parameters - initialization_array\n",
    "distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "\n",
    "print('Distance to Initialization:\\t\\t', np.round(distance_to_initialization_aggregate, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')   \n",
    "\n",
    "distance_to_sample_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    distance_to_sample = test_network_titanic_parameters - sample\n",
    "    distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "    distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "\n",
    "print('Average Distance to Train Data:\\t\\t', np.round(distance_to_sample_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_data_titanic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_titanic_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_titanic_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_titanic, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_titanic.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "absenteeism_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           'Weight', \n",
    "                           'Height', \n",
    "                           'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = []\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(absenteeism_data)\n",
    "\n",
    "absenteeism_data = transformer.transform(absenteeism_data)\n",
    "absenteeism_data = pd.DataFrame(absenteeism_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    absenteeism_data[ordinal_feature] = OrdinalEncoder().fit_transform(absenteeism_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "absenteeism_data = absenteeism_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n",
    "\n",
    "print(X_data_absenteeism.shape)\n",
    "\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_absenteeism.shape[1] > number_of_variables:\n",
    "    #X_data_absenteeism = X_data_absenteeism.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_absenteeism = ExtraTreesClassifier(n_estimators=100)\n",
    "    clf_absenteeism = clf_absenteeism.fit(X_data_absenteeism, y_data_absenteeism)\n",
    "\n",
    "    selector_absenteeism = SelectFromModel(clf_absenteeism, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_absenteeism.get_support()   \n",
    "    X_data_absenteeism = X_data_absenteeism.loc[:,feature_idx]        \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_absenteeism.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_absenteeism[column_name] = np.zeros(X_data_absenteeism.shape[0])\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_absenteeism:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_absenteeism[column_name].values.reshape(-1, 1))\n",
    "    X_data_absenteeism[column_name] = scaler.transform(X_data_absenteeism[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_absenteeism_with_valid, X_test_absenteeism, y_train_absenteeism_with_valid, y_test_absenteeism = train_test_split(X_data_absenteeism, y_data_absenteeism, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_absenteeism, X_valid_absenteeism, y_train_absenteeism, y_valid_absenteeism = train_test_split(X_train_absenteeism_with_valid, y_train_absenteeism_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_absenteeism.shape, y_train_absenteeism.shape)\n",
    "print(X_valid_absenteeism.shape, y_valid_absenteeism.shape)\n",
    "print(X_test_absenteeism.shape, y_test_absenteeism.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_absenteeism, y_train_absenteeism = oversample.fit_resample(X_train_absenteeism, y_train_absenteeism)\n",
    "\n",
    "    true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "    false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_absenteeism = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_absenteeism.fit(X_train_absenteeism,\n",
    "                                      y_train_absenteeism, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_absenteeism, y_valid_absenteeism),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism_parameters = shaped_network_parameters_to_array(test_network_absenteeism.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_absenteeism_dt_inet = model.predict(np.array([test_network_absenteeism_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dt_type == 'vanilla':\n",
    "    dataset_size_list_absenteeism = [1_000, 5_000, 10_000, 100_000, 1_000_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "else:\n",
    "    dataset_size_list_absenteeism = [1_000, 10_000, config['evaluation']['per_network_optimization_dataset_size'], 'TRAIN_DATA']\n",
    "\n",
    "results_absenteeism_list = []\n",
    "dt_distilled_absenteeism_list = []\n",
    "for dataset_size in dataset_size_list_absenteeism:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_absenteeism.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_absenteeism['inet_scores']['runtime'] = inet_runtime\n",
    "    results_absenteeism_list.append(results_absenteeism)\n",
    "    dt_distilled_absenteeism_list.append(dt_distilled_absenteeism)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_absenteeism['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_absenteeism['dt_scores']['accuracy_data_random'], 3), np.round(results_absenteeism['dt_scores']['accuracy'], 3), np.round(results_absenteeism['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_absenteeism['dt_scores']['f1_score_data_random'], 3), np.round(results_absenteeism['dt_scores']['f1_score'], 3), np.round(results_absenteeism['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime', np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "absenteeism_evaluation_result_dict = None\n",
    "for some_dict in results_absenteeism_list:\n",
    "    if absenteeism_evaluation_result_dict == None:\n",
    "        absenteeism_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        absenteeism_evaluation_result_dict = mergeDict(absenteeism_evaluation_result_dict, some_dict)\n",
    "\n",
    "absenteeism_evaluation_result_dict['dataset_size'] = dataset_size_list_absenteeism\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "std = np.std(lambda_net_dataset_train.network_parameters_array, axis=0)\n",
    "\n",
    "z_score = (test_network_absenteeism_parameters-mean)/std\n",
    "z_score_aggregate = np.sum(np.abs(z_score))\n",
    "\n",
    "print('Z-Score (Sample to Train Data):\\t\\t', np.round(z_score_aggregate, 3), '\\t', '(' + str(np.round(z_score_average_train, 3)) + ' for Train)')\n",
    "\n",
    "initialization_array = shaped_network_parameters_to_array(generate_base_model(config).get_weights(), config)\n",
    "\n",
    "distance_to_initialization = test_network_absenteeism_parameters - initialization_array\n",
    "distance_to_initialization_aggregate = np.sum(np.abs(distance_to_initialization))\n",
    "\n",
    "print('Distance to Initialization:\\t\\t', np.round(distance_to_initialization_aggregate, 3), '\\t', '(' + str(np.round(distance_to_initialization_average_train, 3)) + ' for Train)')   \n",
    "\n",
    "distance_to_sample_aggregate_list = []\n",
    "for sample in lambda_net_dataset_train.network_parameters_array:\n",
    "    distance_to_sample = test_network_absenteeism_parameters - sample\n",
    "    distance_to_sample_aggregate = np.sum(np.abs(distance_to_sample))\n",
    "    distance_to_sample_aggregate_list.append(distance_to_sample_aggregate)\n",
    "\n",
    "distance_to_sample_average = np.mean(distance_to_sample_aggregate_list)\n",
    "distance_to_sample_min = np.min(distance_to_sample_aggregate_list)\n",
    "\n",
    "print('Average Distance to Train Data:\\t\\t', np.round(distance_to_sample_average, 3), '\\t', '(' + str(np.round(distance_to_sample_average_average_train, 3)) + ' for Train)')   \n",
    "print('Distance to closest Train Data Sample:\\t', np.round(distance_to_sample_min, 3), '\\t', '(' + str(np.round(distance_to_sample_min_average_train, 3)) + ' for Train)')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_absenteeism_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_absenteeism_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_absenteeism, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_absenteeism.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "        if different_eval_data:\n",
    "            flat_config = flatten_dict(config_train)\n",
    "        else:\n",
    "            flat_config = flatten_dict(config)\n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key + ';')\n",
    "            \n",
    "        text_file.write('dt_scores_binary_crossentropy_artificial_mean' + ';')\n",
    "        text_file.write('dt_scores_accuracy_artificial_mean' + ';')\n",
    "        text_file.write('dt_f1_score_artificial_mean' + ';')\n",
    "        text_file.write('dt_scores_runtime_artificial_mean' + ';')\n",
    "        text_file.write('inet_binary_crossentropy_artificial_mean' + ';')\n",
    "        text_file.write('inet_accuracy_artificial_mean' + ';')\n",
    "        text_file.write('inet_score_artificial_mean' + ';')\n",
    "        text_file.write('inet_runtime_artificial_mean' + ';')\n",
    "        \n",
    "        \n",
    "        for dataset_size in dataset_size_list_adult:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_adult_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_adult_' + str(dataset_size) + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list_titanic:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_titanic_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_titanic_' + str(dataset_size) + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list_adult:\n",
    "            text_file.write('dt_scores_data_random_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_data_random_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_data_random_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_f1_score_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('dt_scores_runtime_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_binary_crossentropy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_accuracy_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_score_absenteeism_' + str(dataset_size) + ';')\n",
    "            text_file.write('inet_runtime_absenteeism_' + str(dataset_size) + ';')        \n",
    "    \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['runtime']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['runtime']) + ';')\n",
    "    \n",
    "    \n",
    "    for i in range(len(dataset_size_list_adult)):\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(adult_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "    \n",
    "    for i in range(len(dataset_size_list_titanic)):\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(titanic_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "    \n",
    "    for i in range(len(dataset_size_list_absenteeism)):\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['binary_crossentropy_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['accuracy_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['f1_score_data_random'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['dt_scores']['runtime'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['binary_crossentropy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['accuracy'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['f1_score'][i]) + ';')\n",
    "        text_file.write(str(absenteeism_evaluation_result_dict['inet_scores']['runtime'][i]) + ';')\n",
    "        \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import gc\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "test_network = generate_lambda_net_from_config(config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network = generate_lambda_net_from_config(config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
