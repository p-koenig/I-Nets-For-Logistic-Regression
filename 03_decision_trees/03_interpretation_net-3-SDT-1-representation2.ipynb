{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:23.994589Z",
     "iopub.status.busy": "2021-12-01T19:54:23.993642Z",
     "iopub.status.idle": "2021-12-01T19:54:24.015932Z",
     "shell.execute_reply": "2021-12-01T19:54:24.015277Z",
     "shell.execute_reply.started": "2021-12-01T19:54:23.994417Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 3,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': -1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'SDT', #'vanilla', 'SDT'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 10, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [0,1,2],\n",
    "        \n",
    "        'function_generation_type': 'random_decision_tree',# 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [4096, 2048, 1024, 512],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.2, 0.2, 0.2, 0],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.001,\n",
    "        'loss': 'binary_crossentropy', #mse\n",
    "        'metrics': ['mse', 'binary_accuracy'],\n",
    "        \n",
    "        'epochs': 200, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 10000,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 2, # 1=standard representation; 2=sparse representation with classification for variables\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "        'soft_labels': False,\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 50,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "            \n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 10,\n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '1',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:24.016851Z",
     "iopub.status.busy": "2021-12-01T19:54:24.016689Z",
     "iopub.status.idle": "2021-12-01T19:54:24.029455Z",
     "shell.execute_reply": "2021-12-01T19:54:24.028616Z",
     "shell.execute_reply.started": "2021-12-01T19:54:24.016832Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:24.030807Z",
     "iopub.status.busy": "2021-12-01T19:54:24.030627Z",
     "iopub.status.idle": "2021-12-01T19:54:28.472639Z",
     "shell.execute_reply": "2021-12-01T19:54:28.471368Z",
     "shell.execute_reply.started": "2021-12-01T19:54:24.030787Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:28.474689Z",
     "iopub.status.busy": "2021-12-01T19:54:28.474515Z",
     "iopub.status.idle": "2021-12-01T19:54:28.481662Z",
     "shell.execute_reply": "2021-12-01T19:54:28.481136Z",
     "shell.execute_reply.started": "2021-12-01T19:54:28.474670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:28.482878Z",
     "iopub.status.busy": "2021-12-01T19:54:28.482692Z",
     "iopub.status.idle": "2021-12-01T19:54:28.493853Z",
     "shell.execute_reply": "2021-12-01T19:54:28.492948Z",
     "shell.execute_reply.started": "2021-12-01T19:54:28.482859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:28.494935Z",
     "iopub.status.busy": "2021-12-01T19:54:28.494743Z",
     "iopub.status.idle": "2021-12-01T19:54:28.502671Z",
     "shell.execute_reply": "2021-12-01T19:54:28.501711Z",
     "shell.execute_reply.started": "2021-12-01T19:54:28.494916Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:28.504012Z",
     "iopub.status.busy": "2021-12-01T19:54:28.503844Z",
     "iopub.status.idle": "2021-12-01T19:54:30.375653Z",
     "shell.execute_reply": "2021-12-01T19:54:30.374233Z",
     "shell.execute_reply.started": "2021-12-01T19:54:28.503994Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else None\n",
    "                                                            )\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:30.377250Z",
     "iopub.status.busy": "2021-12-01T19:54:30.377076Z",
     "iopub.status.idle": "2021-12-01T19:54:30.383230Z",
     "shell.execute_reply": "2021-12-01T19:54:30.382228Z",
     "shell.execute_reply.started": "2021-12-01T19:54:30.377231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets10000_var10_class2_random_decision_tree_xMax1_xMin0_xDistuniform_depth3_beta1_decisionSpars-1_SDT_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense4096-2048-1024-512_drop0.2-0.2-0.2-0e200b256_adam\n",
      "lNetSize5000_numLNets10000_var10_class2_random_decision_tree_xMax1_xMin0_xDistuniform_depth3_beta1_decisionSpars-1_SDT_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:30.384298Z",
     "iopub.status.busy": "2021-12-01T19:54:30.384142Z",
     "iopub.status.idle": "2021-12-01T19:54:30.433901Z",
     "shell.execute_reply": "2021-12-01T19:54:30.433248Z",
     "shell.execute_reply.started": "2021-12-01T19:54:30.384279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:30.435383Z",
     "iopub.status.busy": "2021-12-01T19:54:30.435195Z",
     "iopub.status.idle": "2021-12-01T19:54:30.444755Z",
     "shell.execute_reply": "2021-12-01T19:54:30.444200Z",
     "shell.execute_reply.started": "2021-12-01T19:54:30.435361Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "       \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              config) for network_parameters_row in network_parameters.values)          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    #def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "    #    lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "    \n",
    "    #def initialize_target_function_wrapper(config, lambda_net):\n",
    "    #    lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:30.445757Z",
     "iopub.status.busy": "2021-12-01T19:54:30.445603Z",
     "iopub.status.idle": "2021-12-01T19:54:44.963106Z",
     "shell.execute_reply": "2021-12-01T19:54:44.961301Z",
     "shell.execute_reply.started": "2021-12-01T19:54:30.445738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=10)]: Done 244 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=10)]: Done 8212 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=10)]: Done 10000 out of 10000 | elapsed:    9.5s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "\n",
    "    lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "    lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)    \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:44.967636Z",
     "iopub.status.busy": "2021-12-01T19:54:44.967419Z",
     "iopub.status.idle": "2021-12-01T19:54:44.975552Z",
     "shell.execute_reply": "2021-12-01T19:54:44.974368Z",
     "shell.execute_reply.started": "2021-12-01T19:54:44.967613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8955, 1632)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:44.976672Z",
     "iopub.status.busy": "2021-12-01T19:54:44.976500Z",
     "iopub.status.idle": "2021-12-01T19:54:44.986404Z",
     "shell.execute_reply": "2021-12-01T19:54:44.985518Z",
     "shell.execute_reply.started": "2021-12-01T19:54:44.976648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 1632)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:44.989374Z",
     "iopub.status.busy": "2021-12-01T19:54:44.988457Z",
     "iopub.status.idle": "2021-12-01T19:54:44.997405Z",
     "shell.execute_reply": "2021-12-01T19:54:44.996455Z",
     "shell.execute_reply.started": "2021-12-01T19:54:44.989308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1632)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:44.999448Z",
     "iopub.status.busy": "2021-12-01T19:54:44.999049Z",
     "iopub.status.idle": "2021-12-01T19:54:50.532731Z",
     "shell.execute_reply": "2021-12-01T19:54:50.531260Z",
     "shell.execute_reply.started": "2021-12-01T19:54:44.999416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f6v9</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>lp4c0</th>\n",
       "      <th>lp4c1</th>\n",
       "      <th>lp5c0</th>\n",
       "      <th>lp5c1</th>\n",
       "      <th>lp6c0</th>\n",
       "      <th>lp6c1</th>\n",
       "      <th>lp7c0</th>\n",
       "      <th>lp7c1</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1437</th>\n",
       "      <th>wb_1438</th>\n",
       "      <th>wb_1439</th>\n",
       "      <th>wb_1440</th>\n",
       "      <th>wb_1441</th>\n",
       "      <th>wb_1442</th>\n",
       "      <th>wb_1443</th>\n",
       "      <th>wb_1444</th>\n",
       "      <th>wb_1445</th>\n",
       "      <th>wb_1446</th>\n",
       "      <th>wb_1447</th>\n",
       "      <th>wb_1448</th>\n",
       "      <th>wb_1449</th>\n",
       "      <th>wb_1450</th>\n",
       "      <th>wb_1451</th>\n",
       "      <th>wb_1452</th>\n",
       "      <th>wb_1453</th>\n",
       "      <th>wb_1454</th>\n",
       "      <th>wb_1455</th>\n",
       "      <th>wb_1456</th>\n",
       "      <th>wb_1457</th>\n",
       "      <th>wb_1458</th>\n",
       "      <th>wb_1459</th>\n",
       "      <th>wb_1460</th>\n",
       "      <th>wb_1461</th>\n",
       "      <th>wb_1462</th>\n",
       "      <th>wb_1463</th>\n",
       "      <th>wb_1464</th>\n",
       "      <th>wb_1465</th>\n",
       "      <th>wb_1466</th>\n",
       "      <th>wb_1467</th>\n",
       "      <th>wb_1468</th>\n",
       "      <th>wb_1469</th>\n",
       "      <th>wb_1470</th>\n",
       "      <th>wb_1471</th>\n",
       "      <th>wb_1472</th>\n",
       "      <th>wb_1473</th>\n",
       "      <th>wb_1474</th>\n",
       "      <th>wb_1475</th>\n",
       "      <th>wb_1476</th>\n",
       "      <th>wb_1477</th>\n",
       "      <th>wb_1478</th>\n",
       "      <th>wb_1479</th>\n",
       "      <th>wb_1480</th>\n",
       "      <th>wb_1481</th>\n",
       "      <th>wb_1482</th>\n",
       "      <th>wb_1483</th>\n",
       "      <th>wb_1484</th>\n",
       "      <th>wb_1485</th>\n",
       "      <th>wb_1486</th>\n",
       "      <th>wb_1487</th>\n",
       "      <th>wb_1488</th>\n",
       "      <th>wb_1489</th>\n",
       "      <th>wb_1490</th>\n",
       "      <th>wb_1491</th>\n",
       "      <th>wb_1492</th>\n",
       "      <th>wb_1493</th>\n",
       "      <th>wb_1494</th>\n",
       "      <th>wb_1495</th>\n",
       "      <th>wb_1496</th>\n",
       "      <th>wb_1497</th>\n",
       "      <th>wb_1498</th>\n",
       "      <th>wb_1499</th>\n",
       "      <th>wb_1500</th>\n",
       "      <th>wb_1501</th>\n",
       "      <th>wb_1502</th>\n",
       "      <th>wb_1503</th>\n",
       "      <th>wb_1504</th>\n",
       "      <th>wb_1505</th>\n",
       "      <th>wb_1506</th>\n",
       "      <th>wb_1507</th>\n",
       "      <th>wb_1508</th>\n",
       "      <th>wb_1509</th>\n",
       "      <th>wb_1510</th>\n",
       "      <th>wb_1511</th>\n",
       "      <th>wb_1512</th>\n",
       "      <th>wb_1513</th>\n",
       "      <th>wb_1514</th>\n",
       "      <th>wb_1515</th>\n",
       "      <th>wb_1516</th>\n",
       "      <th>wb_1517</th>\n",
       "      <th>wb_1518</th>\n",
       "      <th>wb_1519</th>\n",
       "      <th>wb_1520</th>\n",
       "      <th>wb_1521</th>\n",
       "      <th>wb_1522</th>\n",
       "      <th>wb_1523</th>\n",
       "      <th>wb_1524</th>\n",
       "      <th>wb_1525</th>\n",
       "      <th>wb_1526</th>\n",
       "      <th>wb_1527</th>\n",
       "      <th>wb_1528</th>\n",
       "      <th>wb_1529</th>\n",
       "      <th>wb_1530</th>\n",
       "      <th>wb_1531</th>\n",
       "      <th>wb_1532</th>\n",
       "      <th>wb_1533</th>\n",
       "      <th>wb_1534</th>\n",
       "      <th>wb_1535</th>\n",
       "      <th>wb_1536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>6671.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.311</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.348</td>\n",
       "      <td>-1.304</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.354</td>\n",
       "      <td>-2.005</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-1.683</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-1.306</td>\n",
       "      <td>0.390</td>\n",
       "      <td>-1.020</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>-0.877</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-1.561</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>1.032</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-1.353</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-1.766</td>\n",
       "      <td>-1.401</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-2.208</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>-1.197</td>\n",
       "      <td>-1.252</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-1.805</td>\n",
       "      <td>-1.784</td>\n",
       "      <td>-1.421</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-1.065</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-1.093</td>\n",
       "      <td>-1.075</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-1.630</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-1.716</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>-2.286</td>\n",
       "      <td>-1.043</td>\n",
       "      <td>-2.212</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.383</td>\n",
       "      <td>-1.211</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>-1.501</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-2.138</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.604</td>\n",
       "      <td>-1.320</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>3274.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.757</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-2.083</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.634</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.038</td>\n",
       "      <td>1.399</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-1.510</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-1.611</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-1.508</td>\n",
       "      <td>-1.204</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-1.429</td>\n",
       "      <td>1.071</td>\n",
       "      <td>-1.513</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-1.894</td>\n",
       "      <td>-1.067</td>\n",
       "      <td>-0.675</td>\n",
       "      <td>-1.495</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>1.278</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-1.037</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>-1.379</td>\n",
       "      <td>0.567</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-1.237</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.572</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-1.155</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.611</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-1.498</td>\n",
       "      <td>-1.791</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-1.568</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.592</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-1.700</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.562</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-1.582</td>\n",
       "      <td>-1.325</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.561</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-1.244</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>3095.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.265</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>1.457</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-1.151</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.435</td>\n",
       "      <td>1.415</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>1.492</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-1.564</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-1.913</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>-0.551</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-1.302</td>\n",
       "      <td>-0.574</td>\n",
       "      <td>1.296</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>2.106</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>0.144</td>\n",
       "      <td>1.294</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-1.408</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.462</td>\n",
       "      <td>1.956</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.305</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>-0.517</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.857</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.408</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-1.012</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.454</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.509</td>\n",
       "      <td>1.512</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>-1.576</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.701</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-1.080</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-1.069</td>\n",
       "      <td>-1.473</td>\n",
       "      <td>2.189</td>\n",
       "      <td>0.545</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>8379.000</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.222</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>1.952</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.585</td>\n",
       "      <td>-2.407</td>\n",
       "      <td>-1.507</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-2.044</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>0.461</td>\n",
       "      <td>-1.945</td>\n",
       "      <td>-1.633</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-1.627</td>\n",
       "      <td>0.736</td>\n",
       "      <td>-1.526</td>\n",
       "      <td>0.516</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>1.066</td>\n",
       "      <td>0.399</td>\n",
       "      <td>-1.109</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-1.507</td>\n",
       "      <td>-2.204</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-1.180</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>0.429</td>\n",
       "      <td>-1.807</td>\n",
       "      <td>0.981</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-1.479</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-1.291</td>\n",
       "      <td>-1.788</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-1.954</td>\n",
       "      <td>-1.347</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.502</td>\n",
       "      <td>-1.675</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.453</td>\n",
       "      <td>-1.677</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-1.565</td>\n",
       "      <td>-1.685</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.512</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-1.292</td>\n",
       "      <td>-1.623</td>\n",
       "      <td>0.530</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>-1.317</td>\n",
       "      <td>1.504</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>3043.000</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.043</td>\n",
       "      <td>...</td>\n",
       "      <td>1.435</td>\n",
       "      <td>-1.541</td>\n",
       "      <td>0.348</td>\n",
       "      <td>1.378</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.431</td>\n",
       "      <td>1.084</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>1.056</td>\n",
       "      <td>0.957</td>\n",
       "      <td>1.418</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.182</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-1.509</td>\n",
       "      <td>1.289</td>\n",
       "      <td>-1.244</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-2.019</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-1.082</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>1.760</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-1.758</td>\n",
       "      <td>1.202</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>1.152</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-1.156</td>\n",
       "      <td>1.390</td>\n",
       "      <td>0.485</td>\n",
       "      <td>-1.903</td>\n",
       "      <td>-0.796</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>1.154</td>\n",
       "      <td>0.462</td>\n",
       "      <td>1.312</td>\n",
       "      <td>-1.621</td>\n",
       "      <td>0.698</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>-1.194</td>\n",
       "      <td>-1.007</td>\n",
       "      <td>-1.299</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.414</td>\n",
       "      <td>1.122</td>\n",
       "      <td>1.286</td>\n",
       "      <td>1.082</td>\n",
       "      <td>-0.536</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>-0.812</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-1.073</td>\n",
       "      <td>-1.517</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.764</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.450</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.810</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed   f0v0   f0v1   f0v2   f0v3  f0v4   f0v5   f0v6   f0v7  \\\n",
       "6671 6671.000    42  0.010  0.115 -0.222  0.217 0.048  0.097  0.230 -0.260   \n",
       "3274 3274.000    42  0.070 -0.092 -0.100  0.019 0.225  0.028 -0.242 -0.075   \n",
       "3095 3095.000    42  0.124 -0.054 -0.095 -0.157 0.231  0.025  0.209 -0.033   \n",
       "8379 8379.000    42 -0.274 -0.212 -0.020  0.066 0.278  0.121  0.024 -0.253   \n",
       "3043 3043.000    42 -0.165 -0.224 -0.076 -0.016 0.211 -0.297 -0.252  0.200   \n",
       "\n",
       "       f0v8   f0v9   f1v0   f1v1   f1v2   f1v3   f1v4   f1v5   f1v6   f1v7  \\\n",
       "6671  0.246  0.075 -0.063 -0.265 -0.103  0.001 -0.188  0.273 -0.304 -0.006   \n",
       "3274 -0.032 -0.162  0.081 -0.155 -0.266  0.205  0.129 -0.090 -0.268 -0.147   \n",
       "3095  0.152  0.114  0.171  0.025  0.284  0.005 -0.150  0.085 -0.157 -0.116   \n",
       "8379 -0.234 -0.068 -0.286  0.312  0.147 -0.171 -0.056  0.274  0.219  0.047   \n",
       "3043  0.188  0.214  0.211 -0.266 -0.029 -0.033  0.006 -0.047 -0.171  0.023   \n",
       "\n",
       "       f1v8   f1v9   f2v0   f2v1  f2v2   f2v3   f2v4   f2v5   f2v6   f2v7  \\\n",
       "6671 -0.293  0.145  0.014 -0.253 0.103 -0.281 -0.050 -0.310  0.181 -0.277   \n",
       "3274  0.203  0.152 -0.056 -0.044 0.221 -0.222  0.144 -0.279  0.243  0.051   \n",
       "3095  0.229 -0.070  0.072 -0.213 0.118 -0.285 -0.311  0.118 -0.012  0.167   \n",
       "8379  0.107 -0.116 -0.069 -0.144 0.256  0.195 -0.011 -0.313 -0.160 -0.084   \n",
       "3043 -0.238 -0.141  0.071  0.300 0.005 -0.074  0.217 -0.207 -0.012 -0.260   \n",
       "\n",
       "       f2v8   f2v9   f3v0   f3v1   f3v2   f3v3   f3v4   f3v5   f3v6   f3v7  \\\n",
       "6671 -0.004  0.240  0.034 -0.013  0.084 -0.041 -0.197 -0.265 -0.226  0.118   \n",
       "3274  0.073 -0.141 -0.254 -0.117  0.303 -0.014  0.304 -0.289  0.141  0.158   \n",
       "3095 -0.148 -0.034 -0.234  0.119 -0.112  0.166  0.080  0.159 -0.028  0.098   \n",
       "8379 -0.200 -0.313 -0.193  0.313 -0.014 -0.108 -0.312 -0.006 -0.099  0.036   \n",
       "3043  0.055  0.171 -0.221  0.274  0.241 -0.267 -0.283 -0.175 -0.211 -0.019   \n",
       "\n",
       "       f3v8   f3v9   f4v0   f4v1   f4v2   f4v3   f4v4   f4v5   f4v6   f4v7  \\\n",
       "6671 -0.111 -0.221 -0.062  0.029  0.205  0.087  0.169  0.187 -0.232  0.041   \n",
       "3274 -0.224 -0.256  0.202  0.088  0.224 -0.251  0.012 -0.130  0.043  0.136   \n",
       "3095 -0.103  0.146  0.235  0.182  0.004 -0.045 -0.090 -0.117  0.250  0.282   \n",
       "8379 -0.154  0.052 -0.131  0.126 -0.105 -0.158  0.266  0.087 -0.084 -0.306   \n",
       "3043 -0.105 -0.163 -0.042 -0.136  0.219 -0.265 -0.226  0.295 -0.226 -0.262   \n",
       "\n",
       "       f4v8   f4v9   f5v0   f5v1   f5v2  f5v3   f5v4   f5v5   f5v6   f5v7  \\\n",
       "6671 -0.144  0.116 -0.190  0.121 -0.260 0.234  0.261  0.311 -0.040 -0.305   \n",
       "3274  0.186  0.010  0.111  0.050  0.070 0.127 -0.121 -0.211  0.249  0.279   \n",
       "3095  0.142 -0.148  0.081 -0.292 -0.123 0.200 -0.211  0.067  0.301  0.277   \n",
       "8379  0.240 -0.211 -0.210  0.186  0.192 0.283  0.300 -0.257 -0.178 -0.177   \n",
       "3043  0.106 -0.195 -0.300  0.311  0.183 0.225 -0.159 -0.100  0.029 -0.119   \n",
       "\n",
       "       f5v8   f5v9   f6v0   f6v1   f6v2   f6v3   f6v4   f6v5   f6v6   f6v7  \\\n",
       "6671 -0.201 -0.273  0.010 -0.116 -0.284  0.221 -0.242  0.146  0.282  0.221   \n",
       "3274  0.304 -0.292 -0.007  0.280  0.079 -0.026 -0.288 -0.168  0.145  0.253   \n",
       "3095 -0.005  0.183 -0.231 -0.030  0.084 -0.102  0.065 -0.091 -0.026 -0.074   \n",
       "8379 -0.021 -0.042 -0.034 -0.064  0.046  0.214  0.247 -0.130  0.051 -0.035   \n",
       "3043  0.154 -0.263  0.070 -0.169 -0.196 -0.040  0.136  0.054  0.316 -0.299   \n",
       "\n",
       "       f6v8   f6v9    b0     b1     b2     b3     b4     b5     b6  lp0c0  \\\n",
       "6671 -0.128  0.129 0.040 -0.010 -0.131 -0.163 -0.032 -0.285  0.016  0.349   \n",
       "3274  0.180 -0.109 0.046 -0.049 -0.253 -0.090 -0.038  0.254 -0.232  0.064   \n",
       "3095  0.062 -0.225 0.133 -0.042 -0.271 -0.223 -0.063 -0.185  0.273 -0.207   \n",
       "8379  0.027 -0.032 0.222 -0.131  0.303 -0.004  0.114 -0.316  0.316  0.293   \n",
       "3043 -0.156  0.298 0.061 -0.253 -0.152 -0.239  0.302 -0.281  0.292  0.139   \n",
       "\n",
       "      lp0c1  lp1c0  lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  lp4c0  lp4c1  lp5c0  \\\n",
       "6671  0.167  0.042  0.023  0.096  0.128 -0.139 -0.169 -0.247  0.028  0.122   \n",
       "3274 -0.189  0.138 -0.004 -0.280 -0.336 -0.154 -0.232 -0.018  0.001 -0.345   \n",
       "3095  0.223  0.328  0.263  0.276  0.310 -0.182  0.001 -0.114  0.265 -0.136   \n",
       "8379 -0.055  0.320 -0.153  0.203  0.167  0.327 -0.036  0.058  0.075 -0.277   \n",
       "3043 -0.294 -0.325 -0.182  0.186  0.139 -0.116  0.294 -0.297 -0.046  0.005   \n",
       "\n",
       "      lp5c1  lp6c0  lp6c1  lp7c0  lp7c1   wb_0   wb_1   wb_2   wb_3   wb_4  \\\n",
       "6671 -0.272  0.320 -0.176  0.082  0.053  0.210 -0.114 -0.031 -0.110 -0.126   \n",
       "3274  0.279  0.119 -0.326  0.040  0.019 -0.108  0.255 -0.068  0.006 -0.034   \n",
       "3095  0.065  0.326 -0.007 -0.109  0.131  0.521  0.432 -0.173 -0.389  0.466   \n",
       "8379 -0.343 -0.348  0.128  0.233 -0.104  0.412 -0.091 -0.034 -0.042 -0.040   \n",
       "3043  0.012  0.344 -0.336  0.247 -0.177  0.263 -0.026  0.007 -0.085  0.043   \n",
       "\n",
       "      ...  wb_1437  wb_1438  wb_1439  wb_1440  wb_1441  wb_1442  wb_1443  \\\n",
       "6671  ...   -1.348   -1.304    0.411    0.139    0.354   -2.005    0.438   \n",
       "3274  ...   -0.977   -0.757    0.677    0.155    0.313   -2.083    0.054   \n",
       "3095  ...    0.434   -0.085    1.457    0.153    0.316   -1.151    0.045   \n",
       "8379  ...    0.728   -0.085    0.388    0.788    0.239   -0.775    1.952   \n",
       "3043  ...    1.435   -1.541    0.348    1.378    0.136   -0.525    0.524   \n",
       "\n",
       "      wb_1444  wb_1445  wb_1446  wb_1447  wb_1448  wb_1449  wb_1450  wb_1451  \\\n",
       "6671    0.407    0.451    0.301   -1.683    0.371    0.560    0.108    0.621   \n",
       "3274   -0.634    0.430    0.571   -0.651   -0.442    0.038    1.399    0.099   \n",
       "3095    0.435    1.415   -0.393   -0.158    1.492    0.039    0.798    0.064   \n",
       "8379    0.405    0.585   -2.407   -1.507    0.470    0.733    0.527    0.529   \n",
       "3043    0.688    0.431    1.084   -0.156    1.056    0.957    1.418    0.988   \n",
       "\n",
       "      wb_1452  wb_1453  wb_1454  wb_1455  wb_1456  wb_1457  wb_1458  wb_1459  \\\n",
       "6671    0.928    0.719    0.395   -1.306    0.390   -1.020    0.974   -0.949   \n",
       "3274    0.133    0.101    0.614   -1.510    0.068   -1.611    0.091   -1.508   \n",
       "3095    0.572    0.559    0.320   -1.564    0.077   -1.913    0.504   -1.361   \n",
       "8379    0.992    0.082    0.472   -2.044    0.078   -1.656    0.461   -1.945   \n",
       "3043    1.182    0.962    0.306   -1.509    1.289   -1.244    0.440   -2.019   \n",
       "\n",
       "      wb_1460  wb_1461  wb_1462  wb_1463  wb_1464  wb_1465  wb_1466  wb_1467  \\\n",
       "6671   -0.877   -0.113    0.338    0.358    0.292   -1.561   -0.999    0.084   \n",
       "3274   -1.204   -0.113   -0.431    0.094    0.436   -0.096   -1.588    0.767   \n",
       "3095   -0.551   -0.113   -0.365    0.506    0.282   -1.302   -0.574    1.296   \n",
       "8379   -1.633   -0.113   -0.467    0.557    0.415   -0.586   -1.627    0.736   \n",
       "3043   -0.962   -0.113   -0.271    0.319    0.337   -0.427   -0.959    0.444   \n",
       "\n",
       "      wb_1468  wb_1469  wb_1470  wb_1471  wb_1472  wb_1473  wb_1474  wb_1475  \\\n",
       "6671   -0.048    0.575   -0.098    0.565    0.295   -0.554   -0.739    1.032   \n",
       "3274   -1.429    1.071   -1.513    0.179    0.531   -1.894   -1.067   -0.675   \n",
       "3095   -0.063    2.106   -0.474    0.520    0.323   -0.100    0.428    0.475   \n",
       "8379   -1.526    0.516   -0.402    1.066    0.399   -1.109    0.805    0.493   \n",
       "3043   -1.082    0.683   -0.388    1.760    0.475   -1.758    1.202    0.224   \n",
       "\n",
       "      wb_1476  wb_1477  wb_1478  wb_1479  wb_1480  wb_1481  wb_1482  wb_1483  \\\n",
       "6671   -0.607   -1.353   -0.926    0.390    0.285   -1.114    0.345   -1.766   \n",
       "3274   -1.495   -0.845   -0.552    1.278   -0.692   -0.520   -1.037   -0.630   \n",
       "3095   -0.146   -0.086   -0.445    0.144    1.294   -0.414   -0.385   -1.408   \n",
       "8379   -1.507   -2.204   -0.480    0.353    0.371   -0.393   -0.332   -1.180   \n",
       "3043   -0.401   -0.087   -0.787    1.152   -0.235   -0.307   -0.285   -0.910   \n",
       "\n",
       "      wb_1484  wb_1485  wb_1486  wb_1487  wb_1488  wb_1489  wb_1490  wb_1491  \\\n",
       "6671   -1.401    0.887    0.345   -2.208   -0.544   -1.197   -1.252    0.373   \n",
       "3274   -0.444   -1.379    0.567   -0.915   -0.653   -0.630   -0.872    0.068   \n",
       "3095    0.044    0.462    1.956   -0.134    0.305   -0.429   -0.517    0.575   \n",
       "8379   -0.983   -0.668    0.429   -1.807    0.981   -0.441   -1.479    0.697   \n",
       "3043   -1.156    1.390    0.485   -1.903   -0.796   -0.515   -0.765    1.154   \n",
       "\n",
       "      wb_1492  wb_1493  wb_1494  wb_1495  wb_1496  wb_1497  wb_1498  wb_1499  \\\n",
       "6671   -1.805   -1.784   -1.421    0.110    0.089   -1.065    0.377   -1.093   \n",
       "3274   -1.237   -0.167   -0.867    0.572   -0.300   -0.538    0.395   -1.155   \n",
       "3095    0.412   -0.429   -0.142    0.857   -0.252    0.436    0.408   -0.744   \n",
       "8379    0.458   -1.291   -1.788    0.468   -1.079   -0.408    0.629   -1.954   \n",
       "3043    0.462    1.312   -1.621    0.698   -0.203   -0.420    0.169   -0.537   \n",
       "\n",
       "      wb_1500  wb_1501  wb_1502  wb_1503  wb_1504  wb_1505  wb_1506  wb_1507  \\\n",
       "6671   -1.075    0.284    0.362   -1.630   -0.587    0.321    0.230   -1.716   \n",
       "3274   -0.892    0.312    0.611   -0.472   -0.441    0.415    0.236   -0.751   \n",
       "3095   -0.455    0.217    0.474    0.422   -1.012    0.509    0.454   -0.818   \n",
       "8379   -1.347    0.394    0.333    0.502   -1.675    0.489    0.453   -1.677   \n",
       "3043   -0.802    0.237    0.783    0.864    1.137    0.771    0.812   -0.950   \n",
       "\n",
       "      wb_1508  wb_1509  wb_1510  wb_1511  wb_1512  wb_1513  wb_1514  wb_1515  \\\n",
       "6671   -0.603   -2.286   -1.043   -2.212    0.341    0.731    0.077    0.383   \n",
       "3274   -1.498   -1.791   -0.485   -1.568    0.507    0.618    0.099    0.592   \n",
       "3095   -0.484   -0.180   -0.328   -0.100    0.239    0.509    1.512    0.070   \n",
       "8379   -0.542   -1.565   -1.685   -1.515    0.484    0.596    0.568    0.441   \n",
       "3043   -1.194   -1.007   -1.299   -0.096    0.414    1.122    1.286    1.082   \n",
       "\n",
       "      wb_1516  wb_1517  wb_1518  wb_1519  wb_1520  wb_1521  wb_1522  wb_1523  \\\n",
       "6671   -1.211   -0.701    0.067   -0.425   -1.501    0.457    0.302   -2.138   \n",
       "3274   -0.956   -1.456    0.067   -1.700   -0.567    0.562   -0.322   -1.582   \n",
       "3095   -1.361   -1.576    0.067   -0.949    0.461    0.701   -0.365   -0.132   \n",
       "8379   -0.512   -0.701    0.067   -1.292   -1.623    0.530   -0.265   -0.598   \n",
       "3043   -0.536   -1.571    0.067   -0.381   -0.812    0.511    0.209   -1.073   \n",
       "\n",
       "      wb_1524  wb_1525  wb_1526  wb_1527  wb_1528  wb_1529  wb_1530  wb_1531  \\\n",
       "6671   -0.818    0.858    0.444    0.109    0.281    0.512    0.198   -0.797   \n",
       "3274   -1.325    1.041    0.059    0.177    0.387    0.112    0.158    0.561   \n",
       "3095   -1.080    0.603    0.049    0.122    0.369    0.112   -0.307   -1.069   \n",
       "8379   -1.317    1.504    0.579    0.984    0.443    0.550   -0.149   -0.356   \n",
       "3043   -1.517    0.541    0.869    1.764    0.293    0.450   -0.091   -0.292   \n",
       "\n",
       "      wb_1532  wb_1533  wb_1534  wb_1535  wb_1536  \n",
       "6671   -0.867    0.604   -1.320    0.316   -0.047  \n",
       "3274   -0.631    0.306   -1.244   -0.417    0.001  \n",
       "3095   -1.473    2.189    0.545   -0.340   -0.175  \n",
       "8379   -1.641    1.056   -0.322    0.464   -0.197  \n",
       "3043   -1.079    0.135   -0.810    0.287   -0.108  \n",
       "\n",
       "[5 rows x 1632 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:50.535725Z",
     "iopub.status.busy": "2021-12-01T19:54:50.535357Z",
     "iopub.status.idle": "2021-12-01T19:54:51.197207Z",
     "shell.execute_reply": "2021-12-01T19:54:51.195837Z",
     "shell.execute_reply.started": "2021-12-01T19:54:50.535689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f6v9</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>lp4c0</th>\n",
       "      <th>lp4c1</th>\n",
       "      <th>lp5c0</th>\n",
       "      <th>lp5c1</th>\n",
       "      <th>lp6c0</th>\n",
       "      <th>lp6c1</th>\n",
       "      <th>lp7c0</th>\n",
       "      <th>lp7c1</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1437</th>\n",
       "      <th>wb_1438</th>\n",
       "      <th>wb_1439</th>\n",
       "      <th>wb_1440</th>\n",
       "      <th>wb_1441</th>\n",
       "      <th>wb_1442</th>\n",
       "      <th>wb_1443</th>\n",
       "      <th>wb_1444</th>\n",
       "      <th>wb_1445</th>\n",
       "      <th>wb_1446</th>\n",
       "      <th>wb_1447</th>\n",
       "      <th>wb_1448</th>\n",
       "      <th>wb_1449</th>\n",
       "      <th>wb_1450</th>\n",
       "      <th>wb_1451</th>\n",
       "      <th>wb_1452</th>\n",
       "      <th>wb_1453</th>\n",
       "      <th>wb_1454</th>\n",
       "      <th>wb_1455</th>\n",
       "      <th>wb_1456</th>\n",
       "      <th>wb_1457</th>\n",
       "      <th>wb_1458</th>\n",
       "      <th>wb_1459</th>\n",
       "      <th>wb_1460</th>\n",
       "      <th>wb_1461</th>\n",
       "      <th>wb_1462</th>\n",
       "      <th>wb_1463</th>\n",
       "      <th>wb_1464</th>\n",
       "      <th>wb_1465</th>\n",
       "      <th>wb_1466</th>\n",
       "      <th>wb_1467</th>\n",
       "      <th>wb_1468</th>\n",
       "      <th>wb_1469</th>\n",
       "      <th>wb_1470</th>\n",
       "      <th>wb_1471</th>\n",
       "      <th>wb_1472</th>\n",
       "      <th>wb_1473</th>\n",
       "      <th>wb_1474</th>\n",
       "      <th>wb_1475</th>\n",
       "      <th>wb_1476</th>\n",
       "      <th>wb_1477</th>\n",
       "      <th>wb_1478</th>\n",
       "      <th>wb_1479</th>\n",
       "      <th>wb_1480</th>\n",
       "      <th>wb_1481</th>\n",
       "      <th>wb_1482</th>\n",
       "      <th>wb_1483</th>\n",
       "      <th>wb_1484</th>\n",
       "      <th>wb_1485</th>\n",
       "      <th>wb_1486</th>\n",
       "      <th>wb_1487</th>\n",
       "      <th>wb_1488</th>\n",
       "      <th>wb_1489</th>\n",
       "      <th>wb_1490</th>\n",
       "      <th>wb_1491</th>\n",
       "      <th>wb_1492</th>\n",
       "      <th>wb_1493</th>\n",
       "      <th>wb_1494</th>\n",
       "      <th>wb_1495</th>\n",
       "      <th>wb_1496</th>\n",
       "      <th>wb_1497</th>\n",
       "      <th>wb_1498</th>\n",
       "      <th>wb_1499</th>\n",
       "      <th>wb_1500</th>\n",
       "      <th>wb_1501</th>\n",
       "      <th>wb_1502</th>\n",
       "      <th>wb_1503</th>\n",
       "      <th>wb_1504</th>\n",
       "      <th>wb_1505</th>\n",
       "      <th>wb_1506</th>\n",
       "      <th>wb_1507</th>\n",
       "      <th>wb_1508</th>\n",
       "      <th>wb_1509</th>\n",
       "      <th>wb_1510</th>\n",
       "      <th>wb_1511</th>\n",
       "      <th>wb_1512</th>\n",
       "      <th>wb_1513</th>\n",
       "      <th>wb_1514</th>\n",
       "      <th>wb_1515</th>\n",
       "      <th>wb_1516</th>\n",
       "      <th>wb_1517</th>\n",
       "      <th>wb_1518</th>\n",
       "      <th>wb_1519</th>\n",
       "      <th>wb_1520</th>\n",
       "      <th>wb_1521</th>\n",
       "      <th>wb_1522</th>\n",
       "      <th>wb_1523</th>\n",
       "      <th>wb_1524</th>\n",
       "      <th>wb_1525</th>\n",
       "      <th>wb_1526</th>\n",
       "      <th>wb_1527</th>\n",
       "      <th>wb_1528</th>\n",
       "      <th>wb_1529</th>\n",
       "      <th>wb_1530</th>\n",
       "      <th>wb_1531</th>\n",
       "      <th>wb_1532</th>\n",
       "      <th>wb_1533</th>\n",
       "      <th>wb_1534</th>\n",
       "      <th>wb_1535</th>\n",
       "      <th>wb_1536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>3466.000</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495</td>\n",
       "      <td>-1.564</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.585</td>\n",
       "      <td>-1.368</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.557</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-1.893</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-1.394</td>\n",
       "      <td>-1.548</td>\n",
       "      <td>0.547</td>\n",
       "      <td>-1.693</td>\n",
       "      <td>0.528</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-1.629</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-1.433</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.753</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-1.362</td>\n",
       "      <td>-1.418</td>\n",
       "      <td>0.871</td>\n",
       "      <td>-1.728</td>\n",
       "      <td>-1.310</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.526</td>\n",
       "      <td>-1.538</td>\n",
       "      <td>-0.785</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>-1.314</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-1.480</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.886</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.832</td>\n",
       "      <td>-1.209</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.685</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.541</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-1.213</td>\n",
       "      <td>-1.563</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.639</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.477</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.317</td>\n",
       "      <td>0.845</td>\n",
       "      <td>-2.041</td>\n",
       "      <td>1.261</td>\n",
       "      <td>1.596</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.772</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.574</td>\n",
       "      <td>1.204</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.907</td>\n",
       "      <td>1.762</td>\n",
       "      <td>0.854</td>\n",
       "      <td>1.089</td>\n",
       "      <td>-1.997</td>\n",
       "      <td>0.879</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-2.039</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>1.021</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>1.185</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>1.992</td>\n",
       "      <td>0.901</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-1.590</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.585</td>\n",
       "      <td>-1.756</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>1.965</td>\n",
       "      <td>0.839</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-1.709</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-1.774</td>\n",
       "      <td>-1.758</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>1.012</td>\n",
       "      <td>0.862</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-1.287</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.233</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.899</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.777</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4148.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>...</td>\n",
       "      <td>1.163</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.192</td>\n",
       "      <td>1.497</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>1.864</td>\n",
       "      <td>-1.013</td>\n",
       "      <td>1.067</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-1.655</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.710</td>\n",
       "      <td>1.544</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-1.446</td>\n",
       "      <td>2.049</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-1.604</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>1.593</td>\n",
       "      <td>-1.074</td>\n",
       "      <td>1.533</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>1.552</td>\n",
       "      <td>0.977</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-1.619</td>\n",
       "      <td>1.618</td>\n",
       "      <td>1.069</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>-0.864</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>2.217</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-1.135</td>\n",
       "      <td>-0.644</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>0.353</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>0.577</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>1.121</td>\n",
       "      <td>0.628</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>-1.231</td>\n",
       "      <td>0.098</td>\n",
       "      <td>1.157</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.685</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>-1.980</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-2.454</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.343</td>\n",
       "      <td>1.440</td>\n",
       "      <td>1.583</td>\n",
       "      <td>-1.422</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-1.198</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.576</td>\n",
       "      <td>1.751</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-1.396</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>2815.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.305</td>\n",
       "      <td>1.580</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>1.590</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.498</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>0.158</td>\n",
       "      <td>1.536</td>\n",
       "      <td>1.299</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.489</td>\n",
       "      <td>1.292</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.995</td>\n",
       "      <td>-2.679</td>\n",
       "      <td>0.466</td>\n",
       "      <td>-2.402</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.801</td>\n",
       "      <td>1.104</td>\n",
       "      <td>-1.273</td>\n",
       "      <td>-0.911</td>\n",
       "      <td>0.424</td>\n",
       "      <td>-1.759</td>\n",
       "      <td>1.606</td>\n",
       "      <td>-0.643</td>\n",
       "      <td>1.415</td>\n",
       "      <td>0.957</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>1.307</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>-1.578</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>1.231</td>\n",
       "      <td>0.450</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>-1.670</td>\n",
       "      <td>-1.051</td>\n",
       "      <td>0.884</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>1.199</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.664</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-2.007</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>1.663</td>\n",
       "      <td>-1.579</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-1.315</td>\n",
       "      <td>-0.696</td>\n",
       "      <td>-0.626</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>-2.079</td>\n",
       "      <td>0.834</td>\n",
       "      <td>1.056</td>\n",
       "      <td>1.221</td>\n",
       "      <td>0.342</td>\n",
       "      <td>-2.084</td>\n",
       "      <td>-1.065</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-1.386</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-2.511</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>1.343</td>\n",
       "      <td>1.026</td>\n",
       "      <td>1.411</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>1.099</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>0.924</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185</th>\n",
       "      <td>5185.000</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>0.204</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-1.371</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.533</td>\n",
       "      <td>0.566</td>\n",
       "      <td>1.415</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.834</td>\n",
       "      <td>1.586</td>\n",
       "      <td>1.429</td>\n",
       "      <td>1.573</td>\n",
       "      <td>1.788</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>1.575</td>\n",
       "      <td>-0.780</td>\n",
       "      <td>1.427</td>\n",
       "      <td>-1.219</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.583</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>0.939</td>\n",
       "      <td>-1.047</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.822</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.305</td>\n",
       "      <td>1.424</td>\n",
       "      <td>0.513</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>1.410</td>\n",
       "      <td>1.435</td>\n",
       "      <td>1.388</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>0.383</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.716</td>\n",
       "      <td>0.607</td>\n",
       "      <td>-0.810</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>-1.290</td>\n",
       "      <td>0.573</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>-0.747</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>0.777</td>\n",
       "      <td>1.191</td>\n",
       "      <td>1.717</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-1.230</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>0.353</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed   f0v0   f0v1   f0v2   f0v3   f0v4   f0v5   f0v6   f0v7  \\\n",
       "3466 3466.000    42 -0.090 -0.215  0.115 -0.049 -0.202 -0.022  0.061 -0.208   \n",
       "689   689.000    42  0.069 -0.297  0.278 -0.261  0.150  0.263 -0.064  0.006   \n",
       "4148 4148.000    42  0.140 -0.053  0.036 -0.267 -0.228  0.255  0.027 -0.286   \n",
       "2815 2815.000    42  0.109 -0.087  0.129 -0.162  0.258 -0.089  0.308  0.210   \n",
       "5185 5185.000    42 -0.251  0.239 -0.252  0.176  0.021  0.313  0.242 -0.040   \n",
       "\n",
       "       f0v8   f0v9   f1v0   f1v1   f1v2   f1v3   f1v4  f1v5   f1v6   f1v7  \\\n",
       "3466 -0.014 -0.275 -0.004  0.126 -0.028  0.006  0.211 0.219 -0.141 -0.229   \n",
       "689   0.269 -0.062 -0.218 -0.145  0.280 -0.036  0.267 0.030  0.275 -0.181   \n",
       "4148 -0.208  0.229 -0.146  0.063 -0.271  0.255 -0.298 0.153 -0.036 -0.250   \n",
       "2815 -0.149  0.182 -0.208 -0.004 -0.226  0.091  0.296 0.189 -0.001  0.241   \n",
       "5185  0.097 -0.284 -0.182 -0.242  0.008  0.070 -0.170 0.283  0.074  0.046   \n",
       "\n",
       "       f1v8   f1v9   f2v0   f2v1   f2v2   f2v3   f2v4   f2v5   f2v6   f2v7  \\\n",
       "3466 -0.280  0.311  0.229 -0.087 -0.034  0.127 -0.285  0.218  0.200  0.146   \n",
       "689   0.046  0.230  0.160 -0.158  0.207 -0.019 -0.074 -0.090 -0.114  0.268   \n",
       "4148  0.303 -0.086 -0.026  0.280  0.188  0.081 -0.124  0.107  0.104  0.043   \n",
       "2815  0.310  0.140  0.066  0.069 -0.191 -0.049 -0.167  0.036 -0.134  0.039   \n",
       "5185  0.136  0.090 -0.065  0.094 -0.177 -0.225 -0.068 -0.235  0.204 -0.272   \n",
       "\n",
       "       f2v8   f2v9   f3v0   f3v1   f3v2  f3v3   f3v4   f3v5   f3v6   f3v7  \\\n",
       "3466 -0.017 -0.062  0.223  0.310 -0.230 0.086  0.293 -0.208  0.029 -0.098   \n",
       "689   0.139  0.084  0.016 -0.115 -0.217 0.239 -0.193  0.010 -0.138 -0.075   \n",
       "4148 -0.164 -0.287  0.064  0.199  0.189 0.067 -0.219  0.202 -0.221 -0.114   \n",
       "2815  0.291  0.147  0.214  0.245 -0.149 0.180  0.187  0.251  0.044  0.160   \n",
       "5185 -0.187 -0.218 -0.078 -0.111 -0.285 0.274  0.306  0.093  0.307  0.151   \n",
       "\n",
       "       f3v8   f3v9   f4v0   f4v1   f4v2   f4v3   f4v4   f4v5   f4v6   f4v7  \\\n",
       "3466  0.232  0.022 -0.067  0.017 -0.222  0.187  0.115 -0.313  0.273  0.303   \n",
       "689   0.052  0.017  0.055 -0.247  0.027  0.021 -0.178  0.180 -0.078  0.189   \n",
       "4148  0.200  0.066  0.073  0.159  0.001 -0.073  0.095 -0.061  0.283 -0.044   \n",
       "2815  0.017 -0.248 -0.124 -0.297  0.033 -0.071 -0.121  0.274 -0.235 -0.011   \n",
       "5185 -0.286 -0.121 -0.099 -0.275  0.027  0.301  0.232 -0.191 -0.216  0.155   \n",
       "\n",
       "       f4v8   f4v9   f5v0   f5v1   f5v2   f5v3   f5v4   f5v5   f5v6   f5v7  \\\n",
       "3466  0.151  0.315  0.117  0.304 -0.273 -0.159  0.226 -0.190  0.238 -0.282   \n",
       "689  -0.060 -0.184 -0.235 -0.269 -0.302 -0.304 -0.249 -0.168 -0.273  0.036   \n",
       "4148 -0.268  0.267 -0.227 -0.103  0.139 -0.277 -0.301  0.042  0.174  0.277   \n",
       "2815  0.018 -0.064  0.296 -0.249 -0.176  0.263 -0.013 -0.042  0.304  0.001   \n",
       "5185 -0.250  0.267  0.003 -0.254  0.025  0.206  0.049  0.031  0.066 -0.193   \n",
       "\n",
       "       f5v8   f5v9   f6v0   f6v1   f6v2   f6v3   f6v4   f6v5   f6v6   f6v7  \\\n",
       "3466  0.010  0.235  0.184 -0.242 -0.290 -0.244  0.086 -0.090 -0.069  0.080   \n",
       "689  -0.216  0.090  0.185 -0.217 -0.040 -0.092 -0.158 -0.013  0.111 -0.170   \n",
       "4148 -0.279  0.248 -0.226 -0.273 -0.237  0.152 -0.304  0.304  0.150  0.137   \n",
       "2815  0.191 -0.274  0.100 -0.201 -0.198  0.285 -0.177  0.226  0.246 -0.163   \n",
       "5185 -0.205  0.119  0.252  0.034  0.287 -0.100  0.191 -0.305 -0.032 -0.119   \n",
       "\n",
       "       f6v8   f6v9     b0     b1     b2     b3     b4     b5     b6  lp0c0  \\\n",
       "3466 -0.230  0.271 -0.113  0.303  0.094  0.199  0.253  0.061 -0.279 -0.064   \n",
       "689   0.042  0.195  0.140  0.150 -0.176  0.215 -0.084  0.107  0.104 -0.223   \n",
       "4148  0.106 -0.132  0.109 -0.305 -0.070 -0.002 -0.270 -0.180  0.088 -0.045   \n",
       "2815 -0.069 -0.239 -0.299 -0.180 -0.067 -0.224  0.001  0.184  0.273  0.240   \n",
       "5185 -0.004 -0.013  0.087 -0.053  0.196  0.238 -0.269 -0.124  0.286 -0.158   \n",
       "\n",
       "      lp0c1  lp1c0  lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  lp4c0  lp4c1  lp5c0  \\\n",
       "3466 -0.035 -0.185  0.229  0.078  0.160 -0.080  0.245 -0.015  0.330  0.346   \n",
       "689   0.321  0.202 -0.198  0.026 -0.284 -0.042 -0.140 -0.161 -0.266 -0.109   \n",
       "4148 -0.340 -0.180  0.104 -0.292  0.173 -0.104  0.084  0.052 -0.192 -0.041   \n",
       "2815 -0.320  0.245  0.054 -0.320 -0.271 -0.325 -0.138 -0.289 -0.217  0.242   \n",
       "5185 -0.280 -0.004  0.153  0.300  0.050 -0.100  0.234  0.153  0.063 -0.291   \n",
       "\n",
       "      lp5c1  lp6c0  lp6c1  lp7c0  lp7c1   wb_0  wb_1   wb_2   wb_3   wb_4  \\\n",
       "3466  0.205  0.088  0.255  0.297  0.172 -0.161 0.261  0.248 -0.267 -0.257   \n",
       "689  -0.326 -0.256 -0.266 -0.150  0.315  0.344 0.477 -0.165 -0.349 -0.263   \n",
       "4148 -0.042  0.221  0.297  0.276 -0.175  0.067 0.234 -0.126  0.094 -0.257   \n",
       "2815 -0.187 -0.083 -0.144  0.215 -0.189  0.055 0.142  0.066 -0.030 -0.061   \n",
       "5185  0.005 -0.086  0.078  0.096  0.139 -0.015 0.375  0.378 -0.400 -0.392   \n",
       "\n",
       "      ...  wb_1437  wb_1438  wb_1439  wb_1440  wb_1441  wb_1442  wb_1443  \\\n",
       "3466  ...    0.495   -1.564    0.561    0.559    0.209   -0.527    0.892   \n",
       "689   ...    0.881   -0.583    0.977    1.317    0.845   -2.041    1.261   \n",
       "4148  ...    1.163   -0.085    0.192    1.497    0.273   -0.043    1.864   \n",
       "2815  ...    1.367   -0.082    0.305    1.580    0.434   -0.386    1.590   \n",
       "5185  ...   -0.985   -0.080    0.582    0.670    0.214   -1.371    0.568   \n",
       "\n",
       "      wb_1444  wb_1445  wb_1446  wb_1447  wb_1448  wb_1449  wb_1450  wb_1451  \\\n",
       "3466    0.414    0.585   -1.368   -0.843    0.408    0.503    0.392    0.559   \n",
       "689     1.596    0.160    0.772   -0.158    0.574    1.204    0.729    0.907   \n",
       "4148   -1.013    1.067    0.293   -1.655    0.992    0.347    0.393    0.317   \n",
       "2815   -0.888    0.892    1.498   -0.687    0.158    1.536    1.299    0.825   \n",
       "5185    1.533    0.566    1.415   -0.637    0.317    0.834    1.586    1.429   \n",
       "\n",
       "      wb_1452  wb_1453  wb_1454  wb_1455  wb_1456  wb_1457  wb_1458  wb_1459  \\\n",
       "3466    0.597    0.578    0.557   -0.661    0.193   -1.893    0.552   -0.126   \n",
       "689     1.762    0.854    1.089   -1.997    0.879   -0.172    0.086   -0.117   \n",
       "4148    1.710    1.544    0.269   -0.165    0.313   -1.446    2.049   -0.117   \n",
       "2815    0.489    1.292    0.431   -0.493    0.995   -2.679    0.466   -2.402   \n",
       "5185    1.573    1.788    0.504   -0.584    1.575   -0.780    1.427   -1.219   \n",
       "\n",
       "      wb_1460  wb_1461  wb_1462  wb_1463  wb_1464  wb_1465  wb_1466  wb_1467  \\\n",
       "3466   -0.131   -0.113   -0.411    0.558    0.209   -1.394   -1.548    0.547   \n",
       "689    -0.126   -0.113   -0.332    0.973   -0.288   -2.039   -0.638    1.021   \n",
       "4148   -1.604   -0.113   -0.835    1.308    0.164   -0.088   -0.622    1.593   \n",
       "2815   -0.357   -0.113   -0.240    0.801    1.104   -1.273   -0.911    0.424   \n",
       "5185   -0.641   -0.113   -0.307    0.910    0.343   -1.420   -0.098    0.583   \n",
       "\n",
       "      wb_1468  wb_1469  wb_1470  wb_1471  wb_1472  wb_1473  wb_1474  wb_1475  \\\n",
       "3466   -1.693    0.528   -0.558    0.909    0.336   -1.629    0.484    0.442   \n",
       "689    -0.051    0.542   -1.533    1.185   -0.318   -0.100    0.749    0.765   \n",
       "4148   -1.074    1.533   -0.680    1.552    0.977   -0.118    0.324    0.970   \n",
       "2815   -1.759    1.606   -0.643    1.415    0.957   -0.656   -1.524    1.307   \n",
       "5185   -0.566    0.939   -1.047    0.707    0.324   -0.779   -0.716    0.422   \n",
       "\n",
       "      wb_1476  wb_1477  wb_1478  wb_1479  wb_1480  wb_1481  wb_1482  wb_1483  \\\n",
       "3466   -0.405   -0.083   -1.433    0.700    0.753   -0.584   -0.460   -0.484   \n",
       "689    -0.254   -0.087   -0.369    1.992    0.901   -0.476   -0.925   -0.427   \n",
       "4148   -0.347   -0.079   -1.619    1.618    1.069   -0.555   -0.864   -0.576   \n",
       "2815   -0.236   -1.578   -0.310    1.231    0.450   -0.332   -0.404   -0.776   \n",
       "5185   -0.586   -0.067   -0.603    1.045    0.322   -0.822   -0.497    0.996   \n",
       "\n",
       "      wb_1484  wb_1485  wb_1486  wb_1487  wb_1488  wb_1489  wb_1490  wb_1491  \\\n",
       "3466   -1.362   -1.418    0.871   -1.728   -1.310   -0.791   -0.534    0.519   \n",
       "689    -0.442    0.792    0.141   -0.128   -1.590   -0.458   -0.936    0.535   \n",
       "4148   -0.526    2.217    0.998   -0.468   -1.135   -0.644   -0.510    0.353   \n",
       "2815   -1.670   -1.051    0.884   -0.130   -0.639   -0.351   -0.392    1.199   \n",
       "5185    1.305    1.424    0.513   -0.128   -0.504   -0.554   -0.713    1.410   \n",
       "\n",
       "      wb_1492  wb_1493  wb_1494  wb_1495  wb_1496  wb_1497  wb_1498  wb_1499  \\\n",
       "3466    0.526   -1.538   -0.785    0.492   -0.372   -0.972    0.352   -0.511   \n",
       "689    -1.277   -0.398   -0.945    0.106   -0.360    0.378    0.585   -1.756   \n",
       "4148   -0.261   -0.336   -0.575    0.577   -0.345    1.121    0.628   -0.592   \n",
       "2815    0.434   -0.024   -0.472    0.239   -0.234   -0.221    0.664   -0.367   \n",
       "5185    1.435    1.388   -0.682    0.351   -0.411   -0.456    0.383   -0.505   \n",
       "\n",
       "      wb_1500  wb_1501  wb_1502  wb_1503  wb_1504  wb_1505  wb_1506  wb_1507  \\\n",
       "3466   -1.314    0.238    0.738    0.540   -0.270    0.549    0.406   -1.480   \n",
       "689    -0.417   -0.491    1.965    0.839   -0.500    0.336    0.244   -0.368   \n",
       "4148   -1.231    0.098    1.157    0.368   -0.685    0.953    0.252   -0.576   \n",
       "2815   -2.007   -0.174    1.663   -1.579   -0.285    0.246   -1.315   -0.696   \n",
       "5185    0.820    0.251    0.501    0.544   -0.429    0.299    0.109   -0.532   \n",
       "\n",
       "      wb_1508  wb_1509  wb_1510  wb_1511  wb_1512  wb_1513  wb_1514  wb_1515  \\\n",
       "3466   -0.580   -0.174   -0.886   -0.092    0.410    0.455    0.635    0.832   \n",
       "689    -1.709   -0.182   -0.485   -0.086   -0.045    0.902    0.078    0.625   \n",
       "4148   -0.936   -1.980   -0.622   -2.454    0.709    0.343    1.440    1.583   \n",
       "2815   -0.626   -3.000   -1.068   -2.079    0.834    1.056    1.221    0.342   \n",
       "5185   -0.604   -0.730   -0.648   -0.095    0.472    1.280    1.716    0.607   \n",
       "\n",
       "      wb_1516  wb_1517  wb_1518  wb_1519  wb_1520  wb_1521  wb_1522  wb_1523  \\\n",
       "3466   -1.209   -0.918    0.067   -0.339    0.545    0.528    0.323   -0.685   \n",
       "689    -1.774   -1.758    0.067   -0.408    1.012    0.862   -0.324   -0.164   \n",
       "4148   -1.422    0.991    0.067   -0.321   -1.198    0.843   -0.980   -0.164   \n",
       "2815   -2.084   -1.065    0.067   -0.515   -1.386    0.510   -0.537   -2.511   \n",
       "5185   -0.810   -0.571    0.067   -0.513   -1.290    0.573   -0.435   -0.747   \n",
       "\n",
       "      wb_1524  wb_1525  wb_1526  wb_1527  wb_1528  wb_1529  wb_1530  wb_1531  \\\n",
       "3466   -0.711    0.695    0.589    0.703    0.165    0.541   -0.305   -1.213   \n",
       "689    -1.287    0.448    0.910    1.233   -0.341    0.899   -0.358   -0.777   \n",
       "4148   -0.988    0.367    0.307    0.463    0.576    1.751   -0.280    0.308   \n",
       "2815   -0.830    1.343    1.026    1.411   -0.105    1.099   -0.144   -0.445   \n",
       "5185   -0.641    0.777    1.191    1.717    0.408    0.564    0.226   -1.230   \n",
       "\n",
       "      wb_1532  wb_1533  wb_1534  wb_1535  wb_1536  \n",
       "3466   -1.563    0.523    0.639   -0.383    0.012  \n",
       "689    -0.071    0.887    0.369   -0.345    0.207  \n",
       "4148   -1.396    0.451    0.259   -0.348    0.126  \n",
       "2815   -0.840    0.924   -0.430    0.189    0.078  \n",
       "5185   -0.611    0.353   -0.439    0.401    0.091  \n",
       "\n",
       "[5 rows x 1632 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.198299Z",
     "iopub.status.busy": "2021-12-01T19:54:51.198136Z",
     "iopub.status.idle": "2021-12-01T19:54:51.330978Z",
     "shell.execute_reply": "2021-12-01T19:54:51.329449Z",
     "shell.execute_reply.started": "2021-12-01T19:54:51.198281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>f6v8</th>\n",
       "      <th>f6v9</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>lp4c0</th>\n",
       "      <th>lp4c1</th>\n",
       "      <th>lp5c0</th>\n",
       "      <th>lp5c1</th>\n",
       "      <th>lp6c0</th>\n",
       "      <th>lp6c1</th>\n",
       "      <th>lp7c0</th>\n",
       "      <th>lp7c1</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_1437</th>\n",
       "      <th>wb_1438</th>\n",
       "      <th>wb_1439</th>\n",
       "      <th>wb_1440</th>\n",
       "      <th>wb_1441</th>\n",
       "      <th>wb_1442</th>\n",
       "      <th>wb_1443</th>\n",
       "      <th>wb_1444</th>\n",
       "      <th>wb_1445</th>\n",
       "      <th>wb_1446</th>\n",
       "      <th>wb_1447</th>\n",
       "      <th>wb_1448</th>\n",
       "      <th>wb_1449</th>\n",
       "      <th>wb_1450</th>\n",
       "      <th>wb_1451</th>\n",
       "      <th>wb_1452</th>\n",
       "      <th>wb_1453</th>\n",
       "      <th>wb_1454</th>\n",
       "      <th>wb_1455</th>\n",
       "      <th>wb_1456</th>\n",
       "      <th>wb_1457</th>\n",
       "      <th>wb_1458</th>\n",
       "      <th>wb_1459</th>\n",
       "      <th>wb_1460</th>\n",
       "      <th>wb_1461</th>\n",
       "      <th>wb_1462</th>\n",
       "      <th>wb_1463</th>\n",
       "      <th>wb_1464</th>\n",
       "      <th>wb_1465</th>\n",
       "      <th>wb_1466</th>\n",
       "      <th>wb_1467</th>\n",
       "      <th>wb_1468</th>\n",
       "      <th>wb_1469</th>\n",
       "      <th>wb_1470</th>\n",
       "      <th>wb_1471</th>\n",
       "      <th>wb_1472</th>\n",
       "      <th>wb_1473</th>\n",
       "      <th>wb_1474</th>\n",
       "      <th>wb_1475</th>\n",
       "      <th>wb_1476</th>\n",
       "      <th>wb_1477</th>\n",
       "      <th>wb_1478</th>\n",
       "      <th>wb_1479</th>\n",
       "      <th>wb_1480</th>\n",
       "      <th>wb_1481</th>\n",
       "      <th>wb_1482</th>\n",
       "      <th>wb_1483</th>\n",
       "      <th>wb_1484</th>\n",
       "      <th>wb_1485</th>\n",
       "      <th>wb_1486</th>\n",
       "      <th>wb_1487</th>\n",
       "      <th>wb_1488</th>\n",
       "      <th>wb_1489</th>\n",
       "      <th>wb_1490</th>\n",
       "      <th>wb_1491</th>\n",
       "      <th>wb_1492</th>\n",
       "      <th>wb_1493</th>\n",
       "      <th>wb_1494</th>\n",
       "      <th>wb_1495</th>\n",
       "      <th>wb_1496</th>\n",
       "      <th>wb_1497</th>\n",
       "      <th>wb_1498</th>\n",
       "      <th>wb_1499</th>\n",
       "      <th>wb_1500</th>\n",
       "      <th>wb_1501</th>\n",
       "      <th>wb_1502</th>\n",
       "      <th>wb_1503</th>\n",
       "      <th>wb_1504</th>\n",
       "      <th>wb_1505</th>\n",
       "      <th>wb_1506</th>\n",
       "      <th>wb_1507</th>\n",
       "      <th>wb_1508</th>\n",
       "      <th>wb_1509</th>\n",
       "      <th>wb_1510</th>\n",
       "      <th>wb_1511</th>\n",
       "      <th>wb_1512</th>\n",
       "      <th>wb_1513</th>\n",
       "      <th>wb_1514</th>\n",
       "      <th>wb_1515</th>\n",
       "      <th>wb_1516</th>\n",
       "      <th>wb_1517</th>\n",
       "      <th>wb_1518</th>\n",
       "      <th>wb_1519</th>\n",
       "      <th>wb_1520</th>\n",
       "      <th>wb_1521</th>\n",
       "      <th>wb_1522</th>\n",
       "      <th>wb_1523</th>\n",
       "      <th>wb_1524</th>\n",
       "      <th>wb_1525</th>\n",
       "      <th>wb_1526</th>\n",
       "      <th>wb_1527</th>\n",
       "      <th>wb_1528</th>\n",
       "      <th>wb_1529</th>\n",
       "      <th>wb_1530</th>\n",
       "      <th>wb_1531</th>\n",
       "      <th>wb_1532</th>\n",
       "      <th>wb_1533</th>\n",
       "      <th>wb_1534</th>\n",
       "      <th>wb_1535</th>\n",
       "      <th>wb_1536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7217.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.479</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.664</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.331</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>2.814</td>\n",
       "      <td>1.223</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.848</td>\n",
       "      <td>-1.194</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.416</td>\n",
       "      <td>1.221</td>\n",
       "      <td>1.096</td>\n",
       "      <td>1.502</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-1.160</td>\n",
       "      <td>2.673</td>\n",
       "      <td>-1.293</td>\n",
       "      <td>0.561</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-1.034</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-1.373</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-2.951</td>\n",
       "      <td>1.211</td>\n",
       "      <td>-1.001</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-1.074</td>\n",
       "      <td>2.166</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-1.227</td>\n",
       "      <td>-0.907</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>1.928</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>0.539</td>\n",
       "      <td>-2.441</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-1.208</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0.449</td>\n",
       "      <td>-2.131</td>\n",
       "      <td>-1.336</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>-1.105</td>\n",
       "      <td>0.519</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-1.207</td>\n",
       "      <td>0.236</td>\n",
       "      <td>2.689</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.962</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>-1.183</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.315</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.869</td>\n",
       "      <td>2.822</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>1.195</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-2.707</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>1.169</td>\n",
       "      <td>1.162</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.962</td>\n",
       "      <td>-1.604</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.905</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>8291.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423</td>\n",
       "      <td>-1.797</td>\n",
       "      <td>0.599</td>\n",
       "      <td>2.094</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-1.834</td>\n",
       "      <td>0.406</td>\n",
       "      <td>1.980</td>\n",
       "      <td>1.942</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1.591</td>\n",
       "      <td>1.731</td>\n",
       "      <td>0.353</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-1.339</td>\n",
       "      <td>1.083</td>\n",
       "      <td>-1.346</td>\n",
       "      <td>-0.743</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>1.229</td>\n",
       "      <td>0.587</td>\n",
       "      <td>-0.541</td>\n",
       "      <td>-1.762</td>\n",
       "      <td>3.115</td>\n",
       "      <td>-1.407</td>\n",
       "      <td>1.868</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>1.056</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.903</td>\n",
       "      <td>-0.718</td>\n",
       "      <td>-1.856</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>1.379</td>\n",
       "      <td>0.689</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>-2.213</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>-2.875</td>\n",
       "      <td>1.912</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-1.739</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>-1.082</td>\n",
       "      <td>0.253</td>\n",
       "      <td>1.436</td>\n",
       "      <td>0.361</td>\n",
       "      <td>-1.349</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>-1.495</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.281</td>\n",
       "      <td>1.552</td>\n",
       "      <td>1.274</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-1.151</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-1.041</td>\n",
       "      <td>0.361</td>\n",
       "      <td>2.332</td>\n",
       "      <td>0.595</td>\n",
       "      <td>-1.611</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>2.019</td>\n",
       "      <td>2.166</td>\n",
       "      <td>2.244</td>\n",
       "      <td>0.327</td>\n",
       "      <td>1.042</td>\n",
       "      <td>-0.557</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-1.759</td>\n",
       "      <td>1.933</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>1.074</td>\n",
       "      <td>-0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.502</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.491</td>\n",
       "      <td>1.873</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>1.079</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.439</td>\n",
       "      <td>1.052</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>1.483</td>\n",
       "      <td>1.827</td>\n",
       "      <td>1.866</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.700</td>\n",
       "      <td>0.499</td>\n",
       "      <td>-1.699</td>\n",
       "      <td>0.746</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>0.871</td>\n",
       "      <td>-1.527</td>\n",
       "      <td>-1.048</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.892</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-1.204</td>\n",
       "      <td>0.449</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.515</td>\n",
       "      <td>-1.010</td>\n",
       "      <td>1.810</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-1.580</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>1.269</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>0.574</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>-1.091</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>1.731</td>\n",
       "      <td>0.826</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>0.182</td>\n",
       "      <td>1.065</td>\n",
       "      <td>0.584</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.449</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>-1.377</td>\n",
       "      <td>-1.209</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.087</td>\n",
       "      <td>1.153</td>\n",
       "      <td>-1.214</td>\n",
       "      <td>-1.388</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.507</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>-1.179</td>\n",
       "      <td>0.466</td>\n",
       "      <td>1.062</td>\n",
       "      <td>1.891</td>\n",
       "      <td>-1.182</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>1.070</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>5114.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.264</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.305</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.311</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1.160</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.045</td>\n",
       "      <td>1.158</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-1.801</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1.562</td>\n",
       "      <td>1.102</td>\n",
       "      <td>1.356</td>\n",
       "      <td>1.139</td>\n",
       "      <td>-1.912</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-2.799</td>\n",
       "      <td>0.895</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.509</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-1.520</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>1.018</td>\n",
       "      <td>-1.831</td>\n",
       "      <td>1.661</td>\n",
       "      <td>-1.995</td>\n",
       "      <td>0.863</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.729</td>\n",
       "      <td>1.523</td>\n",
       "      <td>-1.767</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-1.251</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-1.122</td>\n",
       "      <td>-1.368</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-1.233</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.334</td>\n",
       "      <td>1.181</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>0.096</td>\n",
       "      <td>1.537</td>\n",
       "      <td>-1.447</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-1.216</td>\n",
       "      <td>-1.469</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-1.164</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.084</td>\n",
       "      <td>1.486</td>\n",
       "      <td>-1.478</td>\n",
       "      <td>-0.501</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-1.587</td>\n",
       "      <td>0.473</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-2.788</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>1.523</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.193</td>\n",
       "      <td>1.380</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>1.094</td>\n",
       "      <td>-0.557</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859.000</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.204</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.299</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.486</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-1.235</td>\n",
       "      <td>0.328</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.357</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>1.648</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>2.014</td>\n",
       "      <td>0.335</td>\n",
       "      <td>1.427</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>-1.596</td>\n",
       "      <td>0.296</td>\n",
       "      <td>1.178</td>\n",
       "      <td>0.108</td>\n",
       "      <td>1.756</td>\n",
       "      <td>1.920</td>\n",
       "      <td>2.440</td>\n",
       "      <td>1.032</td>\n",
       "      <td>-1.034</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.480</td>\n",
       "      <td>-1.788</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>1.426</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-1.519</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>1.997</td>\n",
       "      <td>-1.357</td>\n",
       "      <td>1.869</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.288</td>\n",
       "      <td>1.396</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>0.136</td>\n",
       "      <td>1.876</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>1.174</td>\n",
       "      <td>0.363</td>\n",
       "      <td>1.004</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>-1.267</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-1.507</td>\n",
       "      <td>-1.488</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>1.214</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.190</td>\n",
       "      <td>1.900</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>1.402</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-1.348</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.285</td>\n",
       "      <td>1.735</td>\n",
       "      <td>1.172</td>\n",
       "      <td>-1.577</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.793</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-1.528</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>1.870</td>\n",
       "      <td>1.956</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.756</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.655</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed   f0v0   f0v1   f0v2   f0v3   f0v4   f0v5   f0v6   f0v7  \\\n",
       "7217 7217.000    42  0.290  0.156 -0.196  0.066 -0.153 -0.304  0.150  0.020   \n",
       "8291 8291.000    42  0.039  0.155 -0.213 -0.005  0.130  0.206 -0.188  0.190   \n",
       "4607 4607.000    42  0.029  0.022 -0.138 -0.058  0.224 -0.076  0.235 -0.202   \n",
       "5114 5114.000    42  0.184  0.312  0.176 -0.107  0.021 -0.201  0.249 -0.152   \n",
       "1859 1859.000    42 -0.230 -0.103  0.169  0.206 -0.279  0.036 -0.092  0.053   \n",
       "\n",
       "       f0v8   f0v9  f1v0   f1v1   f1v2   f1v3   f1v4   f1v5   f1v6   f1v7  \\\n",
       "7217  0.089 -0.285 0.140 -0.019  0.119  0.309  0.035 -0.185  0.078 -0.134   \n",
       "8291 -0.162  0.110 0.313  0.155 -0.157 -0.289 -0.229  0.266  0.159 -0.135   \n",
       "4607 -0.256 -0.122 0.297 -0.121 -0.314  0.188 -0.097  0.145 -0.177 -0.307   \n",
       "5114 -0.060  0.277 0.122  0.051 -0.170 -0.121 -0.213  0.135  0.180  0.103   \n",
       "1859  0.095 -0.275 0.177  0.242  0.112 -0.146 -0.308  0.251  0.108  0.053   \n",
       "\n",
       "       f1v8   f1v9   f2v0   f2v1   f2v2   f2v3   f2v4   f2v5   f2v6   f2v7  \\\n",
       "7217 -0.093 -0.239 -0.146  0.140 -0.288  0.310  0.220  0.266  0.275  0.314   \n",
       "8291  0.004 -0.031 -0.219 -0.043  0.082  0.306 -0.199  0.071  0.165 -0.125   \n",
       "4607 -0.239  0.160 -0.141  0.276  0.155  0.088 -0.107  0.135  0.158 -0.241   \n",
       "5114 -0.144 -0.046  0.068  0.119  0.017 -0.285  0.264 -0.148 -0.159 -0.176   \n",
       "1859 -0.011  0.302  0.114 -0.095 -0.134 -0.027  0.204 -0.287 -0.095 -0.299   \n",
       "\n",
       "       f2v8   f2v9   f3v0  f3v1   f3v2   f3v3   f3v4   f3v5   f3v6   f3v7  \\\n",
       "7217  0.203  0.055 -0.115 0.048  0.215  0.042 -0.026  0.266  0.196  0.206   \n",
       "8291  0.300 -0.258 -0.125 0.183  0.137 -0.135 -0.069 -0.094 -0.276 -0.222   \n",
       "4607 -0.217  0.207 -0.261 0.295 -0.151  0.080 -0.285  0.147 -0.270  0.130   \n",
       "5114  0.182 -0.166  0.125 0.178 -0.313  0.086  0.305 -0.210  0.111  0.206   \n",
       "1859 -0.022 -0.028 -0.240 0.160 -0.255 -0.144 -0.277  0.070 -0.209  0.080   \n",
       "\n",
       "       f3v8   f3v9  f4v0   f4v1   f4v2  f4v3   f4v4   f4v5   f4v6   f4v7  \\\n",
       "7217 -0.041  0.172 0.205  0.029  0.056 0.020  0.137  0.153 -0.300  0.199   \n",
       "8291  0.037 -0.239 0.028  0.272 -0.067 0.030  0.230 -0.146  0.074 -0.261   \n",
       "4607 -0.291  0.124 0.121 -0.080  0.247 0.107  0.120 -0.296 -0.229 -0.075   \n",
       "5114  0.311 -0.212 0.071 -0.239 -0.266 0.230 -0.223  0.179 -0.294  0.309   \n",
       "1859  0.278  0.206 0.290  0.296  0.100 0.128 -0.143 -0.233  0.133  0.057   \n",
       "\n",
       "       f4v8   f4v9   f5v0   f5v1   f5v2   f5v3   f5v4   f5v5   f5v6   f5v7  \\\n",
       "7217 -0.034 -0.151  0.284  0.201 -0.288 -0.313 -0.088  0.052  0.141 -0.040   \n",
       "8291  0.144  0.244  0.244 -0.202  0.017 -0.160 -0.056  0.170 -0.166 -0.202   \n",
       "4607  0.007  0.192  0.020  0.185  0.315 -0.153  0.036 -0.070 -0.170 -0.093   \n",
       "5114 -0.239  0.096 -0.147 -0.037  0.124  0.128  0.164  0.271  0.012  0.156   \n",
       "1859 -0.256 -0.306  0.184 -0.126 -0.244 -0.212 -0.125 -0.150 -0.271 -0.156   \n",
       "\n",
       "       f5v8   f5v9   f6v0   f6v1   f6v2   f6v3   f6v4   f6v5   f6v6   f6v7  \\\n",
       "7217 -0.105  0.246  0.250 -0.277 -0.209 -0.222  0.177  0.045 -0.294  0.085   \n",
       "8291 -0.182  0.256 -0.048  0.068 -0.197  0.270 -0.070 -0.096  0.100 -0.308   \n",
       "4607  0.128  0.266  0.114  0.199  0.069  0.213  0.231 -0.183 -0.262 -0.087   \n",
       "5114  0.251 -0.094  0.009  0.019  0.256  0.002 -0.257 -0.077  0.147  0.013   \n",
       "1859 -0.065 -0.180  0.135 -0.309 -0.154  0.299 -0.046 -0.293 -0.258 -0.166   \n",
       "\n",
       "       f6v8   f6v9     b0     b1     b2     b3     b4     b5     b6  lp0c0  \\\n",
       "7217 -0.266 -0.285 -0.142 -0.287 -0.154 -0.048 -0.298 -0.067 -0.307 -0.318   \n",
       "8291 -0.038  0.244  0.011 -0.121 -0.139  0.205 -0.235  0.047 -0.139 -0.181   \n",
       "4607 -0.185 -0.008  0.184  0.126  0.281 -0.129  0.199 -0.260  0.175  0.060   \n",
       "5114  0.076 -0.029 -0.214 -0.068  0.118  0.266  0.211  0.118  0.195  0.009   \n",
       "1859  0.298  0.110  0.156 -0.086  0.059  0.046 -0.171 -0.120  0.249 -0.155   \n",
       "\n",
       "      lp0c1  lp1c0  lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  lp4c0  lp4c1  lp5c0  \\\n",
       "7217 -0.184 -0.254  0.072 -0.287  0.236  0.166 -0.346  0.045  0.202  0.146   \n",
       "8291 -0.231 -0.018  0.064 -0.328 -0.001 -0.193 -0.333  0.036  0.007 -0.118   \n",
       "4607 -0.207 -0.168  0.037 -0.263 -0.161 -0.215  0.147 -0.125 -0.198  0.171   \n",
       "5114 -0.034  0.071  0.238 -0.235 -0.002  0.296 -0.008 -0.145  0.091  0.134   \n",
       "1859 -0.145  0.312 -0.320  0.161 -0.050  0.038  0.065  0.031 -0.248 -0.190   \n",
       "\n",
       "      lp5c1  lp6c0  lp6c1  lp7c0  lp7c1   wb_0   wb_1   wb_2   wb_3   wb_4  \\\n",
       "7217 -0.047  0.067  0.228  0.280  0.308 -0.130  0.045  0.072 -0.479 -0.520   \n",
       "8291 -0.112 -0.170 -0.343  0.157 -0.237  0.397 -0.447 -0.279 -0.139 -0.020   \n",
       "4607 -0.278 -0.136  0.029 -0.175  0.085 -0.036 -0.056  0.079 -0.432 -0.082   \n",
       "5114  0.235  0.048 -0.073  0.002 -0.085  0.071  0.432  0.124 -0.559 -0.203   \n",
       "1859  0.071  0.285 -0.134 -0.307 -0.084  0.486 -0.459 -0.322 -1.235  0.328   \n",
       "\n",
       "      ...  wb_1437  wb_1438  wb_1439  wb_1440  wb_1441  wb_1442  wb_1443  \\\n",
       "7217  ...   -2.664   -0.080    0.543    0.846    0.331   -1.032    2.814   \n",
       "8291  ...    0.423   -1.797    0.599    2.094    0.200   -0.658    0.049   \n",
       "4607  ...    1.502   -0.085    0.491    1.873    0.469   -0.048    1.079   \n",
       "5114  ...    0.805   -0.085    1.094    1.160    0.146   -0.058    0.045   \n",
       "1859  ...   -1.357   -0.076    1.648    0.139    0.016   -0.046    2.014   \n",
       "\n",
       "      wb_1444  wb_1445  wb_1446  wb_1447  wb_1448  wb_1449  wb_1450  wb_1451  \\\n",
       "7217    1.223    0.466    0.848   -1.194    0.598    0.896    0.416    1.221   \n",
       "8291    0.373    0.406    0.012   -1.834    0.406    1.980    1.942    0.457   \n",
       "4607    0.454    0.439    1.052   -1.095   -0.711    1.483    1.827    1.866   \n",
       "5114    1.158    0.164    0.293   -1.801    0.782    0.827    0.936    1.562   \n",
       "1859    0.335    1.427   -0.946   -1.596    0.296    1.178    0.108    1.756   \n",
       "\n",
       "      wb_1452  wb_1453  wb_1454  wb_1455  wb_1456  wb_1457  wb_1458  wb_1459  \\\n",
       "7217    1.096    1.502    0.232   -1.160    2.673   -1.293    0.561   -0.124   \n",
       "8291    1.591    1.731    0.353   -0.874    0.327   -1.339    1.083   -1.346   \n",
       "4607    0.585    1.700    0.499   -1.699    0.746   -1.070    0.871   -1.527   \n",
       "5114    1.102    1.356    1.139   -1.912    0.377   -2.799    0.895   -0.124   \n",
       "1859    1.920    2.440    1.032   -1.034    0.071   -0.166    1.480   -1.788   \n",
       "\n",
       "      wb_1460  wb_1461  wb_1462  wb_1463  wb_1464  wb_1465  wb_1466  wb_1467  \\\n",
       "7217   -0.416   -0.113   -1.034    1.011    0.230   -0.689   -1.373    0.195   \n",
       "8291   -0.743   -0.113   -0.427    1.229    0.587   -0.541   -1.762    3.115   \n",
       "4607   -1.048   -0.113   -0.258    0.813    0.892   -0.099   -1.204    0.449   \n",
       "5114   -0.509   -0.113    0.106    0.782    0.329   -1.520   -1.148    1.018   \n",
       "1859   -0.124   -0.113   -0.325    1.426    0.166   -1.519   -0.106    0.093   \n",
       "\n",
       "      wb_1468  wb_1469  wb_1470  wb_1471  wb_1472  wb_1473  wb_1474  wb_1475  \\\n",
       "7217   -2.951    1.211   -1.001    0.526    0.236   -0.101    1.020    0.866   \n",
       "8291   -1.407    1.868   -0.602    1.056    0.415   -1.008    0.325    0.903   \n",
       "4607   -0.060    0.515   -1.010    1.810   -0.751   -1.580    0.418   -0.572   \n",
       "5114   -1.831    1.661   -1.995    0.863   -0.170   -0.729    1.523   -1.767   \n",
       "1859   -0.055    1.997   -1.357    1.869   -0.263   -0.106    0.288    1.396   \n",
       "\n",
       "      wb_1476  wb_1477  wb_1478  wb_1479  wb_1480  wb_1481  wb_1482  wb_1483  \\\n",
       "7217   -0.367   -0.090   -1.074    2.166    0.312   -1.227   -0.907   -1.095   \n",
       "8291   -0.718   -1.856   -0.518    1.379    0.689   -0.534   -0.444   -0.681   \n",
       "4607   -0.531   -0.714   -0.499    1.269   -0.773   -1.006    0.574   -0.482   \n",
       "5114   -0.404   -1.251   -0.425    0.752    0.459   -0.153   -1.100   -1.122   \n",
       "1859   -0.245   -0.085   -0.386    0.136    1.876   -0.369   -0.352   -0.037   \n",
       "\n",
       "      wb_1484  wb_1485  wb_1486  wb_1487  wb_1488  wb_1489  wb_1490  wb_1491  \\\n",
       "7217    1.928   -0.360    0.539   -2.441   -0.199   -1.208   -0.258    1.142   \n",
       "8291   -2.213   -0.761    0.426   -0.126   -1.158   -0.684   -2.875    1.912   \n",
       "4607    0.696    0.608    0.432   -0.117   -0.467   -0.568   -0.582    0.496   \n",
       "5114   -1.368   -0.935    0.143   -0.130   -1.233   -0.215   -0.467    0.428   \n",
       "1859    1.174    0.363    1.004   -0.115   -0.277   -0.337   -1.267    0.465   \n",
       "\n",
       "      wb_1492  wb_1493  wb_1494  wb_1495  wb_1496  wb_1497  wb_1498  wb_1499  \\\n",
       "7217    0.449   -2.131   -1.336    0.412   -0.592   -1.105    0.519   -0.915   \n",
       "8291    0.323   -1.739   -1.343    0.333   -0.426   -0.751    0.272   -0.863   \n",
       "4607    0.582   -0.604   -1.091    0.426   -0.350    1.731    0.826   -0.783   \n",
       "5114   -0.986   -0.937   -0.134   -0.502   -0.179    0.334    1.181   -0.420   \n",
       "1859    0.285   -1.507   -1.488    0.958   -0.289   -0.345    1.214   -0.666   \n",
       "\n",
       "      wb_1500  wb_1501  wb_1502  wb_1503  wb_1504  wb_1505  wb_1506  wb_1507  \\\n",
       "7217   -1.207    0.236    2.689    0.050   -0.124    0.893    0.962   -0.302   \n",
       "8291   -1.082    0.253    1.436    0.361   -1.349    0.383    0.327   -0.904   \n",
       "4607   -0.782    0.182    1.065    0.584   -0.283    0.474    0.449   -0.798   \n",
       "5114   -0.357    0.096    1.537   -1.447   -0.244    0.531    0.118   -1.216   \n",
       "1859   -0.039    0.190    1.900    0.335   -0.335    1.402    0.207   -0.075   \n",
       "\n",
       "      wb_1508  wb_1509  wb_1510  wb_1511  wb_1512  wb_1513  wb_1514  wb_1515  \\\n",
       "7217   -1.183   -0.561   -0.686   -0.086    0.315    1.130    0.869    2.822   \n",
       "8291   -0.582   -1.495   -0.565   -0.093    0.281    1.552    1.274    0.057   \n",
       "4607   -0.599   -1.377   -1.209   -1.641    0.639    0.908    1.087    1.153   \n",
       "5114   -1.469   -0.988   -1.164   -0.088    0.202    0.404    0.084    1.486   \n",
       "1859   -1.348   -0.169   -0.077   -0.097    1.099    0.285    1.735    1.172   \n",
       "\n",
       "      wb_1516  wb_1517  wb_1518  wb_1519  wb_1520  wb_1521  wb_1522  wb_1523  \\\n",
       "7217   -0.836   -0.382    0.067   -0.212    1.195    0.300   -0.177   -2.707   \n",
       "8291   -0.155   -1.151    0.067   -1.041    0.361    2.332    0.595   -1.611   \n",
       "4607   -1.214   -1.388    0.067   -0.507    0.445    0.974   -0.349   -0.741   \n",
       "5114   -1.478   -0.501    0.067   -0.920   -1.587    0.473   -0.361   -2.788   \n",
       "1859   -1.577   -0.937    0.067   -0.700    0.793    1.750    0.202   -1.528   \n",
       "\n",
       "      wb_1524  wb_1525  wb_1526  wb_1527  wb_1528  wb_1529  wb_1530  wb_1531  \\\n",
       "7217   -0.849    1.169    1.162    0.344    0.284    0.414   -0.088   -0.962   \n",
       "8291   -0.935    2.019    2.166    2.244    0.327    1.042   -0.557   -0.486   \n",
       "4607   -1.179    0.466    1.062    1.891   -1.182    0.870   -0.148    1.070   \n",
       "5114   -0.811    1.523    0.486    0.825    0.193    1.380   -0.455   -0.189   \n",
       "1859   -0.970    1.870    1.956    0.127    0.816    1.756   -0.200   -0.399   \n",
       "\n",
       "      wb_1532  wb_1533  wb_1534  wb_1535  wb_1536  \n",
       "7217   -1.604    0.799    0.905   -0.155    0.031  \n",
       "8291   -1.759    1.933   -0.450    1.074   -0.191  \n",
       "4607   -0.972    0.874    0.374   -1.261    0.056  \n",
       "5114   -0.947    1.094   -0.557   -0.849    0.071  \n",
       "1859   -0.092    1.655    0.300    0.340    0.048  \n",
       "\n",
       "[5 rows x 1632 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.332464Z",
     "iopub.status.busy": "2021-12-01T19:54:51.332300Z",
     "iopub.status.idle": "2021-12-01T19:54:51.335617Z",
     "shell.execute_reply": "2021-12-01T19:54:51.334972Z",
     "shell.execute_reply.started": "2021-12-01T19:54:51.332445Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.336517Z",
     "iopub.status.busy": "2021-12-01T19:54:51.336363Z",
     "iopub.status.idle": "2021-12-01T19:54:51.347770Z",
     "shell.execute_reply": "2021-12-01T19:54:51.346556Z",
     "shell.execute_reply.started": "2021-12-01T19:54:51.336499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=int64, numpy=\n",
       "array([[0],\n",
       "       [1],\n",
       "       [3]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where([True, True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.349860Z",
     "iopub.status.busy": "2021-12-01T19:54:51.349553Z",
     "iopub.status.idle": "2021-12-01T19:54:51.355618Z",
     "shell.execute_reply": "2021-12-01T19:54:51.354934Z",
     "shell.execute_reply.started": "2021-12-01T19:54:51.349841Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 2, 3, 2], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_node = tf.constant([0, 2, 3, 2])\n",
    "indices_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.356639Z",
     "iopub.status.busy": "2021-12-01T19:54:51.356476Z",
     "iopub.status.idle": "2021-12-01T19:54:51.363497Z",
     "shell.execute_reply": "2021-12-01T19:54:51.362110Z",
     "shell.execute_reply.started": "2021-12-01T19:54:51.356620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_node = tf.constant([1, 1, 1, 1])\n",
    "values_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.364840Z",
     "iopub.status.busy": "2021-12-01T19:54:51.364517Z",
     "iopub.status.idle": "2021-12-01T19:54:51.370987Z",
     "shell.execute_reply": "2021-12-01T19:54:51.370158Z",
     "shell.execute_reply.started": "2021-12-01T19:54:51.364818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique(y=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 2, 3], dtype=int32)>, idx=<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 1], dtype=int32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.unique(indices_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.372335Z",
     "iopub.status.busy": "2021-12-01T19:54:51.372181Z",
     "iopub.status.idle": "2021-12-01T19:54:51.396962Z",
     "shell.execute_reply": "2021-12-01T19:54:51.396272Z",
     "shell.execute_reply.started": "2021-12-01T19:54:51.372317Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "values_by_index 1\n",
      "[]\n",
      "values_by_index 0\n",
      "[1 1]\n",
      "values_by_index 2\n",
      "[1]\n",
      "values_by_index 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=2>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_tensor = []\n",
    "for i in range(4):\n",
    "    index_identifier = []\n",
    "    for j, variable_index in enumerate(tf.unstack(indices_node)):\n",
    "        if tf.equal(variable_index, i):\n",
    "            index_identifier.append(j)\n",
    "    index_identifier = tf.cast(tf.expand_dims(tf.stack(index_identifier), axis=1), tf.int64)\n",
    "    #print(index_identifier)\n",
    "    tf.print(tf.gather_nd(values_node, index_identifier))\n",
    "    values_by_index = tf.reduce_sum(tf.gather_nd(values_node, index_identifier))\n",
    "    tf.print('values_by_index', values_by_index)\n",
    "    dense_tensor.append(values_by_index)\n",
    "dense_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.398359Z",
     "iopub.status.busy": "2021-12-01T19:54:51.398067Z",
     "iopub.status.idle": "2021-12-01T19:54:51.414787Z",
     "shell.execute_reply": "2021-12-01T19:54:51.414206Z",
     "shell.execute_reply.started": "2021-12-01T19:54:51.398339Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "values_by_index 1\n",
      "[]\n",
      "values_by_index 0\n",
      "[1 1]\n",
      "values_by_index 2\n",
      "[1]\n",
      "values_by_index 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=2>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_tensor = []\n",
    "for i in range(4):\n",
    "    index_identifier = tf.where(tf.equal(indices_node, i))\n",
    "    tf.print(tf.gather_nd(values_node, index_identifier))\n",
    "    values_by_index = tf.reduce_sum(tf.gather_nd(values_node, index_identifier))\n",
    "    tf.print('values_by_index', values_by_index)\n",
    "    dense_tensor.append(values_by_index)\n",
    "dense_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T19:54:51.415677Z",
     "iopub.status.busy": "2021-12-01T19:54:51.415523Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_accuracy_inet_decision_function_fv_metric\n",
      "\ttraining         \t (min:    0.521, max:    0.656, cur:    0.656)\n",
      "\tvalidation       \t (min:    0.632, max:    0.653, cur:    0.653)\n",
      "Loss\n",
      "\ttraining         \t (min:    0.625, max:    0.896, cur:    0.625)\n",
      "\tvalidation       \t (min:    0.630, max:    0.651, cur:    0.632)\n",
      "mse_inet_decision_function_fv_metric\n",
      "\ttraining         \t (min:    0.217, max:    0.293, cur:    0.218)\n",
      "\tvalidation       \t (min:    0.220, max:    0.229, cur:    0.221)\n",
      "Epoch 27/200\n",
      " 4/35 [==>...........................] - ETA: 23s - loss: 0.6225 - mse_inet_decision_function_fv_metric: 0.2163 - binary_accuracy_inet_decision_function_fv_metric: 0.6583"
     ]
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      callback_names=['plot_losses']\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 3\n",
    "network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "if (config['i_net']['convolution_layers'] != None or config['i_net']['lstm_layers'] != None or (config['i_net']['nas'] and config['i_net']['nas_type'] != 'SEQUENTIAL')) and config['i_net']['data_reshape_version'] is not None:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "number = lambda_net_dataset_test.X_test_lambda_array.shape[0]#10\n",
    "\n",
    "dt_inet_list = model.predict(lambda_net_dataset_test.network_parameters_array[:number])\n",
    "\n",
    "dt_inet_list = []\n",
    "runtime_list = []\n",
    "for network in lambda_net_dataset_test.network_parameters_array[:number]:\n",
    "\n",
    "    start_inet = time.time() \n",
    "\n",
    "    dt_inet = model.predict(np.array([network]))[0]\n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)   \n",
    "    \n",
    "    dt_inet_list.append(dt_inet)\n",
    "    runtime_list.append(inet_runtime)    \n",
    "    \n",
    "dt_inet_list = np.array(dt_inet_list)\n",
    "runtime_list = np.array(runtime_list)\n",
    "\n",
    "\n",
    "parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "\n",
    "inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                               dt_inet,\n",
    "                                                                                                               X_test_lambda, \n",
    "                                                                                                               #y_test_lambda,\n",
    "                                                                                                               config) for lambda_net_parameters, \n",
    "                                                                                                                           dt_inet, \n",
    "                                                                                                                           X_test_lambda in zip(lambda_net_dataset_test.network_parameters_array[:number], \n",
    "                                                                                                                                                dt_inet_list, \n",
    "                                                                                                                                                lambda_net_dataset_test.X_test_lambda_array[:number]))      \n",
    "\n",
    "del parallel_inet_evaluation\n",
    "\n",
    "inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "inet_evaluation_result_dict = None\n",
    "for some_dict in inet_evaluation_results:\n",
    "    if inet_evaluation_result_dict == None:\n",
    "        inet_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        inet_evaluation_result_dict = mergeDict(inet_evaluation_result_dict, some_dict)\n",
    "\n",
    "inet_evaluation_result_dict['inet_scores']['runtime'] = runtime_list\n",
    "        \n",
    "        \n",
    "inet_evaluation_result_dict_mean = {}\n",
    "\n",
    "for key_l1, values_l1 in inet_evaluation_result_dict.items():\n",
    "    if key_l1 != 'function_values':\n",
    "        if isinstance(values_l1, dict):\n",
    "            inet_evaluation_result_dict_mean[key_l1] = {}\n",
    "            for key_l2, values_l2 in values_l1.items():\n",
    "                inet_evaluation_result_dict_mean[key_l1][key_l2] = np.mean(values_l2)\n",
    "\n",
    "                \n",
    "inet_evaluation_result_dict_mean  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Binary Crossentropy:\\t', np.round(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy'], 3), '(Sklearn DT)' , '\\t', np.round(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy'], 3), '(I-Net DT)')\n",
    "print('Accuracy:\\t\\t', np.round(inet_evaluation_result_dict_mean['dt_scores']['accuracy'], 3), '(Sklearn DT)' , '\\t', np.round(inet_evaluation_result_dict_mean['inet_scores']['accuracy'], 3), '(I-Net DT)')\n",
    "print('F1 Score:\\t\\t', np.round(inet_evaluation_result_dict_mean['dt_scores']['f1_score'], 3), '(Sklearn DT)' , '\\t', np.round(inet_evaluation_result_dict_mean['inet_scores']['f1_score'], 3), '(I-Net DT)')\n",
    "\n",
    "print('Runtime:\\t\\t', np.round(inet_evaluation_result_dict_mean['dt_scores']['runtime'], 3), '(Sklearn DT)' , '\\t', np.round(inet_evaluation_result_dict_mean['inet_scores']['runtime'], 3), '(I-Net DT)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file: \n",
    "        if different_eval_data:\n",
    "            flat_config = flatten_dict(config_train)\n",
    "        else:\n",
    "            flat_config = flatten_dict(config)\n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key)\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_binary_crossentropy_' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_accuracy' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_f1_score' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('dt_scores_runtime_' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_binary_crossentropy_' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_accuracy' + str(i))\n",
    "            text_file.write(';')\n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_score' + str(i))\n",
    "            text_file.write(';')                \n",
    "        for i in range(int(lambda_dataset_size*0.25)):\n",
    "            text_file.write('inet_runtime_' + str(i))\n",
    "            text_file.write(';')      \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file: \n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['dt_scores']['binary_crossentropy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['dt_scores']['accuracy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['dt_scores']['f1_score']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['dt_scores']['runtime']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['inet_scores']['binary_crossentropy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['inet_scores']['accuracy']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    for value in inet_evaluation_result_dict['inet_scores']['f1_score']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')        \n",
    "    for value in inet_evaluation_result_dict['inet_scores']['runtime']:\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATA EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "\n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 #\"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 #\"Marital Status\", #5\n",
    "                 #\"Occupation\",  #6\n",
    "                 #\"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 'capital_gain'\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = ['Sex', 'Race', 'Workclass', 'capital_gain']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(adult_data)\n",
    "\n",
    "adult_data = transformer.transform(adult_data)\n",
    "adult_data = pd.DataFrame(adult_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    adult_data[ordinal_feature] = OrdinalEncoder().fit_transform(adult_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "adult_data = adult_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "y_data_adult = adult_data['capital_gain']\n",
    "#le = LabelEncoder()\n",
    "#le.fit(y_data_adult)\n",
    "#y_data_adult = le.transform(y_data_adult)\n",
    "#class_names = le.classes_\n",
    "\n",
    "\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data['capital_gain'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_adult.shape[1] > number_of_variables:\n",
    "    X_data_adult = X_data_adult.sample(n=number_of_variables,axis='columns')\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_adult.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_adult[column_name] = np.zeros(X_data_adult.shape[0])\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_adult:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_adult[column_name].values.reshape(-1, 1))\n",
    "    X_data_adult[column_name] = scaler.transform(X_data_adult[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_adult_with_valid, X_test_adult, y_train_adult_with_valid, y_test_adult = train_test_split(X_data_adult, y_data_adult, train_size=0.8)\n",
    "X_train_adult, X_valid_adult, y_train_adult, y_valid_adult = train_test_split(X_train_adult_with_valid, y_train_adult_with_valid, train_size=0.8)\n",
    "\n",
    "print(X_train_adult.shape, y_train_adult.shape)\n",
    "print(X_valid_adult.shape, y_valid_adult.shape)\n",
    "print(X_test_adult.shape, y_test_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.4 or true_ratio >= 0.6:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "    X_train_adult, y_train_adult = oversample.fit_resample(X_train_adult, y_train_adult)\n",
    "\n",
    "    true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "    false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult = generate_lambda_net_from_config(config)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                  patience=50, \n",
    "                                                  min_delta=0.001, \n",
    "                                                  verbose=0, \n",
    "                                                  mode='min', \n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "model_history = test_network_adult.fit(X_train_adult,\n",
    "                                  y_train_adult, \n",
    "                                  epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                  batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                  callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                  validation_data=(X_valid_adult, y_valid_adult),\n",
    "                                  verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult_parameters = shaped_network_parameters_to_array(test_network_adult.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_adult_dt_inet = model.predict(np.array([test_network_adult_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   \n",
    "\n",
    "results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                   test_network_adult_dt_inet,\n",
    "                                                                   X_test_adult.values, \n",
    "                                                                   #y_test_lambda,\n",
    "                                                                   config)\n",
    "\n",
    "results_adult['inet_scores']['runtime'] = inet_runtime\n",
    "\n",
    "print('Binary Crossentropy:\\t\\t', np.round(results_adult['dt_scores']['binary_crossentropy'], 3), '(Sklearn DT)' , '\\t', np.round(results_adult['inet_scores']['binary_crossentropy'], 3), '(I-Net DT)')\n",
    "print('Accuracy:\\t\\t', np.round(results_adult['dt_scores']['accuracy'], 3), '(Sklearn DT)' , '\\t', np.round(results_adult['inet_scores']['accuracy'], 3), '(I-Net DT)')\n",
    "print('F1 Score:\\t\\t', np.round(results_adult['dt_scores']['f1_score'], 3), '(Sklearn DT)' , '\\t', np.round(results_adult['inet_scores']['f1_score'], 3), '(I-Net DT)')\n",
    "print('Runtime:\\t\\t', np.round(results_adult['dt_scores']['runtime'], 3), '(Sklearn DT)' , '\\t', np.round(results_adult['inet_scores']['runtime'], 3), '(I-Net DT)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_adult_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_adult_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_adult, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_adult.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.drop([\n",
    "                                    'Cabin', \n",
    "                                    'Ticket', \n",
    "                                    'Name', \n",
    "                                    'PassengerId'\n",
    "                                ], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "#titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "categorical_features = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features = ['Sex']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(titanic_data)\n",
    "\n",
    "titanic_data = transformer.transform(titanic_data)\n",
    "titanic_data = pd.DataFrame(titanic_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    titanic_data[ordinal_feature] = OrdinalEncoder().fit_transform(titanic_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "titanic_data = titanic_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_titanic.shape[1] > number_of_variables:\n",
    "    X_data_titanic = X_data_titanic.sample(n=number_of_variables,axis='columns')\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_titanic.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_titanic[column_name] = np.zeros(X_data_titanic.shape[0])\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_titanic:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_titanic[column_name].values.reshape(-1, 1))\n",
    "    X_data_titanic[column_name] = scaler.transform(X_data_titanic[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_titanic_with_valid, X_test_titanic, y_train_titanic_with_valid, y_test_titanic = train_test_split(X_data_titanic, y_data_titanic, train_size=0.8)\n",
    "X_train_titanic, X_valid_titanic, y_train_titanic, y_valid_titanic = train_test_split(X_train_titanic_with_valid, y_train_titanic_with_valid, train_size=0.8)\n",
    "\n",
    "print(X_train_titanic.shape, y_train_titanic.shape)\n",
    "print(X_valid_titanic.shape, y_valid_titanic.shape)\n",
    "print(X_test_titanic.shape, y_test_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.4 or true_ratio >= 0.6:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "    X_train_titanic, y_train_titanic = oversample.fit_resample(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "    false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic = generate_lambda_net_from_config(config)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                  patience=50, \n",
    "                                                  min_delta=0.001, \n",
    "                                                  verbose=0, \n",
    "                                                  mode='min', \n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "model_history = test_network_titanic.fit(X_train_titanic,\n",
    "                                      y_train_titanic, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_titanic, y_valid_titanic),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic_parameters = shaped_network_parameters_to_array(test_network_titanic.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_titanic_dt_inet = model.predict(np.array([test_network_titanic_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   \n",
    "\n",
    "results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                   test_network_titanic_dt_inet,\n",
    "                                                                   X_test_titanic.values, \n",
    "                                                                   #y_test_lambda,\n",
    "                                                                   config)\n",
    "\n",
    "results_titanic['inet_scores']['runtime'] = inet_runtime\n",
    "\n",
    "print('Binary Crossentropy:\\t\\t', np.round(results_titanic['dt_scores']['binary_crossentropy'], 3), '(Sklearn DT)' , '\\t', np.round(results_titanic['inet_scores']['binary_crossentropy'], 3), '(I-Net DT)')\n",
    "print('Accuracy:\\t\\t', np.round(results_titanic['dt_scores']['accuracy'], 3), '(Sklearn DT)' , '\\t', np.round(results_titanic['inet_scores']['accuracy'], 3), '(I-Net DT)')\n",
    "print('F1 Score:\\t\\t', np.round(results_titanic['dt_scores']['f1_score'], 3), '(Sklearn DT)' , '\\t', np.round(results_titanic['inet_scores']['f1_score'], 3), '(I-Net DT)')\n",
    "print('Runtime:\\t\\t', np.round(results_titanic['dt_scores']['runtime'], 3), '(Sklearn DT)' , '\\t', np.round(results_titanic['inet_scores']['runtime'], 3), '(I-Net DT)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_data_titanic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_titanic_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_titanic_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_titanic, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_titanic.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "absenteeism_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           #'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           #'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           #'Weight', \n",
    "                           #'Height', \n",
    "                           #'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = []\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(absenteeism_data)\n",
    "\n",
    "absenteeism_data = transformer.transform(absenteeism_data)\n",
    "absenteeism_data = pd.DataFrame(absenteeism_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    absenteeism_data[ordinal_feature] = OrdinalEncoder().fit_transform(absenteeism_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "absenteeism_data = absenteeism_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 3) * 1) #absenteeism_data['Absenteeism time in hours']\n",
    "\n",
    "print(X_data_absenteeism.shape)\n",
    "\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_absenteeism.shape[1] > number_of_variables:\n",
    "    X_data_absenteeism = X_data_absenteeism.sample(n=number_of_variables,axis='columns')\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_absenteeism.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_absenteeism[column_name] = np.zeros(X_data_absenteeism.shape[0])\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_absenteeism:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_absenteeism[column_name].values.reshape(-1, 1))\n",
    "    X_data_absenteeism[column_name] = scaler.transform(X_data_absenteeism[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_absenteeism_with_valid, X_test_absenteeism, y_train_absenteeism_with_valid, y_test_absenteeism = train_test_split(X_data_absenteeism, y_data_absenteeism, train_size=0.8)\n",
    "X_train_absenteeism, X_valid_absenteeism, y_train_absenteeism, y_valid_absenteeism = train_test_split(X_train_absenteeism_with_valid, y_train_absenteeism_with_valid, train_size=0.8)\n",
    "\n",
    "print(X_train_absenteeism.shape, y_train_absenteeism.shape)\n",
    "print(X_valid_absenteeism.shape, y_valid_absenteeism.shape)\n",
    "print(X_test_absenteeism.shape, y_test_absenteeism.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.4 or true_ratio >= 0.6:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "    X_train_absenteeism, y_train_absenteeism = oversample.fit_resample(X_train_absenteeism, y_train_absenteeism)\n",
    "\n",
    "    true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "    false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism = generate_lambda_net_from_config(config)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                  patience=50, \n",
    "                                                  min_delta=0.001, \n",
    "                                                  verbose=0, \n",
    "                                                  mode='min', \n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "model_history = test_network_absenteeism.fit(X_train_absenteeism,\n",
    "                                  y_train_absenteeism, \n",
    "                                  epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                  batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                  callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                  validation_data=(X_valid_absenteeism, y_valid_absenteeism),\n",
    "                                  verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism_parameters = shaped_network_parameters_to_array(test_network_absenteeism.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "test_network_absenteeism_dt_inet = model.predict(np.array([test_network_absenteeism_parameters]))[0]\n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   \n",
    "\n",
    "results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                   test_network_absenteeism_dt_inet,\n",
    "                                                                   X_test_absenteeism.values, \n",
    "                                                                   #y_test_lambda,\n",
    "                                                                   config)\n",
    "\n",
    "results_absenteeism['inet_scores']['runtime'] = inet_runtime\n",
    "\n",
    "print('Binary Crossentropy:\\t\\t', np.round(results_absenteeism['dt_scores']['binary_crossentropy'], 3), '(Sklearn DT)' , '\\t', np.round(results_absenteeism['inet_scores']['binary_crossentropy'], 3), '(I-Net DT)')\n",
    "print('Accuracy:\\t\\t', np.round(results_absenteeism['dt_scores']['accuracy'], 3), '(Sklearn DT)' , '\\t', np.round(results_absenteeism['inet_scores']['accuracy'], 3), '(I-Net DT)')\n",
    "print('F1 Score:\\t\\t', np.round(results_absenteeism['dt_scores']['f1_score'], 3), '(Sklearn DT)' , '\\t', np.round(results_absenteeism['inet_scores']['f1_score'], 3), '(I-Net DT)')\n",
    "print('Runtime:\\t\\t', np.round(results_absenteeism['dt_scores']['runtime'], 3), '(Sklearn DT)' , '\\t', np.round(results_absenteeism['inet_scores']['runtime'], 3), '(I-Net DT)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_data_absenteeism.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_absenteeism_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_absenteeism_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_absenteeism, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_absenteeism.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "        if different_eval_data:\n",
    "            flat_config = flatten_dict(config_train)\n",
    "        else:\n",
    "            flat_config = flatten_dict(config)\n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key + ';')\n",
    "        text_file.write('dt_scores_binary_crossentropy_artificial_mean' + ';')\n",
    "        text_file.write('dt_scores_accuracy_artificial_mean' + ';')\n",
    "        text_file.write('dt_f1_score_artificial_mean' + ';')\n",
    "        text_file.write('dt_scores_runtime_artificial_mean' + ';')\n",
    "        text_file.write('inet_binary_crossentropy_artificial_mean' + ';')\n",
    "        text_file.write('inet_accuracy_artificial_mean' + ';')\n",
    "        text_file.write('inet_score_artificial_mean' + ';')\n",
    "        text_file.write('inet_runtime_artificial_mean' + ';')\n",
    "        \n",
    "        \n",
    "        text_file.write('dt_scores_binary_crossentropy_adult' + ';')\n",
    "        text_file.write('dt_scores_accuracy_adult' + ';')\n",
    "        text_file.write('dt_f1_score_adult' + ';')\n",
    "        text_file.write('dt_scores_runtime_adult' + ';')\n",
    "        text_file.write('inet_binary_crossentropy_adult' + ';')\n",
    "        text_file.write('inet_accuracy_adult' + ';')\n",
    "        text_file.write('inet_score_adult' + ';')\n",
    "        text_file.write('inet_runtime_adult' + ';')\n",
    "        \n",
    "        text_file.write('dt_scores_binary_crossentropy_titanic' + ';')\n",
    "        text_file.write('dt_scores_accuracy_titanic' + ';')\n",
    "        text_file.write('dt_f1_score_titanic' + ';')\n",
    "        text_file.write('dt_scores_runtime_titanic' + ';')\n",
    "        text_file.write('inet_binary_crossentropy_titanic' + ';')\n",
    "        text_file.write('inet_accuracy_titanic' + ';')\n",
    "        text_file.write('inet_score_titanic' + ';')\n",
    "        text_file.write('inet_runtime_titanic' + ';')\n",
    "        \n",
    "        text_file.write('dt_scores_binary_crossentropy_absenteeism' + ';')\n",
    "        text_file.write('dt_scores_accuracy_absenteeism' + ';')\n",
    "        text_file.write('dt_f1_score_absenteeism' + ';')\n",
    "        text_file.write('dt_scores_runtime_absenteeism' + ';')\n",
    "        text_file.write('inet_binary_crossentropy_absenteeism' + ';')\n",
    "        text_file.write('inet_accuracy_absenteeism' + ';')\n",
    "        text_file.write('inet_score_absenteeism' + ';')\n",
    "        text_file.write('inet_runtime_absenteeism')        \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['dt_scores']['runtime']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(inet_evaluation_result_dict_mean['inet_scores']['runtime']) + ';')\n",
    "    \n",
    "    \n",
    "    text_file.write(str(results_adult['dt_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(results_adult['dt_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(results_adult['dt_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(results_adult['dt_scores']['runtime']) + ';')\n",
    "    text_file.write(str(results_adult['inet_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(results_adult['inet_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(results_adult['inet_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(results_adult['inet_scores']['runtime']) + ';')\n",
    "    \n",
    "    text_file.write(str(results_titanic['dt_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(results_titanic['dt_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(results_titanic['dt_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(results_titanic['dt_scores']['runtime']) + ';')\n",
    "    text_file.write(str(results_titanic['inet_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(results_titanic['inet_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(results_titanic['inet_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(results_titanic['inet_scores']['runtime']) + ';')\n",
    "    \n",
    "    text_file.write(str(results_absenteeism['dt_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(results_absenteeism['dt_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(results_absenteeism['dt_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(results_absenteeism['dt_scores']['runtime']) + ';')\n",
    "    text_file.write(str(results_absenteeism['inet_scores']['binary_crossentropy']) + ';')\n",
    "    text_file.write(str(results_absenteeism['inet_scores']['accuracy']) + ';')\n",
    "    text_file.write(str(results_absenteeism['inet_scores']['f1_score']) + ';')\n",
    "    text_file.write(str(results_absenteeism['inet_scores']['runtime']))    \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
