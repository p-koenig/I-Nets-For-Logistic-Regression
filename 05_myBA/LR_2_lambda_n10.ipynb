{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7413b1-5b9f-472e-9045-ee14068be971",
   "metadata": {},
   "source": [
    "# Config & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d269d23f-33f7-456b-b4fc-a457414ed778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 11:07:05.453104: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-07 11:07:05.453147: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import utilities_LR\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ef29c7-245e-4770-b29d-0045b6b0b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "     'data': {\n",
    "        'n_datasets': 45_000, # the number of datasets\n",
    "        \n",
    "        'n_samples': 5_000, # the number of samples per dataset\n",
    "        \n",
    "        'n_features': 10, \n",
    "        # The total number of features. \n",
    "        # These comprise n_informative informative features, n_redundant redundant features, n_repeated duplicated features and \n",
    "        # n_features-n_informative-n_redundant-n_repeated useless features drawn at random.\n",
    "        \n",
    "        #'n_informative': random.randint(2, 10),\n",
    "        'n_informative': 'random',\n",
    "        # The number of informative features. Each class is composed of a number of gaussian clusters each located around the vertices \n",
    "        # of a hypercube in a subspace of dimension n_informative. For each cluster, informative features are drawn independently \n",
    "        # from N(0, 1) and then randomly linearly combined within each cluster in order to add covariance. The clusters are then \n",
    "        # placed on the vertices of the hypercube.\n",
    "        ### int or 'random'\n",
    "        \n",
    "        'n_targets': 1,\n",
    "        # The number of targets (or labels) of the classification problem.\n",
    "    \n",
    "        'n_clusters_per_class': 1,\n",
    "        # The number of clusters per class.\n",
    "        \n",
    "        'class_sep': 1.0,\n",
    "        # class_sepfloat, default=1.0\n",
    "        # The factor multiplying the hypercube size. Larger values spread out the clusters/classes and make the classification task \n",
    "        # easier.\n",
    "        \n",
    "        'shuffle': True,\n",
    "        # Shuffle the samples and the features.\n",
    "        \n",
    "        'random_state': 44,\n",
    "        # Determines random number generation for dataset creation. Pass an int for reproducible output across multiple function calls.\n",
    "    },\n",
    "    'lambda': {\n",
    "        'data_prep': {\n",
    "            'train_test_val_split': { # refer to sklearn doc\n",
    "                'test_size': 0.1,\n",
    "                'val_size': 0.15,\n",
    "                'random_state': None,\n",
    "                'shuffle': False, # should be always false\n",
    "                'stratify': None\n",
    "            }\n",
    "        },\n",
    "        'model_compile': {\n",
    "            'optimizer_lambda': 'adam',\n",
    "            'loss': 'mae',# keras.losses.BinaryCrossentropy(from_logits=False), #tf.keras.losses.get(config['lambda_net']['loss_lambda']), # 'mae'\n",
    "            'metrics': [] # 'mae', keras.losses.BinaryCrossentropy(from_logits=False)]\n",
    "        },\n",
    "        'model_fit': { # refer to keras API\n",
    "            'batch_size': 64,\n",
    "            'epochs': 500,\n",
    "            'verbose': 0,\n",
    "            'callbacks': None,\n",
    "            'shuffle': True, # usually true\n",
    "            'class_weight': None,\n",
    "            'sample_weight': None,\n",
    "            'initial_epoch': 0,\n",
    "            'steps_per_epoch': None,\n",
    "            'validation_steps': None,\n",
    "            'validation_batch_size': None,\n",
    "            'validation_freq': 1\n",
    "        }\n",
    "    },\n",
    "    'computation':{\n",
    "        'n_jobs': 50,\n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 1,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8c0cc-8b52-4637-aaeb-e16a16634b89",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9518e9f9-6a5d-45e8-9bea-95333bb436d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config['computation']['gpu_numbers'] if config['computation']['use_gpu'] else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if config['computation']['use_gpu'] else ''\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if config['computation']['use_gpu'] else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if config['computation']['use_gpu'] else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d525d7-df11-4db7-bd88-211471e5a29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 11:07:08.666150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-07 11:07:08.666188: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-07 11:07:08.666212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dws-02): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae09b938-bfec-4ac3-b5cd-a33ce494c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76077315-f3bc-495f-92b9-df69649f3eed",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91501bce-140a-4c6c-89c4-94317079c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_datasets_list = np.zeros([config['data']['n_datasets'], config['data']['n_samples'], config['data']['n_features']])\n",
    "\n",
    "if  config['data']['n_targets'] < 2:\n",
    "    y_datasets_list = np.zeros([config['data']['n_datasets'], config['data']['n_samples'], ])\n",
    "else:\n",
    "    y_datasets_list = np.zeros([config['data']['n_datasets'], config['data']['n_samples'], config['data']['n_targets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f258543-80c3-4faa-a6f8-04f4a48e09cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = utilities_LR.data_path_LR(config)\n",
    "\n",
    "with open(directory + '/X.npy', \"rb\") as f:\n",
    "    X_datasets_list = np.load(f, allow_pickle=True)\n",
    "with open(directory + '/y.npy', \"rb\") as f:\n",
    "    y_datasets_list = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65510a-d70f-4277-800b-75ed4df35315",
   "metadata": {},
   "source": [
    "# Save Model & Metrics (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5754bd-00ae-472c-827e-fc2f807f93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models_predictions(weights_list, y_pred_list):\n",
    "    directory = utilities_LR.lambda_path_LR(config)\n",
    "    \n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    np.save(directory + '/lambda_weights_list.npy', weights_list, allow_pickle=True)\n",
    "    np.save(directory + '/lambda_preds_list.npy', y_pred_list, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77189e30-fcd7-4410-a593-dfc50360347f",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf1bd26-92b3-4826-9601-e8c4b6b77654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X, y, index):\n",
    "    # Data Prep\n",
    "    X_train, _, y_train, _ = train_test_split(X, y, \n",
    "                                                        test_size=config['lambda']['data_prep']['train_test_val_split']['test_size'],\n",
    "                                                        train_size=None,\n",
    "                                                        random_state=None,\n",
    "                                                        shuffle=config['lambda']['data_prep']['train_test_val_split']['shuffle'],\n",
    "                                                        stratify=None,\n",
    "                                                       )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Model Def\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                min_delta=0.001,\n",
    "                                patience=12,\n",
    "                                verbose=0,\n",
    "                                mode='auto',\n",
    "                                baseline=None,\n",
    "                                restore_best_weights=True)\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_dim=config['data']['n_features']))\n",
    "    model.add(Dense(50, activation='ReLU'))\n",
    "    #model.add(Dense(60, activation='relu'))\n",
    "    model.add(Dense(config['data']['n_targets'], activation='sigmoid'))\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=config['lambda']['model_compile']['optimizer_lambda'],\n",
    "                  loss=config['lambda']['model_compile']['loss'],\n",
    "                  metrics=config['lambda']['model_compile']['metrics']\n",
    "                 )\n",
    "    \n",
    "    #print(model.summary())\n",
    "    \n",
    "    # Model fit\n",
    "    _ = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        batch_size=config['lambda']['model_fit']['batch_size'],\n",
    "                        epochs=config['lambda']['model_fit']['epochs'],\n",
    "                        verbose=config['lambda']['model_fit']['verbose'],\n",
    "                        callbacks=[early_stopping],\n",
    "                        #validation_data=(X_val, y_val),\n",
    "                        validation_split=config['lambda']['data_prep']['train_test_val_split']['val_size'],\n",
    "                        shuffle=config['lambda']['model_fit']['shuffle'],\n",
    "                        class_weight=config['lambda']['model_fit']['class_weight'],\n",
    "                        sample_weight=config['lambda']['model_fit']['sample_weight'],\n",
    "                        initial_epoch=config['lambda']['model_fit']['initial_epoch'],\n",
    "                        steps_per_epoch=config['lambda']['model_fit']['steps_per_epoch'],\n",
    "                        validation_steps=config['lambda']['model_fit']['validation_steps'],\n",
    "                        validation_batch_size=config['lambda']['model_fit']['validation_batch_size'],\n",
    "                        validation_freq=config['lambda']['model_fit']['validation_freq'],\n",
    "                       )\n",
    "    \n",
    "    lambda_weights = np.concatenate([x.flatten() for x in model.get_weights()])\n",
    "    \n",
    "    y_pred = model.predict(X, verbose=0)\n",
    "    \n",
    "    return lambda_weights, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8ab4a7a-cae7-4fe8-b9a4-277357c64c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=50)]: Using backend LokyBackend with 50 concurrent workers.\n",
      "[Parallel(n_jobs=50)]: Done  13 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=50)]: Done  28 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=50)]: Done  45 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=50)]: Done  62 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=50)]: Done  81 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=50)]: Done 100 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=50)]: Done 121 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=50)]: Done 142 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=50)]: Done 165 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=50)]: Done 188 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=50)]: Done 213 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=50)]: Done 238 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=50)]: Done 265 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=50)]: Done 292 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=50)]: Done 321 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=50)]: Done 350 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=50)]: Done 381 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=50)]: Done 412 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=50)]: Done 445 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=50)]: Done 478 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=50)]: Done 513 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=50)]: Done 548 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=50)]: Done 585 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=50)]: Done 622 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=50)]: Done 661 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=50)]: Done 700 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=50)]: Done 741 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=50)]: Done 782 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=50)]: Done 825 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=50)]: Done 868 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=50)]: Done 913 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=50)]: Done 958 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=50)]: Done 1005 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=50)]: Done 1052 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=50)]: Done 1101 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=50)]: Done 1150 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=50)]: Done 1201 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=50)]: Done 1252 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=50)]: Done 1305 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=50)]: Done 1358 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=50)]: Done 1413 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=50)]: Done 1468 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=50)]: Done 1525 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=50)]: Done 1582 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=50)]: Done 1641 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=50)]: Done 1700 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=50)]: Done 1761 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=50)]: Done 1822 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=50)]: Done 1885 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=50)]: Done 1948 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=50)]: Done 2013 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=50)]: Done 2078 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=50)]: Done 2145 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=50)]: Done 2212 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=50)]: Done 2281 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=50)]: Done 2350 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=50)]: Done 2421 tasks      | elapsed: 38.8min\n",
      "[Parallel(n_jobs=50)]: Done 2492 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=50)]: Done 2565 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=50)]: Done 2638 tasks      | elapsed: 42.4min\n",
      "[Parallel(n_jobs=50)]: Done 2713 tasks      | elapsed: 43.7min\n",
      "[Parallel(n_jobs=50)]: Done 2788 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=50)]: Done 2865 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=50)]: Done 2942 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=50)]: Done 3021 tasks      | elapsed: 48.7min\n",
      "[Parallel(n_jobs=50)]: Done 3100 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=50)]: Done 3181 tasks      | elapsed: 51.2min\n",
      "[Parallel(n_jobs=50)]: Done 3262 tasks      | elapsed: 52.6min\n",
      "[Parallel(n_jobs=50)]: Done 3345 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=50)]: Done 3428 tasks      | elapsed: 55.4min\n",
      "[Parallel(n_jobs=50)]: Done 3513 tasks      | elapsed: 56.9min\n",
      "[Parallel(n_jobs=50)]: Done 3598 tasks      | elapsed: 58.3min\n",
      "[Parallel(n_jobs=50)]: Done 3685 tasks      | elapsed: 59.6min\n",
      "[Parallel(n_jobs=50)]: Done 3772 tasks      | elapsed: 60.9min\n",
      "[Parallel(n_jobs=50)]: Done 3861 tasks      | elapsed: 62.5min\n",
      "[Parallel(n_jobs=50)]: Done 3950 tasks      | elapsed: 64.0min\n",
      "[Parallel(n_jobs=50)]: Done 4041 tasks      | elapsed: 65.5min\n",
      "[Parallel(n_jobs=50)]: Done 4132 tasks      | elapsed: 67.0min\n",
      "[Parallel(n_jobs=50)]: Done 4225 tasks      | elapsed: 68.6min\n",
      "[Parallel(n_jobs=50)]: Done 4318 tasks      | elapsed: 70.1min\n",
      "[Parallel(n_jobs=50)]: Done 4413 tasks      | elapsed: 71.7min\n",
      "[Parallel(n_jobs=50)]: Done 4508 tasks      | elapsed: 73.3min\n",
      "[Parallel(n_jobs=50)]: Done 4605 tasks      | elapsed: 75.0min\n",
      "[Parallel(n_jobs=50)]: Done 4702 tasks      | elapsed: 76.5min\n",
      "[Parallel(n_jobs=50)]: Done 4801 tasks      | elapsed: 78.3min\n",
      "[Parallel(n_jobs=50)]: Done 4900 tasks      | elapsed: 79.9min\n",
      "[Parallel(n_jobs=50)]: Done 5001 tasks      | elapsed: 81.6min\n",
      "[Parallel(n_jobs=50)]: Done 5102 tasks      | elapsed: 83.2min\n",
      "[Parallel(n_jobs=50)]: Done 5205 tasks      | elapsed: 84.9min\n",
      "[Parallel(n_jobs=50)]: Done 5308 tasks      | elapsed: 86.5min\n",
      "[Parallel(n_jobs=50)]: Done 5413 tasks      | elapsed: 88.2min\n",
      "[Parallel(n_jobs=50)]: Done 5518 tasks      | elapsed: 89.8min\n",
      "[Parallel(n_jobs=50)]: Done 5625 tasks      | elapsed: 91.6min\n",
      "[Parallel(n_jobs=50)]: Done 5732 tasks      | elapsed: 93.2min\n",
      "[Parallel(n_jobs=50)]: Done 5841 tasks      | elapsed: 95.1min\n",
      "[Parallel(n_jobs=50)]: Done 5950 tasks      | elapsed: 96.8min\n",
      "[Parallel(n_jobs=50)]: Done 6061 tasks      | elapsed: 98.6min\n",
      "[Parallel(n_jobs=50)]: Done 6172 tasks      | elapsed: 100.4min\n",
      "[Parallel(n_jobs=50)]: Done 6285 tasks      | elapsed: 102.2min\n",
      "[Parallel(n_jobs=50)]: Done 6398 tasks      | elapsed: 104.0min\n",
      "[Parallel(n_jobs=50)]: Done 6513 tasks      | elapsed: 105.9min\n",
      "[Parallel(n_jobs=50)]: Done 6628 tasks      | elapsed: 107.9min\n",
      "[Parallel(n_jobs=50)]: Done 6745 tasks      | elapsed: 109.7min\n",
      "[Parallel(n_jobs=50)]: Done 6862 tasks      | elapsed: 111.6min\n",
      "[Parallel(n_jobs=50)]: Done 6981 tasks      | elapsed: 113.6min\n",
      "[Parallel(n_jobs=50)]: Done 7100 tasks      | elapsed: 115.4min\n",
      "[Parallel(n_jobs=50)]: Done 7221 tasks      | elapsed: 117.4min\n",
      "[Parallel(n_jobs=50)]: Done 7342 tasks      | elapsed: 119.5min\n",
      "[Parallel(n_jobs=50)]: Done 7465 tasks      | elapsed: 121.3min\n",
      "[Parallel(n_jobs=50)]: Done 7588 tasks      | elapsed: 123.4min\n",
      "[Parallel(n_jobs=50)]: Done 7713 tasks      | elapsed: 125.4min\n",
      "[Parallel(n_jobs=50)]: Done 7838 tasks      | elapsed: 127.3min\n",
      "[Parallel(n_jobs=50)]: Done 7965 tasks      | elapsed: 129.5min\n",
      "[Parallel(n_jobs=50)]: Done 8092 tasks      | elapsed: 131.6min\n",
      "[Parallel(n_jobs=50)]: Done 8221 tasks      | elapsed: 133.8min\n",
      "[Parallel(n_jobs=50)]: Done 8350 tasks      | elapsed: 136.0min\n",
      "[Parallel(n_jobs=50)]: Done 8481 tasks      | elapsed: 138.0min\n",
      "[Parallel(n_jobs=50)]: Done 8612 tasks      | elapsed: 140.3min\n",
      "[Parallel(n_jobs=50)]: Done 8745 tasks      | elapsed: 142.3min\n",
      "[Parallel(n_jobs=50)]: Done 8878 tasks      | elapsed: 144.7min\n",
      "[Parallel(n_jobs=50)]: Done 9013 tasks      | elapsed: 146.8min\n",
      "[Parallel(n_jobs=50)]: Done 9148 tasks      | elapsed: 149.1min\n",
      "[Parallel(n_jobs=50)]: Done 9285 tasks      | elapsed: 151.5min\n",
      "[Parallel(n_jobs=50)]: Done 9422 tasks      | elapsed: 153.9min\n",
      "[Parallel(n_jobs=50)]: Done 9561 tasks      | elapsed: 156.2min\n",
      "[Parallel(n_jobs=50)]: Done 9700 tasks      | elapsed: 158.5min\n",
      "[Parallel(n_jobs=50)]: Done 9841 tasks      | elapsed: 161.0min\n",
      "[Parallel(n_jobs=50)]: Done 9982 tasks      | elapsed: 163.3min\n",
      "[Parallel(n_jobs=50)]: Done 10125 tasks      | elapsed: 165.6min\n",
      "[Parallel(n_jobs=50)]: Done 10268 tasks      | elapsed: 168.0min\n",
      "[Parallel(n_jobs=50)]: Done 10413 tasks      | elapsed: 170.4min\n",
      "[Parallel(n_jobs=50)]: Done 10558 tasks      | elapsed: 172.7min\n",
      "[Parallel(n_jobs=50)]: Done 10705 tasks      | elapsed: 175.2min\n",
      "[Parallel(n_jobs=50)]: Done 10852 tasks      | elapsed: 177.6min\n",
      "[Parallel(n_jobs=50)]: Done 11001 tasks      | elapsed: 180.0min\n",
      "[Parallel(n_jobs=50)]: Done 11150 tasks      | elapsed: 182.3min\n",
      "[Parallel(n_jobs=50)]: Done 11301 tasks      | elapsed: 184.8min\n",
      "[Parallel(n_jobs=50)]: Done 11452 tasks      | elapsed: 187.2min\n",
      "[Parallel(n_jobs=50)]: Done 11605 tasks      | elapsed: 189.8min\n",
      "[Parallel(n_jobs=50)]: Done 11758 tasks      | elapsed: 192.1min\n",
      "[Parallel(n_jobs=50)]: Done 11913 tasks      | elapsed: 194.6min\n",
      "[Parallel(n_jobs=50)]: Done 12068 tasks      | elapsed: 197.2min\n",
      "[Parallel(n_jobs=50)]: Done 12225 tasks      | elapsed: 199.8min\n",
      "[Parallel(n_jobs=50)]: Done 12382 tasks      | elapsed: 202.3min\n",
      "[Parallel(n_jobs=50)]: Done 12541 tasks      | elapsed: 204.9min\n",
      "[Parallel(n_jobs=50)]: Done 12700 tasks      | elapsed: 207.5min\n",
      "[Parallel(n_jobs=50)]: Done 12861 tasks      | elapsed: 210.1min\n",
      "[Parallel(n_jobs=50)]: Done 13022 tasks      | elapsed: 212.8min\n",
      "[Parallel(n_jobs=50)]: Done 13185 tasks      | elapsed: 215.5min\n",
      "[Parallel(n_jobs=50)]: Done 13348 tasks      | elapsed: 218.2min\n",
      "[Parallel(n_jobs=50)]: Done 13513 tasks      | elapsed: 221.0min\n",
      "[Parallel(n_jobs=50)]: Done 13678 tasks      | elapsed: 223.7min\n",
      "[Parallel(n_jobs=50)]: Done 13845 tasks      | elapsed: 226.4min\n",
      "[Parallel(n_jobs=50)]: Done 14012 tasks      | elapsed: 229.0min\n",
      "[Parallel(n_jobs=50)]: Done 14181 tasks      | elapsed: 231.9min\n",
      "[Parallel(n_jobs=50)]: Done 14350 tasks      | elapsed: 234.5min\n",
      "[Parallel(n_jobs=50)]: Done 14521 tasks      | elapsed: 237.4min\n",
      "[Parallel(n_jobs=50)]: Done 14692 tasks      | elapsed: 240.4min\n",
      "[Parallel(n_jobs=50)]: Done 14865 tasks      | elapsed: 243.2min\n",
      "[Parallel(n_jobs=50)]: Done 15038 tasks      | elapsed: 246.1min\n",
      "[Parallel(n_jobs=50)]: Done 15213 tasks      | elapsed: 248.8min\n",
      "[Parallel(n_jobs=50)]: Done 15388 tasks      | elapsed: 251.6min\n",
      "[Parallel(n_jobs=50)]: Done 15565 tasks      | elapsed: 254.4min\n",
      "[Parallel(n_jobs=50)]: Done 15742 tasks      | elapsed: 257.3min\n",
      "[Parallel(n_jobs=50)]: Done 15921 tasks      | elapsed: 260.0min\n",
      "[Parallel(n_jobs=50)]: Done 16100 tasks      | elapsed: 262.8min\n",
      "[Parallel(n_jobs=50)]: Done 16281 tasks      | elapsed: 265.7min\n",
      "[Parallel(n_jobs=50)]: Done 16462 tasks      | elapsed: 268.7min\n",
      "[Parallel(n_jobs=50)]: Done 16645 tasks      | elapsed: 271.4min\n",
      "[Parallel(n_jobs=50)]: Done 16828 tasks      | elapsed: 274.3min\n",
      "[Parallel(n_jobs=50)]: Done 17013 tasks      | elapsed: 277.2min\n",
      "[Parallel(n_jobs=50)]: Done 17198 tasks      | elapsed: 280.2min\n",
      "[Parallel(n_jobs=50)]: Done 17385 tasks      | elapsed: 283.2min\n",
      "[Parallel(n_jobs=50)]: Done 17572 tasks      | elapsed: 286.1min\n",
      "[Parallel(n_jobs=50)]: Done 17761 tasks      | elapsed: 289.0min\n",
      "[Parallel(n_jobs=50)]: Done 17950 tasks      | elapsed: 292.1min\n",
      "[Parallel(n_jobs=50)]: Done 18141 tasks      | elapsed: 295.0min\n",
      "[Parallel(n_jobs=50)]: Done 18332 tasks      | elapsed: 298.0min\n",
      "[Parallel(n_jobs=50)]: Done 18525 tasks      | elapsed: 301.1min\n",
      "[Parallel(n_jobs=50)]: Done 18718 tasks      | elapsed: 304.2min\n",
      "[Parallel(n_jobs=50)]: Done 18913 tasks      | elapsed: 307.4min\n",
      "[Parallel(n_jobs=50)]: Done 19108 tasks      | elapsed: 310.6min\n",
      "[Parallel(n_jobs=50)]: Done 19305 tasks      | elapsed: 313.8min\n",
      "[Parallel(n_jobs=50)]: Done 19502 tasks      | elapsed: 317.1min\n",
      "[Parallel(n_jobs=50)]: Done 19701 tasks      | elapsed: 320.2min\n",
      "[Parallel(n_jobs=50)]: Done 19900 tasks      | elapsed: 323.4min\n",
      "[Parallel(n_jobs=50)]: Done 20101 tasks      | elapsed: 326.7min\n",
      "[Parallel(n_jobs=50)]: Done 20302 tasks      | elapsed: 329.8min\n",
      "[Parallel(n_jobs=50)]: Done 20505 tasks      | elapsed: 333.0min\n",
      "[Parallel(n_jobs=50)]: Done 20708 tasks      | elapsed: 336.4min\n",
      "[Parallel(n_jobs=50)]: Done 20913 tasks      | elapsed: 339.7min\n",
      "[Parallel(n_jobs=50)]: Done 21118 tasks      | elapsed: 343.0min\n",
      "[Parallel(n_jobs=50)]: Done 21325 tasks      | elapsed: 346.2min\n",
      "[Parallel(n_jobs=50)]: Done 21532 tasks      | elapsed: 349.4min\n",
      "[Parallel(n_jobs=50)]: Done 21741 tasks      | elapsed: 352.8min\n",
      "[Parallel(n_jobs=50)]: Done 21950 tasks      | elapsed: 356.0min\n",
      "[Parallel(n_jobs=50)]: Done 22161 tasks      | elapsed: 359.4min\n",
      "[Parallel(n_jobs=50)]: Done 22372 tasks      | elapsed: 362.8min\n",
      "[Parallel(n_jobs=50)]: Done 22585 tasks      | elapsed: 366.2min\n",
      "[Parallel(n_jobs=50)]: Done 22798 tasks      | elapsed: 369.6min\n",
      "[Parallel(n_jobs=50)]: Done 23013 tasks      | elapsed: 373.0min\n",
      "[Parallel(n_jobs=50)]: Done 23228 tasks      | elapsed: 376.6min\n",
      "[Parallel(n_jobs=50)]: Done 23445 tasks      | elapsed: 379.8min\n",
      "[Parallel(n_jobs=50)]: Done 23662 tasks      | elapsed: 383.5min\n",
      "[Parallel(n_jobs=50)]: Done 23881 tasks      | elapsed: 387.1min\n",
      "[Parallel(n_jobs=50)]: Done 24100 tasks      | elapsed: 390.7min\n",
      "[Parallel(n_jobs=50)]: Done 24321 tasks      | elapsed: 394.6min\n",
      "[Parallel(n_jobs=50)]: Done 24542 tasks      | elapsed: 402.5min\n",
      "[Parallel(n_jobs=50)]: Done 24765 tasks      | elapsed: 412.4min\n",
      "[Parallel(n_jobs=50)]: Done 24988 tasks      | elapsed: 417.4min\n",
      "[Parallel(n_jobs=50)]: Done 25213 tasks      | elapsed: 421.0min\n",
      "[Parallel(n_jobs=50)]: Done 25438 tasks      | elapsed: 424.7min\n",
      "[Parallel(n_jobs=50)]: Done 25892 tasks      | elapsed: 432.6min\n",
      "[Parallel(n_jobs=50)]: Done 26121 tasks      | elapsed: 436.2min\n",
      "[Parallel(n_jobs=50)]: Done 26350 tasks      | elapsed: 439.8min\n",
      "[Parallel(n_jobs=50)]: Done 26581 tasks      | elapsed: 443.6min\n",
      "[Parallel(n_jobs=50)]: Done 26812 tasks      | elapsed: 447.1min\n",
      "[Parallel(n_jobs=50)]: Done 27045 tasks      | elapsed: 450.7min\n",
      "[Parallel(n_jobs=50)]: Done 27278 tasks      | elapsed: 454.3min\n",
      "[Parallel(n_jobs=50)]: Done 27513 tasks      | elapsed: 458.0min\n",
      "[Parallel(n_jobs=50)]: Done 27748 tasks      | elapsed: 462.1min\n",
      "[Parallel(n_jobs=50)]: Done 27985 tasks      | elapsed: 470.9min\n",
      "[Parallel(n_jobs=50)]: Done 28222 tasks      | elapsed: 478.8min\n",
      "[Parallel(n_jobs=50)]: Done 28461 tasks      | elapsed: 482.4min\n",
      "[Parallel(n_jobs=50)]: Done 28700 tasks      | elapsed: 486.4min\n",
      "[Parallel(n_jobs=50)]: Done 28941 tasks      | elapsed: 490.2min\n",
      "[Parallel(n_jobs=50)]: Done 29182 tasks      | elapsed: 494.0min\n",
      "[Parallel(n_jobs=50)]: Done 29425 tasks      | elapsed: 497.8min\n",
      "[Parallel(n_jobs=50)]: Done 29668 tasks      | elapsed: 501.6min\n",
      "[Parallel(n_jobs=50)]: Done 29913 tasks      | elapsed: 505.5min\n",
      "[Parallel(n_jobs=50)]: Done 30158 tasks      | elapsed: 509.4min\n",
      "[Parallel(n_jobs=50)]: Done 30405 tasks      | elapsed: 513.1min\n",
      "[Parallel(n_jobs=50)]: Done 30652 tasks      | elapsed: 517.0min\n",
      "[Parallel(n_jobs=50)]: Done 30901 tasks      | elapsed: 521.3min\n",
      "[Parallel(n_jobs=50)]: Done 31150 tasks      | elapsed: 532.6min\n",
      "[Parallel(n_jobs=50)]: Done 31401 tasks      | elapsed: 545.2min\n",
      "[Parallel(n_jobs=50)]: Done 31652 tasks      | elapsed: 558.0min\n",
      "[Parallel(n_jobs=50)]: Done 31905 tasks      | elapsed: 570.6min\n",
      "[Parallel(n_jobs=50)]: Done 32158 tasks      | elapsed: 583.2min\n",
      "[Parallel(n_jobs=50)]: Done 32413 tasks      | elapsed: 596.0min\n",
      "[Parallel(n_jobs=50)]: Done 32668 tasks      | elapsed: 609.6min\n",
      "[Parallel(n_jobs=50)]: Done 32925 tasks      | elapsed: 622.8min\n",
      "[Parallel(n_jobs=50)]: Done 33182 tasks      | elapsed: 635.9min\n",
      "[Parallel(n_jobs=50)]: Done 33441 tasks      | elapsed: 649.4min\n",
      "[Parallel(n_jobs=50)]: Done 33700 tasks      | elapsed: 663.2min\n",
      "[Parallel(n_jobs=50)]: Done 33961 tasks      | elapsed: 676.8min\n",
      "[Parallel(n_jobs=50)]: Done 34222 tasks      | elapsed: 690.2min\n",
      "[Parallel(n_jobs=50)]: Done 34485 tasks      | elapsed: 704.6min\n",
      "[Parallel(n_jobs=50)]: Done 34748 tasks      | elapsed: 718.3min\n",
      "[Parallel(n_jobs=50)]: Done 35013 tasks      | elapsed: 732.1min\n",
      "[Parallel(n_jobs=50)]: Done 35278 tasks      | elapsed: 745.9min\n",
      "[Parallel(n_jobs=50)]: Done 35545 tasks      | elapsed: 759.3min\n",
      "[Parallel(n_jobs=50)]: Done 35812 tasks      | elapsed: 772.5min\n",
      "[Parallel(n_jobs=50)]: Done 36081 tasks      | elapsed: 785.8min\n",
      "[Parallel(n_jobs=50)]: Done 36350 tasks      | elapsed: 799.4min\n",
      "[Parallel(n_jobs=50)]: Done 36621 tasks      | elapsed: 812.4min\n",
      "[Parallel(n_jobs=50)]: Done 36892 tasks      | elapsed: 826.4min\n",
      "[Parallel(n_jobs=50)]: Done 37165 tasks      | elapsed: 840.2min\n",
      "[Parallel(n_jobs=50)]: Done 37438 tasks      | elapsed: 853.8min\n",
      "[Parallel(n_jobs=50)]: Done 37713 tasks      | elapsed: 867.6min\n",
      "[Parallel(n_jobs=50)]: Done 37988 tasks      | elapsed: 881.6min\n",
      "[Parallel(n_jobs=50)]: Done 38265 tasks      | elapsed: 895.5min\n",
      "[Parallel(n_jobs=50)]: Done 38542 tasks      | elapsed: 909.6min\n",
      "[Parallel(n_jobs=50)]: Done 38821 tasks      | elapsed: 923.9min\n",
      "[Parallel(n_jobs=50)]: Done 39100 tasks      | elapsed: 938.3min\n",
      "[Parallel(n_jobs=50)]: Done 39381 tasks      | elapsed: 953.6min\n",
      "[Parallel(n_jobs=50)]: Done 39662 tasks      | elapsed: 968.0min\n",
      "[Parallel(n_jobs=50)]: Done 39945 tasks      | elapsed: 982.6min\n",
      "[Parallel(n_jobs=50)]: Done 40228 tasks      | elapsed: 997.5min\n",
      "[Parallel(n_jobs=50)]: Done 40513 tasks      | elapsed: 1012.3min\n",
      "[Parallel(n_jobs=50)]: Done 40798 tasks      | elapsed: 1026.7min\n",
      "[Parallel(n_jobs=50)]: Done 41085 tasks      | elapsed: 1041.1min\n",
      "[Parallel(n_jobs=50)]: Done 41372 tasks      | elapsed: 1055.7min\n",
      "[Parallel(n_jobs=50)]: Done 41661 tasks      | elapsed: 1070.2min\n",
      "[Parallel(n_jobs=50)]: Done 41950 tasks      | elapsed: 1085.3min\n",
      "[Parallel(n_jobs=50)]: Done 42241 tasks      | elapsed: 1100.1min\n",
      "[Parallel(n_jobs=50)]: Done 42532 tasks      | elapsed: 1114.9min\n",
      "[Parallel(n_jobs=50)]: Done 42825 tasks      | elapsed: 1130.0min\n",
      "[Parallel(n_jobs=50)]: Done 43118 tasks      | elapsed: 1144.8min\n",
      "[Parallel(n_jobs=50)]: Done 43413 tasks      | elapsed: 1159.8min\n",
      "[Parallel(n_jobs=50)]: Done 43708 tasks      | elapsed: 1174.8min\n",
      "[Parallel(n_jobs=50)]: Done 44005 tasks      | elapsed: 1191.0min\n",
      "[Parallel(n_jobs=50)]: Done 44302 tasks      | elapsed: 1206.5min\n",
      "[Parallel(n_jobs=50)]: Done 44601 tasks      | elapsed: 1222.1min\n",
      "[Parallel(n_jobs=50)]: Done 44900 tasks      | elapsed: 1237.9min\n",
      "[Parallel(n_jobs=50)]: Done 45000 out of 45000 | elapsed: 1242.5min finished\n"
     ]
    }
   ],
   "source": [
    "parallel = Parallel(n_jobs=config['computation']['n_jobs'], verbose=10, backend='loky') #loky\n",
    "\n",
    "weights_ypred_list = parallel(delayed(train_nn)(X_data, y_data, index) for index, (X_data, y_data) in enumerate(zip(X_datasets_list, y_datasets_list)))\n",
    "#weights_ypred_list = parallel(delayed(train_nn)(X_data, y_data, index) for index, (X_data, y_data) in enumerate(zip(X_datasets_list[:5], y_datasets_list[:5])))\n",
    "                                  \n",
    "del parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c847f21-dd63-423c-95fc-5627f8b2e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_list = np.stack([np.array(x[0]) for x in weights_ypred_list])\n",
    "y_pred_list = np.stack([x[1] for x in weights_ypred_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eaf4b1e-1013-40ac-9d3c-93f6a24c1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = y_pred_list.reshape([config['data']['n_datasets'], config['data']['n_samples']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778c426-b6e2-421c-aa06-17507dfa3a32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inspect Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcd173a-cba2-440d-a63d-ebd1f8b8579e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 641)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92e041fd-5704-498f-9a40-489636bf503c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e440930-b8ca-4b24-bbdd-56c8a5ed1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a2f702f-483b-4f55-8141-e4167eac7117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.205672e-05</td>\n",
       "      <td>9.999943e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.726976e-04</td>\n",
       "      <td>5.805218e-05</td>\n",
       "      <td>9.981251e-01</td>\n",
       "      <td>9.999991e-01</td>\n",
       "      <td>1.631108e-08</td>\n",
       "      <td>4.327217e-07</td>\n",
       "      <td>9.999905e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999346e-01</td>\n",
       "      <td>3.574395e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.259460e-06</td>\n",
       "      <td>6.594980e-04</td>\n",
       "      <td>9.998621e-01</td>\n",
       "      <td>9.999989e-01</td>\n",
       "      <td>1.190422e-03</td>\n",
       "      <td>9.994459e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.390169e-02</td>\n",
       "      <td>9.979529e-01</td>\n",
       "      <td>3.673022e-06</td>\n",
       "      <td>2.003713e-05</td>\n",
       "      <td>1.848896e-06</td>\n",
       "      <td>9.998658e-01</td>\n",
       "      <td>7.999154e-05</td>\n",
       "      <td>2.107190e-06</td>\n",
       "      <td>1.319765e-03</td>\n",
       "      <td>1.485519e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738463e-07</td>\n",
       "      <td>1.150213e-06</td>\n",
       "      <td>3.547199e-05</td>\n",
       "      <td>2.872142e-04</td>\n",
       "      <td>9.999992e-01</td>\n",
       "      <td>9.998686e-01</td>\n",
       "      <td>9.165456e-02</td>\n",
       "      <td>9.999762e-01</td>\n",
       "      <td>9.988837e-01</td>\n",
       "      <td>1.094330e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.689543e-05</td>\n",
       "      <td>2.999646e-10</td>\n",
       "      <td>1.301978e-05</td>\n",
       "      <td>9.997020e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999684e-01</td>\n",
       "      <td>3.945545e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.121484e-07</td>\n",
       "      <td>1.938206e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.320938e-06</td>\n",
       "      <td>3.398682e-06</td>\n",
       "      <td>5.401766e-06</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.822156e-04</td>\n",
       "      <td>3.593247e-05</td>\n",
       "      <td>6.022930e-07</td>\n",
       "      <td>7.663682e-09</td>\n",
       "      <td>5.518998e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.211956e-20</td>\n",
       "      <td>3.974197e-03</td>\n",
       "      <td>1.641967e-08</td>\n",
       "      <td>5.147309e-04</td>\n",
       "      <td>9.854988e-01</td>\n",
       "      <td>2.428273e-01</td>\n",
       "      <td>2.028707e-13</td>\n",
       "      <td>1.731283e-04</td>\n",
       "      <td>9.999956e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999955e-01</td>\n",
       "      <td>3.645138e-26</td>\n",
       "      <td>1.412348e-10</td>\n",
       "      <td>5.114396e-11</td>\n",
       "      <td>9.190845e-12</td>\n",
       "      <td>1.872328e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.139395e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.730897e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.023245e-05</td>\n",
       "      <td>9.999992e-01</td>\n",
       "      <td>3.882052e-05</td>\n",
       "      <td>8.456690e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.935854e-10</td>\n",
       "      <td>9.963199e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999654e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.986376e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.284400e-11</td>\n",
       "      <td>2.572836e-12</td>\n",
       "      <td>9.998657e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.600572e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.748289e-04</td>\n",
       "      <td>3.905157e-07</td>\n",
       "      <td>1.058003e-05</td>\n",
       "      <td>6.743187e-07</td>\n",
       "      <td>9.999923e-01</td>\n",
       "      <td>9.998977e-01</td>\n",
       "      <td>9.998838e-01</td>\n",
       "      <td>9.999982e-01</td>\n",
       "      <td>9.999983e-01</td>\n",
       "      <td>1.235056e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.995495e-01</td>\n",
       "      <td>3.031982e-06</td>\n",
       "      <td>1.233810e-09</td>\n",
       "      <td>9.999978e-01</td>\n",
       "      <td>9.999997e-01</td>\n",
       "      <td>2.041932e-06</td>\n",
       "      <td>9.999169e-01</td>\n",
       "      <td>9.996908e-01</td>\n",
       "      <td>9.999972e-01</td>\n",
       "      <td>9.085975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.435905e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.924858e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.606284e-04</td>\n",
       "      <td>1.214880e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.451193e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.497204e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.796831e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.097852e-10</td>\n",
       "      <td>9.999303e-01</td>\n",
       "      <td>4.818037e-05</td>\n",
       "      <td>2.236084e-04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.151213e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.151642e-02</td>\n",
       "      <td>2.108830e-12</td>\n",
       "      <td>5.227026e-05</td>\n",
       "      <td>6.699341e-05</td>\n",
       "      <td>9.056657e-05</td>\n",
       "      <td>1.486605e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>9.995966e-01</td>\n",
       "      <td>8.194520e-12</td>\n",
       "      <td>8.037652e-05</td>\n",
       "      <td>1.800258e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.972214e-11</td>\n",
       "      <td>8.941127e-07</td>\n",
       "      <td>9.999985e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.071118e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999944e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>4.193002e-06</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.699674e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.312440e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.046317e-11</td>\n",
       "      <td>2.011017e-08</td>\n",
       "      <td>1.190598e-05</td>\n",
       "      <td>9.998519e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.954937e-10</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>7.639632e-07</td>\n",
       "      <td>1.408444e-06</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.308081e-09</td>\n",
       "      <td>1.995756e-19</td>\n",
       "      <td>2.663339e-21</td>\n",
       "      <td>9.357464e-03</td>\n",
       "      <td>9.266161e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999954e-01</td>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>3.469586e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.026828e-14</td>\n",
       "      <td>5.385362e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999216e-01</td>\n",
       "      <td>8.045511e-01</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>9.999958e-01</td>\n",
       "      <td>9.988156e-01</td>\n",
       "      <td>1.110085e-19</td>\n",
       "      <td>9.944763e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.994295e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999706e-01</td>\n",
       "      <td>1.137844e-04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999949e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.071739e-08</td>\n",
       "      <td>9.998351e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.481911e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999970e-01</td>\n",
       "      <td>4.265166e-08</td>\n",
       "      <td>2.977946e-08</td>\n",
       "      <td>9.999991e-01</td>\n",
       "      <td>1.177517e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.741834e-09</td>\n",
       "      <td>2.745737e-03</td>\n",
       "      <td>9.981078e-01</td>\n",
       "      <td>9.999936e-01</td>\n",
       "      <td>9.999900e-01</td>\n",
       "      <td>9.999924e-01</td>\n",
       "      <td>9.999884e-01</td>\n",
       "      <td>1.186875e-08</td>\n",
       "      <td>9.999213e-01</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.793598e-07</td>\n",
       "      <td>9.999799e-01</td>\n",
       "      <td>2.081006e-05</td>\n",
       "      <td>9.998217e-01</td>\n",
       "      <td>9.810155e-01</td>\n",
       "      <td>9.999977e-01</td>\n",
       "      <td>1.119604e-10</td>\n",
       "      <td>3.010289e-06</td>\n",
       "      <td>5.773825e-07</td>\n",
       "      <td>5.111814e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.999840e-01</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>5.554797e-09</td>\n",
       "      <td>9.993706e-01</td>\n",
       "      <td>9.993993e-07</td>\n",
       "      <td>1.073653e-06</td>\n",
       "      <td>4.871920e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>4.544213e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>4.614847e-05</td>\n",
       "      <td>9.999989e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.242738e-06</td>\n",
       "      <td>3.494390e-09</td>\n",
       "      <td>9.999973e-01</td>\n",
       "      <td>5.032891e-09</td>\n",
       "      <td>4.846766e-06</td>\n",
       "      <td>1.532786e-07</td>\n",
       "      <td>4.476266e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.994566e-01</td>\n",
       "      <td>8.231358e-17</td>\n",
       "      <td>2.354249e-12</td>\n",
       "      <td>9.967290e-01</td>\n",
       "      <td>1.889774e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.182079e-10</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>3.247646e-06</td>\n",
       "      <td>1.619729e-06</td>\n",
       "      <td>2.942878e-04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.430234e-04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999997e-01</td>\n",
       "      <td>4.601545e-11</td>\n",
       "      <td>2.188808e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.999992e-01</td>\n",
       "      <td>5.956504e-10</td>\n",
       "      <td>3.289315e-08</td>\n",
       "      <td>8.641128e-04</td>\n",
       "      <td>1.809914e-18</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>9.999989e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.304905e-15</td>\n",
       "      <td>9.997866e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.690600e-17</td>\n",
       "      <td>9.967895e-01</td>\n",
       "      <td>3.242576e-16</td>\n",
       "      <td>1.706532e-09</td>\n",
       "      <td>6.093171e-12</td>\n",
       "      <td>4.675334e-03</td>\n",
       "      <td>1.307035e-07</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>1.056714e-03</td>\n",
       "      <td>4.423693e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.109540e-11</td>\n",
       "      <td>2.622124e-07</td>\n",
       "      <td>1.218060e-04</td>\n",
       "      <td>9.999965e-01</td>\n",
       "      <td>2.201758e-09</td>\n",
       "      <td>4.321400e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.997678e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.860057e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.907494e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.944581e-04</td>\n",
       "      <td>3.830734e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.236486e-01</td>\n",
       "      <td>1.653896e-07</td>\n",
       "      <td>1.783272e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.133992e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.780395e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.304845e-12</td>\n",
       "      <td>1.066456e-01</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>3.177778e-13</td>\n",
       "      <td>9.480217e-01</td>\n",
       "      <td>3.153489e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.107204e-06</td>\n",
       "      <td>9.340957e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.180026e-03</td>\n",
       "      <td>9.971764e-01</td>\n",
       "      <td>2.042674e-04</td>\n",
       "      <td>5.133004e-05</td>\n",
       "      <td>2.961010e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.999946e-01</td>\n",
       "      <td>8.673042e-18</td>\n",
       "      <td>9.993542e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.097763e-14</td>\n",
       "      <td>1.678463e-24</td>\n",
       "      <td>9.999968e-01</td>\n",
       "      <td>6.377863e-04</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.824487e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235376e-07</td>\n",
       "      <td>2.169720e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.104338e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.738291e-03</td>\n",
       "      <td>9.217565e-12</td>\n",
       "      <td>1.081759e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.983849e-01</td>\n",
       "      <td>9.494475e-01</td>\n",
       "      <td>4.472957e-06</td>\n",
       "      <td>9.999498e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.999720e-01</td>\n",
       "      <td>4.291925e-08</td>\n",
       "      <td>9.995096e-01</td>\n",
       "      <td>9.990571e-01</td>\n",
       "      <td>9.999817e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.549261e-01</td>\n",
       "      <td>2.876284e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.878165e-32</td>\n",
       "      <td>8.389350e-07</td>\n",
       "      <td>8.805335e-03</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.948750e-01</td>\n",
       "      <td>9.999148e-01</td>\n",
       "      <td>6.747549e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.999986e-01</td>\n",
       "      <td>9.999729e-01</td>\n",
       "      <td>9.551487e-11</td>\n",
       "      <td>9.958268e-07</td>\n",
       "      <td>1.224167e-01</td>\n",
       "      <td>7.857308e-04</td>\n",
       "      <td>8.948680e-10</td>\n",
       "      <td>1.131900e-03</td>\n",
       "      <td>1.097227e-21</td>\n",
       "      <td>9.999997e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999876e-01</td>\n",
       "      <td>3.169440e-19</td>\n",
       "      <td>2.369634e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.886726e-03</td>\n",
       "      <td>4.014809e-07</td>\n",
       "      <td>1.201698e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2             3             4     \\\n",
       "0   4.205672e-05  9.999943e-01  1.000000e+00  4.726976e-04  5.805218e-05   \n",
       "1   1.390169e-02  9.979529e-01  3.673022e-06  2.003713e-05  1.848896e-06   \n",
       "2   9.689543e-05  2.999646e-10  1.301978e-05  9.997020e-01  1.000000e+00   \n",
       "3   1.000000e+00  1.211956e-20  3.974197e-03  1.641967e-08  5.147309e-04   \n",
       "4   2.730897e-07  1.000000e+00  1.000000e+00  1.023245e-05  9.999992e-01   \n",
       "5   2.748289e-04  3.905157e-07  1.058003e-05  6.743187e-07  9.999923e-01   \n",
       "6   6.435905e-01  1.000000e+00  4.924858e-15  1.000000e+00  2.606284e-04   \n",
       "7   4.151213e-08  1.000000e+00  1.000000e+00  1.000000e+00  1.151642e-02   \n",
       "8   1.000000e+00  3.071118e-07  1.000000e+00  9.999944e-01  9.999999e-01   \n",
       "9   3.308081e-09  1.995756e-19  2.663339e-21  9.357464e-03  9.266161e-09   \n",
       "10  9.994295e-01  1.000000e+00  9.999706e-01  1.137844e-04  1.000000e+00   \n",
       "11  1.741834e-09  2.745737e-03  9.981078e-01  9.999936e-01  9.999900e-01   \n",
       "12  9.999840e-01  9.999996e-01  5.554797e-09  9.993706e-01  9.993993e-07   \n",
       "13  9.994566e-01  8.231358e-17  2.354249e-12  9.967290e-01  1.889774e-06   \n",
       "14  9.999992e-01  5.956504e-10  3.289315e-08  8.641128e-04  1.809914e-18   \n",
       "15  5.109540e-11  2.622124e-07  1.218060e-04  9.999965e-01  2.201758e-09   \n",
       "16  1.133992e-01  1.000000e+00  9.780395e-08  1.000000e+00  1.304845e-12   \n",
       "17  9.999946e-01  8.673042e-18  9.993542e-01  1.000000e+00  5.097763e-14   \n",
       "18  9.983849e-01  9.494475e-01  4.472957e-06  9.999498e-01  0.000000e+00   \n",
       "19  9.999986e-01  9.999729e-01  9.551487e-11  9.958268e-07  1.224167e-01   \n",
       "\n",
       "            5             6             7             8             9     ...  \\\n",
       "0   9.981251e-01  9.999991e-01  1.631108e-08  4.327217e-07  9.999905e-01  ...   \n",
       "1   9.998658e-01  7.999154e-05  2.107190e-06  1.319765e-03  1.485519e-05  ...   \n",
       "2   9.999684e-01  3.945545e-08  1.000000e+00  6.121484e-07  1.938206e-06  ...   \n",
       "3   9.854988e-01  2.428273e-01  2.028707e-13  1.731283e-04  9.999956e-01  ...   \n",
       "4   3.882052e-05  8.456690e-12  1.000000e+00  8.935854e-10  9.963199e-01  ...   \n",
       "5   9.998977e-01  9.998838e-01  9.999982e-01  9.999983e-01  1.235056e-06  ...   \n",
       "6   1.214880e-03  1.000000e+00  1.000000e+00  9.999995e-01  3.451193e-07  ...   \n",
       "7   2.108830e-12  5.227026e-05  6.699341e-05  9.056657e-05  1.486605e-03  ...   \n",
       "8   4.193002e-06  9.999999e-01  3.699674e-06  1.000000e+00  5.312440e-08  ...   \n",
       "9   1.000000e+00  9.999954e-01  9.999950e-01  3.469586e-12  1.000000e+00  ...   \n",
       "10  9.999949e-01  1.000000e+00  1.000000e+00  1.071739e-08  9.998351e-01  ...   \n",
       "11  9.999924e-01  9.999884e-01  1.186875e-08  9.999213e-01  9.999996e-01  ...   \n",
       "12  1.073653e-06  4.871920e-06  1.000000e+00  9.999996e-01  4.544213e-12  ...   \n",
       "13  1.000000e+00  1.000000e+00  1.182079e-10  9.999998e-01  1.000000e+00  ...   \n",
       "14  9.999998e-01  9.999989e-01  1.000000e+00  3.304905e-15  9.997866e-01  ...   \n",
       "15  4.321400e-03  1.000000e+00  1.000000e+00  1.000000e+00  9.997678e-01  ...   \n",
       "16  1.066456e-01  9.999998e-01  3.177778e-13  9.480217e-01  3.153489e-12  ...   \n",
       "17  1.678463e-24  9.999968e-01  6.377863e-04  9.999999e-01  3.824487e-01  ...   \n",
       "18  9.999720e-01  4.291925e-08  9.995096e-01  9.990571e-01  9.999817e-01  ...   \n",
       "19  7.857308e-04  8.948680e-10  1.131900e-03  1.097227e-21  9.999997e-01  ...   \n",
       "\n",
       "            4990          4991          4992          4993          4994  \\\n",
       "0   9.999346e-01  3.574395e-08  1.000000e+00  2.259460e-06  6.594980e-04   \n",
       "1   1.738463e-07  1.150213e-06  3.547199e-05  2.872142e-04  9.999992e-01   \n",
       "2   3.320938e-06  3.398682e-06  5.401766e-06  9.999998e-01  1.822156e-04   \n",
       "3   9.999955e-01  3.645138e-26  1.412348e-10  5.114396e-11  9.190845e-12   \n",
       "4   1.000000e+00  9.999654e-01  1.000000e+00  1.986376e-18  1.000000e+00   \n",
       "5   9.995495e-01  3.031982e-06  1.233810e-09  9.999978e-01  9.999997e-01   \n",
       "6   4.497204e-03  1.000000e+00  1.796831e-09  1.000000e+00  1.097852e-10   \n",
       "7   9.995966e-01  8.194520e-12  8.037652e-05  1.800258e-09  1.000000e+00   \n",
       "8   2.046317e-11  2.011017e-08  1.190598e-05  9.998519e-01  1.000000e+00   \n",
       "9   1.026828e-14  5.385362e-09  1.000000e+00  9.999216e-01  8.045511e-01   \n",
       "10  3.481911e-01  1.000000e+00  1.000000e+00  9.999970e-01  4.265166e-08   \n",
       "11  8.793598e-07  9.999799e-01  2.081006e-05  9.998217e-01  9.810155e-01   \n",
       "12  4.614847e-05  9.999989e-01  1.000000e+00  1.242738e-06  3.494390e-09   \n",
       "13  9.999996e-01  3.247646e-06  1.619729e-06  2.942878e-04  1.000000e+00   \n",
       "14  3.690600e-17  9.967895e-01  3.242576e-16  1.706532e-09  6.093171e-12   \n",
       "15  4.860057e-03  1.000000e+00  1.907494e-05  1.000000e+00  2.944581e-04   \n",
       "16  1.000000e+00  1.107204e-06  9.340957e-01  1.000000e+00  1.000000e+00   \n",
       "17  1.235376e-07  2.169720e-07  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "18  9.549261e-01  2.876284e-12  1.000000e+00  4.878165e-32  8.389350e-07   \n",
       "19  1.000000e+00  1.000000e+00  9.999876e-01  3.169440e-19  2.369634e-08   \n",
       "\n",
       "            4995          4996          4997          4998          4999  \n",
       "0   9.998621e-01  9.999989e-01  1.190422e-03  9.994459e-01  1.000000e+00  \n",
       "1   9.998686e-01  9.165456e-02  9.999762e-01  9.988837e-01  1.094330e-04  \n",
       "2   3.593247e-05  6.022930e-07  7.663682e-09  5.518998e-07  1.000000e+00  \n",
       "3   1.872328e-10  1.000000e+00  9.999998e-01  1.000000e+00  1.139395e-03  \n",
       "4   7.284400e-11  2.572836e-12  9.998657e-01  1.000000e+00  2.600572e-13  \n",
       "5   2.041932e-06  9.999169e-01  9.996908e-01  9.999972e-01  9.085975e-07  \n",
       "6   9.999303e-01  4.818037e-05  2.236084e-04  1.000000e+00  1.000000e+00  \n",
       "7   1.000000e+00  6.972214e-11  8.941127e-07  9.999985e-01  1.000000e+00  \n",
       "8   4.954937e-10  9.999999e-01  7.639632e-07  1.408444e-06  9.999998e-01  \n",
       "9   9.999996e-01  9.999958e-01  9.988156e-01  1.110085e-19  9.944763e-01  \n",
       "10  2.977946e-08  9.999991e-01  1.177517e-06  1.000000e+00  1.000000e+00  \n",
       "11  9.999977e-01  1.119604e-10  3.010289e-06  5.773825e-07  5.111814e-10  \n",
       "12  9.999973e-01  5.032891e-09  4.846766e-06  1.532786e-07  4.476266e-14  \n",
       "13  8.430234e-04  1.000000e+00  9.999997e-01  4.601545e-11  2.188808e-09  \n",
       "14  4.675334e-03  1.307035e-07  9.999996e-01  1.056714e-03  4.423693e-11  \n",
       "15  3.830734e-10  1.000000e+00  1.236486e-01  1.653896e-07  1.783272e-06  \n",
       "16  8.180026e-03  9.971764e-01  2.042674e-04  5.133004e-05  2.961010e-09  \n",
       "17  6.104338e-08  1.000000e+00  7.738291e-03  9.217565e-12  1.081759e-12  \n",
       "18  8.805335e-03  9.999999e-01  9.948750e-01  9.999148e-01  6.747549e-04  \n",
       "19  1.000000e+00  9.999999e-01  1.886726e-03  4.014809e-07  1.201698e-01  \n",
       "\n",
       "[20 rows x 5000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred_list).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4dbf02a-2f09-40ee-a620-51aa1822d3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>631</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "      <th>640</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.355054</td>\n",
       "      <td>1.258699</td>\n",
       "      <td>1.212406</td>\n",
       "      <td>1.113385</td>\n",
       "      <td>1.439091</td>\n",
       "      <td>1.520830</td>\n",
       "      <td>1.396900</td>\n",
       "      <td>1.409739</td>\n",
       "      <td>1.068713</td>\n",
       "      <td>1.309842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357826</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>-0.180221</td>\n",
       "      <td>-0.412792</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>0.520335</td>\n",
       "      <td>0.640489</td>\n",
       "      <td>-0.424582</td>\n",
       "      <td>0.494775</td>\n",
       "      <td>0.020274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.147983</td>\n",
       "      <td>0.965386</td>\n",
       "      <td>1.220783</td>\n",
       "      <td>1.476104</td>\n",
       "      <td>1.238748</td>\n",
       "      <td>1.163151</td>\n",
       "      <td>1.406884</td>\n",
       "      <td>1.262292</td>\n",
       "      <td>1.173563</td>\n",
       "      <td>1.231986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161895</td>\n",
       "      <td>0.340950</td>\n",
       "      <td>-0.504974</td>\n",
       "      <td>0.317095</td>\n",
       "      <td>-0.430866</td>\n",
       "      <td>-0.115820</td>\n",
       "      <td>-0.490671</td>\n",
       "      <td>0.420619</td>\n",
       "      <td>0.336737</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.364424</td>\n",
       "      <td>1.709586</td>\n",
       "      <td>1.079928</td>\n",
       "      <td>1.279753</td>\n",
       "      <td>1.209944</td>\n",
       "      <td>1.744203</td>\n",
       "      <td>1.197026</td>\n",
       "      <td>1.061418</td>\n",
       "      <td>1.359827</td>\n",
       "      <td>1.387002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>0.740861</td>\n",
       "      <td>-0.408153</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>-0.700361</td>\n",
       "      <td>-0.296916</td>\n",
       "      <td>-0.468912</td>\n",
       "      <td>-0.293297</td>\n",
       "      <td>-0.328104</td>\n",
       "      <td>0.087038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.910812</td>\n",
       "      <td>1.598887</td>\n",
       "      <td>2.027739</td>\n",
       "      <td>1.516452</td>\n",
       "      <td>1.392765</td>\n",
       "      <td>1.454487</td>\n",
       "      <td>1.867737</td>\n",
       "      <td>1.575727</td>\n",
       "      <td>1.950724</td>\n",
       "      <td>1.891810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963764</td>\n",
       "      <td>-0.773927</td>\n",
       "      <td>-0.961524</td>\n",
       "      <td>-0.573745</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>1.036717</td>\n",
       "      <td>-0.302263</td>\n",
       "      <td>-1.971713</td>\n",
       "      <td>1.102798</td>\n",
       "      <td>-0.079984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.492469</td>\n",
       "      <td>1.648434</td>\n",
       "      <td>1.413505</td>\n",
       "      <td>1.618590</td>\n",
       "      <td>1.299272</td>\n",
       "      <td>1.720709</td>\n",
       "      <td>1.295839</td>\n",
       "      <td>1.750335</td>\n",
       "      <td>1.117914</td>\n",
       "      <td>1.587039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804552</td>\n",
       "      <td>1.084730</td>\n",
       "      <td>0.954627</td>\n",
       "      <td>-0.861212</td>\n",
       "      <td>-0.635381</td>\n",
       "      <td>-0.877119</td>\n",
       "      <td>0.675543</td>\n",
       "      <td>-0.370964</td>\n",
       "      <td>-1.527482</td>\n",
       "      <td>0.125211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.509707</td>\n",
       "      <td>1.248541</td>\n",
       "      <td>1.039783</td>\n",
       "      <td>1.286908</td>\n",
       "      <td>1.336230</td>\n",
       "      <td>1.361229</td>\n",
       "      <td>1.372215</td>\n",
       "      <td>1.171927</td>\n",
       "      <td>1.506479</td>\n",
       "      <td>1.184397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412547</td>\n",
       "      <td>-0.410850</td>\n",
       "      <td>0.273514</td>\n",
       "      <td>0.453569</td>\n",
       "      <td>0.208198</td>\n",
       "      <td>0.280949</td>\n",
       "      <td>-0.486797</td>\n",
       "      <td>-0.425799</td>\n",
       "      <td>0.439879</td>\n",
       "      <td>-0.141570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.984638</td>\n",
       "      <td>1.731068</td>\n",
       "      <td>1.686331</td>\n",
       "      <td>1.585992</td>\n",
       "      <td>1.185340</td>\n",
       "      <td>1.459885</td>\n",
       "      <td>1.225200</td>\n",
       "      <td>1.550375</td>\n",
       "      <td>1.512282</td>\n",
       "      <td>1.677134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628079</td>\n",
       "      <td>-0.569607</td>\n",
       "      <td>-0.323184</td>\n",
       "      <td>0.868867</td>\n",
       "      <td>-0.348999</td>\n",
       "      <td>-0.335417</td>\n",
       "      <td>1.066389</td>\n",
       "      <td>-0.673192</td>\n",
       "      <td>-0.631434</td>\n",
       "      <td>0.081441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.608833</td>\n",
       "      <td>1.752710</td>\n",
       "      <td>1.716441</td>\n",
       "      <td>1.819558</td>\n",
       "      <td>1.731056</td>\n",
       "      <td>1.213343</td>\n",
       "      <td>1.357826</td>\n",
       "      <td>1.818805</td>\n",
       "      <td>1.274058</td>\n",
       "      <td>1.275260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742374</td>\n",
       "      <td>0.715313</td>\n",
       "      <td>0.803300</td>\n",
       "      <td>0.817026</td>\n",
       "      <td>0.566485</td>\n",
       "      <td>-0.493100</td>\n",
       "      <td>-0.503522</td>\n",
       "      <td>0.942400</td>\n",
       "      <td>-0.472521</td>\n",
       "      <td>-0.233865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.512649</td>\n",
       "      <td>1.573318</td>\n",
       "      <td>1.431265</td>\n",
       "      <td>1.583191</td>\n",
       "      <td>1.476306</td>\n",
       "      <td>1.324691</td>\n",
       "      <td>1.453362</td>\n",
       "      <td>1.311196</td>\n",
       "      <td>1.532918</td>\n",
       "      <td>1.606914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634049</td>\n",
       "      <td>-0.576689</td>\n",
       "      <td>-0.682543</td>\n",
       "      <td>0.749241</td>\n",
       "      <td>0.703365</td>\n",
       "      <td>-0.242877</td>\n",
       "      <td>-0.678376</td>\n",
       "      <td>-0.466662</td>\n",
       "      <td>0.335054</td>\n",
       "      <td>-0.024174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.454038</td>\n",
       "      <td>1.619206</td>\n",
       "      <td>1.293487</td>\n",
       "      <td>1.269309</td>\n",
       "      <td>1.661178</td>\n",
       "      <td>1.718328</td>\n",
       "      <td>1.517605</td>\n",
       "      <td>1.769718</td>\n",
       "      <td>1.428030</td>\n",
       "      <td>1.348190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.586217</td>\n",
       "      <td>-1.602535</td>\n",
       "      <td>0.366264</td>\n",
       "      <td>0.265710</td>\n",
       "      <td>-0.751554</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.610941</td>\n",
       "      <td>-1.788216</td>\n",
       "      <td>-1.334791</td>\n",
       "      <td>0.105862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.364579</td>\n",
       "      <td>1.653588</td>\n",
       "      <td>1.342761</td>\n",
       "      <td>1.356526</td>\n",
       "      <td>1.795561</td>\n",
       "      <td>1.758508</td>\n",
       "      <td>1.565943</td>\n",
       "      <td>1.730931</td>\n",
       "      <td>1.750152</td>\n",
       "      <td>1.355842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390437</td>\n",
       "      <td>-0.447988</td>\n",
       "      <td>-0.500734</td>\n",
       "      <td>-0.787257</td>\n",
       "      <td>-0.634831</td>\n",
       "      <td>-0.508685</td>\n",
       "      <td>-0.721899</td>\n",
       "      <td>-0.572505</td>\n",
       "      <td>-0.466279</td>\n",
       "      <td>-0.081330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.900746</td>\n",
       "      <td>1.315785</td>\n",
       "      <td>1.598511</td>\n",
       "      <td>1.209796</td>\n",
       "      <td>1.411581</td>\n",
       "      <td>1.352484</td>\n",
       "      <td>1.333803</td>\n",
       "      <td>1.180958</td>\n",
       "      <td>1.496719</td>\n",
       "      <td>1.220717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.554167</td>\n",
       "      <td>0.554950</td>\n",
       "      <td>-0.297918</td>\n",
       "      <td>0.603098</td>\n",
       "      <td>-0.602838</td>\n",
       "      <td>0.188352</td>\n",
       "      <td>-0.541580</td>\n",
       "      <td>0.419810</td>\n",
       "      <td>-0.464037</td>\n",
       "      <td>0.073972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.283306</td>\n",
       "      <td>1.649485</td>\n",
       "      <td>0.951844</td>\n",
       "      <td>1.707902</td>\n",
       "      <td>1.446552</td>\n",
       "      <td>1.341454</td>\n",
       "      <td>1.452523</td>\n",
       "      <td>1.691527</td>\n",
       "      <td>1.715968</td>\n",
       "      <td>1.407962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362997</td>\n",
       "      <td>0.682185</td>\n",
       "      <td>-0.135971</td>\n",
       "      <td>-0.864024</td>\n",
       "      <td>0.850833</td>\n",
       "      <td>0.257136</td>\n",
       "      <td>-0.586022</td>\n",
       "      <td>-0.535659</td>\n",
       "      <td>0.863400</td>\n",
       "      <td>-0.057942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.541085</td>\n",
       "      <td>1.467537</td>\n",
       "      <td>2.072684</td>\n",
       "      <td>1.508598</td>\n",
       "      <td>1.365076</td>\n",
       "      <td>1.606994</td>\n",
       "      <td>1.626095</td>\n",
       "      <td>1.774203</td>\n",
       "      <td>1.591783</td>\n",
       "      <td>1.368392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473550</td>\n",
       "      <td>0.836699</td>\n",
       "      <td>0.783009</td>\n",
       "      <td>-0.639521</td>\n",
       "      <td>0.546642</td>\n",
       "      <td>-0.541590</td>\n",
       "      <td>-0.888191</td>\n",
       "      <td>0.580323</td>\n",
       "      <td>0.914017</td>\n",
       "      <td>-0.117161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.129677</td>\n",
       "      <td>1.798518</td>\n",
       "      <td>1.516799</td>\n",
       "      <td>1.706363</td>\n",
       "      <td>1.774112</td>\n",
       "      <td>2.045772</td>\n",
       "      <td>1.709238</td>\n",
       "      <td>2.042151</td>\n",
       "      <td>1.700578</td>\n",
       "      <td>1.678559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770585</td>\n",
       "      <td>-0.676826</td>\n",
       "      <td>0.270471</td>\n",
       "      <td>-0.752686</td>\n",
       "      <td>0.579234</td>\n",
       "      <td>0.478398</td>\n",
       "      <td>0.924838</td>\n",
       "      <td>-0.665700</td>\n",
       "      <td>0.365021</td>\n",
       "      <td>-0.154090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.020920</td>\n",
       "      <td>2.019228</td>\n",
       "      <td>1.716762</td>\n",
       "      <td>2.068063</td>\n",
       "      <td>2.057902</td>\n",
       "      <td>1.948489</td>\n",
       "      <td>2.080891</td>\n",
       "      <td>1.780064</td>\n",
       "      <td>1.844875</td>\n",
       "      <td>1.970516</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022111</td>\n",
       "      <td>1.094790</td>\n",
       "      <td>-0.442146</td>\n",
       "      <td>-0.060943</td>\n",
       "      <td>-0.574101</td>\n",
       "      <td>-0.860051</td>\n",
       "      <td>-0.916650</td>\n",
       "      <td>-1.161305</td>\n",
       "      <td>0.837076</td>\n",
       "      <td>-0.145439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.632148</td>\n",
       "      <td>1.377938</td>\n",
       "      <td>1.256853</td>\n",
       "      <td>1.790385</td>\n",
       "      <td>1.620310</td>\n",
       "      <td>1.412980</td>\n",
       "      <td>1.396462</td>\n",
       "      <td>1.655834</td>\n",
       "      <td>1.771751</td>\n",
       "      <td>1.324231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710979</td>\n",
       "      <td>0.970769</td>\n",
       "      <td>0.224502</td>\n",
       "      <td>0.635699</td>\n",
       "      <td>-0.282257</td>\n",
       "      <td>0.515109</td>\n",
       "      <td>0.487956</td>\n",
       "      <td>-0.548361</td>\n",
       "      <td>0.825394</td>\n",
       "      <td>-0.032823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.453247</td>\n",
       "      <td>1.695871</td>\n",
       "      <td>1.236169</td>\n",
       "      <td>1.782557</td>\n",
       "      <td>1.714878</td>\n",
       "      <td>1.918832</td>\n",
       "      <td>1.564460</td>\n",
       "      <td>1.987908</td>\n",
       "      <td>1.412605</td>\n",
       "      <td>1.576880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950443</td>\n",
       "      <td>0.137682</td>\n",
       "      <td>0.560334</td>\n",
       "      <td>-0.720865</td>\n",
       "      <td>0.560715</td>\n",
       "      <td>0.563378</td>\n",
       "      <td>-0.909183</td>\n",
       "      <td>-0.489473</td>\n",
       "      <td>0.527949</td>\n",
       "      <td>-0.197864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.572079</td>\n",
       "      <td>1.145875</td>\n",
       "      <td>1.547355</td>\n",
       "      <td>1.574831</td>\n",
       "      <td>1.730580</td>\n",
       "      <td>1.205182</td>\n",
       "      <td>1.081406</td>\n",
       "      <td>1.738078</td>\n",
       "      <td>2.003939</td>\n",
       "      <td>1.650679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258234</td>\n",
       "      <td>-0.516502</td>\n",
       "      <td>0.246168</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>-0.974295</td>\n",
       "      <td>-0.949119</td>\n",
       "      <td>-1.014541</td>\n",
       "      <td>0.673542</td>\n",
       "      <td>-0.662771</td>\n",
       "      <td>0.224570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.549302</td>\n",
       "      <td>1.903455</td>\n",
       "      <td>1.736553</td>\n",
       "      <td>1.224825</td>\n",
       "      <td>1.791755</td>\n",
       "      <td>1.622753</td>\n",
       "      <td>1.573425</td>\n",
       "      <td>1.779230</td>\n",
       "      <td>2.128526</td>\n",
       "      <td>1.250329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244077</td>\n",
       "      <td>-0.911241</td>\n",
       "      <td>0.581020</td>\n",
       "      <td>1.094760</td>\n",
       "      <td>-0.493590</td>\n",
       "      <td>0.647192</td>\n",
       "      <td>0.788913</td>\n",
       "      <td>1.025485</td>\n",
       "      <td>-1.664048</td>\n",
       "      <td>-0.032897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 641 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   1.355054  1.258699  1.212406  1.113385  1.439091  1.520830  1.396900   \n",
       "1   1.147983  0.965386  1.220783  1.476104  1.238748  1.163151  1.406884   \n",
       "2   1.364424  1.709586  1.079928  1.279753  1.209944  1.744203  1.197026   \n",
       "3   1.910812  1.598887  2.027739  1.516452  1.392765  1.454487  1.867737   \n",
       "4   1.492469  1.648434  1.413505  1.618590  1.299272  1.720709  1.295839   \n",
       "5   1.509707  1.248541  1.039783  1.286908  1.336230  1.361229  1.372215   \n",
       "6   1.984638  1.731068  1.686331  1.585992  1.185340  1.459885  1.225200   \n",
       "7   1.608833  1.752710  1.716441  1.819558  1.731056  1.213343  1.357826   \n",
       "8   1.512649  1.573318  1.431265  1.583191  1.476306  1.324691  1.453362   \n",
       "9   1.454038  1.619206  1.293487  1.269309  1.661178  1.718328  1.517605   \n",
       "10  1.364579  1.653588  1.342761  1.356526  1.795561  1.758508  1.565943   \n",
       "11  0.900746  1.315785  1.598511  1.209796  1.411581  1.352484  1.333803   \n",
       "12  1.283306  1.649485  0.951844  1.707902  1.446552  1.341454  1.452523   \n",
       "13  1.541085  1.467537  2.072684  1.508598  1.365076  1.606994  1.626095   \n",
       "14  2.129677  1.798518  1.516799  1.706363  1.774112  2.045772  1.709238   \n",
       "15  2.020920  2.019228  1.716762  2.068063  2.057902  1.948489  2.080891   \n",
       "16  1.632148  1.377938  1.256853  1.790385  1.620310  1.412980  1.396462   \n",
       "17  1.453247  1.695871  1.236169  1.782557  1.714878  1.918832  1.564460   \n",
       "18  1.572079  1.145875  1.547355  1.574831  1.730580  1.205182  1.081406   \n",
       "19  1.549302  1.903455  1.736553  1.224825  1.791755  1.622753  1.573425   \n",
       "\n",
       "         7         8         9    ...       631       632       633       634  \\\n",
       "0   1.409739  1.068713  1.309842  ...  0.357826  0.100532 -0.180221 -0.412792   \n",
       "1   1.262292  1.173563  1.231986  ... -0.161895  0.340950 -0.504974  0.317095   \n",
       "2   1.061418  1.359827  1.387002  ... -0.662387  0.740861 -0.408153  0.503132   \n",
       "3   1.575727  1.950724  1.891810  ...  0.963764 -0.773927 -0.961524 -0.573745   \n",
       "4   1.750335  1.117914  1.587039  ...  0.804552  1.084730  0.954627 -0.861212   \n",
       "5   1.171927  1.506479  1.184397  ...  0.412547 -0.410850  0.273514  0.453569   \n",
       "6   1.550375  1.512282  1.677134  ...  0.628079 -0.569607 -0.323184  0.868867   \n",
       "7   1.818805  1.274058  1.275260  ...  0.742374  0.715313  0.803300  0.817026   \n",
       "8   1.311196  1.532918  1.606914  ... -0.634049 -0.576689 -0.682543  0.749241   \n",
       "9   1.769718  1.428030  1.348190  ... -0.586217 -1.602535  0.366264  0.265710   \n",
       "10  1.730931  1.750152  1.355842  ... -0.390437 -0.447988 -0.500734 -0.787257   \n",
       "11  1.180958  1.496719  1.220717  ... -0.554167  0.554950 -0.297918  0.603098   \n",
       "12  1.691527  1.715968  1.407962  ...  0.362997  0.682185 -0.135971 -0.864024   \n",
       "13  1.774203  1.591783  1.368392  ...  0.473550  0.836699  0.783009 -0.639521   \n",
       "14  2.042151  1.700578  1.678559  ...  0.770585 -0.676826  0.270471 -0.752686   \n",
       "15  1.780064  1.844875  1.970516  ...  1.022111  1.094790 -0.442146 -0.060943   \n",
       "16  1.655834  1.771751  1.324231  ...  0.710979  0.970769  0.224502  0.635699   \n",
       "17  1.987908  1.412605  1.576880  ... -0.950443  0.137682  0.560334 -0.720865   \n",
       "18  1.738078  2.003939  1.650679  ...  0.258234 -0.516502  0.246168  0.826057   \n",
       "19  1.779230  2.128526  1.250329  ... -0.244077 -0.911241  0.581020  1.094760   \n",
       "\n",
       "         635       636       637       638       639       640  \n",
       "0   0.437600  0.520335  0.640489 -0.424582  0.494775  0.020274  \n",
       "1  -0.430866 -0.115820 -0.490671  0.420619  0.336737  0.000318  \n",
       "2  -0.700361 -0.296916 -0.468912 -0.293297 -0.328104  0.087038  \n",
       "3   0.708240  1.036717 -0.302263 -1.971713  1.102798 -0.079984  \n",
       "4  -0.635381 -0.877119  0.675543 -0.370964 -1.527482  0.125211  \n",
       "5   0.208198  0.280949 -0.486797 -0.425799  0.439879 -0.141570  \n",
       "6  -0.348999 -0.335417  1.066389 -0.673192 -0.631434  0.081441  \n",
       "7   0.566485 -0.493100 -0.503522  0.942400 -0.472521 -0.233865  \n",
       "8   0.703365 -0.242877 -0.678376 -0.466662  0.335054 -0.024174  \n",
       "9  -0.751554  0.524476  0.610941 -1.788216 -1.334791  0.105862  \n",
       "10 -0.634831 -0.508685 -0.721899 -0.572505 -0.466279 -0.081330  \n",
       "11 -0.602838  0.188352 -0.541580  0.419810 -0.464037  0.073972  \n",
       "12  0.850833  0.257136 -0.586022 -0.535659  0.863400 -0.057942  \n",
       "13  0.546642 -0.541590 -0.888191  0.580323  0.914017 -0.117161  \n",
       "14  0.579234  0.478398  0.924838 -0.665700  0.365021 -0.154090  \n",
       "15 -0.574101 -0.860051 -0.916650 -1.161305  0.837076 -0.145439  \n",
       "16 -0.282257  0.515109  0.487956 -0.548361  0.825394 -0.032823  \n",
       "17  0.560715  0.563378 -0.909183 -0.489473  0.527949 -0.197864  \n",
       "18 -0.974295 -0.949119 -1.014541  0.673542 -0.662771  0.224570  \n",
       "19 -0.493590  0.647192  0.788913  1.025485 -1.664048 -0.032897  \n",
       "\n",
       "[20 rows x 641 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(weights_list).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334925c3-84fb-4005-a6c5-da5915a5708a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32ac9b49-0daa-4851-8f77-56354ff8d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_predictions(weights_list, y_pred_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myBA",
   "language": "python",
   "name": "myba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
