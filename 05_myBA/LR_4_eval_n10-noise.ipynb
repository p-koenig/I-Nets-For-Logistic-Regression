{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89b2195-8060-4d85-8330-19aa6cb1e3ac",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a20ce18-baf7-46be-a2a2-79238d9a1fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "\n",
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "import utilities_LR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, mean_squared_error, roc_curve, auc, roc_auc_score, matthews_corrcoef\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d467f817-f968-4b2c-84d5-e8f8d4627666",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052eeaa4-4c27-41aa-aad8-8fd75ce0a3a7",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c0ab8e-2451-424f-8fca-f26d1a761c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_LR = {\n",
    "    'data': {\n",
    "        'n_datasets': 45_000, # the number of datasets\n",
    "        \n",
    "        'n_samples': 5_000, # the number of samples per dataset\n",
    "        \n",
    "        'n_features': 10, \n",
    "        # The total number of features. \n",
    "        # These comprise n_informative informative features, n_redundant redundant features, n_repeated duplicated features and \n",
    "        # n_features-n_informative-n_redundant-n_repeated useless features drawn at random.\n",
    "        \n",
    "        #'n_informative': random.randint(2, 10),\n",
    "        'n_informative': 'random',\n",
    "        # The number of informative features. Each class is composed of a number of gaussian clusters each located around the vertices \n",
    "        # of a hypercube in a subspace of dimension n_informative. For each cluster, informative features are drawn independently \n",
    "        # from N(0, 1) and then randomly linearly combined within each cluster in order to add covariance. The clusters are then \n",
    "        # placed on the vertices of the hypercube.\n",
    "        ### int or 'random'\n",
    "        \n",
    "        'n_targets': 1,\n",
    "        # The number of targets (or labels) of the classification problem.\n",
    "    \n",
    "        'n_clusters_per_class': 1,\n",
    "        # The number of clusters per class.\n",
    "        \n",
    "        'class_sep': 1.0,\n",
    "        # class_sepfloat, default=1.0\n",
    "        # The factor multiplying the hypercube size. Larger values spread out the clusters/classes and make the classification task \n",
    "        # easier.\n",
    "        \n",
    "        'shuffle': True,\n",
    "        # Shuffle the samples and the features.\n",
    "        \n",
    "        'random_state': 44,\n",
    "        # Determines random number generation for dataset creation. Pass an int for reproducible output across multiple function calls.\n",
    "    },\n",
    "    'lambda': {\n",
    "        'data_prep': {\n",
    "            'train_test_val_split': { # refer to sklearn doc\n",
    "                'test_size': 0.1,\n",
    "                'val_size': 0.15,\n",
    "                'random_state': None,\n",
    "                'shuffle': False, # should be always false\n",
    "                'stratify': None\n",
    "            }\n",
    "        },\n",
    "        'model_compile': {\n",
    "            'optimizer_lambda': 'adam',\n",
    "            'loss': 'mae',# keras.losses.BinaryCrossentropy(from_logits=False), #tf.keras.losses.get(config['lambda_net']['loss_lambda']), # 'mae'\n",
    "            'metrics': ['mae', keras.losses.BinaryCrossentropy(from_logits=False)]\n",
    "        },\n",
    "        'model_fit': { # refer to keras API\n",
    "            'batch_size': 64,\n",
    "            'epochs': 500,\n",
    "            'verbose': 0,\n",
    "            'callbacks': None,\n",
    "            'shuffle': True, # usually true\n",
    "            'class_weight': None,\n",
    "            'sample_weight': None,\n",
    "            'initial_epoch': 0,\n",
    "            'steps_per_epoch': None,\n",
    "            'validation_steps': None,\n",
    "            'validation_batch_size': None,\n",
    "            'validation_freq': 1\n",
    "        }\n",
    "    },\n",
    "    'inets': {\n",
    "        'data_prep': {\n",
    "            'train_test_val_split': { # refer to sklearn doc\n",
    "                'test_size': 0.1,\n",
    "                'val_size': 0.15,\n",
    "                'random_state': None,\n",
    "                'shuffle': False,\n",
    "                'stratify': None\n",
    "            },\n",
    "            'train_noise': 0.1 # y_flip fraction on Y_train pred data from lambda net\n",
    "        },\n",
    "        'model_compile': {\n",
    "            \n",
    "        },\n",
    "        'model_fit': { # refer to keras API\n",
    "            'batch_size': 256,\n",
    "            'epochs': 1000,\n",
    "            'verbose': 'auto',\n",
    "            'callbacks': None,\n",
    "            'shuffle': True,\n",
    "            'class_weight': None,\n",
    "            'sample_weight': None,\n",
    "            'initial_epoch': 0,\n",
    "            'steps_per_epoch': None,\n",
    "            'validation_steps': None,\n",
    "            'validation_batch_size': None,\n",
    "            'validation_freq': 1\n",
    "        }\n",
    "    },\n",
    "    'computation':{\n",
    "        'n_jobs': 30,\n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '4',\n",
    "        'RANDOM_SEED': 1,   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558ba97-34f2-4429-bad1-647654431a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfa43a3-0f84-4a98-b2e6-2cdb39becb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c4ee38-f93f-40be-9c54-1a9005c0f6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config_LR['computation']['gpu_numbers'] if config_LR['computation']['use_gpu'] else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if config_LR['computation']['use_gpu'] else ''\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if config_LR['computation']['use_gpu'] else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if config_LR['computation']['use_gpu'] else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5239304d-59da-4fb9-93a5-5d8c7c4613e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b7b6c-1f54-4d2d-b640-63794af75774",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d71d09-8723-45d9-a164-754a9a57753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def custom_loss(y_predictions_index, y_coef_pred):\n",
    "    \n",
    "    index = y_predictions_index[:, 0]\n",
    "    y_true = y_predictions_index[:, 1:]\n",
    "    \n",
    "    # ADD NOISE TO TRAINING DATA\n",
    "    noise = tf.cast(config['inets']['data_prep']['train_noise'], tf.float32)\n",
    "    noise_logits = tf.tile([[1-noise, noise]], [tf.shape(y_true)[0], tf.constant(1)])\n",
    "    noise_flip = tf.random.categorical(tf.math.log(noise_logits), y_true.shape[1])\n",
    "    y_true = y_true*(1-noise_flip) + (1-y_true)*noise_flip   \n",
    "    \n",
    "    index = tf.cast(index, tf.int32)\n",
    "    \n",
    "    X_feature_data_samples = tf.gather(valid_feature_data, index)\n",
    "    \n",
    "    y_pred = tf.transpose(tf.math.add(tf.transpose(tf.linalg.matvec(X_feature_data_samples, y_coef_pred[:, 1:])), y_coef_pred[:, 0]))\n",
    "\n",
    "    metric = tf.keras.losses.BinaryCrossentropy(\n",
    "                                from_logits=True,\n",
    "                                label_smoothing=0.0,\n",
    "                                axis=-1,\n",
    "                                reduction='auto',\n",
    "                                name='binary_crossentropy')\n",
    "    loss = metric(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7cbf86-55d4-4bb4-9d96-7b9461484129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LR_inet():\n",
    "    path = utilities_LR.inet_path_LR(config_LR)\n",
    "    \n",
    "    #model = keras.models.load_model(path + '/modelKeras', custom_objects={'custom_loss': custom_loss})\n",
    "    model = keras.models.load_model(path + '/modelKeras' + '.h5' , custom_objects={'custom_loss': custom_loss})\n",
    "    print(path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e8e007c-ed95-4adb-afe4-8340f8766374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_LR/nda45000_nsa5000_nfe10_ninrandom_nta1_ncc1_sep1.0_shuTrue_ran44/tsi0.1_vsi0.15_ranNone_shuFalse_strNone_bat64_epo500_shuTrue_claNone_samNone_ini0_steNone_vstNone_vbsNone_vfr1/tsi0.1_vsi0.15_noi0.1_ranNone_shuFalse_strNone_bat256_epo1000_shuTrue_claNone_samNone_ini0_steNone_vstNone_vbsNone_vfr1\n"
     ]
    }
   ],
   "source": [
    "model_LR = load_LR_inet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff70b789-58f8-429a-86b4-e22a4e89fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2048)              1314816   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 11)                5643      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,943,435\n",
      "Trainable params: 3,943,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LR.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a8573-c8e5-44aa-8be7-5de1d6c79eeb",
   "metadata": {},
   "source": [
    "# Load Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cccd16f-0ae2-49f2-b74f-88dc190f66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred_data():\n",
    "    directory = utilities_LR.lambda_path_LR(config_LR)\n",
    "    \n",
    "    return np.load(directory + '/lambda_preds_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ce1564-47d2-4ba4-b5eb-4977a72c653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions_from_lambda = get_y_pred_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a8ab01f-829f-44d5-a5b2-d49515459670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lambda():\n",
    "    directory = utilities_LR.lambda_path_LR(config_LR)\n",
    "    \n",
    "    return np.load(directory + '/lambda_weights_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b900738-128d-4569-a3d8-8027ca78ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_weights = load_lambda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cef52c5-4c16-4390-9e4a-945fb9901ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = utilities_LR.data_path_LR(config_LR)\n",
    "\n",
    "with open(directory + '/X.npy', \"rb\") as f:\n",
    "    X_datasets_list_LR_test = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4885d3-e916-46a1-bc91-2cbfc3a57f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_datasets_list_LR_test, _, y_predictions_from_lambda, _, lambda_weights = train_test_split(X_datasets_list_LR_test, \n",
    "                                                    y_predictions_from_lambda, \n",
    "                                                    lambda_weights,\n",
    "                                                    test_size=config_LR['inets']['data_prep']['train_test_val_split']['test_size'], \n",
    "                                                    random_state=config_LR['inets']['data_prep']['train_test_val_split']['random_state'], \n",
    "                                                    shuffle=config_LR['inets']['data_prep']['train_test_val_split']['shuffle'], \n",
    "                                                    stratify=config_LR['inets']['data_prep']['train_test_val_split']['stratify'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5906643c-f0be-4c45-ad6c-7798682c5e0d",
   "metadata": {},
   "source": [
    "# Evaluate Inet for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "898ad615-be9a-49e4-9a5c-5946088f5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp, fp, tn, fn):\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3797feda-655a-420e-8ad4-c826a2edacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(tp, fp, tn, fn):\n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37144d24-d5b0-4f55-9531-dec28cafbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(tp, fp, tn, fn):\n",
    "    pre = precision(tp, fp, tn, fn)\n",
    "    rec = recall(tp, fp, tn, fn)\n",
    "    return 2 * ((pre * rec) / (pre + rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3d153-6032-4976-96a9-701b5c70113e",
   "metadata": {},
   "source": [
    "# Get Predictions Inet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5414039-da82-4471-b02b-a902cd68725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_true_pred = np.zeros([X_datasets_list_LR_test.shape[0], config_LR['data']['n_samples'], 2]) ## binary classification\n",
    "results_np = np.zeros([X_datasets_list_LR_test.shape[0], 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb23f7e6-d46a-49ff-b47f-e1f5ea480001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0\n",
      "done 100\n",
      "done 200\n",
      "done 300\n",
      "done 400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, (X, y_pred_from_lambda, lambda_weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(X_datasets_list_LR_test, y_predictions_from_lambda, lambda_weights), start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      2\u001b[0m     lambda_weight \u001b[38;5;241m=\u001b[39m lambda_weight\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m, lambda_weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m----> 3\u001b[0m     coef_pred_inet \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_LR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     coef_pred_inet \u001b[38;5;241m=\u001b[39m coef_pred_inet\u001b[38;5;241m.\u001b[39mreshape([config_LR[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      6\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(coef_pred_inet[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mdot(X, coef_pred_inet[\u001b[38;5;241m1\u001b[39m:]))\n",
      "File \u001b[0;32m/work/pkoenig/miniconda3/envs/myBA/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/work/pkoenig/miniconda3/envs/myBA/lib/python3.9/site-packages/keras/engine/training.py:2029\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2027\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[1;32m   2028\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2029\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   2031\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[0;32m/work/pkoenig/miniconda3/envs/myBA/lib/python3.9/site-packages/keras/engine/data_adapter.py:1193\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1193\u001b[0m   data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m/work/pkoenig/miniconda3/envs/myBA/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:494\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    493\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    497\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/pkoenig/miniconda3/envs/myBA/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 696\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/work/pkoenig/miniconda3/envs/myBA/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:721\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(ds_variant):\n\u001b[1;32m    717\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    718\u001b[0m       gen_dataset_ops\u001b[38;5;241m.\u001b[39manonymous_iterator_v3(\n\u001b[1;32m    719\u001b[0m           output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[1;32m    720\u001b[0m           output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes))\n\u001b[0;32m--> 721\u001b[0m   \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/pkoenig/miniconda3/envs/myBA/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3409\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3408\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3409\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3410\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3412\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, (X, y_pred_from_lambda, lambda_weight) in enumerate(zip(X_datasets_list_LR_test, y_predictions_from_lambda, lambda_weights), start=0):\n",
    "    lambda_weight = lambda_weight.reshape([1, lambda_weight.shape[0]])\n",
    "    coef_pred_inet = model_LR.predict(lambda_weight, verbose=0)\n",
    "    coef_pred_inet = coef_pred_inet.reshape([config_LR['data']['n_features'] + 1])\n",
    "    \n",
    "    y_pred = np.add(coef_pred_inet[0], np.dot(X, coef_pred_inet[1:]))\n",
    "    y_pred = keras.activations.sigmoid(y_pred).numpy()\n",
    "    y_pred = y_pred.reshape([config_LR['data']['n_samples'], 1])\n",
    "    \n",
    "    y_true = y_pred_from_lambda\n",
    "    y_true = y_true.reshape([config_LR['data']['n_samples'], 1])\n",
    "    y_true = y_true.round().astype(int)\n",
    "    \n",
    "    classifications_true_pred[index] = np.concatenate([y_true, y_pred], axis=1)\n",
    "    \n",
    "    if index % 100 == 0:\n",
    "        print(\"done\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3016b3a-6631-45fd-a0d7-34571177e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_all = classifications_true_pred[:, :, 0].flatten()\n",
    "y_pred_all = classifications_true_pred[:, :, 1].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43136569-9958-467f-8d76-68907e55fa64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "639d3a09-dfa3-4729-ae14-8d4857ceb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_true_all, y_pred_all, drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9065b03f-e39d-4b8f-a574-155e2d0def3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fprtpr = np.array([fpr, tpr, threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb87d96c-5b5a-4b40-b35a-cd8dab865f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = utilities_LR.inet_path_LR(config_LR)\n",
    "\n",
    "np.save(path + f\"/fprTprThreshold_valid_n{config_LR['data']['n_features']}_noise{config_LR['inets']['data_prep']['train_noise']}\", save_fprtpr, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea0565-eadb-4db0-92a9-72b0a11cd03d",
   "metadata": {},
   "source": [
    "## F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69ca1fc1-9b1d-4c1d-ace8-4b322345eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_valid = threshold[np.argmax(tpr-fpr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77bb354c-02e2-4999-9300-64088945ce67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49483271388667616"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd5939cb-4255-40ae-9178-ade86d390ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(classifications_true_pred.shape[0]):\n",
    "    x = classifications_true_pred[i]\n",
    "    y_true = x[:, 0]\n",
    "    y_pred = x[:, 1]\n",
    "    y_pred = np.where(y_pred > threshold_valid, 1, 0).astype(int)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    roc_score=-1\n",
    "    \n",
    "    results_np[i] = [i, mse, tn, fp, fn, tp, precision(tp, fp, tn, fn), recall(tp, fp, tn, fn), f1(tp, fp, tn, fn), roc_score, mcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f879427-b131-4dae-9016-f1768e1d9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\"index_0=aggregated\", \"mse\",  \"tn\", \"fp\", \"fn\", \"tp\", \"precision\", \"recall\", \"f1\", \"ROC-AUC\", \"MCC\"], data=results_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66b250d7-eaaf-43bd-92a4-077b7ee13dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggragated = pd.DataFrame(result.mean(numeric_only=False)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01440139-3284-4602-807e-ad46f74ef760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_0=aggregated</th>\n",
       "      <th>mse</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2249.5</td>\n",
       "      <td>0.176975</td>\n",
       "      <td>2052.52</td>\n",
       "      <td>447.406667</td>\n",
       "      <td>437.468</td>\n",
       "      <td>2062.605333</td>\n",
       "      <td>0.837331</td>\n",
       "      <td>0.824903</td>\n",
       "      <td>0.818142</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.660174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_0=aggregated       mse       tn          fp       fn           tp  \\\n",
       "0              2249.5  0.176975  2052.52  447.406667  437.468  2062.605333   \n",
       "\n",
       "   precision    recall        f1  ROC-AUC       MCC  \n",
       "0   0.837331  0.824903  0.818142     -1.0  0.660174  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggragated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46762d26-5437-4ec0-8cac-c9915e4131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggragated.at[0, \"index_0=aggregated\"] = 0\n",
    "result_aggregated = pd.concat([aggragated, result], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3321dd04-412b-4d25-bdb5-d7798a900fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_eval_res_valid(df):\n",
    "    path = utilities_LR.inet_path_LR(config_LR)\n",
    "    \n",
    "    model = df.to_csv(path + f\"/evalRes_valid_n{config_LR['data']['n_features']}_noise{config_LR['inets']['data_prep']['train_noise']}.csv\")\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e4896c9-83b1-49cc-b048-dfd0bd362057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_LR/nda45000_nsa5000_nfe10_ninrandom_nta1_ncc1_sep1.0_shuTrue_ran44/tsi0.1_vsi0.15_ranNone_shuFalse_strNone_bat64_epo500_shuTrue_claNone_samNone_ini0_steNone_vstNone_vbsNone_vfr1/tsi0.1_vsi0.15_noi0.1_ranNone_shuFalse_strNone_bat256_epo1000_shuTrue_claNone_samNone_ini0_steNone_vstNone_vbsNone_vfr1\n"
     ]
    }
   ],
   "source": [
    "save_eval_res_valid(result_aggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60a731-90c6-451f-a5d1-7775808de6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# For Comparison: Plain LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f7c4e4d-d733-4657-aff5-b826c32eb45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b80255c1-783d-496d-a708-9c0c3c801677",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_true_pred_plain_logreg = np.zeros([X_datasets_list_LR_test.shape[0], int(config_LR['data']['n_samples']*split), 2]) ## binary classification\n",
    "results_np_plain_logreg = np.zeros([X_datasets_list_LR_test.shape[0], 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed141a00-bf85-4348-a884-20e83bda4a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0\n",
      "done 100\n",
      "done 200\n",
      "done 300\n",
      "done 400\n",
      "done 500\n",
      "done 600\n",
      "done 700\n",
      "done 800\n",
      "done 900\n",
      "done 1000\n",
      "done 1100\n",
      "done 1200\n",
      "done 1300\n",
      "done 1400\n",
      "done 1500\n",
      "done 1600\n",
      "done 1700\n",
      "done 1800\n",
      "done 1900\n",
      "done 2000\n",
      "done 2100\n",
      "done 2200\n",
      "done 2300\n",
      "done 2400\n",
      "done 2500\n",
      "done 2600\n",
      "done 2700\n",
      "done 2800\n",
      "done 2900\n",
      "done 3000\n",
      "done 3100\n",
      "done 3200\n",
      "done 3300\n",
      "done 3400\n",
      "done 3500\n",
      "done 3600\n",
      "done 3700\n",
      "done 3800\n",
      "done 3900\n",
      "done 4000\n",
      "done 4100\n",
      "done 4200\n",
      "done 4300\n",
      "done 4400\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y_pred_from_lambda) in enumerate(zip(X_datasets_list_LR_test, y_predictions_from_lambda), start=0):\n",
    "    \n",
    "    y_true = y_pred_from_lambda\n",
    "    y_true = y_true.round().astype(int)\n",
    "    \n",
    "    X, X_test, y_true, y_true_test = train_test_split(X, y_true, test_size=split)\n",
    "    \n",
    "    noise = config_LR['inets']['data_prep']['train_noise']\n",
    "    index = np.random.choice(y_true_test.shape[0], size=int((y_true_test.shape[0] * noise)), replace=False)\n",
    "    y_true_test[index] = [1 - x for x in y_true_test[index]]\n",
    "    \n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X, y_true)\n",
    "    \n",
    "    y_pred = logreg.predict_proba(X_test)\n",
    "    y_pred = y_pred[:, 1]\n",
    "    \n",
    "    y_pred = y_pred.reshape([y_pred.shape[0], 1])\n",
    "    y_true_test = y_true_test.reshape([y_true_test.shape[0], 1])\n",
    "    \n",
    "    classifications_true_pred_plain_logreg[i] = np.concatenate([y_true_test, y_pred], axis=1)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"done\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e47691b7-efd2-4059-8ce6-47f3d53dd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_all_plain_logreg = classifications_true_pred_plain_logreg[:, :, 0].flatten()\n",
    "y_pred_all_plain_logreg = classifications_true_pred_plain_logreg[:, :, 1].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2549d-460a-48eb-ae78-ce773887d4a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc4b0eb6-61fc-4df8-b8b6-cbc14ca0b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_plain_logreg, tpr_plain_logreg, threshold_plain_logreg = roc_curve(y_true_all_plain_logreg, y_pred_all_plain_logreg, drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2db19ce0-dfa8-4da8-848f-0ff6d40008bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fprtpr_plain_logreg = np.array([fpr_plain_logreg, tpr_plain_logreg, threshold_plain_logreg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71498cc0-9a12-4d85-82a4-ab93bc346406",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = utilities_LR.inet_path_LR(config_LR)\n",
    "\n",
    "np.save(path + f\"/fprTprThreshold_plain_logreg_n{config_LR['data']['n_features']}_noise{config_LR['inets']['data_prep']['train_noise']}\", save_fprtpr_plain_logreg, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba5227-c471-41a2-b83d-822cd6784249",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9475788b-af88-4a16-bdf9-686ec44430cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_plain_logreg = threshold_plain_logreg[np.argmax(tpr_plain_logreg-fpr_plain_logreg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ecf5503-327a-4ce1-bc3f-681e9825c3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4875662677052132"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_plain_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6b9f7ea-d2c7-4257-898c-11cbcdce4d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(classifications_true_pred_plain_logreg.shape[0]):\n",
    "    x = classifications_true_pred_plain_logreg[i]\n",
    "    y_true = x[:, 0]\n",
    "    y_pred = x[:, 1]\n",
    "    y_pred = np.where(y_pred > threshold_plain_logreg, 1, 0).astype(int)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    roc_score = roc_auc_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    results_np_plain_logreg[i] =  [i, mse, tn, fp, fn, tp, precision(tp, fp, tn, fn), recall(tp, fp, tn, fn), f1(tp, fp, tn, fn), roc_score, mcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f663e62-5b38-4f67-8f3e-8373733c0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_plain_logreg = pd.DataFrame(columns=[\"index_0=aggregated\", \"mse\",  \"tn\", \"fp\", \"fn\", \"tp\", \"precision\", \"recall\", \"f1\", \"ROC-AUC\", \"MCC\"], data=results_np_plain_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "039a4771-f6ae-40ce-a97f-a5dd2835493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggragated_plain_logreg = pd.DataFrame(result_plain_logreg.mean(numeric_only=False)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69db1052-af2f-4dd5-9798-90e796d68b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_0=aggregated</th>\n",
       "      <th>mse</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2249.5</td>\n",
       "      <td>0.142892</td>\n",
       "      <td>320.665111</td>\n",
       "      <td>54.351556</td>\n",
       "      <td>52.817778</td>\n",
       "      <td>322.165556</td>\n",
       "      <td>0.856106</td>\n",
       "      <td>0.859113</td>\n",
       "      <td>0.857288</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.714449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_0=aggregated       mse          tn         fp         fn          tp  \\\n",
       "0              2249.5  0.142892  320.665111  54.351556  52.817778  322.165556   \n",
       "\n",
       "   precision    recall        f1   ROC-AUC       MCC  \n",
       "0   0.856106  0.859113  0.857288  0.857062  0.714449  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggragated_plain_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46709423-9d85-4505-8080-097936f90e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggragated_plain_logreg.at[0, \"index_0=aggregated\"] = 0\n",
    "result_aggregated_plain_logreg = pd.concat([aggragated_plain_logreg, result_plain_logreg], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3dfea50-adfd-45d8-b9d6-9eb3e353e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_eval_res_plain_logreg(df):\n",
    "    path = utilities_LR.inet_path_LR(config_LR)\n",
    "    \n",
    "    model = df.to_csv(path + f\"/evalRes_plain_logreg_n{config_LR['data']['n_features']}_noise{config_LR['inets']['data_prep']['train_noise']}.csv\")\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "636b1a10-abe3-4a38-b79a-4dad8fde8268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_LR/nda45000_nsa5000_nfe10_ninrandom_nta1_ncc1_sep1.0_shuTrue_ran44/tsi0.1_vsi0.15_ranNone_shuFalse_strNone_bat64_epo500_shuTrue_claNone_samNone_ini0_steNone_vstNone_vbsNone_vfr1/tsi0.1_vsi0.15_noi0.1_ranNone_shuFalse_strNone_bat256_epo1000_shuTrue_claNone_samNone_ini0_steNone_vstNone_vbsNone_vfr1\n"
     ]
    }
   ],
   "source": [
    "save_eval_res_plain_logreg(result_aggregated_plain_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74c440-05eb-4e0b-9c06-ebf98fda3490",
   "metadata": {},
   "source": [
    "# For Comparison: Plain Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a413690-892c-446e-a2ef-ccd5f49badb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_true_pred_plain_DT = np.zeros([X_datasets_list_LR_test.shape[0], int(config_LR['data']['n_samples']*split), 2]) ## binary classification\n",
    "results_np_plain_DT = np.zeros([X_datasets_list_LR_test.shape[0], 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f49d17-a957-4507-b445-b783aa607b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0\n",
      "done 100\n",
      "done 200\n",
      "done 300\n",
      "done 400\n",
      "done 500\n",
      "done 600\n",
      "done 700\n",
      "done 800\n",
      "done 900\n",
      "done 1000\n",
      "done 1100\n",
      "done 1200\n",
      "done 1300\n",
      "done 1400\n",
      "done 1500\n",
      "done 1600\n",
      "done 1700\n",
      "done 1800\n",
      "done 1900\n",
      "done 2000\n",
      "done 2100\n",
      "done 2200\n",
      "done 2300\n",
      "done 2400\n",
      "done 2500\n",
      "done 2600\n",
      "done 2700\n",
      "done 2800\n",
      "done 2900\n",
      "done 3000\n",
      "done 3100\n",
      "done 3200\n",
      "done 3300\n",
      "done 3400\n",
      "done 3500\n",
      "done 3600\n",
      "done 3700\n",
      "done 3800\n",
      "done 3900\n",
      "done 4000\n",
      "done 4100\n",
      "done 4200\n",
      "done 4300\n",
      "done 4400\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y_pred_from_lambda) in enumerate(zip(X_datasets_list_LR_test, y_predictions_from_lambda), start=0):\n",
    "    \n",
    "    y_true = y_pred_from_lambda\n",
    "    y_true = y_true.round().astype(int)\n",
    "    \n",
    "    X, X_test, y_true, y_true_test = train_test_split(X, y_true, test_size=split)\n",
    "    \n",
    "    noise = config_LR['inets']['data_prep']['train_noise']\n",
    "    index = np.random.choice(y_true_test.shape[0], size=int((y_true_test.shape[0] * noise)), replace=False)\n",
    "    y_true_test[index] = [1 - x for x in y_true_test[index]]\n",
    "    \n",
    "    dt = tree.DecisionTreeClassifier(max_depth=4)\n",
    "    dt.fit(X, y_true)\n",
    "    \n",
    "    y_pred = dt.predict_proba(X_test)\n",
    "    y_pred = y_pred[:, 1]\n",
    "    \n",
    "    y_pred = y_pred.reshape([y_pred.shape[0], 1])\n",
    "    y_true_test = y_true_test.reshape([y_true_test.shape[0], 1])\n",
    "    \n",
    "    classifications_true_pred_plain_DT[i] = np.concatenate([y_true_test, y_pred], axis=1)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"done\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8147631-4a05-4c74-b05f-d75fa53f5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_all_plain_DT = classifications_true_pred_plain_DT[:, :, 0].flatten()\n",
    "y_pred_all_plain_DT = classifications_true_pred_plain_DT[:, :, 1].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44626724-e5fe-4c97-bc12-31753f9c353b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56ccd759-d7e5-4edb-8406-1cebfee8178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_plain_DT, tpr_plain_DT, threshold_plain_DT = roc_curve(y_true_all_plain_DT, y_pred_all_plain_DT, drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fafc274b-b66f-45da-a004-c3c32a885e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fprtpr_plain_DT = np.array([fpr_plain_DT, tpr_plain_DT, threshold_plain_DT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23ebd01e-2460-431d-b879-6e075e8396ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = utilities_LR.inet_path_LR(config_LR)\n",
    "\n",
    "np.save(path + f\"/fprTprThreshold_plain_DT_n{config_LR['data']['n_features']}_noise{config_LR['inets']['data_prep']['train_noise']}\", save_fprtpr_plain_DT, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69154765-c469-4cec-9f83-e3488e57eb42",
   "metadata": {},
   "source": [
    "## F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9c7c860-e086-48f1-b7f4-6fbe101900c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_plain_DT = threshold_plain_DT[np.argmax(tpr_plain_DT-fpr_plain_DT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "196a8b44-c9f0-414d-a29f-04c494724f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5130434782608696"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_plain_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19cf1de9-b543-410f-be90-8d2afbff8b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(classifications_true_pred_plain_DT.shape[0]):\n",
    "    x = classifications_true_pred_plain_DT[i]\n",
    "    y_true = x[:, 0]\n",
    "    y_pred = x[:, 1]\n",
    "    y_pred = np.where(y_pred > threshold_plain_DT, 1, 0).astype(int)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    roc_score = roc_auc_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    results_np_plain_DT[i] = [i, mse, tn, fp, fn, tp, precision(tp, fp, tn, fn), recall(tp, fp, tn, fn), f1(tp, fp, tn, fn), roc_score, mcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d97cad1-8f16-41bf-bfb1-479681f641bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_plain_DT = pd.DataFrame(columns=[\"index_0=aggregated\", \"mse\",  \"tn\", \"fp\", \"fn\", \"tp\", \"precision\", \"recall\", \"f1\", \"ROC-AUC\", \"MCC\"], data=results_np_plain_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e605e948-571d-48ba-915a-6e3a323b882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggragated_plain_DT = pd.DataFrame(result_plain_DT.mean(numeric_only=False)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bdbf1fb-b148-434e-b6d5-ec6fbf23e8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_0=aggregated</th>\n",
       "      <th>mse</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2249.5</td>\n",
       "      <td>0.165944</td>\n",
       "      <td>313.765778</td>\n",
       "      <td>61.640889</td>\n",
       "      <td>62.816889</td>\n",
       "      <td>311.776444</td>\n",
       "      <td>0.835795</td>\n",
       "      <td>0.832187</td>\n",
       "      <td>0.833167</td>\n",
       "      <td>0.833964</td>\n",
       "      <td>0.668999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_0=aggregated       mse          tn         fp         fn          tp  \\\n",
       "0              2249.5  0.165944  313.765778  61.640889  62.816889  311.776444   \n",
       "\n",
       "   precision    recall        f1   ROC-AUC       MCC  \n",
       "0   0.835795  0.832187  0.833167  0.833964  0.668999  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggragated_plain_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87bacf3d-4560-4223-8991-d2691c55e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggragated_plain_DT.at[0, \"index_0=aggregated\"] = 0\n",
    "result_aggregated_plain_DT = pd.concat([aggragated_plain_DT, result_plain_DT], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ef1bdd8-fd4e-44a6-9dca-a9729c6128cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_eval_res_plain_DT(df):\n",
    "    path = utilities_LR.inet_path_LR(config_LR)\n",
    "    \n",
    "    model = df.to_csv(path + f\"/evalRes_plain_DT_n{config_LR['data']['n_features']}_noise{config_LR['inets']['data_prep']['train_noise']}.csv\")\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfda1cbd-d9a6-47dd-a5c9-b47d2cf46e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_LR/nda45000_nsa5000_nfe10_ninrandom_nta1_ncc1_sep1.0_shuTrue_ran44/tsi0.1_vsi0.15_ranNone_shuFalse_strNone_bat64_epo500_shuTrue_claNone_samNone_ini0_steNone_vstNone_vbsNone_vfr1/tsi0.1_vsi0.15_noi0.1_ranNone_shuFalse_strNone_bat256_epo1000_shuTrue_claNone_samNone_ini0_steNone_vstNone_vbsNone_vfr1\n"
     ]
    }
   ],
   "source": [
    "save_eval_res_plain_DT(result_aggregated_plain_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857c546-76c8-4df7-a228-aa6563d2440c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b03abc-b4a6-4be9-83d1-d2b88c6dc461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myBA",
   "language": "python",
   "name": "myba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
