{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.6 (default, Aug 18 2021, 19:38:01) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 4,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,                      \n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 5, \n",
    "        'num_classes': 2,\n",
    "        \n",
    "        'function_generation_type': 'random_decision_tree', # 'make_classification' 'random_decision_tree'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 1000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [64],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [1056, 512],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.2, 0.1],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.001,\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': ['binary_accuracy'],\n",
    "        \n",
    "        'epochs': 10, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 500,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 3, # 1=standard representation; 2=sparse representation, 3=vanilla_dt\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2)\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 50, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        \n",
    "        'n_jobs': -3,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '0',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 11:02:00.997021: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:00.997084: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "from itertools import product       \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "\n",
    "#from prettytable import PrettyTable\n",
    "#import colored\n",
    "import math\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score\n",
    "\n",
    "#from similaritymeasures import frechet_dist, area_between_two_curves, dtw\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import random \n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/lib/cuda-10.1'\n",
    "\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = (2 ** maximum_depth - 1) * number_of_variables + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes\n",
    "config['function_family']['function_representation_length'] = ( (2 ** maximum_depth - 1) * number_of_variables + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 \n",
    "                                                              else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2\n",
    "                                                              else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes)\n",
    "\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize1000_numLNets10000_var5_class2_random_decision_tree_xMax1_xMin0_xDistuniform_depth4_beta1_decisionSpars1_fullyGrown/64_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1056-512_drop0.2-0.1e10b256_adam\n",
      "lNetSize1000_numLNets10000_var5_class2_random_decision_tree_xMax1_xMin0_xDistuniform_depth4_beta1_decisionSpars1_fullyGrown/64_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 11:02:06.559900: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    if psutil.virtual_memory().percent > 80:\n",
    "        raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    path_X_data = directory + 'X_test_lambda.txt'\n",
    "    path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    \n",
    "    X_test_lambda = pd.read_csv(path_X_data, sep=\",\", header=None)\n",
    "    X_test_lambda = X_test_lambda.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        X_test_lambda = X_test_lambda.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "    \n",
    "    y_test_lambda = pd.read_csv(path_y_data, sep=\",\", header=None)\n",
    "    y_test_lambda = y_test_lambda.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        y_test_lambda = y_test_lambda.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "        \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              X_test_lambda_row, \n",
    "                                              y_test_lambda_row, \n",
    "                                              config) for network_parameters_row, X_test_lambda_row, y_test_lambda_row in zip(network_parameters.values, X_test_lambda.values, y_test_lambda.values))          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "        lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    _ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    del parallel\n",
    "    \n",
    "    def initialize_target_function_wrapper(config, lambda_net):\n",
    "        lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    _ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    del parallel\n",
    "        \n",
    "    \n",
    "    #lambda_nets = [None] * network_parameters.shape[0]\n",
    "    #for i, (network_parameters_row, X_test_lambda_row, y_test_lambda_row) in tqdm(enumerate(zip(network_parameters.values, X_test_lambda.values, y_test_lambda.values)), total=network_parameters.values.shape[0]):        \n",
    "    #    lambda_net = LambdaNet(network_parameters_row, X_test_lambda_row, y_test_lambda_row, config)\n",
    "    #    lambda_nets[i] = lambda_net\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 11:02:06.559950: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-06 11:02:06.559995: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dws-13): /proc/driver/nvidia/version does not exist\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "2021-09-06 11:02:19.927821: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:19.927873: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:20.412201: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:20.412244: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:20.793781: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:20.793836: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.056314: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.056377: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.153470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.153535: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.192688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.192748: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.227031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.227090: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.309233: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.309285: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.383077: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.383127: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.456021: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.456087: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.568879: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.568929: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.752366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.752414: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.752462: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.752540: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.755840: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.755882: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:21.768039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:21.768087: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:22.034325: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:22.034374: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:22.048259: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:22.048310: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:22.088149: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:22.088204: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:22.132520: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:22.132573: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:22.197039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:22.197099: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:22.741279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:22.741340: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-06 11:02:23.785179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-09-06 11:02:23.785231: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-3)]: Done 420 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-3)]: Done 500 out of 500 | elapsed:   33.6s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 500 out of 500 | elapsed:   18.1s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 500 out of 500 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if noise_injected_level > 0:\n",
    "    lambda_net_dataset_training = load_lambda_nets(config, no_noise=True, n_jobs=n_jobs)\n",
    "    lambda_net_dataset_evaluation = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_training, test_split=0.1)\n",
    "    _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_evaluation, test_split=test_size)\n",
    "    \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 573)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 573)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 573)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>5885.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.222</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>0.618</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.896</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.747</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.450</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.901</td>\n",
       "      <td>-0.734</td>\n",
       "      <td>0.864</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>6442.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.261</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.608</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.018</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.648</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.631</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.825</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>0.874</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>0.784</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.055</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.778</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>0.506</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>1.024</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>4773.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.399</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>0.517</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.565</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.817</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.549</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.562</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.668</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>0.720</td>\n",
       "      <td>-0.722</td>\n",
       "      <td>1.186</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.581</td>\n",
       "      <td>-0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>2609.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.403</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.458</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.477</td>\n",
       "      <td>-2.010</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.115</td>\n",
       "      <td>1.544</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.849</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.762</td>\n",
       "      <td>1.105</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>1.164</td>\n",
       "      <td>1.387</td>\n",
       "      <td>1.738</td>\n",
       "      <td>1.734</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.791</td>\n",
       "      <td>1.943</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>1.566</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>1.209</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-3.334</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>1.393</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-2.445</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>1.305</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>4721.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.524</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.589</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>0.485</td>\n",
       "      <td>-0.065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2   f0v3   f0v4  f1v0   f1v1   f1v2  \\\n",
       "5885 5885.000    42 0.000 0.000 0.000  0.000  0.404 0.000 -0.419  0.000   \n",
       "6442 6442.000    42 0.000 0.000 0.000  0.000 -0.217 0.000 -0.434  0.000   \n",
       "4773 4773.000    42 0.000 0.000 0.000 -0.386  0.000 0.000  0.000  0.000   \n",
       "2609 2609.000    42 0.275 0.000 0.000  0.000  0.000 0.000  0.000 -0.440   \n",
       "4721 4721.000    42 0.000 0.000 0.000  0.000  0.384 0.254  0.000  0.000   \n",
       "\n",
       "       f1v3  f1v4  f2v0  f2v1  f2v2  f2v3   f2v4  f3v0   f3v1   f3v2   f3v3  \\\n",
       "5885  0.000 0.000 0.000 0.000 0.000 0.000 -0.363 0.000 -0.391  0.000  0.000   \n",
       "6442  0.000 0.000 0.000 0.000 0.293 0.000  0.000 0.000  0.000  0.000 -0.356   \n",
       "4773 -0.412 0.000 0.000 0.395 0.000 0.000  0.000 0.000  0.000 -0.317  0.000   \n",
       "2609  0.000 0.000 0.000 0.000 0.000 0.000  0.367 0.000  0.000  0.426  0.000   \n",
       "4721  0.000 0.000 0.000 0.000 0.000 0.000  0.354 0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f3v4  f4v0  f4v1   f4v2  f4v3  f4v4  f5v0   f5v1  f5v2  f5v3   f5v4  \\\n",
       "5885 0.000 0.328 0.000  0.000 0.000 0.000 0.000  0.441 0.000 0.000  0.000   \n",
       "6442 0.000 0.000 0.000 -0.393 0.000 0.000 0.000  0.000 0.354 0.000  0.000   \n",
       "4773 0.000 0.000 0.000  0.000 0.000 0.422 0.000 -0.354 0.000 0.000  0.000   \n",
       "2609 0.000 0.000 0.000  0.304 0.000 0.000 0.000  0.000 0.000 0.000 -0.384   \n",
       "4721 0.424 0.000 0.000  0.419 0.000 0.000 0.000  0.000 0.000 0.416  0.000   \n",
       "\n",
       "      f6v0   f6v1   f6v2   f6v3   f6v4   f7v0   f7v1  f7v2  f7v3  f7v4  f8v0  \\\n",
       "5885 0.000  0.000  0.000 -0.337  0.000  0.348  0.000 0.000 0.000 0.000 0.000   \n",
       "6442 0.000  0.000  0.360  0.000  0.000  0.000  0.000 0.000 0.000 0.315 0.000   \n",
       "4773 0.000 -0.220  0.000  0.000  0.000  0.000  0.000 0.117 0.000 0.000 0.331   \n",
       "2609 0.000  0.000 -0.384  0.000  0.000  0.000 -0.439 0.000 0.000 0.000 0.000   \n",
       "4721 0.000  0.000  0.000  0.000 -0.312 -0.399  0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f8v1  f8v2   f8v3  f8v4  f9v0   f9v1  f9v2  f9v3   f9v4  f10v0  f10v1  \\\n",
       "5885 0.000 0.000  0.000 0.356 0.000  0.000 0.000 0.392  0.000  0.000  0.000   \n",
       "6442 0.000 0.000 -0.368 0.000 0.000  0.000 0.000 0.000  0.313  0.000  0.000   \n",
       "4773 0.000 0.000  0.000 0.000 0.000 -0.440 0.000 0.000  0.000  0.000 -0.388   \n",
       "2609 0.000 0.000 -0.361 0.000 0.000  0.342 0.000 0.000  0.000  0.000  0.000   \n",
       "4721 0.000 0.000 -0.372 0.000 0.000  0.000 0.000 0.000 -0.438  0.000  0.000   \n",
       "\n",
       "      f10v2  f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  \\\n",
       "5885  0.000 -0.440  0.000  0.000  0.000  0.411  0.000  0.000  0.000  0.000   \n",
       "6442 -0.262  0.000  0.000  0.000 -0.435  0.000  0.000  0.000  0.000  0.000   \n",
       "4773  0.000  0.000  0.000  0.000  0.000  0.000  0.000 -0.408  0.000  0.000   \n",
       "2609 -0.355  0.000  0.000  0.000 -0.397  0.000  0.000  0.000  0.000  0.000   \n",
       "4721  0.287  0.000  0.000  0.395  0.000  0.000  0.000  0.000  0.000  0.316   \n",
       "\n",
       "      f12v2  f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  \\\n",
       "5885  0.000 -0.189  0.000 -0.318  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6442  0.422  0.000  0.000  0.000 -0.430  0.000  0.000  0.000  0.000  0.000   \n",
       "4773  0.000 -0.423  0.000  0.000  0.000  0.000  0.351  0.000  0.000  0.000   \n",
       "2609  0.312  0.000  0.000  0.000  0.000 -0.420  0.000  0.000  0.000  0.000   \n",
       "4721  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.367  0.000  0.000   \n",
       "\n",
       "      f14v2  f14v3  f14v4     b0    b1     b2     b3     b4     b5     b6  \\\n",
       "5885 -0.349  0.000  0.000  0.307 0.050 -0.357  0.224 -0.298 -0.080 -0.037   \n",
       "6442  0.000 -0.435  0.000 -0.278 0.019  0.020 -0.163  0.358  0.409  0.233   \n",
       "4773  0.418  0.000  0.000  0.035 0.215  0.253  0.406 -0.114  0.252  0.034   \n",
       "2609 -0.373  0.000  0.000 -0.095 0.290  0.080 -0.409 -0.155 -0.026 -0.180   \n",
       "4721  0.000  0.000  0.305  0.220 0.426  0.061 -0.261 -0.308  0.147  0.007   \n",
       "\n",
       "         b7    b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  \\\n",
       "5885  0.040 0.287 -0.019  0.217  0.119 -0.019  0.196  0.069  0.148 -0.197   \n",
       "6442  0.174 0.161  0.368 -0.343  0.269  0.400  0.143  0.230  0.046 -0.004   \n",
       "4773 -0.023 0.024  0.163  0.068  0.205  0.422 -0.008  0.387  0.249 -0.044   \n",
       "2609 -0.142 0.272 -0.366 -0.118 -0.446 -0.097 -0.374 -0.269 -0.059  0.018   \n",
       "4721  0.119 0.120 -0.048 -0.402  0.109  0.066 -0.092  0.178  0.243  0.147   \n",
       "\n",
       "      lp1c0  lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  \\\n",
       "5885 -0.021 -0.110  0.000 -0.110  0.126 -0.203  ...   0.342  -0.044  -0.068   \n",
       "6442  0.001  0.060  0.058  0.097  0.037 -0.119  ...   0.491  -0.220   0.323   \n",
       "4773 -0.127 -0.108  0.114  0.141  0.089 -0.171  ...   0.398  -0.043  -0.143   \n",
       "2609  0.159  0.211  0.239  0.161  0.109  0.205  ...   0.352   0.060  -0.087   \n",
       "4721  0.147 -0.184 -0.002 -0.213 -0.159  0.092  ...   0.171   0.106  -0.062   \n",
       "\n",
       "      wb_352  wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  \\\n",
       "5885  -0.071   0.222  -0.029   0.160   0.000  -0.119  -0.030   0.000   0.260   \n",
       "6442   0.446   0.023  -0.167   0.387   0.542   0.374   0.426   0.000  -0.292   \n",
       "4773  -0.067  -0.157  -0.029  -0.187  -0.008  -0.159  -0.147   0.000  -0.207   \n",
       "2609  -0.189   0.232  -0.028  -0.155   0.141  -0.207   0.085   0.000   0.115   \n",
       "4721   0.169  -0.007   0.166   0.027  -0.008  -0.100   0.088   0.000  -0.027   \n",
       "\n",
       "      wb_361  wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  \\\n",
       "5885   0.357   0.216   0.253  -0.051   0.207   0.183  -0.061   0.017  -0.079   \n",
       "6442  -0.044  -0.043  -0.064   0.475   0.493   0.152  -0.048   0.387  -0.100   \n",
       "4773  -0.127  -0.134  -0.150  -0.061  -0.028  -0.155   0.399  -0.106   0.074   \n",
       "2609  -0.058   0.212   0.117  -0.167  -0.045  -0.116  -0.049   0.147  -0.082   \n",
       "4721   0.072   0.075   0.087  -0.067  -0.044  -0.101  -0.082  -0.087   0.025   \n",
       "\n",
       "      wb_370  wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  \\\n",
       "5885   0.133   0.000   0.000  -0.009  -0.047   0.284   0.229  -0.076  -0.104   \n",
       "6442   0.277   0.000   0.000  -0.090  -0.187  -0.045   0.261  -0.131  -0.194   \n",
       "4773  -0.120   0.000   0.000  -0.014  -0.040  -0.176  -0.205  -0.076   0.270   \n",
       "2609   0.002   0.000   0.000   1.032   0.114   0.033   0.063   0.108  -0.797   \n",
       "4721   0.078   0.000   0.000   0.272   0.159   0.018  -0.031   0.162   0.068   \n",
       "\n",
       "      wb_379  wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  \\\n",
       "5885   0.144   0.034   0.160  -0.092   0.133  -0.520  -0.606   0.618  -0.252   \n",
       "6442   0.433  -0.024  -0.081  -0.175   0.201  -0.608   0.602   0.538  -0.771   \n",
       "4773  -0.102   0.411  -0.098  -0.072  -0.163  -0.081  -0.589   0.517  -0.968   \n",
       "2609  -0.081  -0.044  -0.108   0.128  -0.201  -0.458  -0.494   1.403  -0.253   \n",
       "4721  -0.063  -0.035  -0.081   0.158  -0.025  -0.505  -0.442   0.197  -0.249   \n",
       "\n",
       "      wb_388  wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  \\\n",
       "5885  -0.192   0.029   0.914  -0.147  -0.171  -0.272   0.229  -0.662  -0.611   \n",
       "6442  -0.211   0.719   1.018  -0.670  -0.751  -0.272   0.648  -0.112   0.631   \n",
       "4773  -0.202   0.033   0.140  -0.136  -0.774  -0.272   0.434  -0.700  -0.538   \n",
       "2609  -0.194   1.247   0.127  -0.133  -0.173  -0.272   1.458  -0.099   0.367   \n",
       "4721  -0.772   0.575   0.124  -0.561  -0.171  -0.272   0.472  -0.113   0.464   \n",
       "\n",
       "      wb_397  wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  \\\n",
       "5885  -0.146   0.542   0.146   0.896  -0.699  -0.508  -0.140  -0.215  -0.612   \n",
       "6442  -0.824  -0.104   0.982   0.825  -0.131   0.436  -0.711  -0.820  -0.066   \n",
       "4773  -0.150   0.494   0.144  -0.658  -0.135   0.411  -0.146  -0.841  -0.607   \n",
       "2609  -0.145   0.563   0.141   0.477  -2.010  -0.346  -0.550  -0.231  -0.045   \n",
       "4721  -0.710   0.496   0.753   0.524  -0.582  -0.250  -0.632  -0.232  -0.050   \n",
       "\n",
       "      wb_406  wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  \\\n",
       "5885  -0.609   0.509   0.230   0.747  -0.067   0.126  -0.106   0.803  -0.088   \n",
       "6442   0.613   0.199   0.459   0.789  -0.613   0.874  -0.184   0.784  -0.679   \n",
       "4773  -0.564   0.456   0.486   0.565  -0.063   0.817  -0.778  -0.549  -0.090   \n",
       "2609  -0.508  -0.259   0.115   1.544  -0.461   0.109  -0.166   0.849  -0.534   \n",
       "4721  -0.462  -0.059   0.317  -0.045  -0.567   0.117  -0.176   0.512  -0.554   \n",
       "\n",
       "      wb_415  wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  \\\n",
       "5885   0.160   0.229   0.505  -0.088   0.260   0.025   0.224   0.170  -0.294   \n",
       "6442   0.825   1.014   0.087  -0.708   0.605   0.811   0.808   0.625  -0.294   \n",
       "4773   0.708   0.224   0.562  -0.091   0.470   0.017   0.411   0.630  -0.294   \n",
       "2609   0.165   1.762   1.105  -0.087   1.164   1.387   1.738   1.734  -0.294   \n",
       "4721   0.170   0.785   0.208  -0.663   0.385   0.018   0.219   0.432  -0.294   \n",
       "\n",
       "      wb_424  wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  \\\n",
       "5885   0.479   0.839   0.447   0.549   0.209   0.923   0.404  -0.255   0.071   \n",
       "6442  -0.273   0.090   0.177   0.146   0.980   1.055   0.324  -0.265   0.778   \n",
       "4773   0.425   0.668   0.629   0.665   0.199   0.169   0.668  -1.002   0.625   \n",
       "2609   0.170   0.074   0.838   0.791   1.943   0.155   0.166  -0.262   1.566   \n",
       "4721   0.241   0.616   0.651   0.650   0.201   0.149   0.175  -0.782   0.100   \n",
       "\n",
       "      wb_433  wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  \\\n",
       "5885  -0.233   0.230  -0.187  -0.257  -0.152   0.002   0.675   0.450  -0.115   \n",
       "6442  -0.797   0.506  -0.187  -0.257  -0.758  -0.587   0.173   0.237  -0.662   \n",
       "4773  -0.543   0.088  -0.187  -0.257  -0.147  -0.014   0.748   0.441  -0.116   \n",
       "2609  -0.245   1.209  -0.187  -0.257  -3.334  -0.483   1.393   0.079  -0.406   \n",
       "4721  -0.403   0.589  -0.187  -0.257  -0.772  -0.516   0.249   0.194  -0.632   \n",
       "\n",
       "      wb_442  wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "5885  -0.344   0.901  -0.734   0.864  -0.149   0.221   0.149  \n",
       "6442  -0.437   1.024  -0.113   0.194  -0.724   0.494   0.155  \n",
       "4773  -0.539   0.720  -0.722   1.186  -0.167   0.581  -0.136  \n",
       "2609  -2.445   0.158  -0.097   0.156  -0.590   1.305  -0.028  \n",
       "4721  -0.384   0.165  -0.104   0.217  -0.642   0.485  -0.065  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>713.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.354</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-1.256</td>\n",
       "      <td>-1.180</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.758</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>-1.138</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.644</td>\n",
       "      <td>-1.130</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>-1.167</td>\n",
       "      <td>-1.246</td>\n",
       "      <td>-0.548</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.644</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-1.330</td>\n",
       "      <td>0.581</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.543</td>\n",
       "      <td>-1.017</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.605</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.663</td>\n",
       "      <td>-1.288</td>\n",
       "      <td>0.638</td>\n",
       "      <td>-1.098</td>\n",
       "      <td>0.626</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>-0.795</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-1.320</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-1.091</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-1.082</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.791</td>\n",
       "      <td>-1.118</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.894</td>\n",
       "      <td>0.598</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.842</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.574</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>5202.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.626</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.429</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.554</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>0.451</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>0.607</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>5269.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.421</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.674</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>0.704</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.530</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.519</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.484</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.595</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>0.701</td>\n",
       "      <td>-0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9420</th>\n",
       "      <td>9420.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>0.643</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>-1.127</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-1.692</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>-1.202</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-1.187</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.118</td>\n",
       "      <td>-1.710</td>\n",
       "      <td>-1.194</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>1.149</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-1.461</td>\n",
       "      <td>-1.166</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-1.168</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-1.240</td>\n",
       "      <td>-0.792</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-1.614</td>\n",
       "      <td>2.306</td>\n",
       "      <td>-1.886</td>\n",
       "      <td>-1.604</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.651</td>\n",
       "      <td>-1.464</td>\n",
       "      <td>1.433</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-1.249</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.936</td>\n",
       "      <td>2.148</td>\n",
       "      <td>1.151</td>\n",
       "      <td>1.330</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-1.714</td>\n",
       "      <td>1.178</td>\n",
       "      <td>-1.699</td>\n",
       "      <td>1.267</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.939</td>\n",
       "      <td>-1.482</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>2.226</td>\n",
       "      <td>-1.644</td>\n",
       "      <td>1.975</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2   f0v3   f0v4   f1v0   f1v1  f1v2  f1v3  \\\n",
       "713   713.000    42 0.367 0.000 0.000  0.000  0.000  0.000 -0.385 0.000 0.000   \n",
       "799   799.000    42 0.000 0.000 0.438  0.000  0.000 -0.416  0.000 0.000 0.000   \n",
       "5202 5202.000    42 0.000 0.000 0.000 -0.320  0.000  0.000  0.422 0.000 0.000   \n",
       "5269 5269.000    42 0.000 0.000 0.000  0.000 -0.442  0.310  0.000 0.000 0.000   \n",
       "9420 9420.000    42 0.000 0.000 0.000  0.427  0.000  0.000  0.000 0.376 0.000   \n",
       "\n",
       "      f1v4   f2v0  f2v1   f2v2  f2v3  f2v4  f3v0   f3v1   f3v2  f3v3  f3v4  \\\n",
       "713  0.000 -0.350 0.000  0.000 0.000 0.000 0.000  0.000 -0.425 0.000 0.000   \n",
       "799  0.000  0.000 0.000  0.434 0.000 0.000 0.000 -0.267  0.000 0.000 0.000   \n",
       "5202 0.000  0.000 0.000 -0.439 0.000 0.000 0.000  0.000  0.000 0.417 0.000   \n",
       "5269 0.000  0.000 0.000  0.000 0.000 0.320 0.000  0.000  0.000 0.425 0.000   \n",
       "9420 0.000  0.000 0.000 -0.398 0.000 0.000 0.000  0.323  0.000 0.000 0.000   \n",
       "\n",
       "      f4v0  f4v1   f4v2   f4v3   f4v4  f5v0  f5v1  f5v2   f5v3   f5v4  f6v0  \\\n",
       "713  0.433 0.000  0.000  0.000  0.000 0.000 0.000 0.000  0.288  0.000 0.000   \n",
       "799  0.000 0.000  0.000  0.000 -0.370 0.000 0.000 0.000  0.000 -0.222 0.000   \n",
       "5202 0.000 0.000  0.000 -0.383  0.000 0.000 0.000 0.331  0.000  0.000 0.000   \n",
       "5269 0.000 0.000  0.000  0.000  0.364 0.000 0.000 0.000  0.374  0.000 0.000   \n",
       "9420 0.000 0.000 -0.384  0.000  0.000 0.000 0.000 0.000 -0.425  0.000 0.000   \n",
       "\n",
       "      f6v1  f6v2   f6v3   f6v4  f7v0   f7v1  f7v2   f7v3   f7v4  f8v0   f8v1  \\\n",
       "713  0.000 0.000 -0.414  0.000 0.000  0.000 0.000  0.000 -0.399 0.000 -0.389   \n",
       "799  0.000 0.433  0.000  0.000 0.000 -0.427 0.000  0.000  0.000 0.000  0.150   \n",
       "5202 0.000 0.000  0.000 -0.402 0.000  0.000 0.000 -0.392  0.000 0.000  0.000   \n",
       "5269 0.285 0.000  0.000  0.000 0.000  0.000 0.000  0.422  0.000 0.000  0.000   \n",
       "9420 0.000 0.000 -0.350  0.000 0.000  0.000 0.289  0.000  0.000 0.000  0.000   \n",
       "\n",
       "      f8v2  f8v3   f8v4   f9v0  f9v1  f9v2  f9v3  f9v4  f10v0  f10v1  f10v2  \\\n",
       "713  0.000 0.000  0.000  0.000 0.000 0.000 0.443 0.000  0.000  0.000  0.000   \n",
       "799  0.000 0.000  0.000 -0.385 0.000 0.000 0.000 0.000  0.000  0.000  0.411   \n",
       "5202 0.254 0.000  0.000  0.000 0.000 0.000 0.436 0.000  0.000  0.000  0.000   \n",
       "5269 0.000 0.000 -0.326  0.000 0.000 0.000 0.432 0.000  0.000  0.000 -0.421   \n",
       "9420 0.377 0.000  0.000  0.000 0.000 0.000 0.408 0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  f12v2  \\\n",
       "713   0.000  0.426  0.000  0.000  0.000 -0.416  0.000  0.000  0.000  0.000   \n",
       "799   0.000  0.000  0.000  0.000  0.000  0.375  0.000  0.394  0.000  0.000   \n",
       "5202  0.000 -0.336 -0.382  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5269  0.000  0.000  0.000  0.437  0.000  0.000  0.000  0.000  0.360  0.000   \n",
       "9420  0.314  0.000  0.394  0.000  0.000  0.000  0.000 -0.375  0.000  0.000   \n",
       "\n",
       "      f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  f14v2  \\\n",
       "713   0.000 -0.266  0.000  0.000  0.000  0.000 -0.415  0.000  0.000  0.000   \n",
       "799   0.000  0.000  0.000  0.000  0.000  0.000 -0.441  0.000  0.000  0.000   \n",
       "5202  0.371  0.000  0.000  0.299  0.000  0.000  0.000  0.414  0.000  0.000   \n",
       "5269  0.000  0.000  0.406  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "9420  0.000  0.000  0.000  0.000  0.000  0.391  0.000  0.000  0.000  0.414   \n",
       "\n",
       "      f14v3  f14v4     b0     b1     b2     b3     b4     b5     b6     b7  \\\n",
       "713   0.000  0.371  0.115 -0.287  0.140 -0.274 -0.111  0.315  0.003 -0.430   \n",
       "799   0.000  0.298 -0.169  0.214 -0.031  0.341  0.029  0.231  0.005  0.058   \n",
       "5202  0.000  0.000  0.426 -0.004 -0.054 -0.206 -0.096  0.145 -0.173  0.353   \n",
       "5269  0.000 -0.366  0.254  0.287  0.226 -0.339  0.392 -0.163 -0.199  0.372   \n",
       "9420  0.000  0.000 -0.063 -0.141 -0.411  0.078  0.247  0.141  0.071  0.411   \n",
       "\n",
       "         b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  lp1c0  \\\n",
       "713  -0.191 -0.066  0.108 -0.384 -0.198 -0.414 -0.405 -0.000 -0.188  0.010   \n",
       "799   0.102 -0.363  0.439  0.258  0.068 -0.222 -0.145  0.001 -0.102 -0.081   \n",
       "5202  0.060  0.275  0.387 -0.163 -0.016 -0.012 -0.264  0.097  0.162 -0.141   \n",
       "5269  0.262 -0.252 -0.194 -0.288 -0.057 -0.427  0.404 -0.091 -0.011  0.002   \n",
       "9420 -0.221  0.377 -0.384  0.291  0.156 -0.327  0.202 -0.245 -0.178 -0.232   \n",
       "\n",
       "      lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  wb_352  \\\n",
       "713  -0.204 -0.227  0.009 -0.195  0.178  ...  -0.188   0.283  -0.221  -0.116   \n",
       "799  -0.102  0.210  0.013 -0.119 -0.036  ...   0.153   0.459  -0.347  -0.076   \n",
       "5202  0.239 -0.132  0.176 -0.072  0.025  ...  -0.028  -0.056  -0.013  -0.084   \n",
       "5269  0.055  0.132  0.042  0.000  0.011  ...  -0.049   0.251  -0.084  -0.089   \n",
       "9420 -0.228 -0.128  0.177  0.027 -0.169  ...   0.088   0.257   0.003  -0.080   \n",
       "\n",
       "      wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  wb_361  \\\n",
       "713   -0.244   0.332  -0.229   0.056  -0.172  -0.203   0.000  -0.311  -0.211   \n",
       "799   -0.405   0.458  -0.367   0.055  -0.274  -0.290   0.000  -0.440  -0.080   \n",
       "5202  -0.036  -0.027  -0.018   0.000  -0.090  -0.019   0.000  -0.051   0.025   \n",
       "5269  -0.117   0.059  -0.077  -0.005  -0.107  -0.029   0.000  -0.169  -0.058   \n",
       "9420  -0.427   0.118  -0.646  -0.005  -0.154   0.076   0.000  -0.631   0.643   \n",
       "\n",
       "      wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  wb_370  \\\n",
       "713   -0.213  -0.217  -0.065   0.009  -0.240   0.335  -0.215   0.289  -0.202   \n",
       "799   -0.107  -0.095  -0.254  -0.050  -0.373   0.456  -0.321   0.431  -0.296   \n",
       "5202  -0.029  -0.014  -0.070  -0.051  -0.026   0.220   0.009  -0.083  -0.052   \n",
       "5269  -0.094  -0.120  -0.055  -0.026  -0.110  -0.038  -0.057  -0.058  -0.091   \n",
       "9420  -0.498  -0.467  -0.050  -0.028  -0.418   0.123   0.359   0.036  -0.607   \n",
       "\n",
       "      wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  wb_379  \\\n",
       "713    0.000   0.000   0.360   0.321  -0.185  -0.291   0.274   0.174  -0.166   \n",
       "799    0.000   0.000   0.000   0.492  -0.321  -0.422   0.444   0.187  -0.311   \n",
       "5202   0.000   0.000  -0.034  -0.043   0.042  -0.049  -0.079   0.109   0.058   \n",
       "5269   0.000   0.000   0.377   0.315  -0.113  -0.142   0.287   0.002  -0.043   \n",
       "9420   0.000   0.000  -0.006   0.300  -0.333  -0.620   0.086   0.150   0.637   \n",
       "\n",
       "      wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  wb_388  \\\n",
       "713    0.354  -0.121   0.262  -0.240  -0.802  -0.587   0.468  -1.256  -1.180   \n",
       "799    0.475  -0.085   0.438  -0.359  -0.801   0.550   0.672  -1.052  -1.032   \n",
       "5202   0.235   0.083  -0.080  -0.035  -0.446   0.417   0.458  -0.692  -0.670   \n",
       "5269  -0.035  -0.080   0.307  -0.122  -0.340  -0.488   0.145  -0.257  -0.411   \n",
       "9420   0.179   0.568   0.126  -0.514  -1.420  -1.127   0.769  -1.692  -1.588   \n",
       "\n",
       "      wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  wb_397  \\\n",
       "713    0.590   0.758  -0.624  -1.138  -0.272   0.644  -1.130   0.533  -0.154   \n",
       "799    0.690   0.124  -0.841  -0.965  -0.272   0.789  -0.860  -0.666  -1.091   \n",
       "5202   0.036   0.128  -0.136  -0.591  -0.272   0.505  -0.515  -0.361  -0.148   \n",
       "5269   0.614   0.135  -0.662  -0.177  -0.272   0.421  -0.117   0.471  -0.735   \n",
       "9420  -1.202   0.131  -1.187  -0.560  -0.272   1.118  -1.710  -1.194  -0.149   \n",
       "\n",
       "      wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  wb_406  \\\n",
       "713    0.601   0.664   0.578  -0.609  -0.240  -0.690  -1.167  -1.246  -0.548   \n",
       "799    0.473   0.146  -0.827  -0.117   0.505  -0.937  -1.082  -0.909   0.629   \n",
       "5202   0.403   0.140  -0.468  -0.538  -0.277  -0.141  -0.648  -0.463  -0.383   \n",
       "5269   0.570   0.542   0.570  -0.604   0.407  -0.674  -0.236  -0.053   0.515   \n",
       "9420   1.149   0.143  -1.461  -1.166  -0.226  -1.168  -0.456  -1.240  -0.792   \n",
       "\n",
       "      wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  wb_415  \\\n",
       "713    0.417   0.556   0.010  -0.644   0.119  -1.330   0.581  -0.633   0.702   \n",
       "799    0.558   0.642   0.614  -0.765   0.083  -1.061  -0.432  -0.923   0.770   \n",
       "5202   0.246   0.197   0.426  -0.066   0.127  -0.626   0.378  -0.227   0.533   \n",
       "5269   0.459   0.579   0.000  -0.583   0.704  -0.179   0.530  -0.609   0.696   \n",
       "9420   1.047   0.817   0.006  -1.614   2.306  -1.886  -1.604  -0.380   0.538   \n",
       "\n",
       "      wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  wb_424  \\\n",
       "713    0.693   0.543  -1.017   0.606   0.835   0.598   0.605  -0.294   0.356   \n",
       "799    0.211   0.590  -0.888   0.665   1.076   0.768   0.368  -0.294   0.545   \n",
       "5202   0.215   0.444  -0.091   0.004   0.025   0.429  -0.094  -0.294   0.304   \n",
       "5269   0.812   0.519  -0.688   0.540   0.020   0.417   0.514  -0.294   0.418   \n",
       "9420   0.220   0.651  -1.464   1.433   0.021   0.185  -1.249  -0.294   0.936   \n",
       "\n",
       "      wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  wb_433  \\\n",
       "713    0.640   0.684   0.663   0.200   0.533   0.663  -1.288   0.638  -1.098   \n",
       "799    0.356   0.138   0.128   0.764   0.154   0.791  -1.118   0.536  -0.894   \n",
       "5202   0.500   0.534   0.542   0.192   0.149   0.554  -0.724   0.451  -0.236   \n",
       "5269   0.073   0.700   0.702   0.210   0.168   0.484  -0.270   0.595  -0.231   \n",
       "9420   2.148   1.151   1.330   0.212   0.157   0.982  -1.714   1.178  -1.699   \n",
       "\n",
       "      wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  wb_442  \\\n",
       "713    0.626  -0.187  -0.257  -1.079  -0.795   0.428   0.393  -0.700  -0.719   \n",
       "799    0.598  -0.187  -0.257  -0.159  -0.842   0.718   0.574  -0.806  -0.801   \n",
       "5202   0.163  -0.187  -0.257  -0.136  -0.019   0.522   0.246  -0.118  -0.508   \n",
       "5269   0.578  -0.187  -0.257  -0.781  -0.543   0.123   0.452  -0.653  -0.103   \n",
       "9420   1.267  -0.187  -0.257  -0.153  -0.332   0.631   0.939  -1.482  -0.297   \n",
       "\n",
       "      wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "713    0.493  -1.320   0.542  -0.865   0.712  -0.244  \n",
       "799    0.781  -0.991   0.172  -1.295   0.703  -0.314  \n",
       "5202   0.575  -0.561   0.607  -0.157   0.343  -0.032  \n",
       "5269   0.211  -0.104   0.176  -0.701   0.701  -0.159  \n",
       "9420   2.226  -1.644   1.975  -0.883   1.081  -0.133  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f7v0</th>\n",
       "      <th>f7v1</th>\n",
       "      <th>f7v2</th>\n",
       "      <th>f7v3</th>\n",
       "      <th>f7v4</th>\n",
       "      <th>f8v0</th>\n",
       "      <th>f8v1</th>\n",
       "      <th>f8v2</th>\n",
       "      <th>f8v3</th>\n",
       "      <th>f8v4</th>\n",
       "      <th>f9v0</th>\n",
       "      <th>f9v1</th>\n",
       "      <th>f9v2</th>\n",
       "      <th>f9v3</th>\n",
       "      <th>f9v4</th>\n",
       "      <th>f10v0</th>\n",
       "      <th>f10v1</th>\n",
       "      <th>f10v2</th>\n",
       "      <th>f10v3</th>\n",
       "      <th>f10v4</th>\n",
       "      <th>f11v0</th>\n",
       "      <th>f11v1</th>\n",
       "      <th>f11v2</th>\n",
       "      <th>f11v3</th>\n",
       "      <th>f11v4</th>\n",
       "      <th>f12v0</th>\n",
       "      <th>f12v1</th>\n",
       "      <th>f12v2</th>\n",
       "      <th>f12v3</th>\n",
       "      <th>f12v4</th>\n",
       "      <th>f13v0</th>\n",
       "      <th>f13v1</th>\n",
       "      <th>f13v2</th>\n",
       "      <th>f13v3</th>\n",
       "      <th>f13v4</th>\n",
       "      <th>f14v0</th>\n",
       "      <th>f14v1</th>\n",
       "      <th>f14v2</th>\n",
       "      <th>f14v3</th>\n",
       "      <th>f14v4</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>lp0c0</th>\n",
       "      <th>lp0c1</th>\n",
       "      <th>lp1c0</th>\n",
       "      <th>lp1c1</th>\n",
       "      <th>lp2c0</th>\n",
       "      <th>lp2c1</th>\n",
       "      <th>lp3c0</th>\n",
       "      <th>lp3c1</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_349</th>\n",
       "      <th>wb_350</th>\n",
       "      <th>wb_351</th>\n",
       "      <th>wb_352</th>\n",
       "      <th>wb_353</th>\n",
       "      <th>wb_354</th>\n",
       "      <th>wb_355</th>\n",
       "      <th>wb_356</th>\n",
       "      <th>wb_357</th>\n",
       "      <th>wb_358</th>\n",
       "      <th>wb_359</th>\n",
       "      <th>wb_360</th>\n",
       "      <th>wb_361</th>\n",
       "      <th>wb_362</th>\n",
       "      <th>wb_363</th>\n",
       "      <th>wb_364</th>\n",
       "      <th>wb_365</th>\n",
       "      <th>wb_366</th>\n",
       "      <th>wb_367</th>\n",
       "      <th>wb_368</th>\n",
       "      <th>wb_369</th>\n",
       "      <th>wb_370</th>\n",
       "      <th>wb_371</th>\n",
       "      <th>wb_372</th>\n",
       "      <th>wb_373</th>\n",
       "      <th>wb_374</th>\n",
       "      <th>wb_375</th>\n",
       "      <th>wb_376</th>\n",
       "      <th>wb_377</th>\n",
       "      <th>wb_378</th>\n",
       "      <th>wb_379</th>\n",
       "      <th>wb_380</th>\n",
       "      <th>wb_381</th>\n",
       "      <th>wb_382</th>\n",
       "      <th>wb_383</th>\n",
       "      <th>wb_384</th>\n",
       "      <th>wb_385</th>\n",
       "      <th>wb_386</th>\n",
       "      <th>wb_387</th>\n",
       "      <th>wb_388</th>\n",
       "      <th>wb_389</th>\n",
       "      <th>wb_390</th>\n",
       "      <th>wb_391</th>\n",
       "      <th>wb_392</th>\n",
       "      <th>wb_393</th>\n",
       "      <th>wb_394</th>\n",
       "      <th>wb_395</th>\n",
       "      <th>wb_396</th>\n",
       "      <th>wb_397</th>\n",
       "      <th>wb_398</th>\n",
       "      <th>wb_399</th>\n",
       "      <th>wb_400</th>\n",
       "      <th>wb_401</th>\n",
       "      <th>wb_402</th>\n",
       "      <th>wb_403</th>\n",
       "      <th>wb_404</th>\n",
       "      <th>wb_405</th>\n",
       "      <th>wb_406</th>\n",
       "      <th>wb_407</th>\n",
       "      <th>wb_408</th>\n",
       "      <th>wb_409</th>\n",
       "      <th>wb_410</th>\n",
       "      <th>wb_411</th>\n",
       "      <th>wb_412</th>\n",
       "      <th>wb_413</th>\n",
       "      <th>wb_414</th>\n",
       "      <th>wb_415</th>\n",
       "      <th>wb_416</th>\n",
       "      <th>wb_417</th>\n",
       "      <th>wb_418</th>\n",
       "      <th>wb_419</th>\n",
       "      <th>wb_420</th>\n",
       "      <th>wb_421</th>\n",
       "      <th>wb_422</th>\n",
       "      <th>wb_423</th>\n",
       "      <th>wb_424</th>\n",
       "      <th>wb_425</th>\n",
       "      <th>wb_426</th>\n",
       "      <th>wb_427</th>\n",
       "      <th>wb_428</th>\n",
       "      <th>wb_429</th>\n",
       "      <th>wb_430</th>\n",
       "      <th>wb_431</th>\n",
       "      <th>wb_432</th>\n",
       "      <th>wb_433</th>\n",
       "      <th>wb_434</th>\n",
       "      <th>wb_435</th>\n",
       "      <th>wb_436</th>\n",
       "      <th>wb_437</th>\n",
       "      <th>wb_438</th>\n",
       "      <th>wb_439</th>\n",
       "      <th>wb_440</th>\n",
       "      <th>wb_441</th>\n",
       "      <th>wb_442</th>\n",
       "      <th>wb_443</th>\n",
       "      <th>wb_444</th>\n",
       "      <th>wb_445</th>\n",
       "      <th>wb_446</th>\n",
       "      <th>wb_447</th>\n",
       "      <th>wb_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>5459.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.631</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.261</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.946</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>1.291</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.141</td>\n",
       "      <td>1.289</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>1.335</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>1.151</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.255</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.756</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>1.021</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.659</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>1.284</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.932</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>2894.000</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.501</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.604</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>1.363</td>\n",
       "      <td>1.633</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1.243</td>\n",
       "      <td>1.057</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>1.176</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>1.068</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>0.596</td>\n",
       "      <td>1.556</td>\n",
       "      <td>1.001</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.136</td>\n",
       "      <td>1.687</td>\n",
       "      <td>1.652</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>1.085</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.906</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.388</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>1.178</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>2910.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-0.963</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.879</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.621</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>0.756</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.819</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>0.876</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>6897.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.384</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.597</td>\n",
       "      <td>-0.509</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.430</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.389</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.574</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>0.636</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>0.617</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6843</th>\n",
       "      <td>6843.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-1.085</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.487</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.722</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.810</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.569</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-0.794</td>\n",
       "      <td>0.673</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.552</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.852</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.763</td>\n",
       "      <td>-0.113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed   f0v0   f0v1  f0v2  f0v3   f0v4  f1v0  f1v1   f1v2  f1v3  \\\n",
       "5459 5459.000    42  0.000 -0.356 0.000 0.000  0.000 0.000 0.000 -0.324 0.000   \n",
       "2894 2894.000    42 -0.342  0.000 0.000 0.000  0.000 0.000 0.311  0.000 0.000   \n",
       "2910 2910.000    42  0.000  0.349 0.000 0.000  0.000 0.000 0.000  0.000 0.436   \n",
       "6897 6897.000    42  0.000  0.000 0.257 0.000  0.000 0.000 0.000  0.374 0.000   \n",
       "6843 6843.000    42  0.000  0.000 0.000 0.000 -0.419 0.000 0.000  0.000 0.000   \n",
       "\n",
       "       f1v4  f2v0   f2v1  f2v2  f2v3   f2v4  f3v0  f3v1  f3v2   f3v3   f3v4  \\\n",
       "5459  0.000 0.000  0.000 0.000 0.000 -0.432 0.000 0.000 0.000  0.000 -0.403   \n",
       "2894  0.000 0.000 -0.356 0.000 0.000  0.000 0.000 0.000 0.000  0.000  0.440   \n",
       "2910  0.000 0.000 -0.443 0.000 0.000  0.000 0.000 0.000 0.351  0.000  0.000   \n",
       "6897  0.000 0.000  0.000 0.393 0.000  0.000 0.000 0.000 0.000 -0.306  0.000   \n",
       "6843 -0.428 0.356  0.000 0.000 0.000  0.000 0.000 0.000 0.000 -0.324  0.000   \n",
       "\n",
       "       f4v0   f4v1  f4v2   f4v3  f4v4   f5v0  f5v1   f5v2   f5v3  f5v4   f6v0  \\\n",
       "5459  0.000  0.000 0.000 -0.432 0.000  0.365 0.000  0.000  0.000 0.000 -0.309   \n",
       "2894  0.444  0.000 0.000  0.000 0.000 -0.445 0.000  0.000  0.000 0.000  0.000   \n",
       "2910  0.000  0.389 0.000  0.000 0.000  0.000 0.000  0.000 -0.333 0.000  0.000   \n",
       "6897 -0.420  0.000 0.000  0.000 0.000  0.000 0.000 -0.430  0.000 0.000  0.000   \n",
       "6843  0.000 -0.435 0.000  0.000 0.000  0.000 0.000  0.000  0.416 0.000  0.000   \n",
       "\n",
       "      f6v1   f6v2   f6v3  f6v4  f7v0   f7v1  f7v2   f7v3   f7v4   f8v0  f8v1  \\\n",
       "5459 0.000  0.000  0.000 0.000 0.000  0.000 0.000 -0.368  0.000  0.000 0.000   \n",
       "2894 0.000 -0.405  0.000 0.000 0.000  0.000 0.000  0.396  0.000  0.000 0.333   \n",
       "2910 0.000  0.000 -0.409 0.000 0.000  0.000 0.000  0.000  0.444  0.000 0.000   \n",
       "6897 0.000  0.000 -0.306 0.000 0.000  0.000 0.000  0.000 -0.355 -0.355 0.000   \n",
       "6843 0.000  0.000  0.329 0.000 0.000 -0.352 0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "       f8v2   f8v3  f8v4   f9v0  f9v1   f9v2  f9v3   f9v4  f10v0  f10v1  \\\n",
       "5459 -0.436  0.000 0.000  0.000 0.000  0.000 0.000 -0.391  0.000  0.000   \n",
       "2894  0.000  0.000 0.000  0.000 0.437  0.000 0.000  0.000  0.000  0.000   \n",
       "2910  0.000 -0.389 0.000 -0.352 0.000  0.000 0.000  0.000  0.000  0.000   \n",
       "6897  0.000  0.000 0.000  0.000 0.000 -0.334 0.000  0.000  0.000 -0.397   \n",
       "6843  0.000  0.308 0.000  0.350 0.000  0.000 0.000  0.000  0.414  0.000   \n",
       "\n",
       "      f10v2  f10v3  f10v4  f11v0  f11v1  f11v2  f11v3  f11v4  f12v0  f12v1  \\\n",
       "5459  0.000  0.000 -0.227  0.000  0.000  0.000 -0.406  0.000 -0.370  0.000   \n",
       "2894  0.438  0.000  0.000  0.000  0.000  0.376  0.000  0.000 -0.395  0.000   \n",
       "2910  0.000  0.407  0.000  0.000  0.000  0.359  0.000  0.000  0.000  0.000   \n",
       "6897  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.287  0.000  0.000   \n",
       "6843  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.386  0.000  0.000   \n",
       "\n",
       "      f12v2  f12v3  f12v4  f13v0  f13v1  f13v2  f13v3  f13v4  f14v0  f14v1  \\\n",
       "5459  0.000  0.000  0.000 -0.412  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2894  0.000  0.000  0.000  0.000  0.000  0.399  0.000  0.000  0.000  0.000   \n",
       "2910  0.000  0.000 -0.387 -0.273  0.000  0.000  0.000  0.000  0.000  0.440   \n",
       "6897 -0.407  0.000  0.000  0.275  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "6843  0.443  0.000  0.000 -0.344  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f14v2  f14v3  f14v4     b0     b1     b2     b3     b4     b5     b6  \\\n",
       "5459  0.000  0.437  0.000 -0.115  0.114  0.339  0.276  0.150 -0.115  0.039   \n",
       "2894 -0.366  0.000  0.000 -0.116  0.428  0.152  0.352 -0.013  0.395 -0.374   \n",
       "2910  0.000  0.000  0.000  0.116 -0.013 -0.281  0.299  0.302 -0.200  0.008   \n",
       "6897  0.000  0.000  0.400  0.045 -0.303 -0.130  0.202  0.263  0.339  0.188   \n",
       "6843  0.000  0.000  0.437 -0.032 -0.039 -0.003 -0.022 -0.269  0.351  0.134   \n",
       "\n",
       "         b7     b8     b9    b10    b11    b12    b13    b14  lp0c0  lp0c1  \\\n",
       "5459  0.431 -0.205  0.032  0.040 -0.144 -0.368 -0.060 -0.379 -0.008 -0.102   \n",
       "2894  0.055  0.144  0.254 -0.102  0.357  0.162 -0.422 -0.079 -0.013  0.056   \n",
       "2910 -0.405  0.043 -0.377  0.373  0.251  0.239 -0.405  0.203  0.171  0.037   \n",
       "6897 -0.392 -0.148 -0.372 -0.395 -0.381  0.282 -0.146  0.218  0.086 -0.112   \n",
       "6843  0.093 -0.405 -0.246  0.348 -0.044  0.008 -0.098  0.052 -0.196 -0.146   \n",
       "\n",
       "      lp1c0  lp1c1  lp2c0  lp2c1  lp3c0  lp3c1  ...  wb_349  wb_350  wb_351  \\\n",
       "5459 -0.055 -0.184 -0.248  0.225  0.182  0.058  ...   0.572  -0.045  -0.082   \n",
       "2894 -0.249 -0.233 -0.099 -0.136  0.188  0.180  ...   0.448  -0.270   0.074   \n",
       "2910 -0.023 -0.190  0.119  0.006 -0.123  0.199  ...  -0.042   0.051   0.095   \n",
       "6897 -0.086 -0.157 -0.139  0.227 -0.126 -0.041  ...  -0.108   0.242  -0.149   \n",
       "6843  0.051 -0.247  0.187  0.090 -0.220 -0.218  ...   0.251   0.282  -0.078   \n",
       "\n",
       "      wb_352  wb_353  wb_354  wb_355  wb_356  wb_357  wb_358  wb_359  wb_360  \\\n",
       "5459  -0.069   0.472  -0.033   0.609   0.000  -0.116  -0.286   0.000   0.566   \n",
       "2894   0.492   0.074  -0.025   0.501  -0.008   0.250   0.505   0.000  -0.375   \n",
       "2910  -0.065   0.038   0.088  -0.085  -0.014   0.022  -0.064   0.000  -0.040   \n",
       "6897  -0.073  -0.174   0.369  -0.094  -0.010  -0.101  -0.142   0.000  -0.103   \n",
       "6843  -0.066  -0.116   0.337  -0.062  -0.005  -0.012  -0.021   0.000  -0.159   \n",
       "\n",
       "      wb_361  wb_362  wb_363  wb_364  wb_365  wb_366  wb_367  wb_368  wb_369  \\\n",
       "5459   0.631  -0.111  -0.098  -0.017  -0.025   0.253  -0.043   0.258  -0.085   \n",
       "2894  -0.059   0.053  -0.094   0.626   0.604  -0.066  -0.046   0.434  -0.173   \n",
       "2910   0.155   0.010   0.077   0.259   0.230   0.049   0.139   0.138   0.137   \n",
       "6897  -0.136  -0.136  -0.143  -0.055  -0.074  -0.159   0.337  -0.126   0.267   \n",
       "6843  -0.056  -0.107  -0.090  -0.068  -0.032  -0.122   0.128  -0.042   0.312   \n",
       "\n",
       "      wb_370  wb_371  wb_372  wb_373  wb_374  wb_375  wb_376  wb_377  wb_378  \\\n",
       "5459   0.172   0.000   0.000   0.000  -0.046   0.537   0.552  -0.082  -0.314   \n",
       "2894  -0.043   0.000   0.000  -0.011  -0.293  -0.112   0.216  -0.090  -0.232   \n",
       "2910  -0.123   0.000   0.000  -0.018  -0.046   0.113  -0.038  -0.089   0.061   \n",
       "6897  -0.155   0.000   0.000   0.000   0.357  -0.139  -0.104   0.314   0.205   \n",
       "6843  -0.134   0.000   0.000   0.386  -0.028  -0.116  -0.145   0.029  -0.049   \n",
       "\n",
       "      wb_379  wb_380  wb_381  wb_382  wb_383  wb_384  wb_385  wb_386  wb_387  \\\n",
       "5459   0.608  -0.036   0.261  -0.076   0.207  -0.938   0.933   0.946  -0.256   \n",
       "2894   0.344  -0.057  -0.099  -0.255   0.252   0.297  -0.774   0.184  -0.251   \n",
       "2910   0.173   0.160   0.216  -0.077  -0.020  -0.588  -0.535   0.615  -0.963   \n",
       "6897  -0.119   0.384  -0.075   0.262  -0.166  -0.394  -0.369   0.106  -0.776   \n",
       "6843  -0.066   0.418  -0.073  -0.079  -0.124  -0.078  -0.601   0.582  -1.085   \n",
       "\n",
       "      wb_388  wb_389  wb_390  wb_391  wb_392  wb_393  wb_394  wb_395  wb_396  \\\n",
       "5459  -0.872   1.291   0.141  -0.140  -0.166  -0.272   0.176  -0.953  -0.856   \n",
       "2894  -0.218   1.363   1.633  -0.840  -0.899  -0.272   0.367  -0.402  -0.797   \n",
       "2910  -0.949   0.031   0.974  -0.670  -0.772  -0.272   0.415  -0.663  -0.506   \n",
       "6897  -0.719   0.408   0.597  -0.509  -0.617  -0.272   0.430  -0.520  -0.329   \n",
       "6843  -0.213   0.025   0.137  -0.717  -0.789  -0.272   0.487  -0.816  -0.603   \n",
       "\n",
       "      wb_397  wb_398  wb_399  wb_400  wb_401  wb_402  wb_403  wb_404  wb_405  \\\n",
       "5459  -0.146   0.413   0.141   1.289  -0.138  -0.756  -0.140  -0.228  -0.885   \n",
       "2894  -0.145   0.685   1.243   1.057  -0.803  -0.537  -0.089  -0.931  -0.801   \n",
       "2910  -0.144   0.081   0.145  -0.787  -0.623  -0.354  -0.125  -0.817  -0.601   \n",
       "6897  -0.154   0.403   0.626   0.456  -0.505  -0.206  -0.539  -0.652  -0.463   \n",
       "6843  -0.146   0.401   0.152  -0.722  -0.141   0.467  -0.136  -0.887  -0.668   \n",
       "\n",
       "      wb_406  wb_407  wb_408  wb_409  wb_410  wb_411  wb_412  wb_413  wb_414  \\\n",
       "5459  -0.891   0.737   0.272   0.958  -0.067   1.335  -0.169   1.151  -0.087   \n",
       "2894  -0.835   0.764   0.471   0.020  -0.884   1.176  -0.151   1.068  -0.899   \n",
       "2910  -0.529  -0.310   0.121   0.699   0.077   0.879  -0.808  -0.009  -0.635   \n",
       "6897  -0.370  -0.062   0.255  -0.010  -0.467   0.538  -0.679   0.440  -0.446   \n",
       "6843   0.627   0.534   0.643   0.754  -0.700   0.800  -0.858  -0.543  -0.810   \n",
       "\n",
       "      wb_415  wb_416  wb_417  wb_418  wb_419  wb_420  wb_421  wb_422  wb_423  \\\n",
       "5459   0.172   0.221   0.660  -0.087   0.879   0.025   0.211  -0.640  -0.294   \n",
       "2894   0.596   1.556   1.001  -0.095   0.778   0.018   0.813   0.918  -0.294   \n",
       "2910   0.823   0.211   0.514  -0.942   0.040   0.015   0.621  -0.001  -0.294   \n",
       "6897   0.615   0.663   0.422  -0.680   0.118   0.020   0.222   0.389  -0.294   \n",
       "6843   0.804   0.227   0.660  -0.861   0.603   0.020   0.757   0.569  -0.294   \n",
       "\n",
       "      wb_424  wb_425  wb_426  wb_427  wb_428  wb_429  wb_430  wb_431  wb_432  \\\n",
       "5459   0.649   1.255   0.153   0.144   0.334   0.168   0.756  -0.264   1.021   \n",
       "2894  -0.433   0.071   0.975   0.136   1.687   1.652   0.245  -0.263   1.085   \n",
       "2910  -0.016   0.767   0.351   0.647   1.026   0.969   0.737  -0.986   0.756   \n",
       "6897   0.053   0.533   0.591   0.586   0.364   0.630   0.574  -0.781   0.542   \n",
       "6843   0.512   0.075   0.560   0.135   0.196   0.166   0.799  -0.794   0.673   \n",
       "\n",
       "      wb_433  wb_434  wb_435  wb_436  wb_437  wb_438  wb_439  wb_440  wb_441  \\\n",
       "5459  -0.241   0.358  -0.187  -0.257  -0.159   0.001   0.975   0.659  -0.110   \n",
       "2894  -0.961   0.160  -0.187  -0.257  -0.151  -0.906   0.130   0.388  -0.113   \n",
       "2910  -0.913   0.109  -0.187  -0.257  -0.147  -0.007   0.761   0.015  -0.197   \n",
       "6897  -0.699   0.318  -0.187  -0.257  -0.159  -0.482   0.455   0.056  -0.525   \n",
       "6843  -0.867   0.208  -0.187  -0.257  -0.916   0.056   0.122   0.552  -0.266   \n",
       "\n",
       "      wb_442  wb_443  wb_444  wb_445  wb_446  wb_447  wb_448  \n",
       "5459  -0.692   1.284  -0.099   0.932  -0.157   0.195   0.259  \n",
       "2894  -0.631   1.178  -0.085   0.157  -0.846   0.520   0.174  \n",
       "2910  -0.585   0.819  -0.762   0.876  -0.156   0.269  -0.038  \n",
       "6897  -0.457   0.636  -0.651   0.617  -0.577   0.514  -0.158  \n",
       "6843  -0.190   0.852  -0.803   0.179  -0.155   0.763  -0.113  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 11:03:10.146243: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 28s 6s/step - loss: 7.1952 - binary_accuracy_inet_decision_function_fv_metric: 0.5261 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 6.8580 - binary_accuracy_inet_decision_function_fv_metric: 0.5481 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 6.6964 - binary_accuracy_inet_decision_function_fv_metric: 0.5630 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 7.6554 - binary_accuracy_inet_decision_function_fv_metric: 0.4991 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 7.3373 - binary_accuracy_inet_decision_function_fv_metric: 0.5246 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 7.4945 - binary_accuracy_inet_decision_function_fv_metric: 0.5150 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 7.3018 - binary_accuracy_inet_decision_function_fv_metric: 0.5324 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 7.7291 - binary_accuracy_inet_decision_function_fv_metric: 0.4936 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 7.5311 - binary_accuracy_inet_decision_function_fv_metric: 0.5055 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 7.6959 - binary_accuracy_inet_decision_function_fv_metric: 0.5019 - val_loss: 6.8594 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 11:03:44.240915: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0:00:40\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " history,\n",
    "\n",
    " model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=['plot_losses']\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 449)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_1056 (Dense)            (None, 1056)         475200      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation1_relu (Activation)   (None, 1056)         0           hidden1_1056[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout1_0.2 (Dropout)          (None, 1056)         0           activation1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_512 (Dense)             (None, 512)          541184      dropout1_0.2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation2_relu (Activation)   (None, 512)          0           hidden2_512[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout2_0.1 (Dropout)          (None, 512)          0           activation2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_coeff_15 (Dense)         (None, 15)           7695        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier1_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier2_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier3_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier4_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier5_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier6_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier7_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier8_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier9_var1_1 (Dens (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier10_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier11_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier12_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier13_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier14_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier15_var1_1 (Den (None, 5)            2565        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_0 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_1 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_2 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_3 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_4 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_5 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_6 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_7 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_8 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_9 (Dense)      (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_10 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_11 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_12 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_13 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_14 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_15 (Dense)     (None, 2)            1026        dropout2_0.1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_combined (Concatenate)   (None, 122)          0           output_coeff_15[0][0]            \n",
      "                                                                 output_identifier1_var1_1[0][0]  \n",
      "                                                                 output_identifier2_var1_1[0][0]  \n",
      "                                                                 output_identifier3_var1_1[0][0]  \n",
      "                                                                 output_identifier4_var1_1[0][0]  \n",
      "                                                                 output_identifier5_var1_1[0][0]  \n",
      "                                                                 output_identifier6_var1_1[0][0]  \n",
      "                                                                 output_identifier7_var1_1[0][0]  \n",
      "                                                                 output_identifier8_var1_1[0][0]  \n",
      "                                                                 output_identifier9_var1_1[0][0]  \n",
      "                                                                 output_identifier10_var1_1[0][0] \n",
      "                                                                 output_identifier11_var1_1[0][0] \n",
      "                                                                 output_identifier12_var1_1[0][0] \n",
      "                                                                 output_identifier13_var1_1[0][0] \n",
      "                                                                 output_identifier14_var1_1[0][0] \n",
      "                                                                 output_identifier15_var1_1[0][0] \n",
      "                                                                 output_leaf_node_0[0][0]         \n",
      "                                                                 output_leaf_node_1[0][0]         \n",
      "                                                                 output_leaf_node_2[0][0]         \n",
      "                                                                 output_leaf_node_3[0][0]         \n",
      "                                                                 output_leaf_node_4[0][0]         \n",
      "                                                                 output_leaf_node_5[0][0]         \n",
      "                                                                 output_leaf_node_6[0][0]         \n",
      "                                                                 output_leaf_node_7[0][0]         \n",
      "                                                                 output_leaf_node_8[0][0]         \n",
      "                                                                 output_leaf_node_9[0][0]         \n",
      "                                                                 output_leaf_node_10[0][0]        \n",
      "                                                                 output_leaf_node_11[0][0]        \n",
      "                                                                 output_leaf_node_12[0][0]        \n",
      "                                                                 output_leaf_node_13[0][0]        \n",
      "                                                                 output_leaf_node_14[0][0]        \n",
      "                                                                 output_leaf_node_15[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,078,970\n",
      "Trainable params: 1,078,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 449)\n",
      "[-0.1228093   0.0474214  -0.3681943   0.13793102 -0.08740006  0.23613304\n",
      " -0.22431242 -0.406705   -0.17728838  0.18454176 -0.46662295  0.10797334\n",
      " -0.12901036 -0.2911343  -0.0644475   0.21177219  0.23245329  0.17899959\n",
      "  0.2106232   0.16615167  0.21709408  0.1472025   0.24135701  0.23630182\n",
      "  0.15804462  0.23138483  0.22453432  0.16631062  0.20083857  0.17693171\n",
      "  0.22346263  0.22114107  0.17947958  0.1765267   0.19939002  0.20864922\n",
      "  0.23071034  0.18586572  0.20998736  0.16478732  0.20391414  0.14763406\n",
      "  0.21947278  0.2505019   0.17847708  0.211737    0.23507808  0.16105044\n",
      "  0.14306642  0.24906799  0.17564811  0.18129735  0.16628005  0.23259696\n",
      "  0.24417754  0.24085054  0.15491506  0.285232    0.17047903  0.14852343\n",
      "  0.2189746   0.16513933  0.21549116  0.24984272  0.15055221  0.23466073\n",
      "  0.13533823  0.27692637  0.15368026  0.19939436  0.165059    0.27675685\n",
      "  0.22127213  0.13929814  0.19761391  0.24195515  0.12024033  0.17938617\n",
      "  0.22009104  0.23832725  0.16031148  0.22579822  0.2132311   0.14287311\n",
      "  0.25778615  0.25529563  0.12988195  0.15963745  0.23730008  0.21788487\n",
      "  0.5435814   0.45641857  0.60702795  0.39297202  0.5621704   0.43782955\n",
      "  0.49938256  0.50061744  0.48226482  0.51773524  0.41709366  0.58290637\n",
      "  0.3936676   0.6063324   0.5154717   0.48452833  0.44778106  0.552219\n",
      "  0.48210946  0.5178905   0.5235056   0.47649437  0.66304016  0.33695978\n",
      "  0.5294549   0.47054508  0.55411506  0.44588497  0.43596777  0.56403226\n",
      "  0.5710384   0.42896163]\n"
     ]
    }
   ],
   "source": [
    "lambda_net = np.array([lambda_net_dataset_test.network_parameters_array[0]])\n",
    "X_data = lambda_net_dataset_test.X_test_lambda_array[2]\n",
    "y_data = lambda_net_dataset_test.y_test_lambda_array[0]\n",
    "print(lambda_net.shape)\n",
    "dt_pred = model.predict(lambda_net)[0]\n",
    "print(dt_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "import queue\n",
    "\n",
    "def level_to_pre(arr,ind,new_arr):\n",
    "    if ind>=len(arr): return new_arr #nodes at ind don't exist\n",
    "    new_arr.append(arr[ind]) #append to back of the array\n",
    "    new_arr = level_to_pre(arr,ind*2+1,new_arr) #recursive call to left\n",
    "    new_arr = level_to_pre(arr,ind*2+2,new_arr) #recursive call to right\n",
    "    return new_arr\n",
    "\n",
    "def pre_to_level(arr):\n",
    "    def left_tree_size(n):\n",
    "        if n<=1: return 0\n",
    "        l = int(log2(n+1)) #l = no of completely filled levels\n",
    "        ans = 2**(l-1)\n",
    "        last_level_nodes = min(n-2**l+1,ans)\n",
    "        return ans + last_level_nodes -1       \n",
    "    \n",
    "    que = queue.Queue()\n",
    "    que.put((0,len(arr)))\n",
    "    ans = [] #this will be answer\n",
    "    while not que.empty():\n",
    "        iroot,size = que.get() #index of root and size of subtree\n",
    "        if iroot>=len(arr) or size==0: continue ##nodes at iroot don't exist\n",
    "        else : ans.append(arr[iroot]) #append to back of output array\n",
    "        sz_of_left = left_tree_size(size) \n",
    "        que.put((iroot+1,sz_of_left)) #insert left sub-tree info to que\n",
    "        que.put((iroot+1+sz_of_left,size-sz_of_left-1)) #right sub-tree info \n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sklearn.tree._tree.Tree object at 0x7fbf56fe2180>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 4,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "sklearn_dt = DecisionTreeClassifier(max_depth=4)\n",
    "#print(sklearn_dt.tree_)\n",
    "sklearn_dt.fit(X_data, y_data)\n",
    "sklearn_dt.tree_.node_count = 31\n",
    "sklearn_dt.tree_.capacity = 31\n",
    "sklearn_dt.fit(X_data, y_data)\n",
    "\n",
    "print(sklearn_dt.tree_)\n",
    "sklearn_dt.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.tree._tree.Tree at 0x7fbfe48b3a40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_dt.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_dt.tree_.capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115., 135.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_dt.tree_.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sklearn_dt.tree_.value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array([[116., 136.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(174.67826086956524, 195.696, 'X[1] <= 0.768\\ngini = 0.497\\nsamples = 250\\nvalue = [115, 135]'),\n",
       " Text(94.61739130434783, 152.208, 'X[0] <= 0.914\\ngini = 0.484\\nsamples = 195\\nvalue = [80, 115]'),\n",
       " Text(58.22608695652174, 108.72, 'X[4] <= 0.88\\ngini = 0.493\\nsamples = 179\\nvalue = [79, 100]'),\n",
       " Text(29.11304347826087, 65.232, 'X[0] <= 0.162\\ngini = 0.499\\nsamples = 159\\nvalue = [76, 83]'),\n",
       " Text(14.556521739130435, 21.744, 'gini = 0.397\\nsamples = 22\\nvalue = [16, 6]'),\n",
       " Text(43.66956521739131, 21.744, 'gini = 0.492\\nsamples = 137\\nvalue = [60, 77]'),\n",
       " Text(87.33913043478262, 65.232, 'X[3] <= 0.192\\ngini = 0.255\\nsamples = 20\\nvalue = [3, 17]'),\n",
       " Text(72.78260869565217, 21.744, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(101.89565217391305, 21.744, 'gini = 0.198\\nsamples = 18\\nvalue = [2, 16]'),\n",
       " Text(131.0086956521739, 108.72, 'X[2] <= 0.056\\ngini = 0.117\\nsamples = 16\\nvalue = [1, 15]'),\n",
       " Text(116.45217391304348, 65.232, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(145.56521739130434, 65.232, 'gini = 0.0\\nsamples = 15\\nvalue = [0, 15]'),\n",
       " Text(254.73913043478262, 152.208, 'X[4] <= 0.468\\ngini = 0.463\\nsamples = 55\\nvalue = [35, 20]'),\n",
       " Text(203.7913043478261, 108.72, 'X[4] <= 0.301\\ngini = 0.5\\nsamples = 26\\nvalue = [13, 13]'),\n",
       " Text(174.67826086956524, 65.232, 'X[3] <= 0.882\\ngini = 0.43\\nsamples = 16\\nvalue = [11, 5]'),\n",
       " Text(160.12173913043478, 21.744, 'gini = 0.337\\nsamples = 14\\nvalue = [11, 3]'),\n",
       " Text(189.23478260869567, 21.744, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(232.90434782608696, 65.232, 'X[3] <= 0.865\\ngini = 0.32\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " Text(218.34782608695653, 21.744, 'gini = 0.198\\nsamples = 9\\nvalue = [1, 8]'),\n",
       " Text(247.4608695652174, 21.744, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(305.68695652173915, 108.72, 'X[0] <= 0.62\\ngini = 0.366\\nsamples = 29\\nvalue = [22, 7]'),\n",
       " Text(291.1304347826087, 65.232, 'X[0] <= 0.504\\ngini = 0.455\\nsamples = 20\\nvalue = [13, 7]'),\n",
       " Text(276.5739130434783, 21.744, 'gini = 0.305\\nsamples = 16\\nvalue = [13, 3]'),\n",
       " Text(305.68695652173915, 21.744, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(320.24347826086955, 65.232, 'gini = 0.0\\nsamples = 9\\nvalue = [9, 0]')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(sklearn_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_dt.tree_.value[0] = np.array([[116., 136.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_dt.tree_.node_count = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_dt.tree_.capacity = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(31)\n",
    "    #clf.tree_.children_left[i] = #children_left[i]\n",
    "    #clf.tree_.children_right[i] = #children_right[i]            \n",
    "    clf.tree_.value[i] = #value[i]\n",
    "    #clf.tree_.impurity[i] = #impurity[i]\n",
    "    #clf.tree_.n_node_samples[i] = #n_node_samples[i]\n",
    "    clf.tree_.weighted_n_node_samples[i] = #weighted_n_node_samples[i]\n",
    "    clf.tree_.feature[i] = #feature[i]\n",
    "    clf.tree_.threshold[i] = #threshold[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.15000000e+002, 1.35000000e+002]],\n",
       "\n",
       "       [[8.00000000e+001, 1.15000000e+002]],\n",
       "\n",
       "       [[7.90000000e+001, 1.00000000e+002]],\n",
       "\n",
       "       [[7.60000000e+001, 8.30000000e+001]],\n",
       "\n",
       "       [[1.60000000e+001, 6.00000000e+000]],\n",
       "\n",
       "       [[6.00000000e+001, 7.70000000e+001]],\n",
       "\n",
       "       [[3.00000000e+000, 1.70000000e+001]],\n",
       "\n",
       "       [[1.00000000e+000, 1.00000000e+000]],\n",
       "\n",
       "       [[2.00000000e+000, 1.60000000e+001]],\n",
       "\n",
       "       [[1.00000000e+000, 1.50000000e+001]],\n",
       "\n",
       "       [[1.00000000e+000, 0.00000000e+000]],\n",
       "\n",
       "       [[0.00000000e+000, 1.50000000e+001]],\n",
       "\n",
       "       [[3.50000000e+001, 2.00000000e+001]],\n",
       "\n",
       "       [[1.30000000e+001, 1.30000000e+001]],\n",
       "\n",
       "       [[1.10000000e+001, 5.00000000e+000]],\n",
       "\n",
       "       [[0.00000000e+000, 2.00000000e+000]],\n",
       "\n",
       "       [[1.10000000e+001, 3.00000000e+000]],\n",
       "\n",
       "       [[2.00000000e+000, 8.00000000e+000]],\n",
       "\n",
       "       [[1.00000000e+000, 8.00000000e+000]],\n",
       "\n",
       "       [[1.00000000e+000, 0.00000000e+000]],\n",
       "\n",
       "       [[2.20000000e+001, 7.00000000e+000]],\n",
       "\n",
       "       [[1.30000000e+001, 7.00000000e+000]],\n",
       "\n",
       "       [[1.30000000e+001, 3.00000000e+000]],\n",
       "\n",
       "       [[0.00000000e+000, 4.00000000e+000]],\n",
       "\n",
       "       [[9.00000000e+000, 0.00000000e+000]],\n",
       "\n",
       "       [[0.00000000e+000, 5.58294180e-322]],\n",
       "\n",
       "       [[4.67247332e-310, 4.67248261e-310]],\n",
       "\n",
       "       [[0.00000000e+000, 0.00000000e+000]],\n",
       "\n",
       "       [[0.00000000e+000, 0.00000000e+000]],\n",
       "\n",
       "       [[0.00000000e+000, 0.00000000e+000]],\n",
       "\n",
       "       [[0.00000000e+000, 0.00000000e+000]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_dt.tree_.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77219/1705769632.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(174.67826086956524, 195.696, 'X[1] <= 0.768\\ngini = 0.497\\nsamples = 250\\nvalue = [115, 135]'),\n",
       " Text(94.61739130434783, 152.208, 'X[0] <= 0.914\\ngini = 0.484\\nsamples = 195\\nvalue = [80, 115]'),\n",
       " Text(58.22608695652174, 108.72, 'X[4] <= 0.88\\ngini = 0.493\\nsamples = 179\\nvalue = [79, 100]'),\n",
       " Text(29.11304347826087, 65.232, 'X[0] <= 0.162\\ngini = 0.499\\nsamples = 159\\nvalue = [76, 83]'),\n",
       " Text(14.556521739130435, 21.744, 'gini = 0.397\\nsamples = 22\\nvalue = [16, 6]'),\n",
       " Text(43.66956521739131, 21.744, 'gini = 0.492\\nsamples = 137\\nvalue = [60, 77]'),\n",
       " Text(87.33913043478262, 65.232, 'X[3] <= 0.192\\ngini = 0.255\\nsamples = 20\\nvalue = [3, 17]'),\n",
       " Text(72.78260869565217, 21.744, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(101.89565217391305, 21.744, 'gini = 0.198\\nsamples = 18\\nvalue = [2, 16]'),\n",
       " Text(131.0086956521739, 108.72, 'X[2] <= 0.056\\ngini = 0.117\\nsamples = 16\\nvalue = [1, 15]'),\n",
       " Text(116.45217391304348, 65.232, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(145.56521739130434, 65.232, 'gini = 0.0\\nsamples = 15\\nvalue = [0, 15]'),\n",
       " Text(254.73913043478262, 152.208, 'X[4] <= 0.468\\ngini = 0.463\\nsamples = 55\\nvalue = [35, 20]'),\n",
       " Text(203.7913043478261, 108.72, 'X[4] <= 0.301\\ngini = 0.5\\nsamples = 26\\nvalue = [13, 13]'),\n",
       " Text(174.67826086956524, 65.232, 'X[0] <= 0.086\\ngini = 0.43\\nsamples = 16\\nvalue = [11, 5]'),\n",
       " Text(160.12173913043478, 21.744, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(189.23478260869567, 21.744, 'gini = 0.337\\nsamples = 14\\nvalue = [11, 3]'),\n",
       " Text(232.90434782608696, 65.232, 'X[3] <= 0.865\\ngini = 0.32\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " Text(218.34782608695653, 21.744, 'gini = 0.198\\nsamples = 9\\nvalue = [1, 8]'),\n",
       " Text(247.4608695652174, 21.744, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(305.68695652173915, 108.72, 'X[0] <= 0.62\\ngini = 0.366\\nsamples = 29\\nvalue = [22, 7]'),\n",
       " Text(291.1304347826087, 65.232, 'X[0] <= 0.504\\ngini = 0.455\\nsamples = 20\\nvalue = [13, 7]'),\n",
       " Text(276.5739130434783, 21.744, 'gini = 0.305\\nsamples = 16\\nvalue = [13, 3]'),\n",
       " Text(305.68695652173915, 21.744, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(320.24347826086955, 65.232, 'gini = 0.0\\nsamples = 9\\nvalue = [9, 0]')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(sklearn_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nspect.getmembers(sklearn.tree._tree.Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_dt.tree_.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_dt.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(p):\n",
    "    return (p)*(1 - (p)) + (1 - p)*(1 - (1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf=sklearn_dt\n",
    "n_nodes = clf.tree_.node_count\n",
    "print('n_nodes', n_nodes)\n",
    "children_left = clf.tree_.children_left\n",
    "print('children_left', children_left)\n",
    "children_right = clf.tree_.children_right\n",
    "print('children_right', children_right)\n",
    "feature = clf.tree_.feature\n",
    "print('feature', feature)\n",
    "threshold = clf.tree_.threshold\n",
    "print('threshold', threshold)\n",
    "\n",
    "print('clf.tree_.value', clf.tree_.value)\n",
    "print('clf.tree_.impurity', clf.tree_.impurity)\n",
    "print('clf.tree_n_node_samples', clf.tree_.n_node_samples)\n",
    "print('clf.tree_.weighted_n_node_samples', clf.tree_.weighted_n_node_samples)\n",
    "\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "while len(stack) > 0:\n",
    "    # `pop` ensures each node is only visited once\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "\n",
    "    # If the left and right child of a node is not the same we have a split\n",
    "    # node\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    # If a split node, append left and right children and depth to `stack`\n",
    "    # so we can loop through them\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print('node_depth', node_depth)\n",
    "print('is_leaves', is_leaves)  \n",
    "\n",
    "print(\"The binary tree structure has {n} nodes and has \"\n",
    "      \"the following tree structure:\\n\".format(n=n_nodes))\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"{space}node={node} is a leaf node.\".format(\n",
    "            space=node_depth[i] * \"\\t\", node=i))\n",
    "    else:\n",
    "        print(\"{space}node={node} is a split node: \"\n",
    "              \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "              \"else to node {right}.\".format(\n",
    "                  space=node_depth[i] * \"\\t\",\n",
    "                  node=i,\n",
    "                  left=children_left[i],\n",
    "                  feature=feature[i],\n",
    "                  threshold=threshold[i],\n",
    "                  right=children_right[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, leaf_classes = get_shaped_parameters_for_decision_tree(dt_pred, config)\n",
    "print(splits)\n",
    "print(leaf_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dt_array_to_sklearn(vanilla_dt_array, config,X_data, y_data, printing=False):\n",
    "    def gini(p):\n",
    "        return (p)*(1 - (p)) + (1 - p)*(1 - (1-p))    \n",
    "    \n",
    "    splits, leaf_classes= get_shaped_parameters_for_decision_tree(vanilla_dt_array, config)\n",
    "    \n",
    "    if printing:\n",
    "        print('splits', splits)\n",
    "        print('leaf_classes', leaf_classes)\n",
    "        \n",
    "    internal_node_num = 2 ** config['function_family']['maximum_depth'] -1    \n",
    "    leaf_node_num = 2 ** config['function_family']['maximum_depth']    \n",
    "    n_nodes = internal_node_num + leaf_node_num\n",
    "\n",
    "    indices_list = [i for i in range(internal_node_num + leaf_node_num)]\n",
    "    pre_order_from_level = np.array(level_to_pre(indices_list, 0, []))\n",
    "\n",
    "    level_order_from_pre = np.array(pre_to_level(indices_list))\n",
    "    children_left = []\n",
    "    children_right = []\n",
    "    counter = 0\n",
    "    for i in pre_order_from_level:#pre_order_from_level:\n",
    "        left = 2*i+1 \n",
    "        right = 2*i+2 \n",
    "        if left < n_nodes:\n",
    "            children_left.append(level_order_from_pre[left])\n",
    "        else:\n",
    "            children_left.append(-1)\n",
    "        if left < n_nodes:\n",
    "            children_right.append(level_order_from_pre[right])\n",
    "        else:\n",
    "            children_right.append(-1)            \n",
    "            \n",
    "        #try:\n",
    "        #    children_left.append(level_order_from_pre[left])\n",
    "        #except:\n",
    "        #    children_left.append(-1)\n",
    "        #try:\n",
    "        #    children_right.append(level_order_from_pre[right])\n",
    "        #except:\n",
    "        #    children_right.append(-1)            \n",
    "        \n",
    "    children_left = np.array(children_left)\n",
    "    children_right = np.array(children_right)\n",
    "    \n",
    "    #print('children_left', children_left.shape, children_left)\n",
    "    #print('children_right', children_right.shape, children_right)\n",
    "    \n",
    "    indices_list = [i for i in range(internal_node_num+leaf_node_num)]\n",
    "    new_order = np.array(level_to_pre(indices_list, 0, []))\n",
    "    \n",
    "    feature = [np.argmax(split) for split in splits]\n",
    "    feature.extend([-2 for i in range(leaf_node_num)])\n",
    "    feature = np.array(feature)[new_order]\n",
    "    threshold = [np.max(split) for split in splits]\n",
    "    threshold.extend([-2 for i in range(leaf_node_num)])\n",
    "    threshold = np.array(threshold)[new_order]    \n",
    "    \n",
    "    samples = 500\n",
    "    value_list = []\n",
    "    n_node_samples_list = []\n",
    "    impurity_list = []\n",
    "    \n",
    "    value_list_previous = None\n",
    "    for current_depth in reversed(range(1, (config['function_family']['maximum_depth']+1)+1)):\n",
    "        internal_node_num_current_depth = (2 ** current_depth - 1) - (2 ** (current_depth-1) - 1)\n",
    "        #print(internal_node_num_current_depth)\n",
    "        n_node_samples = [samples for _ in range(internal_node_num_current_depth)]\n",
    "        if current_depth > config['function_family']['maximum_depth']: #is leaf\n",
    "            values = []\n",
    "            impurity = []\n",
    "            for leaf_class in leaf_classes:\n",
    "                current_value = [samples, 0] if leaf_class == 0 else [0, samples]\n",
    "                curent_impurity = 0\n",
    "                values.append(current_value)\n",
    "                impurity.append(curent_impurity)\n",
    "            #values = [[0, samples] for _ in range(internal_node_num_current_depth)]\n",
    "            #impurity = [0.5 for _ in range(internal_node_num_current_depth)]\n",
    "        else:\n",
    "            value_list_previous_left = value_list_previous[::2]\n",
    "            value_list_previous_right = value_list_previous[1::2]\n",
    "            samples_sum_list = np.add(value_list_previous_left, value_list_previous_right)\n",
    "            \n",
    "            values = [samples_sum for samples_sum in samples_sum_list]\n",
    "            impurity = [gini(value[0]/sum(value)) for value in values]\n",
    "        samples = samples*2\n",
    "        \n",
    "        value_list_previous = values\n",
    "\n",
    "        \n",
    "        n_node_samples_list[0:0] = n_node_samples\n",
    "        value_list[0:0] = values\n",
    "        impurity_list[0:0] = impurity        \n",
    "        #n_node_samples_list.extend(n_node_samples)\n",
    "        #value_list.extend(values)\n",
    "        #impurity_list.extend(impurity)\n",
    "        \n",
    "    value = np.expand_dims(np.array(value_list), axis=1) #shape [node_count, n_outputs, max_n_classes]; number of samples for each class\n",
    "    value = value[new_order].astype(np.float64)\n",
    "    impurity =  np.array(impurity_list) #\n",
    "    impurity = impurity[new_order]\n",
    "    n_node_samples = np.array(n_node_samples_list) #number of samples at each node\n",
    "    n_node_samples = n_node_samples[new_order]\n",
    "    weighted_n_node_samples = 1 * np.array(n_node_samples_list) #same as tree_n_node_samples, but weighted    \n",
    "    weighted_n_node_samples = weighted_n_node_samples.astype(np.float64)\n",
    "    n_node_samples = n_node_samples[new_order]\n",
    "    \n",
    "    if printing:\n",
    "        node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "        is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "        stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "        while len(stack) > 0:\n",
    "            # `pop` ensures each node is only visited once\n",
    "            node_id, depth = stack.pop()\n",
    "            node_depth[node_id] = depth\n",
    "\n",
    "            # If the left and right child of a node is not the same we have a split\n",
    "            # node\n",
    "            is_split_node = children_left[node_id] != children_right[node_id]\n",
    "            # If a split node, append left and right children and depth to `stack`\n",
    "            # so we can loop through them\n",
    "            if is_split_node:\n",
    "                stack.append((children_left[node_id], depth + 1))\n",
    "                stack.append((children_right[node_id], depth + 1))\n",
    "            else:\n",
    "                is_leaves[node_id] = True\n",
    "\n",
    "        print(\"The binary tree structure has {n} nodes and has \"\n",
    "              \"the following tree structure:\\n\".format(n=n_nodes))\n",
    "        for i in range(n_nodes):\n",
    "            if is_leaves[i]:\n",
    "                print(\"{space}node={node} is a leaf node.\".format(space=node_depth[i] * \"\\t\", node=i))\n",
    "            else:\n",
    "                print(\"{space}node={node} is a split node: \"\n",
    "                      \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "                      \"else to node {right}.\".format(\n",
    "                          space=node_depth[i] * \"\\t\",\n",
    "                          node=i,\n",
    "                          left=children_left[i],\n",
    "                          feature=feature[i],\n",
    "                          threshold=threshold[i],\n",
    "                          right=children_right[i]))    \n",
    "\n",
    "        \n",
    "    clf=DecisionTreeClassifier(max_depth=config['function_family']['maximum_depth'])\n",
    "    #y_data = [i for i in range(config['data']['num_classes'])]\n",
    "    #X_data = [[0 for i in range(config['data']['number_of_variables'])] for _ in range(config['data']['num_classes'])]\n",
    "    clf.fit(X_data, y_data)\n",
    "    \n",
    "    print(type(clf.tree_.node_count), type(n_nodes))\n",
    "    print(type(clf.tree_.capacity), type(n_nodes))    \n",
    "    clf.tree_.node_count = n_nodes\n",
    "    clf.tree_.capacity = n_nodes\n",
    "    \n",
    "    print(type(clf.tree_.node_count), type(n_nodes))\n",
    "    print(type(clf.tree_.capacity), type(n_nodes))       \n",
    "    \n",
    "    #print(clf.tree_.value, np.array(clf.tree_.value.shape))\n",
    "    #print(value, np.array(value).shape)\n",
    "    \n",
    "    #TODO: FR VALUES NICHT IMMER 50/50 BEI INNER UND 100/0 BEI LEAF, SONDERN: BEI LEAFS ANFANGEN UND DANN DEN PFADEN ENTLANG HOCH-ADDIEREN FR JEDEN PARENT NODE\n",
    "    print('-------------------------------------------------------------')\n",
    "    print(clf.tree_.value.dtype, value.dtype)\n",
    "    print(clf.tree_.impurity.dtype, impurity.dtype)\n",
    "    print(clf.tree_.n_node_samples.dtype, n_node_samples.dtype)\n",
    "    print(clf.tree_.weighted_n_node_samples.dtype, weighted_n_node_samples.dtype)\n",
    "    print(clf.tree_.children_left.dtype, children_left.dtype)\n",
    "    print(clf.tree_.children_right.dtype, children_right.dtype)\n",
    "    print(clf.tree_.feature.dtype, feature.dtype)\n",
    "    print(clf.tree_.threshold.dtype, threshold.dtype)\n",
    "    if True:\n",
    "        for i in indices_list:\n",
    "            print(clf.tree_.value[i].dtype, value[i].dtype)\n",
    "            print(clf.tree_.impurity[i].dtype, impurity[i].dtype)\n",
    "            print(clf.tree_.n_node_samples[i].dtype, n_node_samples[i].dtype)\n",
    "            print(clf.tree_.weighted_n_node_samples[i].dtype, weighted_n_node_samples[i].dtype)\n",
    "            print(clf.tree_.children_left[i].dtype, children_left[i].dtype)\n",
    "            print(clf.tree_.children_right[i].dtype, children_right[i].dtype)\n",
    "            print(clf.tree_.feature[i].dtype, feature[i].dtype)\n",
    "            print(clf.tree_.threshold[i].dtype, threshold[i].dtype)            \n",
    "            \n",
    "            \n",
    "            clf.tree_.children_left[i] = children_left[i]\n",
    "            clf.tree_.children_right[i] = children_right[i]            \n",
    "            clf.tree_.value[i] = value[i]\n",
    "            clf.tree_.impurity[i] = impurity[i]\n",
    "            clf.tree_.n_node_samples[i] = n_node_samples[i]\n",
    "            clf.tree_.weighted_n_node_samples[i] = weighted_n_node_samples[i]\n",
    "            clf.tree_.feature[i] = feature[i]\n",
    "            clf.tree_.threshold[i] = threshold[i]\n",
    "    print('-------------------------------------------------------------')\n",
    "    print(clf.tree_.children_left)\n",
    "    print(clf.tree_.value)\n",
    "    print(clf.tree_.impurity)\n",
    "    print(clf.tree_.n_node_samples)\n",
    "    print(clf.tree_.weighted_n_node_samples)\n",
    "    print(clf.tree_.children_right)\n",
    "    print(clf.tree_.feature)\n",
    "    print(clf.tree_.threshold)            \n",
    "    print('clf.tree_.max_depth', clf.tree_.max_depth)\n",
    "    \n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    node_count : int\n",
    "        The number of nodes (internal nodes + leaves) in the tree.\n",
    "    capacity : int\n",
    "        The current capacity (i.e., size) of the arrays, which is at least as\n",
    "        great as `node_count`.\n",
    "    max_depth : int\n",
    "        The depth of the tree, i.e. the maximum depth of its leaves.\n",
    "    children_left : array of int, shape [node_count]\n",
    "        children_left[i] holds the node id of the left child of node i.\n",
    "        For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
    "        children_left[i] > i. This child handles the case where\n",
    "        X[:, feature[i]] <= threshold[i].\n",
    "    children_right : array of int, shape [node_count]\n",
    "        children_right[i] holds the node id of the right child of node i.\n",
    "        For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
    "        children_right[i] > i. This child handles the case where\n",
    "        X[:, feature[i]] > threshold[i].\n",
    "    feature : array of int, shape [node_count]\n",
    "        feature[i] holds the feature to split on, for the internal node i.\n",
    "    threshold : array of double, shape [node_count]\n",
    "        threshold[i] holds the threshold for the internal node i.\n",
    "    value : array of double, shape [node_count, n_outputs, max_n_classes]\n",
    "        Contains the constant prediction value of each node.\n",
    "    impurity : array of double, shape [node_count]\n",
    "        impurity[i] holds the impurity (i.e., the value of the splitting\n",
    "        criterion) at node i.\n",
    "    n_node_samples : array of int, shape [node_count]\n",
    "        n_node_samples[i] holds the number of training samples reaching node i.\n",
    "    weighted_n_node_samples : array of int, shape [node_count]\n",
    "        weighted_n_node_samples[i] holds the weighted number of training samples\n",
    "        reaching node i.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new_tree = dt_array_to_sklearn(dt_pred, config, printing=True)\n",
    "new_tree = dt_array_to_sklearn(dt_pred, config, X_data, y_data, printing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(36,12))  # set plot size (denoted in inches)\n",
    "plot_tree(new_tree, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_dt.predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tree.predict(X_data[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_function_value_from_vanilla_decision_tree_parameters_wrapper(X_data[:50], config)(dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 3\n",
    "indices_list = [i for i in range(2**(max_depth+1)-1)]\n",
    "print('indices_list', indices_list)\n",
    "pre_order_from_level = np.array(level_to_pre(indices_list, 0, []))\n",
    "print('pre_order_from_level', pre_order_from_level)\n",
    "leaf_indices_pre_order = np.argwhere(pre_order_from_level>=2**max_depth-1).ravel()\n",
    "print(leaf_indices_pre_order)\n",
    "left_indices_pre_order = np.argwhere(pre_order_from_level % 2 != 0).ravel()\n",
    "right_indices_pre_order = np.argwhere(pre_order_from_level % 2 == 0).ravel()[1:]\n",
    "print('left_indices_pre_order', left_indices_pre_order)\n",
    "print('right_indices_pre_order', right_indices_pre_order)\n",
    "\n",
    "counter = 0\n",
    "order = []\n",
    "children_left = []\n",
    "children_right = []\n",
    "for i in range(2**(max_depth+1)-1):\n",
    "    if i in leaf_indices_pre_order:\n",
    "        order.append(-1)\n",
    "        if i in left_indices_pre_order:\n",
    "            children_left.append(-1)\n",
    "        if i in right_indices_pre_order:\n",
    "            children_right.append(-1)        \n",
    "        continue\n",
    "    else:\n",
    "        order.append(counter)\n",
    "        if i in left_indices_pre_order:\n",
    "            children_left.append(counter)\n",
    "        if i in right_indices_pre_order:\n",
    "            children_right.append(counter)           \n",
    "        counter += 1\n",
    "order = np.array(order)\n",
    "children_left = np.array(children_left)\n",
    "children_right = np.array(children_right)\n",
    "\n",
    "print('order', order)\n",
    "print('children_left', children_left)\n",
    "print('children_right', children_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_target_lambda_list = []\n",
    "bc_target_lambda_list = []\n",
    "\n",
    "acc_lambda_decision_list = []\n",
    "bc_lambda_decision_list = []\n",
    "\n",
    "acc_target_decision_list = []\n",
    "bc_target_decision_list = []\n",
    "\n",
    "decision_function_parameters_list = []\n",
    "decision_functio_list = []\n",
    "\n",
    "for lambda_net in tqdm(lambda_net_dataset_test.lambda_net_list):\n",
    "    \n",
    "    target_function_parameters = lambda_net.target_function_parameters\n",
    "    target_function = lambda_net.target_function\n",
    "    \n",
    "    X_test_lambda = lambda_net.X_test_lambda\n",
    "    y_test_lambda = lambda_net.y_test_lambda\n",
    "    \n",
    "    network = lambda_net.network\n",
    "    network_parameters = lambda_net.network_parameters\n",
    "    \n",
    "    if config['i_net']['convolution_layers'] != None or config['i_net']['lstm_layers'] != None or (config['i_net']['nas'] and config['nas_type']['convolution_layers'] != 'SEQUENTIAL'):\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(np.array([network_parameters]), config, subsequences=None)    \n",
    "      \n",
    "    decision_function_parameters= model.predict(np.array([network_parameters]))[0]\n",
    "    decision_function = generate_decision_tree_from_array(decision_function_parameters, config)\n",
    "    \n",
    "    decision_function_parameters_list.append(decision_function_parameters)\n",
    "    decision_functio_list.append(decision_function)\n",
    "    \n",
    "    y_test_network = network.predict(X_test_lambda)\n",
    "    y_test_decision_function = decision_function.predict_proba(X_test_lambda)\n",
    "    y_test_target_function = target_function.predict_proba(X_test_lambda)  \n",
    "    \n",
    "    acc_target_lambda = accuracy_score(np.round(y_test_target_function), np.round(y_test_network))\n",
    "    bc_target_lambda = log_loss(np.round(y_test_target_function), y_test_network, labels=[0, 1])\n",
    "    \n",
    "    acc_lambda_decision = accuracy_score(np.round(y_test_network), np.round(y_test_decision_function))\n",
    "    bc_lambda_decision = log_loss(np.round(y_test_network), y_test_decision_function, labels=[0, 1])        \n",
    "    \n",
    "    acc_target_decision = accuracy_score(np.round(y_test_target_function), np.round(y_test_decision_function))\n",
    "    bc_target_decision = log_loss(np.round(y_test_target_function), y_test_decision_function, labels=[0, 1])   \n",
    "    \n",
    "    \n",
    "    acc_target_lambda_list.append(acc_target_lambda)\n",
    "    bc_target_lambda_list.append(bc_target_lambda)\n",
    "\n",
    "    acc_lambda_decision_list.append(acc_lambda_decision)\n",
    "    bc_lambda_decision_list.append(bc_lambda_decision)\n",
    "\n",
    "    acc_target_decision_list.append(acc_target_decision)\n",
    "    bc_target_decision_list.append(bc_target_decision)\n",
    "    \n",
    "\n",
    "acc_target_lambda_array = np.array(acc_target_lambda_list)\n",
    "bc_target_lambda_array = np.array(bc_target_lambda_list)\n",
    "\n",
    "acc_lambda_decision_array = np.array(acc_lambda_decision_list)\n",
    "bc_lambda_decision_array = np.array(bc_lambda_decision_list)\n",
    "\n",
    "acc_target_decision_array = np.array(acc_target_decision_list)\n",
    "bc_target_decision_array = np.array(bc_target_decision_list)\n",
    "    \n",
    "    \n",
    "acc_target_lambda = np.mean(acc_target_lambda_array)\n",
    "bc_target_lambda = np.mean(bc_target_lambda_array[~np.isnan(bc_target_lambda_array)])\n",
    "\n",
    "acc_lambda_decision = np.mean(acc_lambda_decision_array)\n",
    "bc_lambda_decision = np.mean(bc_lambda_decision_array[~np.isnan(bc_lambda_decision_array)])\n",
    "\n",
    "acc_target_decision = np.mean(acc_target_decision_array)\n",
    "bc_target_decision = np.mean(bc_target_decision_array[~np.isnan(bc_target_decision_array)])\n",
    "\n",
    "\n",
    "print('Accuracy Target Lambda', acc_target_lambda)\n",
    "print('Binary Crossentropy Target Lambda', bc_target_lambda)\n",
    "print('Accuracy Lambda Decision', acc_lambda_decision)\n",
    "print('Binary Crossentropy Lambda Decision', bc_lambda_decision)\n",
    "print('Accuracy Target Decision', acc_target_decision)\n",
    "print('Binary Crossentropy Target Decision', bc_target_decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_test_network).ravel()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_test_decision_function).ravel()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lambda_decision_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO BENCHMARK RANDOM GUESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
