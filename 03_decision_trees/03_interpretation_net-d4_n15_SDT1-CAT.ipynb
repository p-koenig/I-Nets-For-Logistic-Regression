{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:07.875378Z",
     "iopub.status.busy": "2022-01-03T14:46:07.874150Z",
     "iopub.status.idle": "2022-01-03T14:46:07.920801Z",
     "shell.execute_reply": "2022-01-03T14:46:07.918790Z",
     "shell.execute_reply.started": "2022-01-03T14:46:07.875233Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 4,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'SDT', #'SDT', 'vanilla'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 15, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [0,1,2,9],\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': 5, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'random_decision_tree_trained',# 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [1024, 1024, 256, 2048, 2048],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.0001,\n",
    "        'loss': 'binary_crossentropy', #mse; soft_mse; binary_crossentropy; soft_binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['soft_binary_crossentropy', 'binary_accuracy'],\n",
    "        \n",
    "        'epochs': 500, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 10000,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 3, # 1=standard representation; 2=sparse representation with classification for variables; 3=softmax to select classes (n top probabilities)\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "        'soft_labels': False,\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2,3) #3=autoencoder dimensionality reduction\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "            \n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 7,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:07.923407Z",
     "iopub.status.busy": "2022-01-03T14:46:07.922834Z",
     "iopub.status.idle": "2022-01-03T14:46:07.936768Z",
     "shell.execute_reply": "2022-01-03T14:46:07.935307Z",
     "shell.execute_reply.started": "2022-01-03T14:46:07.923352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:07.940828Z",
     "iopub.status.busy": "2022-01-03T14:46:07.940315Z",
     "iopub.status.idle": "2022-01-03T14:46:11.876123Z",
     "shell.execute_reply": "2022-01-03T14:46:11.875237Z",
     "shell.execute_reply.started": "2022-01-03T14:46:07.940739Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:11.877619Z",
     "iopub.status.busy": "2022-01-03T14:46:11.877345Z",
     "iopub.status.idle": "2022-01-03T14:46:11.884924Z",
     "shell.execute_reply": "2022-01-03T14:46:11.884163Z",
     "shell.execute_reply.started": "2022-01-03T14:46:11.877588Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:11.886334Z",
     "iopub.status.busy": "2022-01-03T14:46:11.886018Z",
     "iopub.status.idle": "2022-01-03T14:46:11.905495Z",
     "shell.execute_reply": "2022-01-03T14:46:11.904529Z",
     "shell.execute_reply.started": "2022-01-03T14:46:11.886296Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:11.907436Z",
     "iopub.status.busy": "2022-01-03T14:46:11.907022Z",
     "iopub.status.idle": "2022-01-03T14:46:11.917711Z",
     "shell.execute_reply": "2022-01-03T14:46:11.916759Z",
     "shell.execute_reply.started": "2022-01-03T14:46:11.907394Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:11.919789Z",
     "iopub.status.busy": "2022-01-03T14:46:11.919404Z",
     "iopub.status.idle": "2022-01-03T14:46:14.284811Z",
     "shell.execute_reply": "2022-01-03T14:46:14.284042Z",
     "shell.execute_reply.started": "2022-01-03T14:46:11.919746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type == 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:14.287298Z",
     "iopub.status.busy": "2022-01-03T14:46:14.287032Z",
     "iopub.status.idle": "2022-01-03T14:46:14.291397Z",
     "shell.execute_reply": "2022-01-03T14:46:14.290724Z",
     "shell.execute_reply.started": "2022-01-03T14:46:14.287272Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets10000_var15_class2_random_decision_tree_trained_xMax1_xMin0_xDistuniform_cat0-1-2-9_depth5_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1024-1024-256-2048-2048_drop0.3-0.3-0.3-0.3-0.3e500b256_adam\n",
      "lNetSize5000_numLNets10000_var15_class2_random_decision_tree_trained_xMax1_xMin0_xDistuniform_cat0-1-2-9_depth5_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:14.292561Z",
     "iopub.status.busy": "2022-01-03T14:46:14.292313Z",
     "iopub.status.idle": "2022-01-03T14:46:14.305876Z",
     "shell.execute_reply": "2022-01-03T14:46:14.305148Z",
     "shell.execute_reply.started": "2022-01-03T14:46:14.292525Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:14.307336Z",
     "iopub.status.busy": "2022-01-03T14:46:14.306984Z",
     "iopub.status.idle": "2022-01-03T14:46:14.319558Z",
     "shell.execute_reply": "2022-01-03T14:46:14.318836Z",
     "shell.execute_reply.started": "2022-01-03T14:46:14.307310Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "       \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              config) for network_parameters_row in network_parameters.values)          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    #def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "    #    lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "    \n",
    "    #def initialize_target_function_wrapper(config, lambda_net):\n",
    "    #    lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:14.323840Z",
     "iopub.status.busy": "2022-01-03T14:46:14.323325Z",
     "iopub.status.idle": "2022-01-03T14:46:35.490738Z",
     "shell.execute_reply": "2022-01-03T14:46:35.489742Z",
     "shell.execute_reply.started": "2022-01-03T14:46:14.323810Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=7)]: Done 540 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=7)]: Done 9892 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=7)]: Done 10000 out of 10000 | elapsed:   12.1s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "    if False:\n",
    "        lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_train_with_valid = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)   \n",
    "        \n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:35.492537Z",
     "iopub.status.busy": "2022-01-03T14:46:35.492301Z",
     "iopub.status.idle": "2022-01-03T14:46:35.498539Z",
     "shell.execute_reply": "2022-01-03T14:46:35.497686Z",
     "shell.execute_reply.started": "2022-01-03T14:46:35.492504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8955, 2451)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:35.500091Z",
     "iopub.status.busy": "2022-01-03T14:46:35.499826Z",
     "iopub.status.idle": "2022-01-03T14:46:35.521392Z",
     "shell.execute_reply": "2022-01-03T14:46:35.520685Z",
     "shell.execute_reply.started": "2022-01-03T14:46:35.500065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 2451)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:35.522645Z",
     "iopub.status.busy": "2022-01-03T14:46:35.522365Z",
     "iopub.status.idle": "2022-01-03T14:46:35.527595Z",
     "shell.execute_reply": "2022-01-03T14:46:35.526986Z",
     "shell.execute_reply.started": "2022-01-03T14:46:35.522619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2451)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:35.528709Z",
     "iopub.status.busy": "2022-01-03T14:46:35.528465Z",
     "iopub.status.idle": "2022-01-03T14:46:44.360911Z",
     "shell.execute_reply": "2022-01-03T14:46:44.360312Z",
     "shell.execute_reply.started": "2022-01-03T14:46:35.528684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f3v10</th>\n",
       "      <th>f3v11</th>\n",
       "      <th>f3v12</th>\n",
       "      <th>f3v13</th>\n",
       "      <th>f3v14</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f4v10</th>\n",
       "      <th>f4v11</th>\n",
       "      <th>f4v12</th>\n",
       "      <th>f4v13</th>\n",
       "      <th>f4v14</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f5v10</th>\n",
       "      <th>f5v11</th>\n",
       "      <th>f5v12</th>\n",
       "      <th>f5v13</th>\n",
       "      <th>f5v14</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_2077</th>\n",
       "      <th>wb_2078</th>\n",
       "      <th>wb_2079</th>\n",
       "      <th>wb_2080</th>\n",
       "      <th>wb_2081</th>\n",
       "      <th>wb_2082</th>\n",
       "      <th>wb_2083</th>\n",
       "      <th>wb_2084</th>\n",
       "      <th>wb_2085</th>\n",
       "      <th>wb_2086</th>\n",
       "      <th>wb_2087</th>\n",
       "      <th>wb_2088</th>\n",
       "      <th>wb_2089</th>\n",
       "      <th>wb_2090</th>\n",
       "      <th>wb_2091</th>\n",
       "      <th>wb_2092</th>\n",
       "      <th>wb_2093</th>\n",
       "      <th>wb_2094</th>\n",
       "      <th>wb_2095</th>\n",
       "      <th>wb_2096</th>\n",
       "      <th>wb_2097</th>\n",
       "      <th>wb_2098</th>\n",
       "      <th>wb_2099</th>\n",
       "      <th>wb_2100</th>\n",
       "      <th>wb_2101</th>\n",
       "      <th>wb_2102</th>\n",
       "      <th>wb_2103</th>\n",
       "      <th>wb_2104</th>\n",
       "      <th>wb_2105</th>\n",
       "      <th>wb_2106</th>\n",
       "      <th>wb_2107</th>\n",
       "      <th>wb_2108</th>\n",
       "      <th>wb_2109</th>\n",
       "      <th>wb_2110</th>\n",
       "      <th>wb_2111</th>\n",
       "      <th>wb_2112</th>\n",
       "      <th>wb_2113</th>\n",
       "      <th>wb_2114</th>\n",
       "      <th>wb_2115</th>\n",
       "      <th>wb_2116</th>\n",
       "      <th>wb_2117</th>\n",
       "      <th>wb_2118</th>\n",
       "      <th>wb_2119</th>\n",
       "      <th>wb_2120</th>\n",
       "      <th>wb_2121</th>\n",
       "      <th>wb_2122</th>\n",
       "      <th>wb_2123</th>\n",
       "      <th>wb_2124</th>\n",
       "      <th>wb_2125</th>\n",
       "      <th>wb_2126</th>\n",
       "      <th>wb_2127</th>\n",
       "      <th>wb_2128</th>\n",
       "      <th>wb_2129</th>\n",
       "      <th>wb_2130</th>\n",
       "      <th>wb_2131</th>\n",
       "      <th>wb_2132</th>\n",
       "      <th>wb_2133</th>\n",
       "      <th>wb_2134</th>\n",
       "      <th>wb_2135</th>\n",
       "      <th>wb_2136</th>\n",
       "      <th>wb_2137</th>\n",
       "      <th>wb_2138</th>\n",
       "      <th>wb_2139</th>\n",
       "      <th>wb_2140</th>\n",
       "      <th>wb_2141</th>\n",
       "      <th>wb_2142</th>\n",
       "      <th>wb_2143</th>\n",
       "      <th>wb_2144</th>\n",
       "      <th>wb_2145</th>\n",
       "      <th>wb_2146</th>\n",
       "      <th>wb_2147</th>\n",
       "      <th>wb_2148</th>\n",
       "      <th>wb_2149</th>\n",
       "      <th>wb_2150</th>\n",
       "      <th>wb_2151</th>\n",
       "      <th>wb_2152</th>\n",
       "      <th>wb_2153</th>\n",
       "      <th>wb_2154</th>\n",
       "      <th>wb_2155</th>\n",
       "      <th>wb_2156</th>\n",
       "      <th>wb_2157</th>\n",
       "      <th>wb_2158</th>\n",
       "      <th>wb_2159</th>\n",
       "      <th>wb_2160</th>\n",
       "      <th>wb_2161</th>\n",
       "      <th>wb_2162</th>\n",
       "      <th>wb_2163</th>\n",
       "      <th>wb_2164</th>\n",
       "      <th>wb_2165</th>\n",
       "      <th>wb_2166</th>\n",
       "      <th>wb_2167</th>\n",
       "      <th>wb_2168</th>\n",
       "      <th>wb_2169</th>\n",
       "      <th>wb_2170</th>\n",
       "      <th>wb_2171</th>\n",
       "      <th>wb_2172</th>\n",
       "      <th>wb_2173</th>\n",
       "      <th>wb_2174</th>\n",
       "      <th>wb_2175</th>\n",
       "      <th>wb_2176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>6671.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.112</td>\n",
       "      <td>-1.775</td>\n",
       "      <td>0.943</td>\n",
       "      <td>1.772</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-1.928</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-2.207</td>\n",
       "      <td>0.267</td>\n",
       "      <td>1.920</td>\n",
       "      <td>2.739</td>\n",
       "      <td>1.808</td>\n",
       "      <td>1.195</td>\n",
       "      <td>0.932</td>\n",
       "      <td>1.354</td>\n",
       "      <td>-2.334</td>\n",
       "      <td>0.858</td>\n",
       "      <td>-1.573</td>\n",
       "      <td>2.354</td>\n",
       "      <td>-0.852</td>\n",
       "      <td>-1.120</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-1.303</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>1.515</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-1.069</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-1.159</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-1.179</td>\n",
       "      <td>0.207</td>\n",
       "      <td>1.329</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-1.155</td>\n",
       "      <td>-1.199</td>\n",
       "      <td>-1.191</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-1.307</td>\n",
       "      <td>-1.603</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-2.431</td>\n",
       "      <td>-1.751</td>\n",
       "      <td>-2.337</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.308</td>\n",
       "      <td>2.599</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>-1.408</td>\n",
       "      <td>3.288</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>0.653</td>\n",
       "      <td>-0.814</td>\n",
       "      <td>-1.457</td>\n",
       "      <td>-1.549</td>\n",
       "      <td>0.207</td>\n",
       "      <td>1.061</td>\n",
       "      <td>2.258</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.156</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>1.814</td>\n",
       "      <td>0.664</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>3274.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.428</td>\n",
       "      <td>1.318</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-1.292</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.315</td>\n",
       "      <td>1.239</td>\n",
       "      <td>0.082</td>\n",
       "      <td>1.054</td>\n",
       "      <td>-0.608</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-1.521</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>0.806</td>\n",
       "      <td>-1.240</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>1.165</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>-0.573</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-1.136</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>0.616</td>\n",
       "      <td>-0.738</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.878</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.581</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>-1.205</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>-1.272</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-1.311</td>\n",
       "      <td>1.346</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.986</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-1.470</td>\n",
       "      <td>0.316</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>3095.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.778</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.565</td>\n",
       "      <td>3.658</td>\n",
       "      <td>1.028</td>\n",
       "      <td>-2.062</td>\n",
       "      <td>2.760</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.631</td>\n",
       "      <td>-2.254</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>1.112</td>\n",
       "      <td>1.845</td>\n",
       "      <td>2.353</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.091</td>\n",
       "      <td>3.047</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.390</td>\n",
       "      <td>-1.858</td>\n",
       "      <td>1.065</td>\n",
       "      <td>-2.277</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-1.024</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-2.261</td>\n",
       "      <td>-1.059</td>\n",
       "      <td>1.012</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-2.077</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.450</td>\n",
       "      <td>-2.193</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-2.031</td>\n",
       "      <td>1.648</td>\n",
       "      <td>0.637</td>\n",
       "      <td>-1.381</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-1.542</td>\n",
       "      <td>-1.885</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>1.261</td>\n",
       "      <td>-1.265</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.715</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.659</td>\n",
       "      <td>-1.329</td>\n",
       "      <td>-1.433</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.763</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-1.619</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-3.276</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.540</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-1.703</td>\n",
       "      <td>2.913</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>3.377</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-1.650</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.586</td>\n",
       "      <td>3.655</td>\n",
       "      <td>3.649</td>\n",
       "      <td>0.190</td>\n",
       "      <td>3.579</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>0.447</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.228</td>\n",
       "      <td>-1.459</td>\n",
       "      <td>-1.118</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>8379.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.806</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.829</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-1.203</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>0.370</td>\n",
       "      <td>-1.437</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-1.353</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.823</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.541</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.736</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.213</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-1.050</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.508</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>1.273</td>\n",
       "      <td>-1.010</td>\n",
       "      <td>-1.028</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.331</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>3043.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-0.944</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.222</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.884</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-1.664</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>0.588</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-1.431</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.389</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.683</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-1.249</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.420</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.583</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.653</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.755</td>\n",
       "      <td>-0.819</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.642</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>1.029</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "6671 6671.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 3274.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 3095.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 8379.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 3043.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f1v0  f1v1  f1v2  f1v3  f1v4  \\\n",
       "6671 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v5  f1v6  f1v7  f1v8  f1v9  f1v10  f1v11  f1v12  f1v13  f1v14  f2v0  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "      f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  f2v11  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "      f2v12  f2v13  f2v14  f3v0  f3v1  f3v2  f3v3  f3v4  f3v5  f3v6  f3v7  \\\n",
       "6671  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f3v8  f3v9  f3v10  f3v11  f3v12  f3v13  f3v14  f4v0  f4v1  f4v2  f4v3  \\\n",
       "6671 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "3274 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "3095 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "8379 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "3043 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f4v4  f4v5  f4v6  f4v7  f4v8  f4v9  f4v10  f4v11  f4v12  f4v13  f4v14  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  f5v7  f5v8  f5v9  f5v10  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "\n",
       "      f5v11  f5v12  f5v13  f5v14  f6v0  f6v1  f6v2  f6v3  f6v4  f6v5  f6v6  \\\n",
       "6671  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f6v7  ...  wb_2077  wb_2078  wb_2079  wb_2080  wb_2081  wb_2082  \\\n",
       "6671 0.000  ...   -1.112   -1.775    0.943    1.772    0.248   -1.928   \n",
       "3274 0.000  ...    0.054   -0.175    0.428    1.318    0.357   -0.273   \n",
       "3095 0.000  ...    2.778   -0.254    0.565    3.658    1.028   -2.062   \n",
       "8379 0.000  ...    0.310   -0.442    0.304    0.868    0.200   -0.288   \n",
       "3043 0.000  ...    0.870   -0.944    0.276    0.174    0.222   -0.310   \n",
       "\n",
       "      wb_2083  wb_2084  wb_2085  wb_2086  wb_2087  wb_2088  wb_2089  wb_2090  \\\n",
       "6671    0.221    0.235    0.266    0.269   -2.207    0.267    1.920    2.739   \n",
       "3274    0.048    0.293    0.287    0.282   -1.292    0.259    0.773    0.693   \n",
       "3095    2.760    0.831    0.112    0.631   -2.254   -0.147    1.112    1.845   \n",
       "8379    0.052    0.217    0.232    0.108   -0.569    0.213    0.097    0.340   \n",
       "3043    0.518    0.389    0.323    0.366   -0.468   -0.711    0.300    0.305   \n",
       "\n",
       "      wb_2091  wb_2092  wb_2093  wb_2094  wb_2095  wb_2096  wb_2097  wb_2098  \\\n",
       "6671    1.808    1.195    0.932    1.354   -2.334    0.858   -1.573    2.354   \n",
       "3274    0.315    1.239    0.082    1.054   -0.608    0.368   -1.521    0.431   \n",
       "3095    2.353    1.247    0.091    3.047   -0.239    0.390   -1.858    1.065   \n",
       "8379    0.232    0.527    0.343    0.322   -0.427    0.321   -0.411    0.806   \n",
       "3043    0.309    0.296    0.269    0.884   -0.412    0.076   -1.664    0.405   \n",
       "\n",
       "      wb_2099  wb_2100  wb_2101  wb_2102  wb_2103  wb_2104  wb_2105  wb_2106  \\\n",
       "6671   -0.852   -1.120   -0.113    0.281    0.399    0.206   -1.303   -0.143   \n",
       "3274   -0.411   -0.657   -0.102   -0.266    0.651    0.214   -0.561   -0.797   \n",
       "3095   -2.277   -0.967   -0.113   -1.024    0.258    0.153   -2.261   -1.059   \n",
       "8379   -0.063   -0.829   -0.113    0.320    0.208    0.157   -1.203   -0.490   \n",
       "3043   -0.763   -0.772   -0.113   -0.169    0.289    0.225   -0.715   -0.568   \n",
       "\n",
       "      wb_2107  wb_2108  wb_2109  wb_2110  wb_2111  wb_2112  wb_2113  wb_2114  \\\n",
       "6671    1.515   -1.033    0.224   -0.739    0.514   -1.069   -1.002    0.152   \n",
       "3274    0.806   -1.240    0.190   -0.497    1.165    0.458   -0.105    0.147   \n",
       "3095    1.012   -0.064    0.542   -0.218    0.746    0.365   -2.077    0.126   \n",
       "8379    0.370   -1.437    0.298   -0.579    0.257    0.230   -1.353    0.171   \n",
       "3043    0.313   -0.443    0.102   -0.513    0.588   -0.884   -0.908    0.224   \n",
       "\n",
       "      wb_2115  wb_2116  wb_2117  wb_2118  wb_2119  wb_2120  wb_2121  wb_2122  \\\n",
       "6671   -0.329   -0.164   -0.938   -0.081    0.138   -0.207   -1.159    0.171   \n",
       "3274    0.084   -0.148   -0.575   -0.573    0.890    0.256   -1.136    0.460   \n",
       "3095    0.450   -2.193   -0.097   -2.031    1.648    0.637   -1.381   -0.116   \n",
       "8379   -0.163   -0.491   -0.107    0.571    0.282    0.054   -0.565   -0.827   \n",
       "3043    0.217   -0.307   -0.545   -0.797    0.192    0.479   -0.960    0.267   \n",
       "\n",
       "      wb_2123  wb_2124  wb_2125  wb_2126  wb_2127  wb_2128  wb_2129  wb_2130  \\\n",
       "6671   -0.480   -1.179    0.207    1.329   -0.925    0.024   -0.423   -0.396   \n",
       "3274   -0.437   -0.334    0.505    0.275   -0.364   -0.369   -0.148   -0.329   \n",
       "3095   -1.533   -0.694    0.544    0.608   -0.974   -1.542   -1.885   -0.258   \n",
       "8379   -0.292   -0.264   -0.402    0.260   -0.823   -0.179   -0.541   -0.279   \n",
       "3043   -0.127   -1.431    0.340    0.389   -0.866   -0.024   -0.190   -0.348   \n",
       "\n",
       "      wb_2131  wb_2132  wb_2133  wb_2134  wb_2135  wb_2136  wb_2137  wb_2138  \\\n",
       "6671    0.306   -1.155   -1.199   -1.191    0.255   -0.763    0.122    0.263   \n",
       "3274    0.616   -0.738   -1.114   -0.531    0.094   -0.196   -0.878    0.229   \n",
       "3095    1.261   -1.265   -0.178   -0.189    0.357   -0.331   -0.108    0.715   \n",
       "8379    0.610    0.233   -0.684   -0.800    0.082   -0.141   -0.736    0.135   \n",
       "3043    0.056    0.185   -0.683   -0.156    0.244   -0.139    0.231    0.334   \n",
       "\n",
       "      wb_2139  wb_2140  wb_2141  wb_2142  wb_2143  wb_2144  wb_2145  wb_2146  \\\n",
       "6671   -0.234   -0.542    0.102    0.269   -1.307   -1.603    0.418    0.172   \n",
       "3274   -0.351   -0.050    0.049    0.366   -0.213   -0.581    0.295    0.323   \n",
       "3095   -0.214   -0.176    0.191    0.659   -1.329   -1.433    0.340    0.763   \n",
       "8379   -0.233   -0.220    0.050    0.111    0.213   -0.362    0.291    0.168   \n",
       "3043   -0.166   -1.249    0.163    0.415    0.206   -0.387    0.192    0.138   \n",
       "\n",
       "      wb_2147  wb_2148  wb_2149  wb_2150  wb_2151  wb_2152  wb_2153  wb_2154  \\\n",
       "6671   -2.431   -1.751   -2.337   -0.892   -0.106    0.264    0.308    2.599   \n",
       "3274   -0.146   -1.350   -1.205   -0.302   -1.272    0.206    0.363    0.091   \n",
       "3095   -0.600   -1.619   -0.242   -3.276   -0.630    0.141    0.741    0.090   \n",
       "8379   -0.499   -1.050   -0.476   -0.311   -0.980    0.210    0.355    0.747   \n",
       "3043   -0.620   -0.216   -0.431   -0.773   -0.098    0.232    0.287    0.086   \n",
       "\n",
       "      wb_2155  wb_2156  wb_2157  wb_2158  wb_2159  wb_2160  wb_2161  wb_2162  \\\n",
       "6671    1.693   -1.006   -1.408    3.288   -0.079   -0.635    0.653   -0.814   \n",
       "3274    0.054   -0.648   -1.311    1.346   -0.692   -0.193    0.986   -0.087   \n",
       "3095    2.540   -0.286   -1.703    2.913   -1.068   -0.082    3.377   -0.093   \n",
       "8379    0.508   -1.027   -0.044    1.273   -1.010   -1.028    0.380    0.243   \n",
       "3043    0.420   -0.181   -0.317    0.583   -0.599   -0.242    0.653   -0.196   \n",
       "\n",
       "      wb_2163  wb_2164  wb_2165  wb_2166  wb_2167  wb_2168  wb_2169  wb_2170  \\\n",
       "6671   -1.457   -1.549    0.207    1.061    2.258    0.093    1.156    0.017   \n",
       "3274   -1.470    0.316    1.034    1.031    0.118    0.052    0.406   -0.361   \n",
       "3095   -1.650   -0.177    0.586    3.655    3.649    0.190    3.579   -0.576   \n",
       "8379   -0.288   -0.122    0.246    0.355    0.134    0.087    0.331   -0.047   \n",
       "3043   -0.755   -0.819    0.253    0.767    0.282    0.128    0.642   -0.051   \n",
       "\n",
       "      wb_2171  wb_2172  wb_2173  wb_2174  wb_2175  wb_2176  \n",
       "6671    0.147   -0.858    1.814    0.664   -0.198   -0.006  \n",
       "3274    0.544   -0.900    0.093   -0.733   -0.135    0.048  \n",
       "3095    0.447   -0.189    1.228   -1.459   -1.118    0.035  \n",
       "8379   -0.189   -0.276    0.435    0.230    0.113    0.120  \n",
       "3043    0.455   -0.449    1.029   -0.374   -0.166   -0.135  \n",
       "\n",
       "[5 rows x 2451 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:44.362133Z",
     "iopub.status.busy": "2022-01-03T14:46:44.361884Z",
     "iopub.status.idle": "2022-01-03T14:46:45.524831Z",
     "shell.execute_reply": "2022-01-03T14:46:45.524238Z",
     "shell.execute_reply.started": "2022-01-03T14:46:44.362106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f3v10</th>\n",
       "      <th>f3v11</th>\n",
       "      <th>f3v12</th>\n",
       "      <th>f3v13</th>\n",
       "      <th>f3v14</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f4v10</th>\n",
       "      <th>f4v11</th>\n",
       "      <th>f4v12</th>\n",
       "      <th>f4v13</th>\n",
       "      <th>f4v14</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f5v10</th>\n",
       "      <th>f5v11</th>\n",
       "      <th>f5v12</th>\n",
       "      <th>f5v13</th>\n",
       "      <th>f5v14</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_2077</th>\n",
       "      <th>wb_2078</th>\n",
       "      <th>wb_2079</th>\n",
       "      <th>wb_2080</th>\n",
       "      <th>wb_2081</th>\n",
       "      <th>wb_2082</th>\n",
       "      <th>wb_2083</th>\n",
       "      <th>wb_2084</th>\n",
       "      <th>wb_2085</th>\n",
       "      <th>wb_2086</th>\n",
       "      <th>wb_2087</th>\n",
       "      <th>wb_2088</th>\n",
       "      <th>wb_2089</th>\n",
       "      <th>wb_2090</th>\n",
       "      <th>wb_2091</th>\n",
       "      <th>wb_2092</th>\n",
       "      <th>wb_2093</th>\n",
       "      <th>wb_2094</th>\n",
       "      <th>wb_2095</th>\n",
       "      <th>wb_2096</th>\n",
       "      <th>wb_2097</th>\n",
       "      <th>wb_2098</th>\n",
       "      <th>wb_2099</th>\n",
       "      <th>wb_2100</th>\n",
       "      <th>wb_2101</th>\n",
       "      <th>wb_2102</th>\n",
       "      <th>wb_2103</th>\n",
       "      <th>wb_2104</th>\n",
       "      <th>wb_2105</th>\n",
       "      <th>wb_2106</th>\n",
       "      <th>wb_2107</th>\n",
       "      <th>wb_2108</th>\n",
       "      <th>wb_2109</th>\n",
       "      <th>wb_2110</th>\n",
       "      <th>wb_2111</th>\n",
       "      <th>wb_2112</th>\n",
       "      <th>wb_2113</th>\n",
       "      <th>wb_2114</th>\n",
       "      <th>wb_2115</th>\n",
       "      <th>wb_2116</th>\n",
       "      <th>wb_2117</th>\n",
       "      <th>wb_2118</th>\n",
       "      <th>wb_2119</th>\n",
       "      <th>wb_2120</th>\n",
       "      <th>wb_2121</th>\n",
       "      <th>wb_2122</th>\n",
       "      <th>wb_2123</th>\n",
       "      <th>wb_2124</th>\n",
       "      <th>wb_2125</th>\n",
       "      <th>wb_2126</th>\n",
       "      <th>wb_2127</th>\n",
       "      <th>wb_2128</th>\n",
       "      <th>wb_2129</th>\n",
       "      <th>wb_2130</th>\n",
       "      <th>wb_2131</th>\n",
       "      <th>wb_2132</th>\n",
       "      <th>wb_2133</th>\n",
       "      <th>wb_2134</th>\n",
       "      <th>wb_2135</th>\n",
       "      <th>wb_2136</th>\n",
       "      <th>wb_2137</th>\n",
       "      <th>wb_2138</th>\n",
       "      <th>wb_2139</th>\n",
       "      <th>wb_2140</th>\n",
       "      <th>wb_2141</th>\n",
       "      <th>wb_2142</th>\n",
       "      <th>wb_2143</th>\n",
       "      <th>wb_2144</th>\n",
       "      <th>wb_2145</th>\n",
       "      <th>wb_2146</th>\n",
       "      <th>wb_2147</th>\n",
       "      <th>wb_2148</th>\n",
       "      <th>wb_2149</th>\n",
       "      <th>wb_2150</th>\n",
       "      <th>wb_2151</th>\n",
       "      <th>wb_2152</th>\n",
       "      <th>wb_2153</th>\n",
       "      <th>wb_2154</th>\n",
       "      <th>wb_2155</th>\n",
       "      <th>wb_2156</th>\n",
       "      <th>wb_2157</th>\n",
       "      <th>wb_2158</th>\n",
       "      <th>wb_2159</th>\n",
       "      <th>wb_2160</th>\n",
       "      <th>wb_2161</th>\n",
       "      <th>wb_2162</th>\n",
       "      <th>wb_2163</th>\n",
       "      <th>wb_2164</th>\n",
       "      <th>wb_2165</th>\n",
       "      <th>wb_2166</th>\n",
       "      <th>wb_2167</th>\n",
       "      <th>wb_2168</th>\n",
       "      <th>wb_2169</th>\n",
       "      <th>wb_2170</th>\n",
       "      <th>wb_2171</th>\n",
       "      <th>wb_2172</th>\n",
       "      <th>wb_2173</th>\n",
       "      <th>wb_2174</th>\n",
       "      <th>wb_2175</th>\n",
       "      <th>wb_2176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>3466.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.315</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.509</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.796</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>0.910</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.821</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.588</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.468</td>\n",
       "      <td>1.063</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>1.297</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-0.873</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.291</td>\n",
       "      <td>1.465</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-2.142</td>\n",
       "      <td>1.524</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.580</td>\n",
       "      <td>1.083</td>\n",
       "      <td>0.861</td>\n",
       "      <td>1.550</td>\n",
       "      <td>1.820</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-1.417</td>\n",
       "      <td>1.327</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>0.613</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>1.304</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.497</td>\n",
       "      <td>-1.253</td>\n",
       "      <td>-0.676</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-1.166</td>\n",
       "      <td>-1.265</td>\n",
       "      <td>-1.178</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>1.315</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.403</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>0.169</td>\n",
       "      <td>1.633</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>-0.795</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.242</td>\n",
       "      <td>1.236</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-1.001</td>\n",
       "      <td>-1.658</td>\n",
       "      <td>0.852</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>-1.518</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.057</td>\n",
       "      <td>1.711</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.639</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4148.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.069</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.229</td>\n",
       "      <td>1.230</td>\n",
       "      <td>0.713</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>1.406</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.292</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.779</td>\n",
       "      <td>1.453</td>\n",
       "      <td>0.708</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>1.119</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.451</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.650</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.707</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.354</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.863</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.768</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.174</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>1.360</td>\n",
       "      <td>1.153</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.954</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>0.089</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.707</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.090</td>\n",
       "      <td>1.123</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.175</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>0.855</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>1.176</td>\n",
       "      <td>1.372</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.642</td>\n",
       "      <td>1.388</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>1.249</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>2815.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>0.618</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.331</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.391</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.563</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.456</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.573</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185</th>\n",
       "      <td>5185.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1.114</td>\n",
       "      <td>0.755</td>\n",
       "      <td>-2.033</td>\n",
       "      <td>1.162</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.173</td>\n",
       "      <td>2.628</td>\n",
       "      <td>1.739</td>\n",
       "      <td>1.385</td>\n",
       "      <td>0.884</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>1.220</td>\n",
       "      <td>-1.283</td>\n",
       "      <td>1.712</td>\n",
       "      <td>-1.777</td>\n",
       "      <td>-1.097</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>0.752</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.409</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.923</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>1.273</td>\n",
       "      <td>1.550</td>\n",
       "      <td>-1.413</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.932</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-1.711</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.772</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>1.164</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.873</td>\n",
       "      <td>-2.139</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>1.414</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>0.562</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-1.047</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>-1.276</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-1.249</td>\n",
       "      <td>0.183</td>\n",
       "      <td>1.774</td>\n",
       "      <td>1.389</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>1.342</td>\n",
       "      <td>-1.046</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.449</td>\n",
       "      <td>-1.192</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>1.153</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.501</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>1.312</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "3466 3466.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689   689.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 4148.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 2815.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 5185.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f1v0  f1v1  f1v2  f1v3  f1v4  \\\n",
       "3466 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689  0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v5  f1v6  f1v7  f1v8  f1v9  f1v10  f1v11  f1v12  f1v13  f1v14  f2v0  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "      f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  f2v11  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "      f2v12  f2v13  f2v14  f3v0  f3v1  f3v2  f3v3  f3v4  f3v5  f3v6  f3v7  \\\n",
       "3466  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689   0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f3v8  f3v9  f3v10  f3v11  f3v12  f3v13  f3v14  f4v0  f4v1  f4v2  f4v3  \\\n",
       "3466 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "689  0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "4148 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "2815 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "5185 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f4v4  f4v5  f4v6  f4v7  f4v8  f4v9  f4v10  f4v11  f4v12  f4v13  f4v14  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  f5v7  f5v8  f5v9  f5v10  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "\n",
       "      f5v11  f5v12  f5v13  f5v14  f6v0  f6v1  f6v2  f6v3  f6v4  f6v5  f6v6  \\\n",
       "3466  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689   0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f6v7  ...  wb_2077  wb_2078  wb_2079  wb_2080  wb_2081  wb_2082  \\\n",
       "3466 0.000  ...    1.315   -0.378    0.600    0.457    0.290   -0.046   \n",
       "689  0.000  ...    0.607   -0.322    0.459    0.515    0.414   -2.142   \n",
       "4148 0.000  ...    1.069   -0.215    0.229    1.230    0.713   -0.646   \n",
       "2815 0.000  ...   -0.052   -0.050    0.108    0.173    0.413   -0.504   \n",
       "5185 0.000  ...    0.838   -0.350    0.573    1.114    0.755   -2.033   \n",
       "\n",
       "      wb_2083  wb_2084  wb_2085  wb_2086  wb_2087  wb_2088  wb_2089  wb_2090  \\\n",
       "3466    0.271   -0.561    0.206   -0.354   -0.509    0.622    0.849    0.796   \n",
       "689     1.524   -0.610    0.266    0.273   -0.717    0.309    0.267    0.580   \n",
       "4148    1.406   -0.169    0.151    0.109   -0.761    0.648    0.467    0.292   \n",
       "2815    0.565    0.472    0.319    0.315   -0.248    0.293    0.065    0.430   \n",
       "5185    1.162   -0.841    0.141   -0.282   -0.163   -0.222    0.223    0.173   \n",
       "\n",
       "      wb_2091  wb_2092  wb_2093  wb_2094  wb_2095  wb_2096  wb_2097  wb_2098  \\\n",
       "3466    1.047    0.410    0.354    0.337   -0.558    0.179   -0.646    0.910   \n",
       "689     1.083    0.861    1.550    1.820   -0.931    0.456   -1.417    1.327   \n",
       "4148    1.308    0.779    1.453    0.708   -0.606    1.119   -0.166    1.451   \n",
       "2815    0.363    0.590    0.599    0.198   -0.562    0.510   -0.561    0.618   \n",
       "5185    2.628    1.739    1.385    0.884   -0.269    1.220   -1.283    1.712   \n",
       "\n",
       "      wb_2099  wb_2100  wb_2101  wb_2102  wb_2103  wb_2104  wb_2105  wb_2106  \\\n",
       "3466   -0.519   -0.809   -0.113   -0.170    0.315   -0.101   -1.095   -0.326   \n",
       "689    -1.350   -0.157   -0.113   -0.506    0.613   -0.069   -0.769   -0.251   \n",
       "4148   -0.059   -0.650   -0.632   -0.191    0.707   -0.024   -0.716   -0.221   \n",
       "2815   -0.277   -0.589   -0.113   -0.325    0.363    0.292   -0.357   -0.405   \n",
       "5185   -1.777   -1.097   -0.113   -0.402    0.752   -0.014   -2.173   -0.240   \n",
       "\n",
       "      wb_2107  wb_2108  wb_2109  wb_2110  wb_2111  wb_2112  wb_2113  wb_2114  \\\n",
       "3466    0.211   -0.811    0.102   -0.210    0.451   -0.357   -0.821   -0.105   \n",
       "689     1.304   -0.853    0.236   -0.181    0.415    0.497   -1.253   -0.676   \n",
       "4148    0.354   -0.500    0.169   -0.533    0.446    0.142   -0.461   -0.016   \n",
       "2815    0.105   -0.068    0.331   -0.414    0.550    0.391   -0.114    0.219   \n",
       "5185    0.409   -0.065    0.923   -0.191    1.273    1.550   -1.413    0.759   \n",
       "\n",
       "      wb_2115  wb_2116  wb_2117  wb_2118  wb_2119  wb_2120  wb_2121  wb_2122  \\\n",
       "3466    0.208   -0.318   -0.102   -0.398    0.707    0.195   -0.300   -0.167   \n",
       "689     0.254   -1.166   -1.265   -1.178    0.454    0.275   -0.465   -0.304   \n",
       "4148    0.863   -0.428   -0.099   -0.220    0.913    0.768   -0.416    0.914   \n",
       "2815    0.374   -0.513   -0.102    0.079    0.405    0.373   -0.057   -0.371   \n",
       "5185    0.932   -0.562   -1.711   -0.330    0.986    0.772   -0.625   -0.166   \n",
       "\n",
       "      wb_2123  wb_2124  wb_2125  wb_2126  wb_2127  wb_2128  wb_2129  wb_2130  \\\n",
       "3466   -0.311   -0.387   -0.332    0.179   -0.973   -0.209   -0.259   -0.265   \n",
       "689    -0.310   -0.397   -0.801    1.315   -0.526    0.310   -0.568   -0.302   \n",
       "4148   -0.137   -0.191    1.225    1.174   -0.569   -0.170   -0.191   -0.203   \n",
       "2815   -0.134    0.036    0.487    0.563   -0.556   -0.327   -0.409   -0.410   \n",
       "5185   -0.253    1.164   -0.204    0.873   -2.139   -0.125   -0.470   -0.151   \n",
       "\n",
       "      wb_2131  wb_2132  wb_2133  wb_2134  wb_2135  wb_2136  wb_2137  wb_2138  \\\n",
       "3466    0.966    0.252   -0.161   -0.351    0.128   -0.165    0.163    0.316   \n",
       "689     0.436   -0.303   -0.590   -0.937    0.099   -0.079    0.410    0.327   \n",
       "4148    1.360    1.153   -0.165   -0.471    0.034   -0.096    1.196    0.954   \n",
       "2815    0.540    0.431   -0.420   -0.427   -0.089   -0.315   -0.361    0.377   \n",
       "5185    1.414    0.118   -0.123   -0.418    0.115   -0.129   -0.538    0.562   \n",
       "\n",
       "      wb_2139  wb_2140  wb_2141  wb_2142  wb_2143  wb_2144  wb_2145  wb_2146  \\\n",
       "3466   -0.263   -0.375    0.074    0.755    0.148   -0.188    0.076    0.588   \n",
       "689    -0.223   -1.524    0.170    1.403   -0.495   -0.555    0.169    1.633   \n",
       "4148   -0.233   -0.572    0.089    1.148   -0.154   -0.235    0.111    0.707   \n",
       "2815   -0.385   -0.049   -0.024    0.456   -0.395   -0.249    0.363    0.256   \n",
       "5185   -0.287   -0.391    0.091    0.851    0.122   -1.047    0.369    0.282   \n",
       "\n",
       "      wb_2147  wb_2148  wb_2149  wb_2150  wb_2151  wb_2152  wb_2153  wb_2154  \\\n",
       "3466   -0.223   -0.451   -0.584   -0.245   -0.099    0.064    0.468    1.063   \n",
       "689    -0.533   -0.605   -0.694   -0.452   -0.795    0.137    0.242    1.236   \n",
       "4148   -0.247   -0.649   -0.121   -0.240   -0.106    0.090    1.123    1.225   \n",
       "2815   -0.419   -0.235   -0.363   -0.454   -0.094    0.197    0.458    0.654   \n",
       "5185   -0.098   -0.694   -1.276   -0.998   -1.249    0.183    1.774    1.389   \n",
       "\n",
       "      wb_2155  wb_2156  wb_2157  wb_2158  wb_2159  wb_2160  wb_2161  wb_2162  \\\n",
       "3466    0.306   -0.235   -0.034    1.297   -0.345    0.265    0.364    0.496   \n",
       "689     1.158   -0.994   -0.390    0.306   -1.001   -1.658    0.852   -0.508   \n",
       "4148    1.175   -0.710   -0.455    0.855   -0.535    1.176    1.372   -0.331   \n",
       "2815    0.081   -0.569   -0.042    0.573   -0.463   -0.458    0.158   -0.354   \n",
       "5185    0.228   -0.250   -0.947    1.342   -1.046    0.880    0.324    0.449   \n",
       "\n",
       "      wb_2163  wb_2164  wb_2165  wb_2166  wb_2167  wb_2168  wb_2169  wb_2170  \\\n",
       "3466   -0.873   -0.218    0.291    1.465    0.431   -0.112    0.630   -0.169   \n",
       "689    -1.518   -0.719    0.461    0.057    1.711    0.428    0.170   -0.287   \n",
       "4148   -0.700   -0.381    0.642    1.388    0.859    0.134    0.336   -0.126   \n",
       "2815   -0.184   -0.082    0.405    0.535    0.630   -0.168    0.393   -0.302   \n",
       "5185   -1.192   -0.642    1.153    1.477    0.639    0.406    0.501   -0.086   \n",
       "\n",
       "      wb_2171  wb_2172  wb_2173  wb_2174  wb_2175  wb_2176  \n",
       "3466   -0.417   -0.147    0.948    0.264    0.132    0.032  \n",
       "689    -0.190   -0.100    0.639   -0.534   -0.642   -0.053  \n",
       "4148   -0.202   -0.652    1.249    0.813    0.366   -0.125  \n",
       "2815    0.380   -0.074    0.588    0.393   -0.348    0.179  \n",
       "5185   -0.214   -0.297    1.312   -0.264    0.085   -0.026  \n",
       "\n",
       "[5 rows x 2451 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:45.526035Z",
     "iopub.status.busy": "2022-01-03T14:46:45.525788Z",
     "iopub.status.idle": "2022-01-03T14:46:45.784974Z",
     "shell.execute_reply": "2022-01-03T14:46:45.784377Z",
     "shell.execute_reply.started": "2022-01-03T14:46:45.526009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>f0v0</th>\n",
       "      <th>f0v1</th>\n",
       "      <th>f0v2</th>\n",
       "      <th>f0v3</th>\n",
       "      <th>f0v4</th>\n",
       "      <th>f0v5</th>\n",
       "      <th>f0v6</th>\n",
       "      <th>f0v7</th>\n",
       "      <th>f0v8</th>\n",
       "      <th>f0v9</th>\n",
       "      <th>f0v10</th>\n",
       "      <th>f0v11</th>\n",
       "      <th>f0v12</th>\n",
       "      <th>f0v13</th>\n",
       "      <th>f0v14</th>\n",
       "      <th>f1v0</th>\n",
       "      <th>f1v1</th>\n",
       "      <th>f1v2</th>\n",
       "      <th>f1v3</th>\n",
       "      <th>f1v4</th>\n",
       "      <th>f1v5</th>\n",
       "      <th>f1v6</th>\n",
       "      <th>f1v7</th>\n",
       "      <th>f1v8</th>\n",
       "      <th>f1v9</th>\n",
       "      <th>f1v10</th>\n",
       "      <th>f1v11</th>\n",
       "      <th>f1v12</th>\n",
       "      <th>f1v13</th>\n",
       "      <th>f1v14</th>\n",
       "      <th>f2v0</th>\n",
       "      <th>f2v1</th>\n",
       "      <th>f2v2</th>\n",
       "      <th>f2v3</th>\n",
       "      <th>f2v4</th>\n",
       "      <th>f2v5</th>\n",
       "      <th>f2v6</th>\n",
       "      <th>f2v7</th>\n",
       "      <th>f2v8</th>\n",
       "      <th>f2v9</th>\n",
       "      <th>f2v10</th>\n",
       "      <th>f2v11</th>\n",
       "      <th>f2v12</th>\n",
       "      <th>f2v13</th>\n",
       "      <th>f2v14</th>\n",
       "      <th>f3v0</th>\n",
       "      <th>f3v1</th>\n",
       "      <th>f3v2</th>\n",
       "      <th>f3v3</th>\n",
       "      <th>f3v4</th>\n",
       "      <th>f3v5</th>\n",
       "      <th>f3v6</th>\n",
       "      <th>f3v7</th>\n",
       "      <th>f3v8</th>\n",
       "      <th>f3v9</th>\n",
       "      <th>f3v10</th>\n",
       "      <th>f3v11</th>\n",
       "      <th>f3v12</th>\n",
       "      <th>f3v13</th>\n",
       "      <th>f3v14</th>\n",
       "      <th>f4v0</th>\n",
       "      <th>f4v1</th>\n",
       "      <th>f4v2</th>\n",
       "      <th>f4v3</th>\n",
       "      <th>f4v4</th>\n",
       "      <th>f4v5</th>\n",
       "      <th>f4v6</th>\n",
       "      <th>f4v7</th>\n",
       "      <th>f4v8</th>\n",
       "      <th>f4v9</th>\n",
       "      <th>f4v10</th>\n",
       "      <th>f4v11</th>\n",
       "      <th>f4v12</th>\n",
       "      <th>f4v13</th>\n",
       "      <th>f4v14</th>\n",
       "      <th>f5v0</th>\n",
       "      <th>f5v1</th>\n",
       "      <th>f5v2</th>\n",
       "      <th>f5v3</th>\n",
       "      <th>f5v4</th>\n",
       "      <th>f5v5</th>\n",
       "      <th>f5v6</th>\n",
       "      <th>f5v7</th>\n",
       "      <th>f5v8</th>\n",
       "      <th>f5v9</th>\n",
       "      <th>f5v10</th>\n",
       "      <th>f5v11</th>\n",
       "      <th>f5v12</th>\n",
       "      <th>f5v13</th>\n",
       "      <th>f5v14</th>\n",
       "      <th>f6v0</th>\n",
       "      <th>f6v1</th>\n",
       "      <th>f6v2</th>\n",
       "      <th>f6v3</th>\n",
       "      <th>f6v4</th>\n",
       "      <th>f6v5</th>\n",
       "      <th>f6v6</th>\n",
       "      <th>f6v7</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_2077</th>\n",
       "      <th>wb_2078</th>\n",
       "      <th>wb_2079</th>\n",
       "      <th>wb_2080</th>\n",
       "      <th>wb_2081</th>\n",
       "      <th>wb_2082</th>\n",
       "      <th>wb_2083</th>\n",
       "      <th>wb_2084</th>\n",
       "      <th>wb_2085</th>\n",
       "      <th>wb_2086</th>\n",
       "      <th>wb_2087</th>\n",
       "      <th>wb_2088</th>\n",
       "      <th>wb_2089</th>\n",
       "      <th>wb_2090</th>\n",
       "      <th>wb_2091</th>\n",
       "      <th>wb_2092</th>\n",
       "      <th>wb_2093</th>\n",
       "      <th>wb_2094</th>\n",
       "      <th>wb_2095</th>\n",
       "      <th>wb_2096</th>\n",
       "      <th>wb_2097</th>\n",
       "      <th>wb_2098</th>\n",
       "      <th>wb_2099</th>\n",
       "      <th>wb_2100</th>\n",
       "      <th>wb_2101</th>\n",
       "      <th>wb_2102</th>\n",
       "      <th>wb_2103</th>\n",
       "      <th>wb_2104</th>\n",
       "      <th>wb_2105</th>\n",
       "      <th>wb_2106</th>\n",
       "      <th>wb_2107</th>\n",
       "      <th>wb_2108</th>\n",
       "      <th>wb_2109</th>\n",
       "      <th>wb_2110</th>\n",
       "      <th>wb_2111</th>\n",
       "      <th>wb_2112</th>\n",
       "      <th>wb_2113</th>\n",
       "      <th>wb_2114</th>\n",
       "      <th>wb_2115</th>\n",
       "      <th>wb_2116</th>\n",
       "      <th>wb_2117</th>\n",
       "      <th>wb_2118</th>\n",
       "      <th>wb_2119</th>\n",
       "      <th>wb_2120</th>\n",
       "      <th>wb_2121</th>\n",
       "      <th>wb_2122</th>\n",
       "      <th>wb_2123</th>\n",
       "      <th>wb_2124</th>\n",
       "      <th>wb_2125</th>\n",
       "      <th>wb_2126</th>\n",
       "      <th>wb_2127</th>\n",
       "      <th>wb_2128</th>\n",
       "      <th>wb_2129</th>\n",
       "      <th>wb_2130</th>\n",
       "      <th>wb_2131</th>\n",
       "      <th>wb_2132</th>\n",
       "      <th>wb_2133</th>\n",
       "      <th>wb_2134</th>\n",
       "      <th>wb_2135</th>\n",
       "      <th>wb_2136</th>\n",
       "      <th>wb_2137</th>\n",
       "      <th>wb_2138</th>\n",
       "      <th>wb_2139</th>\n",
       "      <th>wb_2140</th>\n",
       "      <th>wb_2141</th>\n",
       "      <th>wb_2142</th>\n",
       "      <th>wb_2143</th>\n",
       "      <th>wb_2144</th>\n",
       "      <th>wb_2145</th>\n",
       "      <th>wb_2146</th>\n",
       "      <th>wb_2147</th>\n",
       "      <th>wb_2148</th>\n",
       "      <th>wb_2149</th>\n",
       "      <th>wb_2150</th>\n",
       "      <th>wb_2151</th>\n",
       "      <th>wb_2152</th>\n",
       "      <th>wb_2153</th>\n",
       "      <th>wb_2154</th>\n",
       "      <th>wb_2155</th>\n",
       "      <th>wb_2156</th>\n",
       "      <th>wb_2157</th>\n",
       "      <th>wb_2158</th>\n",
       "      <th>wb_2159</th>\n",
       "      <th>wb_2160</th>\n",
       "      <th>wb_2161</th>\n",
       "      <th>wb_2162</th>\n",
       "      <th>wb_2163</th>\n",
       "      <th>wb_2164</th>\n",
       "      <th>wb_2165</th>\n",
       "      <th>wb_2166</th>\n",
       "      <th>wb_2167</th>\n",
       "      <th>wb_2168</th>\n",
       "      <th>wb_2169</th>\n",
       "      <th>wb_2170</th>\n",
       "      <th>wb_2171</th>\n",
       "      <th>wb_2172</th>\n",
       "      <th>wb_2173</th>\n",
       "      <th>wb_2174</th>\n",
       "      <th>wb_2175</th>\n",
       "      <th>wb_2176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7217.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.559</td>\n",
       "      <td>-1.145</td>\n",
       "      <td>1.606</td>\n",
       "      <td>2.464</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1.506</td>\n",
       "      <td>-1.169</td>\n",
       "      <td>1.408</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.208</td>\n",
       "      <td>1.164</td>\n",
       "      <td>0.650</td>\n",
       "      <td>2.606</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>1.661</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>3.116</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1.351</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-1.860</td>\n",
       "      <td>-0.536</td>\n",
       "      <td>0.880</td>\n",
       "      <td>-1.978</td>\n",
       "      <td>1.513</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>1.211</td>\n",
       "      <td>0.497</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>0.826</td>\n",
       "      <td>1.586</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-1.715</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>1.117</td>\n",
       "      <td>0.265</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>1.087</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>2.791</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.865</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.086</td>\n",
       "      <td>2.044</td>\n",
       "      <td>1.005</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1.058</td>\n",
       "      <td>1.086</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>0.808</td>\n",
       "      <td>1.696</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.681</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>1.814</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>8291.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-1.013</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.567</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-2.183</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-1.761</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.602</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-0.764</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.630</td>\n",
       "      <td>1.566</td>\n",
       "      <td>0.708</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>1.152</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.695</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1.078</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.710</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>1.627</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>1.118</td>\n",
       "      <td>0.190</td>\n",
       "      <td>1.069</td>\n",
       "      <td>-1.034</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.126</td>\n",
       "      <td>1.591</td>\n",
       "      <td>-1.366</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1.256</td>\n",
       "      <td>0.159</td>\n",
       "      <td>1.426</td>\n",
       "      <td>1.591</td>\n",
       "      <td>1.078</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>1.590</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.374</td>\n",
       "      <td>-0.752</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-1.127</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.511</td>\n",
       "      <td>0.518</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>1.070</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.484</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.549</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-2.070</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.812</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-2.158</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.814</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.112</td>\n",
       "      <td>1.002</td>\n",
       "      <td>2.034</td>\n",
       "      <td>1.579</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-1.071</td>\n",
       "      <td>1.219</td>\n",
       "      <td>1.535</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-1.108</td>\n",
       "      <td>0.298</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.095</td>\n",
       "      <td>1.104</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.395</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>5114.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.858</td>\n",
       "      <td>1.133</td>\n",
       "      <td>0.463</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>0.591</td>\n",
       "      <td>1.467</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.934</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.774</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.622</td>\n",
       "      <td>-1.161</td>\n",
       "      <td>0.899</td>\n",
       "      <td>-0.792</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-1.403</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-1.059</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.445</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.430</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.305</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.788</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>1.653</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.485</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.774</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-1.417</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.685</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1.385</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.841</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-1.733</td>\n",
       "      <td>0.887</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.564</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-1.107</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.852</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>0.929</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.645</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.408</td>\n",
       "      <td>-0.551</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.911</td>\n",
       "      <td>0.564</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-0.517</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.448</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.669</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>0.594</td>\n",
       "      <td>-0.551</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.264</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.454</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  f0v0  f0v1  f0v2  f0v3  f0v4  f0v5  f0v6  f0v7  f0v8  \\\n",
       "7217 7217.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 8291.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 4607.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 5114.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 1859.000    42 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f0v9  f0v10  f0v11  f0v12  f0v13  f0v14  f1v0  f1v1  f1v2  f1v3  f1v4  \\\n",
       "7217 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f1v5  f1v6  f1v7  f1v8  f1v9  f1v10  f1v11  f1v12  f1v13  f1v14  f2v0  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000   \n",
       "\n",
       "      f2v1  f2v2  f2v3  f2v4  f2v5  f2v6  f2v7  f2v8  f2v9  f2v10  f2v11  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000   \n",
       "\n",
       "      f2v12  f2v13  f2v14  f3v0  f3v1  f3v2  f3v3  f3v4  f3v5  f3v6  f3v7  \\\n",
       "7217  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f3v8  f3v9  f3v10  f3v11  f3v12  f3v13  f3v14  f4v0  f4v1  f4v2  f4v3  \\\n",
       "7217 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "8291 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "4607 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "5114 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "1859 0.000 0.000  0.000  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f4v4  f4v5  f4v6  f4v7  f4v8  f4v9  f4v10  f4v11  f4v12  f4v13  f4v14  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      f5v0  f5v1  f5v2  f5v3  f5v4  f5v5  f5v6  f5v7  f5v8  f5v9  f5v10  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000   \n",
       "\n",
       "      f5v11  f5v12  f5v13  f5v14  f6v0  f6v1  f6v2  f6v3  f6v4  f6v5  f6v6  \\\n",
       "7217  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859  0.000  0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "      f6v7  ...  wb_2077  wb_2078  wb_2079  wb_2080  wb_2081  wb_2082  \\\n",
       "7217 0.000  ...    1.559   -1.145    1.606    2.464    0.235   -0.926   \n",
       "8291 0.000  ...    0.633   -0.302    0.204    0.148    0.439   -1.013   \n",
       "4607 0.000  ...    0.096   -0.184    1.118    0.190    1.069   -1.034   \n",
       "5114 0.000  ...    0.843   -0.265    0.858    1.133    0.463   -0.652   \n",
       "1859 0.000  ...    0.290   -0.645    0.313    0.525    0.234   -0.053   \n",
       "\n",
       "      wb_2083  wb_2084  wb_2085  wb_2086  wb_2087  wb_2088  wb_2089  wb_2090  \\\n",
       "7217    0.056    0.947    0.904    1.506   -1.169    1.408    0.900    0.208   \n",
       "8291    0.636    0.550    0.198    0.131   -1.062   -0.010    0.426    0.358   \n",
       "4607    0.209    0.799    0.126    1.591   -1.366    0.166    0.938    1.256   \n",
       "5114    0.591    1.467    0.139    0.934   -0.345    0.482    0.813    0.781   \n",
       "1859    0.593    0.327    0.217    0.137   -0.681   -0.038    0.387    0.328   \n",
       "\n",
       "      wb_2091  wb_2092  wb_2093  wb_2094  wb_2095  wb_2096  wb_2097  wb_2098  \\\n",
       "7217    1.164    0.650    2.606    0.208   -0.739    1.661   -0.684    3.116   \n",
       "8291    0.273    0.746    0.959    0.567   -0.865    0.703   -0.635    0.386   \n",
       "4607    0.159    1.426    1.591    1.078   -0.493    1.590   -0.969    0.243   \n",
       "5114    0.644    0.647    0.641    0.774   -0.145    0.622   -1.161    0.899   \n",
       "1859    0.118    0.387    0.376    0.408   -0.551    0.337   -0.911    0.564   \n",
       "\n",
       "      wb_2099  wb_2100  wb_2101  wb_2102  wb_2103  wb_2104  wb_2105  wb_2106  \\\n",
       "7217   -0.662   -0.498   -0.113    0.135    1.351    0.367   -1.860   -0.536   \n",
       "8291   -2.183   -0.656   -0.113    0.140    0.462    0.221   -1.761   -0.248   \n",
       "4607   -1.374   -0.752   -1.656   -0.774    0.529    0.128   -1.127   -0.072   \n",
       "5114   -0.792   -0.707   -0.113   -0.196    0.327   -0.011   -0.319   -0.229   \n",
       "1859   -0.876   -0.517   -0.113    0.164    0.190    0.081   -0.087   -0.521   \n",
       "\n",
       "      wb_2107  wb_2108  wb_2109  wb_2110  wb_2111  wb_2112  wb_2113  wb_2114  \\\n",
       "7217    0.880   -1.978    1.513   -0.262    1.211    0.497   -0.535    0.826   \n",
       "8291    0.208   -0.077    0.602   -0.469    0.437    0.046   -0.797    0.179   \n",
       "4607    0.100   -1.511    0.518   -0.663    1.070   -0.992   -0.111    0.484   \n",
       "5114    0.492   -1.403    0.480   -0.185    0.358    0.511   -1.059    0.415   \n",
       "1859    0.317   -0.073    0.448   -0.320    0.293    0.251   -0.669    0.177   \n",
       "\n",
       "      wb_2115  wb_2116  wb_2117  wb_2118  wb_2119  wb_2120  wb_2121  wb_2122  \\\n",
       "7217    1.586   -0.311   -1.715   -0.708    1.117    0.265   -0.804   -0.327   \n",
       "8291   -0.252   -0.231   -0.107   -0.273    0.379   -0.418   -0.542   -0.771   \n",
       "4607   -0.023   -0.549   -0.099   -2.070    0.495    0.298   -0.056    0.068   \n",
       "5114    0.445   -0.933   -0.107   -0.192    0.519    0.430   -0.162    0.305   \n",
       "1859   -0.174   -0.395   -0.097   -0.523    0.530    0.099   -0.250    0.273   \n",
       "\n",
       "      wb_2123  wb_2124  wb_2125  wb_2126  wb_2127  wb_2128  wb_2129  wb_2130  \\\n",
       "7217   -0.339   -0.370   -0.529    1.087   -0.931   -0.159   -0.069   -0.236   \n",
       "8291   -0.360   -0.684    0.527    0.297   -1.588   -0.120   -0.351   -0.171   \n",
       "4607   -0.230   -0.704    0.266    0.320   -1.000   -0.070   -0.812   -0.191   \n",
       "5114   -0.232   -0.175   -0.163    0.788   -0.865   -0.195   -0.361   -0.334   \n",
       "1859   -0.299   -0.231   -0.284    0.594   -0.551   -0.105   -0.779   -0.029   \n",
       "\n",
       "      wb_2131  wb_2132  wb_2133  wb_2134  wb_2135  wb_2136  wb_2137  wb_2138  \\\n",
       "7217    2.791    0.314   -0.985   -0.523    0.865   -0.135   -0.297    0.286   \n",
       "8291    0.072    0.258   -0.640   -0.309    0.096   -0.601   -0.404    0.260   \n",
       "4607    0.232   -0.586   -0.161   -0.153    0.016   -0.193    0.096    0.188   \n",
       "5114    1.653    0.606    0.485   -0.253    0.870   -0.190    0.631    0.774   \n",
       "1859    0.633    0.262   -0.018   -0.131    0.099   -0.218    0.256    0.264   \n",
       "\n",
       "      wb_2139  wb_2140  wb_2141  wb_2142  wb_2143  wb_2144  wb_2145  wb_2146  \\\n",
       "7217   -0.256   -0.387    0.086    2.044    1.005   -0.632    0.824    0.100   \n",
       "8291   -0.190   -0.356    0.032    0.512    0.434    0.172    0.135    0.278   \n",
       "4607   -0.199   -2.158   -0.045    0.178   -0.814   -0.811    0.161    0.808   \n",
       "5114   -0.246   -1.417    0.130    0.660    0.685   -0.155    0.122   -0.405   \n",
       "1859   -0.313   -0.079    0.101    0.107    0.274   -0.605    0.127    0.164   \n",
       "\n",
       "      wb_2147  wb_2148  wb_2149  wb_2150  wb_2151  wb_2152  wb_2153  wb_2154  \\\n",
       "7217   -0.349   -0.339   -0.176   -0.318   -0.100    0.747    0.803    1.058   \n",
       "8291   -0.310   -0.701   -0.764   -0.179   -0.098    0.186    0.630    1.566   \n",
       "4607   -0.255   -0.888   -0.888   -0.588   -0.096    0.112    1.002    2.034   \n",
       "5114   -0.186   -0.388   -0.622   -0.439   -0.106    0.270    1.385    0.095   \n",
       "1859   -0.621   -0.399   -0.474   -0.360   -0.095    0.175    0.312    0.093   \n",
       "\n",
       "      wb_2155  wb_2156  wb_2157  wb_2158  wb_2159  wb_2160  wb_2161  wb_2162  \\\n",
       "7217    1.086   -0.798   -0.978    0.047   -0.296   -0.341    0.843   -0.258   \n",
       "8291    0.708   -0.283   -0.338    1.152   -0.188   -0.410    0.695   -0.244   \n",
       "4607    1.579   -0.682   -0.570    0.385   -1.071    1.219    1.535    0.440   \n",
       "5114    0.841   -0.138   -1.733    0.887   -0.605    0.742    0.784    0.564   \n",
       "1859    0.629   -0.354   -0.353    0.073   -0.413   -0.287    0.475    0.438   \n",
       "\n",
       "      wb_2163  wb_2164  wb_2165  wb_2166  wb_2167  wb_2168  wb_2169  wb_2170  \\\n",
       "7217   -0.614   -0.476    0.808    1.696    0.134    0.500    1.681   -0.128   \n",
       "8291   -0.389   -0.297    0.583    1.078    0.943    0.085    0.710   -0.000   \n",
       "4607   -0.184   -1.108    0.298    1.099    1.167    0.095    1.104    0.001   \n",
       "5114   -0.172   -1.107    0.446    0.782    0.852   -0.724    0.929   -0.084   \n",
       "1859   -0.571   -0.353    0.126    0.387    0.775    0.251    0.454   -0.322   \n",
       "\n",
       "      wb_2171  wb_2172  wb_2173  wb_2174  wb_2175  wb_2176  \n",
       "7217   -0.628   -0.315    1.814    0.483    0.097   -0.147  \n",
       "8291   -0.181   -0.364    1.627   -0.654   -0.067    0.012  \n",
       "4607   -0.100   -0.166    1.395   -0.422   -0.609    0.011  \n",
       "5114   -0.135   -0.191    0.173    0.489    0.496    0.050  \n",
       "1859   -0.242   -0.435    0.484    0.215    0.246    0.176  \n",
       "\n",
       "[5 rows x 2451 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:45.786155Z",
     "iopub.status.busy": "2022-01-03T14:46:45.785907Z",
     "iopub.status.idle": "2022-01-03T14:46:45.788884Z",
     "shell.execute_reply": "2022-01-03T14:46:45.788337Z",
     "shell.execute_reply.started": "2022-01-03T14:46:45.786129Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir data/logging/ --port=8811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:45.789914Z",
     "iopub.status.busy": "2022-01-03T14:46:45.789683Z",
     "iopub.status.idle": "2022-01-03T14:46:45.796040Z",
     "shell.execute_reply": "2022-01-03T14:46:45.795488Z",
     "shell.execute_reply.started": "2022-01-03T14:46:45.789890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:46:45.797087Z",
     "iopub.status.busy": "2022-01-03T14:46:45.796837Z",
     "iopub.status.idle": "2022-01-03T15:57:27.114895Z",
     "shell.execute_reply": "2022-01-03T15:57:27.113722Z",
     "shell.execute_reply.started": "2022-01-03T14:46:45.797062Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/500\n",
      "35/35 - 40s - loss: 0.6923 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6918 - binary_accuracy_inet_decision_function_fv_metric: 0.5136 - val_loss: 0.6920 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6926 - val_binary_accuracy_inet_decision_function_fv_metric: 0.4966\n",
      "Epoch 2/500\n",
      "35/35 - 16s - loss: 0.6738 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6804 - binary_accuracy_inet_decision_function_fv_metric: 0.5837 - val_loss: 0.6631 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6769 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6193\n",
      "Epoch 3/500\n",
      "35/35 - 17s - loss: 0.6561 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6689 - binary_accuracy_inet_decision_function_fv_metric: 0.6238 - val_loss: 0.6580 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6737 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6216\n",
      "Epoch 4/500\n",
      "35/35 - 17s - loss: 0.6521 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6669 - binary_accuracy_inet_decision_function_fv_metric: 0.6262 - val_loss: 0.6569 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6728 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6225\n",
      "Epoch 5/500\n",
      "35/35 - 16s - loss: 0.6499 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6655 - binary_accuracy_inet_decision_function_fv_metric: 0.6277 - val_loss: 0.6546 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6712 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6221\n",
      "Epoch 6/500\n",
      "35/35 - 16s - loss: 0.6488 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6647 - binary_accuracy_inet_decision_function_fv_metric: 0.6285 - val_loss: 0.6557 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6723 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6228\n",
      "Epoch 7/500\n",
      "35/35 - 17s - loss: 0.6481 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6645 - binary_accuracy_inet_decision_function_fv_metric: 0.6292 - val_loss: 0.6537 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6705 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6235\n",
      "Epoch 8/500\n",
      "35/35 - 16s - loss: 0.6475 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6641 - binary_accuracy_inet_decision_function_fv_metric: 0.6298 - val_loss: 0.6541 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6708 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6231\n",
      "Epoch 9/500\n",
      "35/35 - 16s - loss: 0.6472 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6640 - binary_accuracy_inet_decision_function_fv_metric: 0.6302 - val_loss: 0.6551 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6711 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6232\n",
      "Epoch 10/500\n",
      "35/35 - 16s - loss: 0.6468 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6636 - binary_accuracy_inet_decision_function_fv_metric: 0.6305 - val_loss: 0.6530 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6699 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6232\n",
      "Epoch 11/500\n",
      "35/35 - 16s - loss: 0.6473 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6641 - binary_accuracy_inet_decision_function_fv_metric: 0.6305 - val_loss: 0.6531 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6696 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6230\n",
      "Epoch 12/500\n",
      "35/35 - 16s - loss: 0.6468 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6636 - binary_accuracy_inet_decision_function_fv_metric: 0.6304 - val_loss: 0.6559 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6719 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6228\n",
      "Epoch 13/500\n",
      "35/35 - 16s - loss: 0.6462 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6634 - binary_accuracy_inet_decision_function_fv_metric: 0.6305 - val_loss: 0.6542 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6714 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6236\n",
      "Epoch 14/500\n",
      "35/35 - 16s - loss: 0.6456 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6631 - binary_accuracy_inet_decision_function_fv_metric: 0.6309 - val_loss: 0.6538 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6711 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6238\n",
      "Epoch 15/500\n",
      "35/35 - 16s - loss: 0.6457 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6631 - binary_accuracy_inet_decision_function_fv_metric: 0.6312 - val_loss: 0.6537 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6707 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6237\n",
      "Epoch 16/500\n",
      "35/35 - 16s - loss: 0.6454 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6629 - binary_accuracy_inet_decision_function_fv_metric: 0.6314 - val_loss: 0.6539 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6711 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6238\n",
      "Epoch 17/500\n",
      "35/35 - 16s - loss: 0.6456 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6630 - binary_accuracy_inet_decision_function_fv_metric: 0.6311 - val_loss: 0.6551 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6721 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6227\n",
      "Epoch 18/500\n",
      "35/35 - 16s - loss: 0.6449 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6626 - binary_accuracy_inet_decision_function_fv_metric: 0.6318 - val_loss: 0.6537 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6705 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6242\n",
      "Epoch 19/500\n",
      "35/35 - 16s - loss: 0.6443 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6622 - binary_accuracy_inet_decision_function_fv_metric: 0.6325 - val_loss: 0.6528 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6708 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6254\n",
      "Epoch 20/500\n",
      "35/35 - 16s - loss: 0.6457 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6629 - binary_accuracy_inet_decision_function_fv_metric: 0.6321 - val_loss: 0.6528 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6701 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6250\n",
      "Epoch 21/500\n",
      "35/35 - 16s - loss: 0.6429 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6613 - binary_accuracy_inet_decision_function_fv_metric: 0.6345 - val_loss: 0.6507 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6691 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6282\n",
      "Epoch 22/500\n",
      "35/35 - 16s - loss: 0.6415 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6606 - binary_accuracy_inet_decision_function_fv_metric: 0.6359 - val_loss: 0.6498 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6692 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6300\n",
      "Epoch 23/500\n",
      "35/35 - 16s - loss: 0.6406 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6601 - binary_accuracy_inet_decision_function_fv_metric: 0.6363 - val_loss: 0.6486 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6678 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6268\n",
      "Epoch 24/500\n",
      "35/35 - 16s - loss: 0.6400 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6597 - binary_accuracy_inet_decision_function_fv_metric: 0.6364 - val_loss: 0.6507 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6692 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6269\n",
      "Epoch 25/500\n",
      "35/35 - 16s - loss: 0.6396 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6596 - binary_accuracy_inet_decision_function_fv_metric: 0.6369 - val_loss: 0.6486 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6682 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6318\n",
      "Epoch 26/500\n",
      "35/35 - 16s - loss: 0.6381 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6587 - binary_accuracy_inet_decision_function_fv_metric: 0.6391 - val_loss: 0.6423 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6642 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6340\n",
      "Epoch 27/500\n",
      "35/35 - 16s - loss: 0.6354 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6571 - binary_accuracy_inet_decision_function_fv_metric: 0.6417 - val_loss: 0.6389 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6611 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6355\n",
      "Epoch 28/500\n",
      "35/35 - 16s - loss: 0.6343 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6565 - binary_accuracy_inet_decision_function_fv_metric: 0.6428 - val_loss: 0.6387 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6621 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6368\n",
      "Epoch 29/500\n",
      "35/35 - 16s - loss: 0.6324 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6554 - binary_accuracy_inet_decision_function_fv_metric: 0.6444 - val_loss: 0.6362 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6611 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6420\n",
      "Epoch 30/500\n",
      "35/35 - 16s - loss: 0.6303 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - binary_accuracy_inet_decision_function_fv_metric: 0.6458 - val_loss: 0.6323 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6580 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6429\n",
      "Epoch 31/500\n",
      "35/35 - 16s - loss: 0.6298 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6540 - binary_accuracy_inet_decision_function_fv_metric: 0.6469 - val_loss: 0.6309 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6572 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6432\n",
      "Epoch 32/500\n",
      "35/35 - 16s - loss: 0.6285 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - binary_accuracy_inet_decision_function_fv_metric: 0.6477 - val_loss: 0.6308 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6573 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6448\n",
      "Epoch 33/500\n",
      "35/35 - 16s - loss: 0.6274 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6525 - binary_accuracy_inet_decision_function_fv_metric: 0.6483 - val_loss: 0.6327 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6591 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6423\n",
      "Epoch 34/500\n",
      "35/35 - 16s - loss: 0.6265 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6522 - binary_accuracy_inet_decision_function_fv_metric: 0.6487 - val_loss: 0.6310 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6584 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6436\n",
      "Epoch 35/500\n",
      "35/35 - 16s - loss: 0.6255 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6515 - binary_accuracy_inet_decision_function_fv_metric: 0.6507 - val_loss: 0.6320 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6592 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6462\n",
      "Epoch 36/500\n",
      "35/35 - 16s - loss: 0.6241 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6507 - binary_accuracy_inet_decision_function_fv_metric: 0.6530 - val_loss: 0.6301 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6576 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6472\n",
      "Epoch 37/500\n",
      "35/35 - 16s - loss: 0.6245 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6511 - binary_accuracy_inet_decision_function_fv_metric: 0.6514 - val_loss: 0.6314 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6585 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6453\n",
      "Epoch 38/500\n",
      "35/35 - 16s - loss: 0.6203 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6487 - binary_accuracy_inet_decision_function_fv_metric: 0.6553 - val_loss: 0.6271 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6568 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6505\n",
      "Epoch 39/500\n",
      "35/35 - 16s - loss: 0.6206 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6488 - binary_accuracy_inet_decision_function_fv_metric: 0.6555 - val_loss: 0.6260 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6556 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6502\n",
      "Epoch 40/500\n",
      "35/35 - 16s - loss: 0.6178 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6474 - binary_accuracy_inet_decision_function_fv_metric: 0.6574 - val_loss: 0.6253 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6547 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6503\n",
      "Epoch 41/500\n",
      "35/35 - 16s - loss: 0.6171 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6468 - binary_accuracy_inet_decision_function_fv_metric: 0.6585 - val_loss: 0.6218 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6538\n",
      "Epoch 42/500\n",
      "35/35 - 16s - loss: 0.6178 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6470 - binary_accuracy_inet_decision_function_fv_metric: 0.6596 - val_loss: 0.6238 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6546\n",
      "Epoch 43/500\n",
      "35/35 - 16s - loss: 0.6138 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6449 - binary_accuracy_inet_decision_function_fv_metric: 0.6627 - val_loss: 0.6194 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6520 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6587\n",
      "Epoch 44/500\n",
      "35/35 - 16s - loss: 0.6088 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6421 - binary_accuracy_inet_decision_function_fv_metric: 0.6663 - val_loss: 0.6142 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6493 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6629\n",
      "Epoch 45/500\n",
      "35/35 - 16s - loss: 0.6096 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6425 - binary_accuracy_inet_decision_function_fv_metric: 0.6654 - val_loss: 0.6092 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6465 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6656\n",
      "Epoch 46/500\n",
      "35/35 - 16s - loss: 0.6116 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6438 - binary_accuracy_inet_decision_function_fv_metric: 0.6638 - val_loss: 0.6154 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6491 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6585\n",
      "Epoch 47/500\n",
      "35/35 - 16s - loss: 0.6085 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6422 - binary_accuracy_inet_decision_function_fv_metric: 0.6659 - val_loss: 0.6116 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6473 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6637\n",
      "Epoch 48/500\n",
      "35/35 - 16s - loss: 0.6058 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6407 - binary_accuracy_inet_decision_function_fv_metric: 0.6680 - val_loss: 0.6143 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6491 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6629\n",
      "Epoch 49/500\n",
      "35/35 - 16s - loss: 0.6058 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6407 - binary_accuracy_inet_decision_function_fv_metric: 0.6680 - val_loss: 0.6112 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6466 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6646\n",
      "Epoch 50/500\n",
      "35/35 - 16s - loss: 0.6051 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6404 - binary_accuracy_inet_decision_function_fv_metric: 0.6692 - val_loss: 0.6104 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6470 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6663\n",
      "Epoch 51/500\n",
      "35/35 - 16s - loss: 0.6050 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6402 - binary_accuracy_inet_decision_function_fv_metric: 0.6689 - val_loss: 0.6112 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6474 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6650\n",
      "Epoch 52/500\n",
      "35/35 - 16s - loss: 0.6041 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6398 - binary_accuracy_inet_decision_function_fv_metric: 0.6692 - val_loss: 0.6059 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6443 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6680\n",
      "Epoch 53/500\n",
      "35/35 - 16s - loss: 0.6044 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6400 - binary_accuracy_inet_decision_function_fv_metric: 0.6690 - val_loss: 0.6076 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6452 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6647\n",
      "Epoch 54/500\n",
      "35/35 - 16s - loss: 0.6042 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6400 - binary_accuracy_inet_decision_function_fv_metric: 0.6692 - val_loss: 0.6051 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6443 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6696\n",
      "Epoch 55/500\n",
      "35/35 - 16s - loss: 0.6016 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6385 - binary_accuracy_inet_decision_function_fv_metric: 0.6713 - val_loss: 0.6078 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6458 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6667\n",
      "Epoch 56/500\n",
      "35/35 - 16s - loss: 0.6000 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6376 - binary_accuracy_inet_decision_function_fv_metric: 0.6728 - val_loss: 0.6035 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6425 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6696\n",
      "Epoch 57/500\n",
      "35/35 - 16s - loss: 0.5994 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6374 - binary_accuracy_inet_decision_function_fv_metric: 0.6727 - val_loss: 0.6070 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6446 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6673\n",
      "Epoch 58/500\n",
      "35/35 - 16s - loss: 0.6013 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6385 - binary_accuracy_inet_decision_function_fv_metric: 0.6715 - val_loss: 0.6026 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6421 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6689\n",
      "Epoch 59/500\n",
      "35/35 - 16s - loss: 0.5979 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6366 - binary_accuracy_inet_decision_function_fv_metric: 0.6735 - val_loss: 0.6045 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6435 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6669\n",
      "Epoch 60/500\n",
      "35/35 - 16s - loss: 0.5989 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6372 - binary_accuracy_inet_decision_function_fv_metric: 0.6728 - val_loss: 0.6050 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6443 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6687\n",
      "Epoch 61/500\n",
      "35/35 - 16s - loss: 0.5982 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6370 - binary_accuracy_inet_decision_function_fv_metric: 0.6734 - val_loss: 0.6035 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6434 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6710\n",
      "Epoch 62/500\n",
      "35/35 - 16s - loss: 0.5975 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6364 - binary_accuracy_inet_decision_function_fv_metric: 0.6740 - val_loss: 0.6008 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6419 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6735\n",
      "Epoch 63/500\n",
      "35/35 - 16s - loss: 0.5961 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6356 - binary_accuracy_inet_decision_function_fv_metric: 0.6749 - val_loss: 0.6008 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6422 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6730\n",
      "Epoch 64/500\n",
      "35/35 - 16s - loss: 0.5976 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6365 - binary_accuracy_inet_decision_function_fv_metric: 0.6739 - val_loss: 0.5989 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6406 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6722\n",
      "Epoch 65/500\n",
      "35/35 - 16s - loss: 0.5957 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6353 - binary_accuracy_inet_decision_function_fv_metric: 0.6758 - val_loss: 0.6003 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6422 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6751\n",
      "Epoch 66/500\n",
      "35/35 - 16s - loss: 0.5936 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6343 - binary_accuracy_inet_decision_function_fv_metric: 0.6779 - val_loss: 0.5955 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6386 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6764\n",
      "Epoch 67/500\n",
      "35/35 - 16s - loss: 0.5961 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6356 - binary_accuracy_inet_decision_function_fv_metric: 0.6755 - val_loss: 0.5996 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6409 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6731\n",
      "Epoch 68/500\n",
      "35/35 - 16s - loss: 0.5935 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6342 - binary_accuracy_inet_decision_function_fv_metric: 0.6776 - val_loss: 0.5973 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6403 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6758\n",
      "Epoch 69/500\n",
      "35/35 - 16s - loss: 0.5909 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6327 - binary_accuracy_inet_decision_function_fv_metric: 0.6803 - val_loss: 0.5946 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6391 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6804\n",
      "Epoch 70/500\n",
      "35/35 - 16s - loss: 0.5942 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6344 - binary_accuracy_inet_decision_function_fv_metric: 0.6782 - val_loss: 0.5949 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6392 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6790\n",
      "Epoch 71/500\n",
      "35/35 - 16s - loss: 0.5916 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6331 - binary_accuracy_inet_decision_function_fv_metric: 0.6801 - val_loss: 0.5931 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6379 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6799\n",
      "Epoch 72/500\n",
      "35/35 - 16s - loss: 0.5877 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6310 - binary_accuracy_inet_decision_function_fv_metric: 0.6829 - val_loss: 0.5899 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6367 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6852\n",
      "Epoch 73/500\n",
      "35/35 - 16s - loss: 0.5861 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6302 - binary_accuracy_inet_decision_function_fv_metric: 0.6839 - val_loss: 0.5886 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6353 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6861\n",
      "Epoch 74/500\n",
      "35/35 - 16s - loss: 0.5850 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6296 - binary_accuracy_inet_decision_function_fv_metric: 0.6857 - val_loss: 0.5887 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6356 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6866\n",
      "Epoch 75/500\n",
      "35/35 - 16s - loss: 0.5835 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6288 - binary_accuracy_inet_decision_function_fv_metric: 0.6871 - val_loss: 0.5814 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6310 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6898\n",
      "Epoch 76/500\n",
      "35/35 - 16s - loss: 0.5851 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6297 - binary_accuracy_inet_decision_function_fv_metric: 0.6852 - val_loss: 0.5857 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6340 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6879\n",
      "Epoch 77/500\n",
      "35/35 - 16s - loss: 0.5858 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6299 - binary_accuracy_inet_decision_function_fv_metric: 0.6852 - val_loss: 0.5858 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6346 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6881\n",
      "Epoch 78/500\n",
      "35/35 - 16s - loss: 0.5865 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6304 - binary_accuracy_inet_decision_function_fv_metric: 0.6835 - val_loss: 0.5824 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6319 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6884\n",
      "Epoch 79/500\n",
      "35/35 - 16s - loss: 0.5825 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6282 - binary_accuracy_inet_decision_function_fv_metric: 0.6877 - val_loss: 0.5800 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6311 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6918\n",
      "Epoch 80/500\n",
      "35/35 - 16s - loss: 0.5826 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6283 - binary_accuracy_inet_decision_function_fv_metric: 0.6872 - val_loss: 0.5766 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6284 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6928\n",
      "Epoch 81/500\n",
      "35/35 - 16s - loss: 0.5803 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6269 - binary_accuracy_inet_decision_function_fv_metric: 0.6897 - val_loss: 0.5775 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6298 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6926\n",
      "Epoch 82/500\n",
      "35/35 - 16s - loss: 0.5778 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6256 - binary_accuracy_inet_decision_function_fv_metric: 0.6909 - val_loss: 0.5732 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6273 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6962\n",
      "Epoch 83/500\n",
      "35/35 - 16s - loss: 0.5773 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6255 - binary_accuracy_inet_decision_function_fv_metric: 0.6908 - val_loss: 0.5731 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6272 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6955\n",
      "Epoch 84/500\n",
      "35/35 - 16s - loss: 0.5762 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6249 - binary_accuracy_inet_decision_function_fv_metric: 0.6926 - val_loss: 0.5719 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6267 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6985\n",
      "Epoch 85/500\n",
      "35/35 - 16s - loss: 0.5746 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6239 - binary_accuracy_inet_decision_function_fv_metric: 0.6935 - val_loss: 0.5697 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6253 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7028\n",
      "Epoch 86/500\n",
      "35/35 - 16s - loss: 0.5753 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6242 - binary_accuracy_inet_decision_function_fv_metric: 0.6935 - val_loss: 0.5669 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6243 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7042\n",
      "Epoch 87/500\n",
      "35/35 - 16s - loss: 0.5755 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6244 - binary_accuracy_inet_decision_function_fv_metric: 0.6939 - val_loss: 0.5716 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6262 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6974\n",
      "Epoch 88/500\n",
      "35/35 - 16s - loss: 0.5725 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6227 - binary_accuracy_inet_decision_function_fv_metric: 0.6956 - val_loss: 0.5674 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6252 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7054\n",
      "Epoch 89/500\n",
      "35/35 - 16s - loss: 0.5727 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6227 - binary_accuracy_inet_decision_function_fv_metric: 0.6962 - val_loss: 0.5657 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6239 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7065\n",
      "Epoch 90/500\n",
      "35/35 - 16s - loss: 0.5720 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6225 - binary_accuracy_inet_decision_function_fv_metric: 0.6968 - val_loss: 0.5651 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6243 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7072\n",
      "Epoch 91/500\n",
      "35/35 - 16s - loss: 0.5702 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6214 - binary_accuracy_inet_decision_function_fv_metric: 0.6984 - val_loss: 0.5638 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6234 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7080\n",
      "Epoch 92/500\n",
      "35/35 - 16s - loss: 0.5693 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6213 - binary_accuracy_inet_decision_function_fv_metric: 0.6990 - val_loss: 0.5652 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6235 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7066\n",
      "Epoch 93/500\n",
      "35/35 - 16s - loss: 0.5701 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6216 - binary_accuracy_inet_decision_function_fv_metric: 0.6986 - val_loss: 0.5683 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6257 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7035\n",
      "Epoch 94/500\n",
      "35/35 - 16s - loss: 0.5727 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6229 - binary_accuracy_inet_decision_function_fv_metric: 0.6962 - val_loss: 0.5721 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6274 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7020\n",
      "Epoch 95/500\n",
      "35/35 - 16s - loss: 0.5739 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6235 - binary_accuracy_inet_decision_function_fv_metric: 0.6951 - val_loss: 0.5707 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6264 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7022\n",
      "Epoch 96/500\n",
      "35/35 - 16s - loss: 0.5732 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6232 - binary_accuracy_inet_decision_function_fv_metric: 0.6962 - val_loss: 0.5690 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6258 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7045\n",
      "Epoch 97/500\n",
      "35/35 - 16s - loss: 0.5718 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6223 - binary_accuracy_inet_decision_function_fv_metric: 0.6970 - val_loss: 0.5672 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6252 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7075\n",
      "Epoch 98/500\n",
      "35/35 - 16s - loss: 0.5715 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6221 - binary_accuracy_inet_decision_function_fv_metric: 0.6988 - val_loss: 0.5633 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6227 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7072\n",
      "Epoch 99/500\n",
      "35/35 - 16s - loss: 0.5689 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6208 - binary_accuracy_inet_decision_function_fv_metric: 0.6998 - val_loss: 0.5608 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6217 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7100\n",
      "Epoch 100/500\n",
      "35/35 - 16s - loss: 0.5694 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6210 - binary_accuracy_inet_decision_function_fv_metric: 0.6998 - val_loss: 0.5635 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6225 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7073\n",
      "Epoch 101/500\n",
      "35/35 - 16s - loss: 0.5715 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6222 - binary_accuracy_inet_decision_function_fv_metric: 0.6984 - val_loss: 0.5623 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6222 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7097\n",
      "Epoch 102/500\n",
      "35/35 - 16s - loss: 0.5719 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6223 - binary_accuracy_inet_decision_function_fv_metric: 0.6979 - val_loss: 0.5588 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6202 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7124\n",
      "Epoch 103/500\n",
      "35/35 - 16s - loss: 0.5685 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6206 - binary_accuracy_inet_decision_function_fv_metric: 0.7002 - val_loss: 0.5605 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6208 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7083\n",
      "Epoch 104/500\n",
      "35/35 - 16s - loss: 0.5675 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6201 - binary_accuracy_inet_decision_function_fv_metric: 0.7018 - val_loss: 0.5593 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6200 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7112\n",
      "Epoch 105/500\n",
      "35/35 - 16s - loss: 0.5697 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6213 - binary_accuracy_inet_decision_function_fv_metric: 0.6987 - val_loss: 0.5615 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6207 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7073\n",
      "Epoch 106/500\n",
      "35/35 - 16s - loss: 0.5661 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6195 - binary_accuracy_inet_decision_function_fv_metric: 0.7020 - val_loss: 0.5563 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6184 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7121\n",
      "Epoch 107/500\n",
      "35/35 - 16s - loss: 0.5679 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6202 - binary_accuracy_inet_decision_function_fv_metric: 0.7009 - val_loss: 0.5587 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6200 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7104\n",
      "Epoch 108/500\n",
      "35/35 - 16s - loss: 0.5666 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6196 - binary_accuracy_inet_decision_function_fv_metric: 0.7024 - val_loss: 0.5582 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6195 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7109\n",
      "Epoch 109/500\n",
      "35/35 - 16s - loss: 0.5644 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6186 - binary_accuracy_inet_decision_function_fv_metric: 0.7028 - val_loss: 0.5589 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6199 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7112\n",
      "Epoch 110/500\n",
      "35/35 - 16s - loss: 0.5636 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6182 - binary_accuracy_inet_decision_function_fv_metric: 0.7036 - val_loss: 0.5540 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6175 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7155\n",
      "Epoch 111/500\n",
      "35/35 - 16s - loss: 0.5630 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6179 - binary_accuracy_inet_decision_function_fv_metric: 0.7035 - val_loss: 0.5570 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6203 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7139\n",
      "Epoch 112/500\n",
      "35/35 - 16s - loss: 0.5629 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6178 - binary_accuracy_inet_decision_function_fv_metric: 0.7044 - val_loss: 0.5537 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6180 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7164\n",
      "Epoch 113/500\n",
      "35/35 - 16s - loss: 0.5631 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6179 - binary_accuracy_inet_decision_function_fv_metric: 0.7037 - val_loss: 0.5564 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6193 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7129\n",
      "Epoch 114/500\n",
      "35/35 - 16s - loss: 0.5608 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6166 - binary_accuracy_inet_decision_function_fv_metric: 0.7063 - val_loss: 0.5572 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6193 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7107\n",
      "Epoch 115/500\n",
      "35/35 - 16s - loss: 0.5639 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6185 - binary_accuracy_inet_decision_function_fv_metric: 0.7026 - val_loss: 0.5606 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6215 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7083\n",
      "Epoch 116/500\n",
      "35/35 - 16s - loss: 0.5622 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6175 - binary_accuracy_inet_decision_function_fv_metric: 0.7035 - val_loss: 0.5600 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6210 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7087\n",
      "Epoch 117/500\n",
      "35/35 - 16s - loss: 0.5650 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6190 - binary_accuracy_inet_decision_function_fv_metric: 0.7025 - val_loss: 0.5628 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6224 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7069\n",
      "Epoch 118/500\n",
      "35/35 - 16s - loss: 0.5646 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6188 - binary_accuracy_inet_decision_function_fv_metric: 0.7023 - val_loss: 0.5634 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6231 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7051\n",
      "Epoch 119/500\n",
      "35/35 - 16s - loss: 0.5679 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6206 - binary_accuracy_inet_decision_function_fv_metric: 0.6992 - val_loss: 0.5592 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6211 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7119\n",
      "Epoch 120/500\n",
      "35/35 - 16s - loss: 0.5666 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6198 - binary_accuracy_inet_decision_function_fv_metric: 0.7008 - val_loss: 0.5584 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6203 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7112\n",
      "Epoch 121/500\n",
      "35/35 - 16s - loss: 0.5643 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6185 - binary_accuracy_inet_decision_function_fv_metric: 0.7039 - val_loss: 0.5559 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6191 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7128\n",
      "Epoch 122/500\n",
      "35/35 - 16s - loss: 0.5653 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6191 - binary_accuracy_inet_decision_function_fv_metric: 0.7024 - val_loss: 0.5574 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6201 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7124\n",
      "Epoch 123/500\n",
      "35/35 - 16s - loss: 0.5638 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6182 - binary_accuracy_inet_decision_function_fv_metric: 0.7038 - val_loss: 0.5544 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6189 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7150\n",
      "Epoch 124/500\n",
      "35/35 - 16s - loss: 0.5623 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6175 - binary_accuracy_inet_decision_function_fv_metric: 0.7051 - val_loss: 0.5538 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6180 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7140\n",
      "Epoch 125/500\n",
      "35/35 - 16s - loss: 0.5622 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6174 - binary_accuracy_inet_decision_function_fv_metric: 0.7047 - val_loss: 0.5527 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6175 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7150\n",
      "Epoch 126/500\n",
      "35/35 - 16s - loss: 0.5633 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6179 - binary_accuracy_inet_decision_function_fv_metric: 0.7040 - val_loss: 0.5560 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6191 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7110\n",
      "Epoch 127/500\n",
      "35/35 - 16s - loss: 0.5589 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6159 - binary_accuracy_inet_decision_function_fv_metric: 0.7072 - val_loss: 0.5522 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6176 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7163\n",
      "Epoch 128/500\n",
      "35/35 - 16s - loss: 0.5614 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6170 - binary_accuracy_inet_decision_function_fv_metric: 0.7056 - val_loss: 0.5560 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6189 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7122\n",
      "Epoch 129/500\n",
      "35/35 - 16s - loss: 0.5611 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6171 - binary_accuracy_inet_decision_function_fv_metric: 0.7050 - val_loss: 0.5521 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6170 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7143\n",
      "Epoch 130/500\n",
      "35/35 - 16s - loss: 0.5628 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6176 - binary_accuracy_inet_decision_function_fv_metric: 0.7047 - val_loss: 0.5511 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6163 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7159\n",
      "Epoch 131/500\n",
      "35/35 - 16s - loss: 0.5601 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6162 - binary_accuracy_inet_decision_function_fv_metric: 0.7075 - val_loss: 0.5488 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6150 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7185\n",
      "Epoch 132/500\n",
      "35/35 - 16s - loss: 0.5607 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6168 - binary_accuracy_inet_decision_function_fv_metric: 0.7053 - val_loss: 0.5531 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6171 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7141\n",
      "Epoch 133/500\n",
      "35/35 - 16s - loss: 0.5639 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6182 - binary_accuracy_inet_decision_function_fv_metric: 0.7035 - val_loss: 0.5536 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6177 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7158\n",
      "Epoch 134/500\n",
      "35/35 - 16s - loss: 0.5633 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6181 - binary_accuracy_inet_decision_function_fv_metric: 0.7038 - val_loss: 0.5525 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6164 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7165\n",
      "Epoch 135/500\n",
      "35/35 - 16s - loss: 0.5606 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6165 - binary_accuracy_inet_decision_function_fv_metric: 0.7064 - val_loss: 0.5503 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6154 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7151\n",
      "Epoch 136/500\n",
      "35/35 - 16s - loss: 0.5617 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6172 - binary_accuracy_inet_decision_function_fv_metric: 0.7058 - val_loss: 0.5557 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6187 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7130\n",
      "Epoch 137/500\n",
      "35/35 - 16s - loss: 0.5569 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6149 - binary_accuracy_inet_decision_function_fv_metric: 0.7092 - val_loss: 0.5503 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6164 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7167\n",
      "Epoch 138/500\n",
      "35/35 - 16s - loss: 0.5588 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6156 - binary_accuracy_inet_decision_function_fv_metric: 0.7079 - val_loss: 0.5524 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6166 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7162\n",
      "Epoch 139/500\n",
      "35/35 - 16s - loss: 0.5586 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6156 - binary_accuracy_inet_decision_function_fv_metric: 0.7078 - val_loss: 0.5480 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6145 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7189\n",
      "Epoch 140/500\n",
      "35/35 - 16s - loss: 0.5587 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6154 - binary_accuracy_inet_decision_function_fv_metric: 0.7083 - val_loss: 0.5540 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6175 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7131\n",
      "Epoch 141/500\n",
      "35/35 - 16s - loss: 0.5583 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6154 - binary_accuracy_inet_decision_function_fv_metric: 0.7081 - val_loss: 0.5481 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6151 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7182\n",
      "Epoch 142/500\n",
      "35/35 - 16s - loss: 0.5581 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6152 - binary_accuracy_inet_decision_function_fv_metric: 0.7086 - val_loss: 0.5490 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6155 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7174\n",
      "Epoch 143/500\n",
      "35/35 - 16s - loss: 0.5571 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6147 - binary_accuracy_inet_decision_function_fv_metric: 0.7082 - val_loss: 0.5492 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6161 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7170\n",
      "Epoch 144/500\n",
      "35/35 - 16s - loss: 0.5574 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6152 - binary_accuracy_inet_decision_function_fv_metric: 0.7086 - val_loss: 0.5479 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6145 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7180\n",
      "Epoch 145/500\n",
      "35/35 - 16s - loss: 0.5563 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6142 - binary_accuracy_inet_decision_function_fv_metric: 0.7092 - val_loss: 0.5467 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6147 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7203\n",
      "Epoch 146/500\n",
      "35/35 - 16s - loss: 0.5583 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6154 - binary_accuracy_inet_decision_function_fv_metric: 0.7073 - val_loss: 0.5530 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6179 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7160\n",
      "Epoch 147/500\n",
      "35/35 - 16s - loss: 0.5568 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6149 - binary_accuracy_inet_decision_function_fv_metric: 0.7090 - val_loss: 0.5505 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6160 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7149\n",
      "Epoch 148/500\n",
      "35/35 - 16s - loss: 0.5575 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6150 - binary_accuracy_inet_decision_function_fv_metric: 0.7085 - val_loss: 0.5481 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6151 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7198\n",
      "Epoch 149/500\n",
      "35/35 - 16s - loss: 0.5561 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6144 - binary_accuracy_inet_decision_function_fv_metric: 0.7093 - val_loss: 0.5453 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6130 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7183\n",
      "Epoch 150/500\n",
      "35/35 - 16s - loss: 0.5528 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6126 - binary_accuracy_inet_decision_function_fv_metric: 0.7116 - val_loss: 0.5461 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6141 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7190\n",
      "Epoch 151/500\n",
      "35/35 - 16s - loss: 0.5552 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6138 - binary_accuracy_inet_decision_function_fv_metric: 0.7099 - val_loss: 0.5529 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6174 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7133\n",
      "Epoch 152/500\n",
      "35/35 - 16s - loss: 0.5585 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6156 - binary_accuracy_inet_decision_function_fv_metric: 0.7070 - val_loss: 0.5543 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6191 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7131\n",
      "Epoch 153/500\n",
      "35/35 - 16s - loss: 0.5558 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6144 - binary_accuracy_inet_decision_function_fv_metric: 0.7091 - val_loss: 0.5466 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6142 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7219\n",
      "Epoch 154/500\n",
      "35/35 - 16s - loss: 0.5533 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6128 - binary_accuracy_inet_decision_function_fv_metric: 0.7116 - val_loss: 0.5479 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6152 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7198\n",
      "Epoch 155/500\n",
      "35/35 - 16s - loss: 0.5557 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6142 - binary_accuracy_inet_decision_function_fv_metric: 0.7099 - val_loss: 0.5464 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6145 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7204\n",
      "Epoch 156/500\n",
      "35/35 - 16s - loss: 0.5564 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6144 - binary_accuracy_inet_decision_function_fv_metric: 0.7091 - val_loss: 0.5523 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6172 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7160\n",
      "Epoch 157/500\n",
      "35/35 - 16s - loss: 0.5575 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6151 - binary_accuracy_inet_decision_function_fv_metric: 0.7086 - val_loss: 0.5493 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6156 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7173\n",
      "Epoch 158/500\n",
      "35/35 - 16s - loss: 0.5557 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6144 - binary_accuracy_inet_decision_function_fv_metric: 0.7090 - val_loss: 0.5497 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6155 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7173\n",
      "Epoch 159/500\n",
      "35/35 - 16s - loss: 0.5564 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6144 - binary_accuracy_inet_decision_function_fv_metric: 0.7087 - val_loss: 0.5525 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6175 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7146\n",
      "Epoch 160/500\n",
      "35/35 - 16s - loss: 0.5545 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6137 - binary_accuracy_inet_decision_function_fv_metric: 0.7103 - val_loss: 0.5512 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6167 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7147\n",
      "Epoch 161/500\n",
      "35/35 - 16s - loss: 0.5544 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6134 - binary_accuracy_inet_decision_function_fv_metric: 0.7096 - val_loss: 0.5469 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6141 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7181\n",
      "Epoch 162/500\n",
      "35/35 - 16s - loss: 0.5553 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6138 - binary_accuracy_inet_decision_function_fv_metric: 0.7101 - val_loss: 0.5480 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6157 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7173\n",
      "Epoch 163/500\n",
      "35/35 - 16s - loss: 0.5538 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6132 - binary_accuracy_inet_decision_function_fv_metric: 0.7108 - val_loss: 0.5447 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6131 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7198\n",
      "Epoch 164/500\n",
      "35/35 - 16s - loss: 0.5539 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6131 - binary_accuracy_inet_decision_function_fv_metric: 0.7109 - val_loss: 0.5472 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6148 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7182\n",
      "Epoch 165/500\n",
      "35/35 - 16s - loss: 0.5560 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6143 - binary_accuracy_inet_decision_function_fv_metric: 0.7090 - val_loss: 0.5533 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6177 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7123\n",
      "Epoch 166/500\n",
      "35/35 - 16s - loss: 0.5549 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6139 - binary_accuracy_inet_decision_function_fv_metric: 0.7092 - val_loss: 0.5454 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6133 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7194\n",
      "Epoch 167/500\n",
      "35/35 - 16s - loss: 0.5537 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6132 - binary_accuracy_inet_decision_function_fv_metric: 0.7109 - val_loss: 0.5485 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6156 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7189\n",
      "Epoch 168/500\n",
      "35/35 - 16s - loss: 0.5555 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6141 - binary_accuracy_inet_decision_function_fv_metric: 0.7093 - val_loss: 0.5513 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6176 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7156\n",
      "Epoch 169/500\n",
      "35/35 - 16s - loss: 0.5541 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6135 - binary_accuracy_inet_decision_function_fv_metric: 0.7103 - val_loss: 0.5460 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6140 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7165\n",
      "Epoch 170/500\n",
      "35/35 - 16s - loss: 0.5536 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6129 - binary_accuracy_inet_decision_function_fv_metric: 0.7111 - val_loss: 0.5466 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6145 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7197\n",
      "Epoch 171/500\n",
      "35/35 - 16s - loss: 0.5535 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6130 - binary_accuracy_inet_decision_function_fv_metric: 0.7104 - val_loss: 0.5483 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6149 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7172\n",
      "Epoch 172/500\n",
      "35/35 - 16s - loss: 0.5566 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6145 - binary_accuracy_inet_decision_function_fv_metric: 0.7093 - val_loss: 0.5492 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6154 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7168\n",
      "Epoch 173/500\n",
      "35/35 - 16s - loss: 0.5576 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6150 - binary_accuracy_inet_decision_function_fv_metric: 0.7081 - val_loss: 0.5508 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6160 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7152\n",
      "Epoch 174/500\n",
      "35/35 - 16s - loss: 0.5610 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6169 - binary_accuracy_inet_decision_function_fv_metric: 0.7048 - val_loss: 0.5481 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6154 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7176\n",
      "Epoch 175/500\n",
      "35/35 - 16s - loss: 0.5571 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6150 - binary_accuracy_inet_decision_function_fv_metric: 0.7080 - val_loss: 0.5427 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6120 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7207\n",
      "Epoch 176/500\n",
      "35/35 - 16s - loss: 0.5554 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6137 - binary_accuracy_inet_decision_function_fv_metric: 0.7105 - val_loss: 0.5470 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6138 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7174\n",
      "Epoch 177/500\n",
      "35/35 - 16s - loss: 0.5542 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6135 - binary_accuracy_inet_decision_function_fv_metric: 0.7099 - val_loss: 0.5478 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6149 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7175\n",
      "Epoch 178/500\n",
      "35/35 - 16s - loss: 0.5533 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6129 - binary_accuracy_inet_decision_function_fv_metric: 0.7101 - val_loss: 0.5466 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6139 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7183\n",
      "Epoch 179/500\n",
      "35/35 - 16s - loss: 0.5539 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6131 - binary_accuracy_inet_decision_function_fv_metric: 0.7100 - val_loss: 0.5509 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6167 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7155\n",
      "Epoch 180/500\n",
      "35/35 - 16s - loss: 0.5545 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6135 - binary_accuracy_inet_decision_function_fv_metric: 0.7101 - val_loss: 0.5432 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6124 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7208\n",
      "Epoch 181/500\n",
      "35/35 - 16s - loss: 0.5533 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6131 - binary_accuracy_inet_decision_function_fv_metric: 0.7104 - val_loss: 0.5470 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6151 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7185\n",
      "Epoch 182/500\n",
      "35/35 - 16s - loss: 0.5530 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6129 - binary_accuracy_inet_decision_function_fv_metric: 0.7103 - val_loss: 0.5451 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6131 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7188\n",
      "Epoch 183/500\n",
      "35/35 - 16s - loss: 0.5557 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6143 - binary_accuracy_inet_decision_function_fv_metric: 0.7090 - val_loss: 0.5504 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6158 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7164\n",
      "Epoch 184/500\n",
      "35/35 - 16s - loss: 0.5566 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6145 - binary_accuracy_inet_decision_function_fv_metric: 0.7086 - val_loss: 0.5438 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6122 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7236\n",
      "Epoch 185/500\n",
      "35/35 - 16s - loss: 0.5583 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6152 - binary_accuracy_inet_decision_function_fv_metric: 0.7080 - val_loss: 0.5514 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6163 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7163\n",
      "Epoch 186/500\n",
      "35/35 - 16s - loss: 0.5586 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6155 - binary_accuracy_inet_decision_function_fv_metric: 0.7078 - val_loss: 0.5459 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6139 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7223\n",
      "Epoch 187/500\n",
      "35/35 - 16s - loss: 0.5537 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6130 - binary_accuracy_inet_decision_function_fv_metric: 0.7117 - val_loss: 0.5489 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6155 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7191\n",
      "Epoch 188/500\n",
      "35/35 - 16s - loss: 0.5537 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6131 - binary_accuracy_inet_decision_function_fv_metric: 0.7109 - val_loss: 0.5464 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6135 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7203\n",
      "Epoch 189/500\n",
      "35/35 - 16s - loss: 0.5537 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6131 - binary_accuracy_inet_decision_function_fv_metric: 0.7110 - val_loss: 0.5440 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6121 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7236\n",
      "Epoch 190/500\n",
      "35/35 - 16s - loss: 0.5539 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6132 - binary_accuracy_inet_decision_function_fv_metric: 0.7113 - val_loss: 0.5480 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6149 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7200\n",
      "Epoch 191/500\n",
      "35/35 - 16s - loss: 0.5533 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6128 - binary_accuracy_inet_decision_function_fv_metric: 0.7110 - val_loss: 0.5462 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6139 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7215\n",
      "Epoch 192/500\n",
      "35/35 - 16s - loss: 0.5537 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6132 - binary_accuracy_inet_decision_function_fv_metric: 0.7104 - val_loss: 0.5486 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6151 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7177\n",
      "Epoch 193/500\n",
      "35/35 - 16s - loss: 0.5568 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6149 - binary_accuracy_inet_decision_function_fv_metric: 0.7080 - val_loss: 0.5469 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6143 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7203\n",
      "Epoch 194/500\n",
      "35/35 - 16s - loss: 0.5531 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6127 - binary_accuracy_inet_decision_function_fv_metric: 0.7117 - val_loss: 0.5425 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6118 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7234\n",
      "Epoch 195/500\n",
      "35/35 - 16s - loss: 0.5525 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6126 - binary_accuracy_inet_decision_function_fv_metric: 0.7115 - val_loss: 0.5409 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6112 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7239\n",
      "Epoch 196/500\n",
      "35/35 - 16s - loss: 0.5486 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6106 - binary_accuracy_inet_decision_function_fv_metric: 0.7140 - val_loss: 0.5392 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6103 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7257\n",
      "Epoch 197/500\n",
      "35/35 - 16s - loss: 0.5475 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6097 - binary_accuracy_inet_decision_function_fv_metric: 0.7152 - val_loss: 0.5405 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6104 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7223\n",
      "Epoch 198/500\n",
      "35/35 - 16s - loss: 0.5492 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6111 - binary_accuracy_inet_decision_function_fv_metric: 0.7135 - val_loss: 0.5449 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6126 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7186\n",
      "Epoch 199/500\n",
      "35/35 - 16s - loss: 0.5505 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6115 - binary_accuracy_inet_decision_function_fv_metric: 0.7120 - val_loss: 0.5444 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6134 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7206\n",
      "Epoch 200/500\n",
      "35/35 - 17s - loss: 0.5513 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6118 - binary_accuracy_inet_decision_function_fv_metric: 0.7120 - val_loss: 0.5397 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6104 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7244\n",
      "Epoch 201/500\n",
      "35/35 - 16s - loss: 0.5500 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6113 - binary_accuracy_inet_decision_function_fv_metric: 0.7130 - val_loss: 0.5467 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6140 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7173\n",
      "Epoch 202/500\n",
      "35/35 - 16s - loss: 0.5517 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6122 - binary_accuracy_inet_decision_function_fv_metric: 0.7122 - val_loss: 0.5424 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6118 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7220\n",
      "Epoch 203/500\n",
      "35/35 - 16s - loss: 0.5481 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6103 - binary_accuracy_inet_decision_function_fv_metric: 0.7148 - val_loss: 0.5443 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6128 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7200\n",
      "Epoch 204/500\n",
      "35/35 - 16s - loss: 0.5484 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6105 - binary_accuracy_inet_decision_function_fv_metric: 0.7143 - val_loss: 0.5423 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6128 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7223\n",
      "Epoch 205/500\n",
      "35/35 - 16s - loss: 0.5497 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6113 - binary_accuracy_inet_decision_function_fv_metric: 0.7130 - val_loss: 0.5455 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6140 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7180\n",
      "Epoch 206/500\n",
      "35/35 - 16s - loss: 0.5528 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6128 - binary_accuracy_inet_decision_function_fv_metric: 0.7108 - val_loss: 0.5435 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6126 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7217\n",
      "Epoch 207/500\n",
      "35/35 - 16s - loss: 0.5519 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6122 - binary_accuracy_inet_decision_function_fv_metric: 0.7111 - val_loss: 0.5461 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6138 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7176\n",
      "Epoch 208/500\n",
      "35/35 - 16s - loss: 0.5536 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6133 - binary_accuracy_inet_decision_function_fv_metric: 0.7101 - val_loss: 0.5510 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6165 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7137\n",
      "Epoch 209/500\n",
      "35/35 - 16s - loss: 0.5560 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6147 - binary_accuracy_inet_decision_function_fv_metric: 0.7075 - val_loss: 0.5507 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6165 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7154\n",
      "Epoch 210/500\n",
      "35/35 - 16s - loss: 0.5550 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6140 - binary_accuracy_inet_decision_function_fv_metric: 0.7089 - val_loss: 0.5509 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6167 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7150\n",
      "Epoch 211/500\n",
      "35/35 - 16s - loss: 0.5533 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6131 - binary_accuracy_inet_decision_function_fv_metric: 0.7105 - val_loss: 0.5427 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6122 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7220\n",
      "Epoch 212/500\n",
      "35/35 - 16s - loss: 0.5526 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6128 - binary_accuracy_inet_decision_function_fv_metric: 0.7120 - val_loss: 0.5453 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6134 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7209\n",
      "Epoch 213/500\n",
      "35/35 - 16s - loss: 0.5498 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6111 - binary_accuracy_inet_decision_function_fv_metric: 0.7137 - val_loss: 0.5399 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6101 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7240\n",
      "Epoch 214/500\n",
      "35/35 - 16s - loss: 0.5504 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6115 - binary_accuracy_inet_decision_function_fv_metric: 0.7131 - val_loss: 0.5451 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6135 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7190\n",
      "Epoch 215/500\n",
      "35/35 - 16s - loss: 0.5491 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6110 - binary_accuracy_inet_decision_function_fv_metric: 0.7132 - val_loss: 0.5439 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6126 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7187\n",
      "Epoch 216/500\n",
      "35/35 - 16s - loss: 0.5511 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6120 - binary_accuracy_inet_decision_function_fv_metric: 0.7119 - val_loss: 0.5409 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6110 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7242\n",
      "Epoch 217/500\n",
      "35/35 - 16s - loss: 0.5473 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6100 - binary_accuracy_inet_decision_function_fv_metric: 0.7152 - val_loss: 0.5417 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6117 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7227\n",
      "Epoch 218/500\n",
      "35/35 - 16s - loss: 0.5519 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6122 - binary_accuracy_inet_decision_function_fv_metric: 0.7122 - val_loss: 0.5474 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6153 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7186\n",
      "Epoch 219/500\n",
      "35/35 - 16s - loss: 0.5516 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6123 - binary_accuracy_inet_decision_function_fv_metric: 0.7123 - val_loss: 0.5476 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6147 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7174\n",
      "Epoch 220/500\n",
      "35/35 - 16s - loss: 0.5499 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6114 - binary_accuracy_inet_decision_function_fv_metric: 0.7133 - val_loss: 0.5459 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6143 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7186\n",
      "Epoch 221/500\n",
      "35/35 - 16s - loss: 0.5524 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6125 - binary_accuracy_inet_decision_function_fv_metric: 0.7113 - val_loss: 0.5492 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6154 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7180\n",
      "Epoch 222/500\n",
      "35/35 - 16s - loss: 0.5515 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6122 - binary_accuracy_inet_decision_function_fv_metric: 0.7124 - val_loss: 0.5420 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6118 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7231\n",
      "Epoch 223/500\n",
      "35/35 - 19s - loss: 0.5507 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6119 - binary_accuracy_inet_decision_function_fv_metric: 0.7124 - val_loss: 0.5437 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6125 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7207\n",
      "Epoch 224/500\n",
      "35/35 - 20s - loss: 0.5494 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6111 - binary_accuracy_inet_decision_function_fv_metric: 0.7134 - val_loss: 0.5401 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6110 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7230\n",
      "Epoch 225/500\n",
      "35/35 - 18s - loss: 0.5481 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6105 - binary_accuracy_inet_decision_function_fv_metric: 0.7148 - val_loss: 0.5442 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6134 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7201\n",
      "Epoch 226/500\n",
      "35/35 - 17s - loss: 0.5510 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6120 - binary_accuracy_inet_decision_function_fv_metric: 0.7116 - val_loss: 0.5467 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6142 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7168\n",
      "Epoch 227/500\n",
      "35/35 - 19s - loss: 0.5516 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6122 - binary_accuracy_inet_decision_function_fv_metric: 0.7117 - val_loss: 0.5455 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6137 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7181\n",
      "Epoch 228/500\n",
      "35/35 - 24s - loss: 0.5511 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6121 - binary_accuracy_inet_decision_function_fv_metric: 0.7108 - val_loss: 0.5424 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6124 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7196\n",
      "Epoch 229/500\n",
      "35/35 - 26s - loss: 0.5525 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6128 - binary_accuracy_inet_decision_function_fv_metric: 0.7110 - val_loss: 0.5449 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6129 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7183\n",
      "Epoch 230/500\n",
      "35/35 - 28s - loss: 0.5501 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6114 - binary_accuracy_inet_decision_function_fv_metric: 0.7130 - val_loss: 0.5442 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6120 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7202\n",
      "Epoch 231/500\n",
      "35/35 - 29s - loss: 0.5495 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6112 - binary_accuracy_inet_decision_function_fv_metric: 0.7139 - val_loss: 0.5418 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6117 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7203\n",
      "Epoch 232/500\n",
      "35/35 - 28s - loss: 0.5506 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6117 - binary_accuracy_inet_decision_function_fv_metric: 0.7126 - val_loss: 0.5445 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6136 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7174\n",
      "Epoch 233/500\n",
      "35/35 - 29s - loss: 0.5492 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6113 - binary_accuracy_inet_decision_function_fv_metric: 0.7127 - val_loss: 0.5436 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6125 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7194\n",
      "Epoch 234/500\n",
      "35/35 - 27s - loss: 0.5498 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6114 - binary_accuracy_inet_decision_function_fv_metric: 0.7132 - val_loss: 0.5423 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6119 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7208\n",
      "Epoch 235/500\n",
      "35/35 - 28s - loss: 0.5498 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6114 - binary_accuracy_inet_decision_function_fv_metric: 0.7131 - val_loss: 0.5398 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6110 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7255\n",
      "Epoch 236/500\n",
      "35/35 - 28s - loss: 0.5500 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6116 - binary_accuracy_inet_decision_function_fv_metric: 0.7120 - val_loss: 0.5384 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6097 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7237\n",
      "Epoch 237/500\n",
      "35/35 - 29s - loss: 0.5496 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6112 - binary_accuracy_inet_decision_function_fv_metric: 0.7130 - val_loss: 0.5410 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6116 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7232\n",
      "Epoch 238/500\n",
      "35/35 - 29s - loss: 0.5480 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6107 - binary_accuracy_inet_decision_function_fv_metric: 0.7141 - val_loss: 0.5419 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6121 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7241\n",
      "Epoch 239/500\n",
      "35/35 - 29s - loss: 0.5523 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6127 - binary_accuracy_inet_decision_function_fv_metric: 0.7106 - val_loss: 0.5484 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6152 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7168\n",
      "Epoch 240/500\n",
      "35/35 - 28s - loss: 0.5506 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6117 - binary_accuracy_inet_decision_function_fv_metric: 0.7126 - val_loss: 0.5415 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6114 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7227\n",
      "Epoch 241/500\n",
      "35/35 - 29s - loss: 0.5489 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6109 - binary_accuracy_inet_decision_function_fv_metric: 0.7138 - val_loss: 0.5410 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6111 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7216\n",
      "Epoch 242/500\n",
      "35/35 - 28s - loss: 0.5483 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6107 - binary_accuracy_inet_decision_function_fv_metric: 0.7142 - val_loss: 0.5417 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6118 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7230\n",
      "Epoch 243/500\n",
      "35/35 - 29s - loss: 0.5492 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6111 - binary_accuracy_inet_decision_function_fv_metric: 0.7134 - val_loss: 0.5439 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6129 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7171\n",
      "Epoch 244/500\n",
      "35/35 - 28s - loss: 0.5482 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6106 - binary_accuracy_inet_decision_function_fv_metric: 0.7142 - val_loss: 0.5414 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6116 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7208\n",
      "Epoch 245/500\n",
      "35/35 - 29s - loss: 0.5503 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6118 - binary_accuracy_inet_decision_function_fv_metric: 0.7127 - val_loss: 0.5439 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6128 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7186\n",
      "Epoch 246/500\n",
      "35/35 - 27s - loss: 0.5508 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6121 - binary_accuracy_inet_decision_function_fv_metric: 0.7114 - val_loss: 0.5460 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6139 - val_binary_accuracy_inet_decision_function_fv_metric: 0.7178\n",
      "Training Time: 1:10:36\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model,\n",
    " encoder_model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=['tensorboard'] #plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:27.116714Z",
     "iopub.status.busy": "2022-01-03T15:57:27.116384Z",
     "iopub.status.idle": "2022-01-03T15:57:27.626473Z",
     "shell.execute_reply": "2022-01-03T15:57:27.625400Z",
     "shell.execute_reply.started": "2022-01-03T15:57:27.116669Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "        \n",
    "    writepath_nas = './results_nas.csv'\n",
    "\n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "\n",
    "    if not os.path.exists(writepath_nas):\n",
    "        with open(writepath_nas, 'w+') as text_file:       \n",
    "            for key in flat_config.keys():\n",
    "                text_file.write(key)\n",
    "                text_file.write(';')         \n",
    "\n",
    "            for hp in history[0].hyperparameters.values.keys():\n",
    "                text_file.write(hp + ';')    \n",
    "               \n",
    "            text_file.write('score')\n",
    "            \n",
    "            text_file.write('\\n')\n",
    "            \n",
    "            \n",
    "\n",
    "    with open(writepath_nas, 'a+') as text_file:  \n",
    "        for value in flat_config.values():\n",
    "            text_file.write(str(value))\n",
    "            text_file.write(';')\n",
    "\n",
    "        for hp, value in history[0].hyperparameters.values.items():\n",
    "            text_file.write(str(value) + ';')        \n",
    "\n",
    "        \n",
    "        text_file.write(str(history[0].score))\n",
    "            \n",
    "        text_file.write('\\n')            \n",
    "\n",
    "        text_file.close()      \n",
    "        \n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:27.628572Z",
     "iopub.status.busy": "2022-01-03T15:57:27.628145Z",
     "iopub.status.idle": "2022-01-03T15:57:28.787087Z",
     "shell.execute_reply": "2022-01-03T15:57:28.785031Z",
     "shell.execute_reply.started": "2022-01-03T15:57:27.628527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 3\n",
    "network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data(network_parameters, config, encoder_model)    \n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:28.789361Z",
     "iopub.status.busy": "2022-01-03T15:57:28.788906Z",
     "iopub.status.idle": "2022-01-03T15:57:28.842682Z",
     "shell.execute_reply": "2022-01-03T15:57:28.841239Z",
     "shell.execute_reply.started": "2022-01-03T15:57:28.789318Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 2177)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_1024 (Dense)            (None, 1024)         2230272     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation1_relu (Activation)   (None, 1024)         0           hidden1_1024[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout1_0.3 (Dropout)          (None, 1024)         0           activation1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_1024 (Dense)            (None, 1024)         1049600     dropout1_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation2_relu (Activation)   (None, 1024)         0           hidden2_1024[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout2_0.3 (Dropout)          (None, 1024)         0           activation2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden3_256 (Dense)             (None, 256)          262400      dropout2_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation3_relu (Activation)   (None, 256)          0           hidden3_256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout3_0.3 (Dropout)          (None, 256)          0           activation3_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden4_2048 (Dense)            (None, 2048)         526336      dropout3_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation4_relu (Activation)   (None, 2048)         0           hidden4_2048[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout4_0.3 (Dropout)          (None, 2048)         0           activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden5_2048 (Dense)            (None, 2048)         4196352     dropout4_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation5_relu (Activation)   (None, 2048)         0           hidden5_2048[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout5_0.3 (Dropout)          (None, 2048)         0           activation5_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_coeff_225 (Dense)        (None, 225)          461025      dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_1 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_2 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_3 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_4 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_5 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_6 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_7 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_8 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_9 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_10 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_11 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_12 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_13 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_14 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_15 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_bias_15 (Dense)          (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_nodes_32 (Dense)    (None, 32)           65568       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_combined (Concatenate)   (None, 497)          0           output_coeff_225[0][0]           \n",
      "                                                                 output_identifier_1[0][0]        \n",
      "                                                                 output_identifier_2[0][0]        \n",
      "                                                                 output_identifier_3[0][0]        \n",
      "                                                                 output_identifier_4[0][0]        \n",
      "                                                                 output_identifier_5[0][0]        \n",
      "                                                                 output_identifier_6[0][0]        \n",
      "                                                                 output_identifier_7[0][0]        \n",
      "                                                                 output_identifier_8[0][0]        \n",
      "                                                                 output_identifier_9[0][0]        \n",
      "                                                                 output_identifier_10[0][0]       \n",
      "                                                                 output_identifier_11[0][0]       \n",
      "                                                                 output_identifier_12[0][0]       \n",
      "                                                                 output_identifier_13[0][0]       \n",
      "                                                                 output_identifier_14[0][0]       \n",
      "                                                                 output_identifier_15[0][0]       \n",
      "                                                                 output_bias_15[0][0]             \n",
      "                                                                 output_leaf_nodes_32[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 9,283,313\n",
      "Trainable params: 9,283,313\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:28.845011Z",
     "iopub.status.busy": "2022-01-03T15:57:28.844555Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_train.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_train.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)   \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    \n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=10, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_train.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_train.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_train = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_train == None:\n",
    "            inet_evaluation_result_dict_train = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_train = mergeDict(inet_evaluation_result_dict_train, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_train['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_train = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_train.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_train[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_train[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_train[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('TRAIN DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_train = np.round(np.mean(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "std_train = np.round(np.std(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_train.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_train = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_train = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_train = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_train = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_train = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_train = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_valid.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_valid.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)  \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_valid.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_valid.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_valid = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_valid == None:\n",
    "            inet_evaluation_result_dict_valid = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_valid = mergeDict(inet_evaluation_result_dict_valid, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_valid['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_valid = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_valid.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_valid[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_valid[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_valid[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('VALID DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_valid.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_valid = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_valid = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_valid = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_valid = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_valid = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_valid = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = lambda_net_dataset_test.X_test_lambda_array.shape[0]#10\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_test.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)  \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_test.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_test.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_test = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_test == None:\n",
    "            inet_evaluation_result_dict_test = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_test = mergeDict(inet_evaluation_result_dict_test, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_test['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_test = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_test.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_test[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_test[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_test[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('TEST DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_test.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_test = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_test = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_test = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_test = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_test = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_test = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Train', 'Train ', ' Train ', 'Valid', 'Valid ', ' Valid ', 'Test', 'Test ', ' Test ']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Metric', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net'],\n",
    "        ['Soft Binary Crossentropy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime_median'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime_median'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATA EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "\n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "#adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "#adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 'capital_gain'\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "categorical_features = ['Race', 'Workclass', 'Education', \"Marital Status\", \"Occupation\", \"Relationship\"]#[1, 2, 7]\n",
    "ordinal_features = ['Sex', 'capital_gain']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(adult_data)\n",
    "\n",
    "adult_data = transformer.transform(adult_data)\n",
    "adult_data = pd.DataFrame(adult_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    adult_data[ordinal_feature] = OrdinalEncoder().fit_transform(adult_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "adult_data = adult_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "y_data_adult = adult_data['capital_gain']\n",
    "\n",
    "print(X_data_adult.shape)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_adult.shape[1] > number_of_variables:\n",
    "    #X_data_adult = X_data_adult.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_adult = ExtraTreesClassifier(n_estimators=100,\n",
    "                                      random_state=RANDOM_SEED)\n",
    "    clf_adult = clf_adult.fit(X_data_adult, y_data_adult)\n",
    "\n",
    "    selector_adult = SelectFromModel(clf_adult, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_adult.get_support()   \n",
    "    X_data_adult = X_data_adult.loc[:,feature_idx]\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_adult.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_adult[column_name] = np.zeros(X_data_adult.shape[0])\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_adult:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_adult[column_name].values.reshape(-1, 1))\n",
    "    X_data_adult[column_name] = scaler.transform(X_data_adult[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_adult_with_valid, X_test_adult, y_train_adult_with_valid, y_test_adult = train_test_split(X_data_adult, y_data_adult, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_adult, X_valid_adult, y_train_adult, y_valid_adult = train_test_split(X_train_adult_with_valid, y_train_adult_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_adult.shape, y_train_adult.shape)\n",
    "print(X_valid_adult.shape, y_valid_adult.shape)\n",
    "print(X_test_adult.shape, y_test_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_adult, y_train_adult = oversample.fit_resample(X_train_adult, y_train_adult)\n",
    "\n",
    "    true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "    false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_adult = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_adult.fit(X_train_adult,\n",
    "                                      y_train_adult, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_adult, y_valid_adult),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult_parameters = shaped_network_parameters_to_array(test_network_adult.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_adult_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_adult_dt_inet = model.predict(network_parameters)[0]    \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size_list = [1_000, 10_000, 100_000, 1_000_000, 'TRAIN_DATA']\n",
    "    \n",
    "results_adult_list = []\n",
    "dt_distilled_adult_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_adult.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_adult['inet_scores']['runtime'] = inet_runtime\n",
    "    results_adult_list.append(results_adult)\n",
    "    dt_distilled_adult_list.append(dt_distilled_adult)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_adult['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy',  np.round(results_adult['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['binary_crossentropy'], 3), np.round(results_adult['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_adult['dt_scores']['accuracy_data_random'], 3), np.round(results_adult['dt_scores']['accuracy'], 3), np.round(results_adult['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_adult['dt_scores']['f1_score_data_random'], 3), np.round(results_adult['dt_scores']['f1_score'], 3), np.round(results_adult['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n",
    "        \n",
    "adult_evaluation_result_dict = None\n",
    "for some_dict in results_adult_list:\n",
    "    if adult_evaluation_result_dict == None:\n",
    "        adult_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        adult_evaluation_result_dict = mergeDict(adult_evaluation_result_dict, some_dict)\n",
    "\n",
    "#adult_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_adult, \n",
    " distance_to_initialization_aggregate_adult, \n",
    " distance_to_sample_average_adult, \n",
    " distance_to_sample_min_adult,\n",
    " max_distance_to_neuron_average_adult,\n",
    " max_distance_to_neuron_min_adult) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_adult_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3)],           \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_adult_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_adult_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_adult, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_adult.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.drop([\n",
    "                                    'Cabin', \n",
    "                                    'Ticket', \n",
    "                                    'Name', \n",
    "                                    'PassengerId'\n",
    "                                ], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "categorical_features = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features = ['Sex']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(titanic_data)\n",
    "\n",
    "titanic_data = transformer.transform(titanic_data)\n",
    "titanic_data = pd.DataFrame(titanic_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    titanic_data[ordinal_feature] = OrdinalEncoder().fit_transform(titanic_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "titanic_data = titanic_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n",
    "\n",
    "print(X_data_titanic.shape)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_titanic.shape[1] > number_of_variables:\n",
    "    #X_data_titanic = X_data_titanic.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_titanic = ExtraTreesClassifier(n_estimators=100,\n",
    "                                      random_state=RANDOM_SEED)\n",
    "    clf_titanic = clf_titanic.fit(X_data_titanic, y_data_titanic)\n",
    "\n",
    "    selector_titanic = SelectFromModel(clf_titanic, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_titanic.get_support()   \n",
    "    X_data_titanic = X_data_titanic.loc[:,feature_idx]    \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_titanic.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_titanic[column_name] = np.zeros(X_data_titanic.shape[0])\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_titanic:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_titanic[column_name].values.reshape(-1, 1))\n",
    "    X_data_titanic[column_name] = scaler.transform(X_data_titanic[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_titanic_with_valid, X_test_titanic, y_train_titanic_with_valid, y_test_titanic = train_test_split(X_data_titanic, y_data_titanic, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_titanic, X_valid_titanic, y_train_titanic, y_valid_titanic = train_test_split(X_train_titanic_with_valid, y_train_titanic_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_titanic.shape, y_train_titanic.shape)\n",
    "print(X_valid_titanic.shape, y_valid_titanic.shape)\n",
    "print(X_test_titanic.shape, y_test_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_titanic, y_train_titanic = oversample.fit_resample(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "    false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_titanic = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_titanic.fit(X_train_titanic,\n",
    "                                          y_train_titanic, \n",
    "                                          epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                          batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                          callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                          validation_data=(X_valid_titanic, y_valid_titanic),\n",
    "                                          verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic_parameters = shaped_network_parameters_to_array(test_network_titanic.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_titanic_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_titanic_dt_inet = model.predict(network_parameters)[0]    \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_titanic_list = []\n",
    "dt_distilled_titanic_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_titanic.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_titanic['inet_scores']['runtime'] = inet_runtime\n",
    "    results_titanic_list.append(results_titanic)\n",
    "    dt_distilled_titanic_list.append(dt_distilled_titanic)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_titanic['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_titanic['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_titanic['dt_scores']['accuracy_data_random'], 3), np.round(results_titanic['dt_scores']['accuracy'], 3), np.round(results_titanic['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_titanic['dt_scores']['f1_score_data_random'], 3), np.round(results_titanic['dt_scores']['f1_score'], 3), np.round(results_titanic['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "titanic_evaluation_result_dict = None\n",
    "for some_dict in results_titanic_list:\n",
    "    if titanic_evaluation_result_dict == None:\n",
    "        titanic_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        titanic_evaluation_result_dict = mergeDict(titanic_evaluation_result_dict, some_dict)\n",
    "\n",
    "#titanic_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_titanic, \n",
    " distance_to_initialization_aggregate_titanic, \n",
    " distance_to_sample_average_titanic, \n",
    " distance_to_sample_min_titanic,\n",
    " max_distance_to_neuron_average_titanic,\n",
    " max_distance_to_neuron_min_titanic) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_titanic_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data', 'Titanic Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3), np.round(z_score_aggregate_titanic, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3), np.round(distance_to_initialization_aggregate_titanic, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3), np.round(distance_to_sample_average_titanic, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3), np.round(distance_to_sample_min_titanic, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3), np.round(max_distance_to_neuron_average_titanic, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3), np.round(max_distance_to_neuron_min_titanic, 3)],           \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_titanic_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_titanic_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_titanic, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_titanic.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "absenteeism_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           'Weight', \n",
    "                           'Height', \n",
    "                           'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = []\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(absenteeism_data)\n",
    "\n",
    "absenteeism_data = transformer.transform(absenteeism_data)\n",
    "absenteeism_data = pd.DataFrame(absenteeism_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    absenteeism_data[ordinal_feature] = OrdinalEncoder().fit_transform(absenteeism_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "absenteeism_data = absenteeism_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n",
    "\n",
    "print(X_data_absenteeism.shape)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_absenteeism.shape[1] > number_of_variables:\n",
    "    #X_data_absenteeism = X_data_absenteeism.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_absenteeism = ExtraTreesClassifier(n_estimators=100,\n",
    "                                          random_state=RANDOM_SEED)\n",
    "    clf_absenteeism = clf_absenteeism.fit(X_data_absenteeism, y_data_absenteeism)\n",
    "\n",
    "    selector_absenteeism = SelectFromModel(clf_absenteeism, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_absenteeism.get_support()   \n",
    "    X_data_absenteeism = X_data_absenteeism.loc[:,feature_idx]        \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_absenteeism.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_absenteeism[column_name] = np.zeros(X_data_absenteeism.shape[0])\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_absenteeism:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_absenteeism[column_name].values.reshape(-1, 1))\n",
    "    X_data_absenteeism[column_name] = scaler.transform(X_data_absenteeism[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_absenteeism_with_valid, X_test_absenteeism, y_train_absenteeism_with_valid, y_test_absenteeism = train_test_split(X_data_absenteeism, y_data_absenteeism, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_absenteeism, X_valid_absenteeism, y_train_absenteeism, y_valid_absenteeism = train_test_split(X_train_absenteeism_with_valid, y_train_absenteeism_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_absenteeism.shape, y_train_absenteeism.shape)\n",
    "print(X_valid_absenteeism.shape, y_valid_absenteeism.shape)\n",
    "print(X_test_absenteeism.shape, y_test_absenteeism.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_absenteeism, y_train_absenteeism = oversample.fit_resample(X_train_absenteeism, y_train_absenteeism)\n",
    "\n",
    "    true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "    false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_absenteeism = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_absenteeism.fit(X_train_absenteeism,\n",
    "                                      y_train_absenteeism, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_absenteeism, y_valid_absenteeism),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism_parameters = shaped_network_parameters_to_array(test_network_absenteeism.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_absenteeism_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_absenteeism_dt_inet = model.predict(network_parameters)[0]  \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_absenteeism_list = []\n",
    "dt_distilled_absenteeism_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_absenteeism.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_absenteeism['inet_scores']['runtime'] = inet_runtime\n",
    "    results_absenteeism_list.append(results_absenteeism)\n",
    "    dt_distilled_absenteeism_list.append(dt_distilled_absenteeism)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_absenteeism['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_absenteeism['dt_scores']['accuracy_data_random'], 3), np.round(results_absenteeism['dt_scores']['accuracy'], 3), np.round(results_absenteeism['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_absenteeism['dt_scores']['f1_score_data_random'], 3), np.round(results_absenteeism['dt_scores']['f1_score'], 3), np.round(results_absenteeism['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime', np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "\n",
    "    \n",
    "absenteeism_evaluation_result_dict = None\n",
    "for some_dict in results_absenteeism_list:\n",
    "    if absenteeism_evaluation_result_dict == None:\n",
    "        absenteeism_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        absenteeism_evaluation_result_dict = mergeDict(absenteeism_evaluation_result_dict, some_dict)\n",
    "\n",
    "#absenteeism_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_absenteeism, \n",
    " distance_to_initialization_aggregate_absenteeism, \n",
    " distance_to_sample_average_absenteeism, \n",
    " distance_to_sample_min_absenteeism,\n",
    " max_distance_to_neuron_average_absenteeism,\n",
    " max_distance_to_neuron_min_absenteeism) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_absenteeism_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data', 'Titanic Data', 'Absenteeism Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3), np.round(z_score_aggregate_titanic, 3), np.round(z_score_aggregate_absenteeism, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3), np.round(distance_to_initialization_aggregate_titanic, 3), np.round(distance_to_initialization_aggregate_absenteeism, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3), np.round(distance_to_sample_average_titanic, 3), np.round(distance_to_sample_average_absenteeism, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3), np.round(distance_to_sample_min_titanic, 3), np.round(distance_to_sample_min_absenteeism, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3), np.round(max_distance_to_neuron_average_titanic, 3), np.round(max_distance_to_neuron_average_absenteeism, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3), np.round(max_distance_to_neuron_min_titanic, 3), np.round(max_distance_to_neuron_min_absenteeism, 3)],        \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_absenteeism_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_absenteeism_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_absenteeism, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_absenteeism.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size = 10000\n",
    "\n",
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', \n",
    "                   #'Dist. (Random) Adult', \n",
    "                   'Dist. Adult', \n",
    "                   'I-Net Adult',\n",
    "                   #'Dist. (Random) Titanic', \n",
    "                   'Dist. Titanic', \n",
    "                   'I-Net Titanic',                   \n",
    "                   #'Dist. (Random) Absent.', \n",
    "                   'Dist. Absent.', \n",
    "                   'I-Net Absent.',\n",
    "                  ]\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft BC', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                      \n",
    "                      ]),\n",
    "        flatten_list(['BC',  \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                       \n",
    "                     ]),\n",
    "        flatten_list(['Acc', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),      \n",
    "                     ]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                            \n",
    "                     ]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                            \n",
    "                     ])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if different_eval_data:\n",
    "    flat_config = flatten_dict(config_train)\n",
    "else:\n",
    "    flat_config = flatten_dict(config)    \n",
    "\n",
    "flat_dict_train = flatten_dict(inet_evaluation_result_dict_train)\n",
    "flat_dict_valid = flatten_dict(inet_evaluation_result_dict_valid)\n",
    "flat_dict_test = flatten_dict(inet_evaluation_result_dict_test)\n",
    "\n",
    "\n",
    "#TODO ADD FUNCTION VALUES FOR EACH DATASET SIZE (IN SEPARATE FILE?)\n",
    "#    - COLLECT ERRORS PER NETWORK / FIND FILE WHERE SAVED\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file:       \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key)\n",
    "            text_file.write(';')      \n",
    "        \n",
    "        number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_train.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_train_' + str(i) + ';')    \n",
    "                    \n",
    "        number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_valid.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_valid_' + str(i) + ';')       \n",
    "                    \n",
    "        number_of_evaluated_networks = np.array(flat_dict_test['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_test.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_test_' + str(i) + ';')        \n",
    "        \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file:  \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "            \n",
    "        \n",
    "    number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_train.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_valid.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_test['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_test.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "                    \n",
    "    text_file.write('\\n')            \n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inet_evaluation_result_dict_mean_train_flat = flatten_dict(inet_evaluation_result_dict_mean_train)\n",
    "inet_evaluation_result_dict_mean_valid_flat = flatten_dict(inet_evaluation_result_dict_mean_valid)\n",
    "inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_test)\n",
    "    \n",
    "results_adult_flat = flatten_dict(results_adult)\n",
    "del results_adult_flat['function_values_y_test_inet_dt']\n",
    "del results_adult_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "results_titanic_flat = flatten_dict(results_titanic)\n",
    "del results_titanic_flat['function_values_y_test_inet_dt']\n",
    "del results_titanic_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "results_absenteeism_flat = flatten_dict(results_absenteeism)\n",
    "del results_absenteeism_flat['function_values_y_test_inet_dt']\n",
    "del results_absenteeism_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "adult_evaluation_result_dict_flat = flatten_dict(adult_evaluation_result_dict)\n",
    "del adult_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del adult_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del adult_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "titanic_evaluation_result_dict_flat = flatten_dict(titanic_evaluation_result_dict)\n",
    "del titanic_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del titanic_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del titanic_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "absenteeism_evaluation_result_dict_flat = flatten_dict(absenteeism_evaluation_result_dict)\n",
    "del absenteeism_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del absenteeism_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del absenteeism_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "\n",
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key + ';')\n",
    "         \n",
    "        for key in inet_evaluation_result_dict_mean_train_flat.keys():\n",
    "            text_file.write('train_' + key + ';')\n",
    "        for key in inet_evaluation_result_dict_mean_valid_flat.keys():\n",
    "            text_file.write('valid_' + key + ';')            \n",
    "        for key in inet_evaluation_result_dict_mean_test_flat.keys():\n",
    "            text_file.write('test_' + key + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list:\n",
    "            for key in results_adult_flat.keys():\n",
    "                text_file.write(key + '_adult_' + str(dataset_size) + ';')\n",
    "        \n",
    "            for key in results_titanic_flat.keys():\n",
    "                text_file.write(key + '_titanic_' + str(dataset_size) + ';')\n",
    "                \n",
    "            for key in results_absenteeism_flat.keys():\n",
    "                text_file.write(key + '_absenteeism_' + str(dataset_size) + ';')    \n",
    "         \n",
    "        text_file.write('z-score_train' + ';')    \n",
    "        text_file.write('z-score_valid' + ';')    \n",
    "        text_file.write('z-score_test' + ';')    \n",
    "        text_file.write('z-score_adult' + ';')    \n",
    "        text_file.write('z-score_titanic' + ';')    \n",
    "        text_file.write('z-score_absenteeism' + ';')    \n",
    "\n",
    "        text_file.write('dist_to_init_train' + ';')    \n",
    "        text_file.write('dist_to_init_valid' + ';')    \n",
    "        text_file.write('dist_to_init_test' + ';')    \n",
    "        text_file.write('dist_to_init_adult' + ';')    \n",
    "        text_file.write('dist_to_init_titanic' + ';')    \n",
    "        text_file.write('dist_to_init_absenteeism' + ';')    \n",
    "        \n",
    "        text_file.write('avg_dist_to_train_train' + ';')    \n",
    "        text_file.write('avg_dist_to_train_valid' + ';')    \n",
    "        text_file.write('avg_dist_to_train_test' + ';')    \n",
    "        text_file.write('avg_dist_to_train_adult' + ';')    \n",
    "        text_file.write('avg_dist_to_train_titanic' + ';')    \n",
    "        text_file.write('avg_dist_to_train_absenteeism' + ';')    \n",
    "        \n",
    "        text_file.write('min_dist_to_train_sample_train' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_valid' + ';')    \n",
    "        text_file.write('min_dist_to_train_samplee_test' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_adult' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_titanic' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_absenteeism')    \n",
    "        \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    for value in inet_evaluation_result_dict_mean_train_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "    for value in inet_evaluation_result_dict_mean_valid_flat.values():\n",
    "        text_file.write(str(value) + ';')            \n",
    "    for value in inet_evaluation_result_dict_mean_test_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "\n",
    "    for i in range(len(dataset_size_list)):\n",
    "        for values in adult_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "\n",
    "        for values in titanic_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "\n",
    "        for values in absenteeism_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "    \n",
    "    text_file.write(str(z_score_average_train) + ';')    \n",
    "    text_file.write(str(z_score_average_valid) + ';')    \n",
    "    text_file.write(str(z_score_average_test) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_adult) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_titanic) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_initialization_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_adult) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_sample_average_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_adult) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_sample_min_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_adult) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_absenteeism))       \n",
    "    \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
