{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inerpretation-Net Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specitication of Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:10.978195Z",
     "iopub.status.busy": "2022-01-04T11:01:10.977626Z",
     "iopub.status.idle": "2022-01-04T11:01:11.031205Z",
     "shell.execute_reply": "2022-01-04T11:01:11.029075Z",
     "shell.execute_reply.started": "2022-01-04T11:01:10.978045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### CONFIG FILE ####################################################################\n",
    "#######################################################################################################################################\n",
    "sleep_time = 0 #minutes\n",
    "\n",
    "\n",
    "config = {\n",
    "    'function_family': {\n",
    "        'maximum_depth': 4,\n",
    "        'beta': 1,\n",
    "        'decision_sparsity': 1,\n",
    "        'fully_grown': True,    \n",
    "        'dt_type': 'vanilla', #'SDT', 'vanilla'\n",
    "    },\n",
    "    'data': {\n",
    "        'number_of_variables': 15, \n",
    "        'num_classes': 2,\n",
    "        'categorical_indices': [],\n",
    "        \n",
    "        'dt_type_train': 'vanilla', # (None, 'vanilla', 'SDT')\n",
    "        'maximum_depth_train': 5, #None or int\n",
    "        'decision_sparsity_train': 1, #None or int\n",
    "        \n",
    "        'function_generation_type': 'make_classification_trained',# 'make_classification', 'make_classification_trained', 'random_decision_tree', 'random_decision_tree_trained'\n",
    "        'objective': 'classification', # 'regression'\n",
    "        \n",
    "        'x_max': 1,\n",
    "        'x_min': 0,\n",
    "        'x_distrib': 'uniform', #'normal', 'uniform',       \n",
    "                \n",
    "        'lambda_dataset_size': 5000, #number of samples per function\n",
    "        #'number_of_generated_datasets': 10000,\n",
    "        \n",
    "        'noise_injected_level': 0, \n",
    "        'noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'\n",
    "    }, \n",
    "    'lambda_net': {\n",
    "        'epochs_lambda': 1000,\n",
    "        'early_stopping_lambda': True, \n",
    "        'early_stopping_min_delta_lambda': 1e-2,\n",
    "        'batch_lambda': 64,\n",
    "        'dropout_lambda': 0,\n",
    "        'lambda_network_layers': [128],\n",
    "        'optimizer_lambda': 'adam',\n",
    "        'loss_lambda': 'binary_crossentropy', #categorical_crossentropy\n",
    "        \n",
    "        'number_of_lambda_weights': None,\n",
    "        \n",
    "        'number_initializations_lambda': 1, \n",
    "        \n",
    "        'number_of_trained_lambda_nets': 10000,\n",
    "    },     \n",
    "    \n",
    "    'i_net': {\n",
    "        'dense_layers': [1024, 1024, 256, 2048, 2048],\n",
    "        'convolution_layers': None,\n",
    "        'lstm_layers': None,\n",
    "        'dropout': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
    "        \n",
    "        'optimizer': 'adam', #adam\n",
    "        'learning_rate': 0.0001,\n",
    "        'loss': 'binary_crossentropy', #mse; soft_mse; binary_crossentropy; soft_binary_crossentropy; 'binary_accuracy'\n",
    "        'metrics': ['soft_binary_crossentropy', 'binary_accuracy'],\n",
    "        \n",
    "        'epochs': 500, \n",
    "        'early_stopping': True,\n",
    "        'batch_size': 256,\n",
    "\n",
    "        'interpretation_dataset_size': 10000,\n",
    "                \n",
    "        'test_size': 50, #Float for fraction, Int for number 0\n",
    "        \n",
    "        'function_representation_type': 3, # 1=standard representation; 2=sparse representation with classification for variables; 3=softmax to select classes (n top probabilities)\n",
    "        'normalize_lambda_nets': False,\n",
    "\n",
    "        'optimize_decision_function': True, #False\n",
    "        'function_value_loss': True, #False\n",
    "        'soft_labels': False,\n",
    "                      \n",
    "        'data_reshape_version': None, #default to 2 options:(None, 0,1 2,3) #3=autoencoder dimensionality reduction\n",
    "        \n",
    "        'nas': False,\n",
    "        'nas_type': 'SEQUENTIAL', #options:(None, 'SEQUENTIAL', 'CNN', 'LSTM', 'CNN-LSTM', 'CNN-LSTM-parallel')      \n",
    "        'nas_trials': 100,\n",
    "    },    \n",
    "    \n",
    "    'evaluation': {   \n",
    "        #'inet_holdout_seed_evaluation': False,\n",
    "            \n",
    "        'random_evaluation_dataset_size': 500, \n",
    "        'per_network_optimization_dataset_size': 5000,\n",
    "\n",
    "        'sklearn_dt_benchmark': False,\n",
    "        'sdt_benchmark': False,\n",
    "        \n",
    "        'different_eval_data': False,\n",
    "        \n",
    "        'eval_data_description': {\n",
    "            ######### data #########\n",
    "            'eval_data_function_generation_type': 'make_classification',\n",
    "            'eval_data_lambda_dataset_size': 5000, #number of samples per function\n",
    "            'eval_data_noise_injected_level': 0, \n",
    "            'eval_data_noise_injected_type': 'flip_percentage', # '' 'normal' 'uniform' 'normal_range' 'uniform_range'     \n",
    "            ######### lambda_net #########\n",
    "            'eval_data_number_of_trained_lambda_nets': 100,\n",
    "            ######### i_net #########\n",
    "            'eval_data_interpretation_dataset_size': 100,\n",
    "            \n",
    "        }\n",
    "        \n",
    "    },    \n",
    "    \n",
    "    'computation':{\n",
    "        'load_model': False,\n",
    "        'n_jobs': 7,\n",
    "        'use_gpu': False,\n",
    "        'gpu_numbers': '2',\n",
    "        'RANDOM_SEED': 42,   \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:11.035641Z",
     "iopub.status.busy": "2022-01-04T11:01:11.035144Z",
     "iopub.status.idle": "2022-01-04T11:01:11.051708Z",
     "shell.execute_reply": "2022-01-04T11:01:11.050332Z",
     "shell.execute_reply.started": "2022-01-04T11:01:11.035572Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T11:56:36.233201Z",
     "start_time": "2021-01-08T11:56:36.208062Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:11.054429Z",
     "iopub.status.busy": "2022-01-04T11:01:11.053849Z",
     "iopub.status.idle": "2022-01-04T11:01:15.053420Z",
     "shell.execute_reply": "2022-01-04T11:01:15.052529Z",
     "shell.execute_reply.started": "2022-01-04T11:01:11.054371Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "##################################################### IMPORT LIBRARIES ################################################################\n",
    "#######################################################################################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "from itertools import product       \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import psutil\n",
    "\n",
    "from functools import reduce\n",
    "from more_itertools import random_product \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random \n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, KFold, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, mean_absolute_error, r2_score, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex, clear_output\n",
    "\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:15.054811Z",
     "iopub.status.busy": "2022-01-04T11:01:15.054525Z",
     "iopub.status.idle": "2022-01-04T11:01:15.061579Z",
     "shell.execute_reply": "2022-01-04T11:01:15.060960Z",
     "shell.execute_reply.started": "2022-01-04T11:01:15.054784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:15.063856Z",
     "iopub.status.busy": "2022-01-04T11:01:15.063582Z",
     "iopub.status.idle": "2022-01-04T11:01:15.076777Z",
     "shell.execute_reply": "2022-01-04T11:01:15.076132Z",
     "shell.execute_reply.started": "2022-01-04T11:01:15.063831Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "################################################### VARIABLE ADJUSTMENTS ##############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['i_net']['data_reshape_version'] = 2 if data_reshape_version == None and (convolution_layers != None or lstm_layers != None or (nas and nas_type != 'SEQUENTIAL')) else data_reshape_version\n",
    "config['function_family']['decision_sparsity'] = config['function_family']['decision_sparsity'] if config['function_family']['decision_sparsity'] != -1 else config['data']['number_of_variables'] \n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### SET VARIABLES + DESIGN #########################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_numbers if use_gpu else ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' if use_gpu else ''\n",
    "\n",
    "#os.environ['XLA_FLAGS'] =  '--xla_gpu_cuda_data_dir=/usr/local/cuda-10.1'\n",
    "\n",
    "#os.environ['XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4' if use_gpu else ''#-10.1' #--xla_gpu_cuda_data_dir=/usr/local/cuda, \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 ,--tf_xla_enable_xla_devices' if use_gpu else ''#'--tf_xla_auto_jit=2' #, --tf_xla_enable_xla_devices\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if int(tf.__version__[0]) >= 2:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "else:\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:15.077860Z",
     "iopub.status.busy": "2022-01-04T11:01:15.077668Z",
     "iopub.status.idle": "2022-01-04T11:01:15.085027Z",
     "shell.execute_reply": "2022-01-04T11:01:15.084403Z",
     "shell.execute_reply.started": "2022-01-04T11:01:15.077837Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "########################################### IMPORT GLOBAL VARIABLES FROM CONFIG #######################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:15.086238Z",
     "iopub.status.busy": "2022-01-04T11:01:15.085973Z",
     "iopub.status.idle": "2022-01-04T11:01:17.461998Z",
     "shell.execute_reply": "2022-01-04T11:01:17.460734Z",
     "shell.execute_reply.started": "2022-01-04T11:01:15.086213Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities.InterpretationNet import *\n",
    "from utilities.LambdaNet import *\n",
    "from utilities.metrics import *\n",
    "from utilities.utility_functions import *\n",
    "from utilities.DecisionTree_BASIC import *\n",
    "\n",
    "#######################################################################################################################################\n",
    "####################################################### CONFIG ADJUSTMENTS ############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "config['lambda_net']['number_of_lambda_weights'] = get_number_of_lambda_net_parameters(lambda_network_layers, number_of_variables, num_classes)\n",
    "config['function_family']['basic_function_representation_length'] = get_number_of_function_parameters(dt_type, maximum_depth, number_of_variables, num_classes)\n",
    "config['function_family']['function_representation_length'] = ( \n",
    "       #((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes  if function_representation_type == 1 and dt_type == 'SDT'\n",
    "       (2 ** maximum_depth - 1) * (number_of_variables + 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 1 and dt_type == 'SDT'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + (2 ** maximum_depth - 1) + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) * num_classes if function_representation_type == 2 and dt_type == 'SDT'\n",
    "  else ((2 ** maximum_depth - 1) * decision_sparsity) * 2 + (2 ** maximum_depth)  if function_representation_type == 1 and dt_type == 'vanilla'\n",
    "  else (2 ** maximum_depth - 1) * decision_sparsity + ((2 ** maximum_depth - 1)  * decision_sparsity * number_of_variables) + (2 ** maximum_depth) if function_representation_type == 2 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth)  if function_representation_type == 3 and dt_type == 'vanilla'\n",
    "  else ((2 ** maximum_depth - 1) * number_of_variables * 2) + (2 ** maximum_depth - 1) + (2 ** maximum_depth) * num_classes if function_representation_type == 3 and dt_type == 'SDT'\n",
    "  else None\n",
    "                                                            )\n",
    "#######################################################################################################################################\n",
    "################################################## UPDATE VARIABLES ###################################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(config['function_family'])\n",
    "globals().update(config['data'])\n",
    "globals().update(config['lambda_net'])\n",
    "globals().update(config['i_net'])\n",
    "globals().update(config['evaluation'])\n",
    "globals().update(config['computation'])\n",
    "\n",
    "#initialize_LambdaNet_config_from_curent_notebook(config)\n",
    "#initialize_metrics_config_from_curent_notebook(config)\n",
    "#initialize_utility_functions_config_from_curent_notebook(config)\n",
    "#initialize_InterpretationNet_config_from_curent_notebook(config)\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "###################################################### PATH + FOLDER CREATION #########################################################\n",
    "#######################################################################################################################################\n",
    "globals().update(generate_paths(config, path_type='interpretation_net'))\n",
    "\n",
    "create_folders_inet(config)\n",
    "\n",
    "#######################################################################################################################################\n",
    "############################################################ SLEEP TIMER ##############################################################\n",
    "#######################################################################################################################################\n",
    "sleep_minutes(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:17.463481Z",
     "iopub.status.busy": "2022-01-04T11:01:17.463283Z",
     "iopub.status.idle": "2022-01-04T11:01:17.470854Z",
     "shell.execute_reply": "2022-01-04T11:01:17.469712Z",
     "shell.execute_reply.started": "2022-01-04T11:01:17.463456Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNetSize5000_numLNets10000_var15_class2_make_classification_trained_xMax1_xMin0_xDistuniform_depth5_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42/inet_dense1024-1024-256-2048-2048_drop0.3-0.3-0.3-0.3-0.3e500b256_adam\n",
      "lNetSize5000_numLNets10000_var15_class2_make_classification_trained_xMax1_xMin0_xDistuniform_depth5_beta1_decisionSpars1_vanilla_fullyGrown/128_e1000ES0.01_b64_drop0_adam_binary_crossentropy_fixedInit1-seed42\n"
     ]
    }
   ],
   "source": [
    "print(path_identifier_interpretation_net)\n",
    "\n",
    "print(path_identifier_lambda_net_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.600530Z",
     "start_time": "2021-01-05T08:33:49.583928Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:17.471955Z",
     "iopub.status.busy": "2022-01-04T11:01:17.471779Z",
     "iopub.status.idle": "2022-01-04T11:01:17.479723Z",
     "shell.execute_reply": "2022-01-04T11:01:17.479006Z",
     "shell.execute_reply.started": "2022-01-04T11:01:17.471932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num XLA-GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T08:33:49.994944Z",
     "start_time": "2021-01-05T08:33:49.957264Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:17.481150Z",
     "iopub.status.busy": "2022-01-04T11:01:17.480938Z",
     "iopub.status.idle": "2022-01-04T11:01:17.489809Z",
     "shell.execute_reply": "2022-01-04T11:01:17.489021Z",
     "shell.execute_reply.started": "2022-01-04T11:01:17.481127Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lambda_nets(config, no_noise=False, n_jobs=1):\n",
    "    \n",
    "    #def generate_lambda_net()\n",
    "    \n",
    "    #if psutil.virtual_memory().percent > 80:\n",
    "        #raise SystemExit(\"Out of RAM!\")\n",
    "    \n",
    "    if no_noise==True:\n",
    "        config['noise_injected_level'] = 0\n",
    "    path_dict = generate_paths(config, path_type='interpretation_net')        \n",
    "        \n",
    "    directory = './data/weights/' + 'weights_' + path_dict['path_identifier_lambda_net_data'] + '/'\n",
    "    path_network_parameters = directory + 'weights' + '.txt'\n",
    "    #path_X_data = directory + 'X_test_lambda.txt'\n",
    "    #path_y_data = directory + 'y_test_lambda.txt'        \n",
    "    \n",
    "    network_parameters = pd.read_csv(path_network_parameters, sep=\",\", header=None)\n",
    "    network_parameters = network_parameters.sort_values(by=0)\n",
    "    if no_noise == False:\n",
    "        network_parameters = network_parameters.sample(n=config['i_net']['interpretation_dataset_size'], random_state=config['computation']['RANDOM_SEED'])\n",
    "       \n",
    "        \n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='loky') #loky\n",
    "\n",
    "    lambda_nets = parallel(delayed(LambdaNet)(network_parameters_row, \n",
    "                                              #X_test_lambda_row, \n",
    "                                              #y_test_lambda_row, \n",
    "                                              config) for network_parameters_row in network_parameters.values)          \n",
    "    del parallel\n",
    "    \n",
    "    base_model = generate_base_model(config)  \n",
    "    \n",
    "    #def initialize_network_wrapper(config, lambda_net, base_model):\n",
    "    #    lambda_net.initialize_network(config, base_model)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_network_wrapper)(config, lambda_net, base_model) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "    \n",
    "    #def initialize_target_function_wrapper(config, lambda_net):\n",
    "    #    lambda_net.initialize_target_function(config)\n",
    "    \n",
    "    #parallel = Parallel(n_jobs=n_jobs, verbose=3, backend='sequential')\n",
    "    #_ = parallel(delayed(initialize_target_function_wrapper)(config, lambda_net) for lambda_net in lambda_nets)   \n",
    "    #del parallel\n",
    "                \n",
    "    lambda_net_dataset = LambdaNetDataset(lambda_nets)\n",
    "        \n",
    "    return lambda_net_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:29:48.869797Z",
     "start_time": "2021-01-05T08:33:49.997149Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:17.491123Z",
     "iopub.status.busy": "2022-01-04T11:01:17.490939Z",
     "iopub.status.idle": "2022-01-04T11:01:40.174400Z",
     "shell.execute_reply": "2022-01-04T11:01:40.172768Z",
     "shell.execute_reply.started": "2022-01-04T11:01:17.491101Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=7)]: Done 1038 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=7)]: Done 9892 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=7)]: Done 10000 out of 10000 | elapsed:   12.1s finished\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "if different_eval_data:\n",
    "    config_train = deepcopy(config)\n",
    "    config_eval = deepcopy(config)\n",
    "    \n",
    "    config_eval['data']['function_generation_type'] = config['evaluation']['eval_data_description']['eval_data_function_generation_type']\n",
    "    config_eval['data']['lambda_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_lambda_dataset_size']\n",
    "    config_eval['data']['noise_injected_level'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_level']\n",
    "    config_eval['data']['noise_injected_type'] = config['evaluation']['eval_data_description']['eval_data_noise_injected_type'] \n",
    "    config_eval['lambda_net']['number_of_trained_lambda_nets'] = config['evaluation']['eval_data_description']['eval_data_number_of_trained_lambda_nets']   \n",
    "    config_eval['i_net']['interpretation_dataset_size'] = config['evaluation']['eval_data_description']['eval_data_interpretation_dataset_size']   \n",
    "    \n",
    "    if False:\n",
    "        lambda_net_dataset_train = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        lambda_net_dataset_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "    else:\n",
    "        lambda_net_dataset_train_with_valid = load_lambda_nets(config_train, n_jobs=n_jobs)\n",
    "        lambda_net_dataset_eval = load_lambda_nets(config_eval, n_jobs=n_jobs)\n",
    "\n",
    "        _, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset_eval, test_split=test_size)   \n",
    "        lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)   \n",
    "        \n",
    "        \n",
    "else:\n",
    "    lambda_net_dataset = load_lambda_nets(config, n_jobs=n_jobs)\n",
    "\n",
    "    lambda_net_dataset_train_with_valid, lambda_net_dataset_test = split_LambdaNetDataset(lambda_net_dataset, test_split=test_size)\n",
    "    lambda_net_dataset_train, lambda_net_dataset_valid = split_LambdaNetDataset(lambda_net_dataset_train_with_valid, test_split=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:01:21.350996Z",
     "start_time": "2020-09-16T18:01:21.343717Z"
    }
   },
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:40.178680Z",
     "iopub.status.busy": "2022-01-04T11:01:40.177638Z",
     "iopub.status.idle": "2022-01-04T11:01:40.187988Z",
     "shell.execute_reply": "2022-01-04T11:01:40.186952Z",
     "shell.execute_reply.started": "2022-01-04T11:01:40.178637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8955, 2225)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:40.190180Z",
     "iopub.status.busy": "2022-01-04T11:01:40.189673Z",
     "iopub.status.idle": "2022-01-04T11:01:40.198508Z",
     "shell.execute_reply": "2022-01-04T11:01:40.197679Z",
     "shell.execute_reply.started": "2022-01-04T11:01:40.190132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 2225)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:40.205229Z",
     "iopub.status.busy": "2022-01-04T11:01:40.204796Z",
     "iopub.status.idle": "2022-01-04T11:01:40.210936Z",
     "shell.execute_reply": "2022-01-04T11:01:40.210181Z",
     "shell.execute_reply.started": "2022-01-04T11:01:40.205196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2225)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:04.155343Z",
     "start_time": "2021-01-05T09:33:11.544785Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:40.212614Z",
     "iopub.status.busy": "2022-01-04T11:01:40.212135Z",
     "iopub.status.idle": "2022-01-04T11:01:48.830753Z",
     "shell.execute_reply": "2022-01-04T11:01:48.829414Z",
     "shell.execute_reply.started": "2022-01-04T11:01:40.212585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>split0</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>split6</th>\n",
       "      <th>split7</th>\n",
       "      <th>split8</th>\n",
       "      <th>split9</th>\n",
       "      <th>split10</th>\n",
       "      <th>split11</th>\n",
       "      <th>split12</th>\n",
       "      <th>split13</th>\n",
       "      <th>split14</th>\n",
       "      <th>lp0</th>\n",
       "      <th>lp1</th>\n",
       "      <th>lp2</th>\n",
       "      <th>lp3</th>\n",
       "      <th>lp4</th>\n",
       "      <th>lp5</th>\n",
       "      <th>lp6</th>\n",
       "      <th>lp7</th>\n",
       "      <th>lp8</th>\n",
       "      <th>lp9</th>\n",
       "      <th>lp10</th>\n",
       "      <th>lp11</th>\n",
       "      <th>lp12</th>\n",
       "      <th>lp13</th>\n",
       "      <th>lp14</th>\n",
       "      <th>lp15</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_2077</th>\n",
       "      <th>wb_2078</th>\n",
       "      <th>wb_2079</th>\n",
       "      <th>wb_2080</th>\n",
       "      <th>wb_2081</th>\n",
       "      <th>wb_2082</th>\n",
       "      <th>wb_2083</th>\n",
       "      <th>wb_2084</th>\n",
       "      <th>wb_2085</th>\n",
       "      <th>wb_2086</th>\n",
       "      <th>wb_2087</th>\n",
       "      <th>wb_2088</th>\n",
       "      <th>wb_2089</th>\n",
       "      <th>wb_2090</th>\n",
       "      <th>wb_2091</th>\n",
       "      <th>wb_2092</th>\n",
       "      <th>wb_2093</th>\n",
       "      <th>wb_2094</th>\n",
       "      <th>wb_2095</th>\n",
       "      <th>wb_2096</th>\n",
       "      <th>wb_2097</th>\n",
       "      <th>wb_2098</th>\n",
       "      <th>wb_2099</th>\n",
       "      <th>wb_2100</th>\n",
       "      <th>wb_2101</th>\n",
       "      <th>wb_2102</th>\n",
       "      <th>wb_2103</th>\n",
       "      <th>wb_2104</th>\n",
       "      <th>wb_2105</th>\n",
       "      <th>wb_2106</th>\n",
       "      <th>wb_2107</th>\n",
       "      <th>wb_2108</th>\n",
       "      <th>wb_2109</th>\n",
       "      <th>wb_2110</th>\n",
       "      <th>wb_2111</th>\n",
       "      <th>wb_2112</th>\n",
       "      <th>wb_2113</th>\n",
       "      <th>wb_2114</th>\n",
       "      <th>wb_2115</th>\n",
       "      <th>wb_2116</th>\n",
       "      <th>wb_2117</th>\n",
       "      <th>wb_2118</th>\n",
       "      <th>wb_2119</th>\n",
       "      <th>wb_2120</th>\n",
       "      <th>wb_2121</th>\n",
       "      <th>wb_2122</th>\n",
       "      <th>wb_2123</th>\n",
       "      <th>wb_2124</th>\n",
       "      <th>wb_2125</th>\n",
       "      <th>wb_2126</th>\n",
       "      <th>wb_2127</th>\n",
       "      <th>wb_2128</th>\n",
       "      <th>wb_2129</th>\n",
       "      <th>wb_2130</th>\n",
       "      <th>wb_2131</th>\n",
       "      <th>wb_2132</th>\n",
       "      <th>wb_2133</th>\n",
       "      <th>wb_2134</th>\n",
       "      <th>wb_2135</th>\n",
       "      <th>wb_2136</th>\n",
       "      <th>wb_2137</th>\n",
       "      <th>wb_2138</th>\n",
       "      <th>wb_2139</th>\n",
       "      <th>wb_2140</th>\n",
       "      <th>wb_2141</th>\n",
       "      <th>wb_2142</th>\n",
       "      <th>wb_2143</th>\n",
       "      <th>wb_2144</th>\n",
       "      <th>wb_2145</th>\n",
       "      <th>wb_2146</th>\n",
       "      <th>wb_2147</th>\n",
       "      <th>wb_2148</th>\n",
       "      <th>wb_2149</th>\n",
       "      <th>wb_2150</th>\n",
       "      <th>wb_2151</th>\n",
       "      <th>wb_2152</th>\n",
       "      <th>wb_2153</th>\n",
       "      <th>wb_2154</th>\n",
       "      <th>wb_2155</th>\n",
       "      <th>wb_2156</th>\n",
       "      <th>wb_2157</th>\n",
       "      <th>wb_2158</th>\n",
       "      <th>wb_2159</th>\n",
       "      <th>wb_2160</th>\n",
       "      <th>wb_2161</th>\n",
       "      <th>wb_2162</th>\n",
       "      <th>wb_2163</th>\n",
       "      <th>wb_2164</th>\n",
       "      <th>wb_2165</th>\n",
       "      <th>wb_2166</th>\n",
       "      <th>wb_2167</th>\n",
       "      <th>wb_2168</th>\n",
       "      <th>wb_2169</th>\n",
       "      <th>wb_2170</th>\n",
       "      <th>wb_2171</th>\n",
       "      <th>wb_2172</th>\n",
       "      <th>wb_2173</th>\n",
       "      <th>wb_2174</th>\n",
       "      <th>wb_2175</th>\n",
       "      <th>wb_2176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>6671.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-1.684</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.062</td>\n",
       "      <td>1.286</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-1.628</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-1.911</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-1.587</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.498</td>\n",
       "      <td>-1.488</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-3.255</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-1.451</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.021</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>1.110</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-1.699</td>\n",
       "      <td>0.513</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-1.377</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-1.131</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-1.717</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-2.941</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-1.675</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-3.307</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-1.760</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-2.192</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.382</td>\n",
       "      <td>1.614</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-1.485</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>3274.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>1.251</td>\n",
       "      <td>0.217</td>\n",
       "      <td>1.329</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.076</td>\n",
       "      <td>1.985</td>\n",
       "      <td>3.332</td>\n",
       "      <td>0.287</td>\n",
       "      <td>1.599</td>\n",
       "      <td>3.372</td>\n",
       "      <td>1.661</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>0.901</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>1.657</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.706</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-3.595</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-2.548</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.284</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-1.793</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-1.297</td>\n",
       "      <td>0.081</td>\n",
       "      <td>2.039</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.764</td>\n",
       "      <td>1.294</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.741</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>-1.705</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.762</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>-2.380</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.323</td>\n",
       "      <td>0.108</td>\n",
       "      <td>4.096</td>\n",
       "      <td>-3.528</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-2.591</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>3.750</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-3.271</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-1.566</td>\n",
       "      <td>-0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>3095.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-1.553</td>\n",
       "      <td>0.213</td>\n",
       "      <td>1.969</td>\n",
       "      <td>-3.157</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.586</td>\n",
       "      <td>2.734</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2.196</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>3.282</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-2.259</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>1.878</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>2.203</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>1.461</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.932</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>1.410</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.922</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-1.009</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1.145</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>1.668</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.354</td>\n",
       "      <td>-2.779</td>\n",
       "      <td>0.297</td>\n",
       "      <td>1.879</td>\n",
       "      <td>-1.237</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.154</td>\n",
       "      <td>2.364</td>\n",
       "      <td>0.108</td>\n",
       "      <td>1.555</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.759</td>\n",
       "      <td>2.304</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>1.436</td>\n",
       "      <td>1.895</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-1.071</td>\n",
       "      <td>1.586</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.129</td>\n",
       "      <td>2.311</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>8379.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.755</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>2.292</td>\n",
       "      <td>-1.999</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-1.312</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.387</td>\n",
       "      <td>1.512</td>\n",
       "      <td>0.265</td>\n",
       "      <td>-2.766</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.489</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>0.309</td>\n",
       "      <td>1.252</td>\n",
       "      <td>-1.555</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-1.669</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.496</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2.338</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>-2.842</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-2.394</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-1.941</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.782</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-2.572</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-2.150</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>2.471</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.899</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>-2.549</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>3043.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>1.226</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.879</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.119</td>\n",
       "      <td>2.916</td>\n",
       "      <td>-1.758</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-1.171</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-1.380</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>1.183</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-1.481</td>\n",
       "      <td>1.434</td>\n",
       "      <td>2.042</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.355</td>\n",
       "      <td>-1.512</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.616</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-1.546</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.886</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>-2.307</td>\n",
       "      <td>-1.001</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-1.038</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-1.412</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-2.529</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-1.264</td>\n",
       "      <td>-2.764</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-1.954</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-1.791</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>2.197</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-1.435</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-1.784</td>\n",
       "      <td>0.340</td>\n",
       "      <td>-0.103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  feat0  feat1  feat2  feat3  feat4  feat5  feat6  feat7  \\\n",
       "6671 6671.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3274 3274.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3095 3095.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8379 8379.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "3043 3043.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      feat8  feat9  feat10  feat11  feat12  feat13  feat14  split0  split1  \\\n",
       "6671  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "3274  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "3095  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "8379  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "3043  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "\n",
       "      split2  split3  split4  split5  split6  split7  split8  split9  split10  \\\n",
       "6671   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "3274   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "3095   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "8379   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "3043   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "\n",
       "      split11  split12  split13  split14   lp0   lp1   lp2   lp3   lp4   lp5  \\\n",
       "6671    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3274    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3095    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8379    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "3043    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "       lp6   lp7   lp8   lp9  lp10  lp11  lp12  lp13  lp14  lp15   wb_0  \\\n",
       "6671 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.011   \n",
       "3274 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.125   \n",
       "3095 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.012   \n",
       "8379 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.101   \n",
       "3043 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.034   \n",
       "\n",
       "       wb_1   wb_2   wb_3   wb_4  wb_5  wb_6   wb_7   wb_8   wb_9  wb_10  \\\n",
       "6671  0.295 -0.100 -0.085  0.044 0.028 0.104 -0.142 -0.164 -0.183 -0.005   \n",
       "3274  0.131 -0.040 -0.027 -0.015 0.036 0.104 -0.145 -0.165 -0.183  0.110   \n",
       "3095 -0.082  0.013  0.041 -0.191 0.012 0.092  0.001 -0.168 -0.183  0.108   \n",
       "8379  0.135  0.051 -0.180 -0.151 0.083 0.104 -0.144 -0.279 -0.183  0.205   \n",
       "3043  0.238 -0.112 -0.089  0.026 0.035 0.104 -0.176 -0.203 -0.183 -0.070   \n",
       "\n",
       "      wb_11  wb_12  wb_13  wb_14  wb_15  wb_16  wb_17  wb_18  wb_19  wb_20  \\\n",
       "6671 -0.103 -0.188  0.108 -0.064 -0.021 -0.201  0.041 -0.428  0.084 -0.206   \n",
       "3274  0.024 -0.182  0.030 -0.005  0.097  0.173 -0.078 -0.156 -0.076 -0.122   \n",
       "3095 -0.042  0.200  0.080 -0.208  0.098  0.111 -0.045  0.084 -0.010  0.100   \n",
       "8379 -0.610  0.087 -0.116  0.097  0.100  0.018 -0.127 -0.023 -0.100  0.000   \n",
       "3043 -0.041  0.226 -0.009 -0.072  0.098 -0.070  0.045  0.203  0.067 -0.324   \n",
       "\n",
       "      wb_21  wb_22  wb_23  wb_24  wb_25  wb_26  wb_27  wb_28  wb_29  wb_30  \\\n",
       "6671  0.064  0.155  0.058  0.097 -0.236  0.181 -0.026 -0.173  0.018 -0.018   \n",
       "3274 -0.015 -0.181 -0.243  0.017 -0.126  0.019  0.054 -0.159 -0.014  0.182   \n",
       "3095  0.031  0.076 -0.050  0.077 -0.003 -0.019  0.269 -0.148  0.187 -0.085   \n",
       "8379 -0.249 -0.045 -0.077  0.120  0.027 -0.040  0.433  0.043  0.372 -0.755   \n",
       "3043 -0.263  0.154 -0.231 -0.024 -0.182  0.040 -0.076 -0.131  0.023 -0.094   \n",
       "\n",
       "      wb_31  wb_32  wb_33  wb_34  wb_35  wb_36  wb_37  wb_38  wb_39  wb_40  \\\n",
       "6671 -0.022  0.184 -0.016 -0.076  0.069 -0.118  0.041 -0.111 -0.198 -0.192   \n",
       "3274  0.075  0.184 -0.066 -0.076  0.069 -0.060  0.098 -0.077 -0.206 -0.116   \n",
       "3095  0.071  0.184  0.028 -0.076  0.069 -0.028  0.096  0.061  0.023 -0.060   \n",
       "8379  0.113  0.184  0.071 -0.076  0.069  0.005  0.161  0.035 -0.208  0.038   \n",
       "3043 -0.079  0.184 -0.081 -0.076  0.069  0.007  0.025 -0.236 -0.198 -0.180   \n",
       "\n",
       "      wb_41  wb_42  wb_43  wb_44  wb_45  wb_46  wb_47  wb_48  wb_49  wb_50  \\\n",
       "6671  0.052  0.165  0.085  0.107  0.116  0.131 -0.059  0.073 -0.202  0.128   \n",
       "3274  0.078  0.080  0.054  0.166  0.031  0.073 -0.070 -0.132 -0.202  0.128   \n",
       "3095  0.051  0.100  0.194  0.171  0.121  0.203 -0.061  0.031 -0.202  0.128   \n",
       "8379  0.093  0.141  0.138  0.152  0.457  0.147 -0.970  0.082 -0.202  0.128   \n",
       "3043 -0.100  0.002 -0.029  0.125  0.109  0.154 -0.192  0.088  0.016  0.128   \n",
       "\n",
       "      wb_51  ...  wb_2077  wb_2078  wb_2079  wb_2080  wb_2081  wb_2082  \\\n",
       "6671 -0.126  ...    0.026   -1.684    0.084    0.194    0.164   -0.080   \n",
       "3274 -0.126  ...    0.258   -0.939    0.107    0.194    0.126   -0.080   \n",
       "3095 -0.126  ...    1.282   -0.060    0.886    0.194    0.398   -0.080   \n",
       "8379 -0.126  ...    2.292   -1.999    0.226    0.194    0.337   -0.080   \n",
       "3043 -0.126  ...    0.029   -0.083    1.226    0.194    0.318   -0.080   \n",
       "\n",
       "      wb_2083  wb_2084  wb_2085  wb_2086  wb_2087  wb_2088  wb_2089  wb_2090  \\\n",
       "6671    0.073    0.498    0.353    0.151   -0.208    0.197    0.062    1.286   \n",
       "3274    0.073    1.251    0.217    1.329   -0.201    0.076    1.985    3.332   \n",
       "3095    0.073   -1.553    0.213    1.969   -3.157    0.026    0.064    0.124   \n",
       "8379    0.073    0.004    0.327    0.255   -1.312    0.248    0.368    0.399   \n",
       "3043    0.073    0.010    0.263    0.328   -0.208    0.192    0.350    1.879   \n",
       "\n",
       "      wb_2091  wb_2092  wb_2093  wb_2094  wb_2095  wb_2096  wb_2097  wb_2098  \\\n",
       "6671    0.107    0.758    0.127    0.145   -1.628    0.089   -0.212    0.135   \n",
       "3274    0.287    1.599    3.372    1.661   -0.459    0.901   -0.212    0.135   \n",
       "3095    0.586    2.734    0.125    2.196   -0.495    3.282   -0.212    0.135   \n",
       "8379    0.508    0.387    1.512    0.265   -2.766    0.406   -0.212    0.135   \n",
       "3043    0.428    0.147    0.119    2.916   -1.758    0.099   -1.171    0.135   \n",
       "\n",
       "      wb_2099  wb_2100  wb_2101  wb_2102  wb_2103  wb_2104  wb_2105  wb_2106  \\\n",
       "6671   -0.133   -0.183   -0.113   -1.911    0.387    0.300   -1.587   -0.119   \n",
       "3274   -0.133   -0.183   -0.113   -0.443    0.083    0.242   -0.123   -0.028   \n",
       "3095   -0.133   -0.183   -0.113   -2.259    0.040    0.244   -0.114   -0.435   \n",
       "8379   -0.133   -0.183   -0.113   -0.325    0.296   -0.454   -0.123   -0.265   \n",
       "3043   -0.133   -0.183   -0.113   -1.380    0.191    0.155   -0.542   -0.148   \n",
       "\n",
       "      wb_2107  wb_2108  wb_2109  wb_2110  wb_2111  wb_2112  wb_2113  wb_2114  \\\n",
       "6671    0.534   -0.092    0.498   -1.488    0.462    0.377   -0.133    0.401   \n",
       "3274    1.657   -0.092    1.706    0.912    0.422    0.347   -0.133    0.066   \n",
       "3095    1.878   -0.092    0.135   -0.311    2.203    0.230   -0.133    1.461   \n",
       "8379    0.327   -0.092    0.205   -0.885    0.450    0.660   -0.133   -1.489   \n",
       "3043    1.183   -0.092    0.134   -1.481    1.434    2.042   -0.133    0.205   \n",
       "\n",
       "      wb_2115  wb_2116  wb_2117  wb_2118  wb_2119  wb_2120  wb_2121  wb_2122  \\\n",
       "6671    0.455   -3.255   -0.107   -0.384    0.161    0.260   -0.465   -1.451   \n",
       "3274    0.036   -3.595   -0.107   -2.548    0.147    0.207   -0.165    0.284   \n",
       "3095   -0.338   -0.361   -0.107   -0.213    0.164   -0.932   -0.631    1.410   \n",
       "8379    0.799   -0.972   -0.107   -0.267    0.309    1.252   -1.555   -0.166   \n",
       "3043    1.355   -1.512   -0.107   -1.616    0.160    0.397   -0.077   -0.506   \n",
       "\n",
       "      wb_2123  wb_2124  wb_2125  wb_2126  wb_2127  wb_2128  wb_2129  wb_2130  \\\n",
       "6671    0.086   -0.035    0.000    1.021   -0.145    0.235   -0.222    1.110   \n",
       "3274   -0.168   -1.793    0.000    1.009   -0.145    0.029   -0.105   -1.297   \n",
       "3095   -0.324   -0.039    0.000    1.922   -0.145   -0.173   -1.009   -0.266   \n",
       "8379   -0.190   -0.044   -1.669    0.171   -0.496   -0.046   -0.859   -0.136   \n",
       "3043   -0.086   -1.546    0.000    0.163   -0.886   -0.117   -0.096   -0.622   \n",
       "\n",
       "      wb_2131  wb_2132  wb_2133  wb_2134  wb_2135  wb_2136  wb_2137  wb_2138  \\\n",
       "6671    0.540    0.444   -0.033   -1.699    0.513   -0.096   -1.377    0.337   \n",
       "3274    0.081    2.039   -0.027   -0.690    0.161   -0.064    0.764    1.294   \n",
       "3095    0.085    1.145   -0.040   -0.384    0.041   -0.652    1.668    0.249   \n",
       "8379    0.415    2.338   -0.431   -2.842    0.231   -0.249   -2.394    0.291   \n",
       "3043    0.093   -2.628   -2.307   -1.001    0.174   -0.099   -1.038    0.163   \n",
       "\n",
       "      wb_2139  wb_2140  wb_2141  wb_2142  wb_2143  wb_2144  wb_2145  wb_2146  \\\n",
       "6671   -0.300   -0.085    0.074    0.405   -1.131   -0.353    0.368    0.294   \n",
       "3274   -0.200   -0.085    0.042    1.741   -1.196   -1.705    0.100    0.762   \n",
       "3095   -0.307   -0.790   -0.027    0.422    1.354   -2.779    0.297    1.879   \n",
       "8379   -0.201   -0.087    0.146   -1.941   -0.227   -0.295    0.174    0.782   \n",
       "3043   -0.210   -1.412    0.156    0.467    0.282   -2.529    0.167    0.250   \n",
       "\n",
       "      wb_2147  wb_2148  wb_2149  wb_2150  wb_2151  wb_2152  wb_2153  wb_2154  \\\n",
       "6671   -0.083   -1.717   -0.193   -2.941   -0.106    0.236    0.523    0.108   \n",
       "3274   -0.327   -0.396   -0.680   -2.380   -0.106    0.180    1.323    0.108   \n",
       "3095   -1.237   -0.185   -0.197   -0.679   -0.106    0.154    2.364    0.108   \n",
       "8379   -0.275   -2.572   -0.481   -0.434   -0.106    0.167    0.362    0.108   \n",
       "3043   -0.180   -0.181   -0.583   -0.126   -0.106    0.213    0.424    0.108   \n",
       "\n",
       "      wb_2155  wb_2156  wb_2157  wb_2158  wb_2159  wb_2160  wb_2161  wb_2162  \\\n",
       "6671    0.082   -1.675   -0.072    0.067   -3.307   -0.006    0.174   -1.760   \n",
       "3274    4.096   -3.528   -0.072    0.067   -2.591   -0.006    3.750    0.170   \n",
       "3095    1.555   -0.188   -0.066    0.067   -0.526   -0.006    0.759    2.304   \n",
       "8379    0.087   -2.150   -0.067    0.067   -0.039   -0.006    2.471   -0.803   \n",
       "3043    0.093   -1.264   -2.764    0.067   -1.954   -0.006    0.358   -1.791   \n",
       "\n",
       "      wb_2163  wb_2164  wb_2165  wb_2166  wb_2167  wb_2168  wb_2169  wb_2170  \\\n",
       "6671   -0.203   -2.192    0.524    0.085    0.149    0.382    1.614   -0.111   \n",
       "3274   -0.203   -0.119    0.165    0.088    0.149    0.642    0.042    0.009   \n",
       "3095   -0.203   -0.117    1.436    1.895    0.149   -1.071    1.586   -0.157   \n",
       "8379   -0.203   -1.350    0.724    0.089    0.149    0.128    0.899   -0.129   \n",
       "3043   -0.203   -0.762    2.197    0.144    0.149    1.002    0.119   -0.075   \n",
       "\n",
       "      wb_2171  wb_2172  wb_2173  wb_2174  wb_2175  wb_2176  \n",
       "6671   -0.324   -1.485    0.118   -0.270   -0.492   -0.110  \n",
       "3274   -0.133   -3.271    0.129   -0.272   -1.566   -0.096  \n",
       "3095   -0.271   -0.348    0.129    2.311   -0.154   -0.016  \n",
       "8379   -0.323   -2.549    0.126   -0.969    0.223   -0.146  \n",
       "3043   -0.135   -1.435    0.120   -1.784    0.340   -0.103  \n",
       "\n",
       "[5 rows x 2225 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_train.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:07.407453Z",
     "start_time": "2021-01-05T09:34:04.157787Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:48.833744Z",
     "iopub.status.busy": "2022-01-04T11:01:48.833364Z",
     "iopub.status.idle": "2022-01-04T11:01:50.006285Z",
     "shell.execute_reply": "2022-01-04T11:01:50.005677Z",
     "shell.execute_reply.started": "2022-01-04T11:01:48.833686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>split0</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>split6</th>\n",
       "      <th>split7</th>\n",
       "      <th>split8</th>\n",
       "      <th>split9</th>\n",
       "      <th>split10</th>\n",
       "      <th>split11</th>\n",
       "      <th>split12</th>\n",
       "      <th>split13</th>\n",
       "      <th>split14</th>\n",
       "      <th>lp0</th>\n",
       "      <th>lp1</th>\n",
       "      <th>lp2</th>\n",
       "      <th>lp3</th>\n",
       "      <th>lp4</th>\n",
       "      <th>lp5</th>\n",
       "      <th>lp6</th>\n",
       "      <th>lp7</th>\n",
       "      <th>lp8</th>\n",
       "      <th>lp9</th>\n",
       "      <th>lp10</th>\n",
       "      <th>lp11</th>\n",
       "      <th>lp12</th>\n",
       "      <th>lp13</th>\n",
       "      <th>lp14</th>\n",
       "      <th>lp15</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_2077</th>\n",
       "      <th>wb_2078</th>\n",
       "      <th>wb_2079</th>\n",
       "      <th>wb_2080</th>\n",
       "      <th>wb_2081</th>\n",
       "      <th>wb_2082</th>\n",
       "      <th>wb_2083</th>\n",
       "      <th>wb_2084</th>\n",
       "      <th>wb_2085</th>\n",
       "      <th>wb_2086</th>\n",
       "      <th>wb_2087</th>\n",
       "      <th>wb_2088</th>\n",
       "      <th>wb_2089</th>\n",
       "      <th>wb_2090</th>\n",
       "      <th>wb_2091</th>\n",
       "      <th>wb_2092</th>\n",
       "      <th>wb_2093</th>\n",
       "      <th>wb_2094</th>\n",
       "      <th>wb_2095</th>\n",
       "      <th>wb_2096</th>\n",
       "      <th>wb_2097</th>\n",
       "      <th>wb_2098</th>\n",
       "      <th>wb_2099</th>\n",
       "      <th>wb_2100</th>\n",
       "      <th>wb_2101</th>\n",
       "      <th>wb_2102</th>\n",
       "      <th>wb_2103</th>\n",
       "      <th>wb_2104</th>\n",
       "      <th>wb_2105</th>\n",
       "      <th>wb_2106</th>\n",
       "      <th>wb_2107</th>\n",
       "      <th>wb_2108</th>\n",
       "      <th>wb_2109</th>\n",
       "      <th>wb_2110</th>\n",
       "      <th>wb_2111</th>\n",
       "      <th>wb_2112</th>\n",
       "      <th>wb_2113</th>\n",
       "      <th>wb_2114</th>\n",
       "      <th>wb_2115</th>\n",
       "      <th>wb_2116</th>\n",
       "      <th>wb_2117</th>\n",
       "      <th>wb_2118</th>\n",
       "      <th>wb_2119</th>\n",
       "      <th>wb_2120</th>\n",
       "      <th>wb_2121</th>\n",
       "      <th>wb_2122</th>\n",
       "      <th>wb_2123</th>\n",
       "      <th>wb_2124</th>\n",
       "      <th>wb_2125</th>\n",
       "      <th>wb_2126</th>\n",
       "      <th>wb_2127</th>\n",
       "      <th>wb_2128</th>\n",
       "      <th>wb_2129</th>\n",
       "      <th>wb_2130</th>\n",
       "      <th>wb_2131</th>\n",
       "      <th>wb_2132</th>\n",
       "      <th>wb_2133</th>\n",
       "      <th>wb_2134</th>\n",
       "      <th>wb_2135</th>\n",
       "      <th>wb_2136</th>\n",
       "      <th>wb_2137</th>\n",
       "      <th>wb_2138</th>\n",
       "      <th>wb_2139</th>\n",
       "      <th>wb_2140</th>\n",
       "      <th>wb_2141</th>\n",
       "      <th>wb_2142</th>\n",
       "      <th>wb_2143</th>\n",
       "      <th>wb_2144</th>\n",
       "      <th>wb_2145</th>\n",
       "      <th>wb_2146</th>\n",
       "      <th>wb_2147</th>\n",
       "      <th>wb_2148</th>\n",
       "      <th>wb_2149</th>\n",
       "      <th>wb_2150</th>\n",
       "      <th>wb_2151</th>\n",
       "      <th>wb_2152</th>\n",
       "      <th>wb_2153</th>\n",
       "      <th>wb_2154</th>\n",
       "      <th>wb_2155</th>\n",
       "      <th>wb_2156</th>\n",
       "      <th>wb_2157</th>\n",
       "      <th>wb_2158</th>\n",
       "      <th>wb_2159</th>\n",
       "      <th>wb_2160</th>\n",
       "      <th>wb_2161</th>\n",
       "      <th>wb_2162</th>\n",
       "      <th>wb_2163</th>\n",
       "      <th>wb_2164</th>\n",
       "      <th>wb_2165</th>\n",
       "      <th>wb_2166</th>\n",
       "      <th>wb_2167</th>\n",
       "      <th>wb_2168</th>\n",
       "      <th>wb_2169</th>\n",
       "      <th>wb_2170</th>\n",
       "      <th>wb_2171</th>\n",
       "      <th>wb_2172</th>\n",
       "      <th>wb_2173</th>\n",
       "      <th>wb_2174</th>\n",
       "      <th>wb_2175</th>\n",
       "      <th>wb_2176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>3466.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>2.052</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.558</td>\n",
       "      <td>2.240</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.591</td>\n",
       "      <td>-1.823</td>\n",
       "      <td>1.085</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-2.021</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.897</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.537</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-1.122</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.553</td>\n",
       "      <td>-1.485</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>0.447</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.628</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.747</td>\n",
       "      <td>-2.348</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.108</td>\n",
       "      <td>1.289</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-1.670</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.702</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.591</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-1.636</td>\n",
       "      <td>1.288</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.121</td>\n",
       "      <td>1.140</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.691</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.265</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.595</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>2.482</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-1.281</td>\n",
       "      <td>1.228</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.117</td>\n",
       "      <td>2.386</td>\n",
       "      <td>1.166</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-0.683</td>\n",
       "      <td>0.311</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-1.876</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>1.351</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-1.652</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.597</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-1.039</td>\n",
       "      <td>-1.808</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.265</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>0.359</td>\n",
       "      <td>1.348</td>\n",
       "      <td>-1.305</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-1.267</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.059</td>\n",
       "      <td>1.036</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.108</td>\n",
       "      <td>2.238</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>2.420</td>\n",
       "      <td>-1.730</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-1.132</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>-1.020</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.790</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4148.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.809</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-2.179</td>\n",
       "      <td>-2.529</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.820</td>\n",
       "      <td>2.677</td>\n",
       "      <td>1.342</td>\n",
       "      <td>0.469</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.088</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.948</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.353</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>1.193</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.416</td>\n",
       "      <td>3.490</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-2.181</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.717</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-2.380</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-1.960</td>\n",
       "      <td>-1.241</td>\n",
       "      <td>-2.775</td>\n",
       "      <td>-2.636</td>\n",
       "      <td>-2.505</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-2.621</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>1.239</td>\n",
       "      <td>-2.434</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.603</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-2.400</td>\n",
       "      <td>2.469</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>2815.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>1.567</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.320</td>\n",
       "      <td>1.396</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>1.217</td>\n",
       "      <td>1.431</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>1.765</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-2.610</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>1.217</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>1.471</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.916</td>\n",
       "      <td>-2.288</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.448</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.163</td>\n",
       "      <td>2.712</td>\n",
       "      <td>0.384</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>-2.207</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.409</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>2.655</td>\n",
       "      <td>2.334</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.329</td>\n",
       "      <td>1.343</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-2.253</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185</th>\n",
       "      <td>5185.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.417</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>1.292</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.678</td>\n",
       "      <td>-1.214</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-0.754</td>\n",
       "      <td>1.112</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-1.659</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-1.474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.753</td>\n",
       "      <td>-0.594</td>\n",
       "      <td>-1.248</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.476</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-0.768</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.108</td>\n",
       "      <td>1.982</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>1.063</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-1.191</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.508</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  feat0  feat1  feat2  feat3  feat4  feat5  feat6  feat7  \\\n",
       "3466 3466.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "689   689.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4148 4148.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2815 2815.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5185 5185.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      feat8  feat9  feat10  feat11  feat12  feat13  feat14  split0  split1  \\\n",
       "3466  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "689   0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "4148  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "2815  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "5185  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "\n",
       "      split2  split3  split4  split5  split6  split7  split8  split9  split10  \\\n",
       "3466   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "689    0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "4148   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "2815   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "5185   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "\n",
       "      split11  split12  split13  split14   lp0   lp1   lp2   lp3   lp4   lp5  \\\n",
       "3466    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "689     0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4148    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "2815    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5185    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "       lp6   lp7   lp8   lp9  lp10  lp11  lp12  lp13  lp14  lp15   wb_0  \\\n",
       "3466 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.089   \n",
       "689  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.409   \n",
       "4148 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.022   \n",
       "2815 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.119   \n",
       "5185 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.137   \n",
       "\n",
       "       wb_1   wb_2   wb_3   wb_4   wb_5  wb_6   wb_7   wb_8   wb_9  wb_10  \\\n",
       "3466 -0.066  0.016 -0.228 -0.037  0.002 0.100 -0.123 -0.008 -0.183  0.121   \n",
       "689   0.116  0.138 -0.321 -0.691  0.041 0.248  0.016 -0.055 -0.183  0.206   \n",
       "4148 -0.026  0.034  0.079 -0.092  0.044 0.095 -0.403 -0.185 -0.183  0.386   \n",
       "2815 -0.221 -0.069 -0.024 -0.493 -0.121 0.094 -0.013 -0.007 -0.183  0.031   \n",
       "5185 -0.017  0.082 -0.329 -0.159  0.034 0.171 -0.097 -0.262 -0.183  0.187   \n",
       "\n",
       "      wb_11  wb_12  wb_13  wb_14  wb_15  wb_16  wb_17  wb_18  wb_19  wb_20  \\\n",
       "3466 -0.020  0.091 -0.022  0.065  0.111 -0.020 -0.061 -0.119 -0.096 -0.131   \n",
       "689   0.060  0.057 -0.113  0.061  0.333  0.077 -0.310  0.014 -0.283 -0.151   \n",
       "4148 -0.149  0.023 -0.034  0.071  0.097 -0.076 -0.096 -0.071  0.121 -0.128   \n",
       "2815 -0.070  0.221  0.082 -0.194  0.099 -0.313  0.022 -0.129  0.042 -0.477   \n",
       "5185 -0.092 -0.008 -0.099  0.136  0.167  0.194 -0.147 -0.053 -0.123 -0.164   \n",
       "\n",
       "      wb_21  wb_22  wb_23  wb_24  wb_25  wb_26  wb_27  wb_28  wb_29  wb_30  \\\n",
       "3466  0.010  0.067 -0.057  0.101 -0.051 -0.119  0.040 -0.080  0.021 -0.044   \n",
       "689  -0.053  0.019 -0.008 -0.015  0.030 -0.205 -0.007 -0.167 -0.051 -0.172   \n",
       "4148 -0.031  0.053  0.093  0.308  0.001 -0.157  0.175 -0.198  0.045 -0.018   \n",
       "2815  0.113  0.132  0.150 -0.009 -0.138  0.074 -0.037 -0.153 -0.174 -0.102   \n",
       "5185 -0.086 -0.034 -0.024  0.149  0.014 -0.086  0.128 -0.161  0.021 -0.095   \n",
       "\n",
       "      wb_31  wb_32  wb_33  wb_34  wb_35  wb_36  wb_37  wb_38  wb_39  wb_40  \\\n",
       "3466  0.080  0.184  0.068 -0.076  0.069 -0.156  0.120 -0.018 -0.198 -0.048   \n",
       "689   0.027  0.184  0.100 -0.076  0.069  0.418  0.260  0.126 -0.204  0.200   \n",
       "4148  0.113  0.184  0.057 -0.085  0.069  0.004  0.150  0.809 -0.230 -0.014   \n",
       "2815 -0.224  0.184 -0.032 -0.076  0.069  0.007  0.025 -0.100 -0.198 -0.312   \n",
       "5185  0.151  0.184  0.099 -0.076  0.069  0.155  0.205  0.066 -0.204  0.098   \n",
       "\n",
       "      wb_41  wb_42  wb_43  wb_44  wb_45  wb_46  wb_47  wb_48  wb_49  wb_50  \\\n",
       "3466  0.046  0.195  0.104  0.158  0.111  0.119 -0.229  0.052 -0.202  0.121   \n",
       "689   0.036  0.179  0.093  0.079  0.146  0.265 -0.066  0.140 -0.202  0.128   \n",
       "4148  0.016  0.227  0.301  0.165  0.255  0.148 -0.185  0.072 -0.202  0.128   \n",
       "2815 -0.049  0.002  0.103  0.018  0.126  0.016 -0.218 -0.267 -0.202  0.128   \n",
       "5185  0.063  0.152  0.156  0.212  0.149  0.280 -0.247  0.155 -0.185  0.166   \n",
       "\n",
       "      wb_51  ...  wb_2077  wb_2078  wb_2079  wb_2080  wb_2081  wb_2082  \\\n",
       "3466 -0.126  ...    0.515   -0.584    0.550    0.194    0.835   -0.080   \n",
       "689  -0.126  ...    0.411   -0.945    0.932    0.194    0.595   -0.080   \n",
       "4148 -0.126  ...    0.128   -0.272    0.317    0.194    0.197   -0.072   \n",
       "2815 -0.345  ...    0.710   -0.066    1.567    0.194    0.131   -0.080   \n",
       "5185 -0.126  ...    0.021   -0.086    0.223    0.194    0.417   -0.080   \n",
       "\n",
       "      wb_2083  wb_2084  wb_2085  wb_2086  wb_2087  wb_2088  wb_2089  wb_2090  \\\n",
       "3466    0.073    2.052    0.387    0.315   -0.208    0.349    0.558    2.240   \n",
       "689     0.073    2.482    0.210    0.113   -0.203   -1.281    1.228    0.064   \n",
       "4148    0.073    0.005    0.247   -2.179   -2.529    0.206    0.820    2.677   \n",
       "2815    0.073    0.010    0.320    1.396   -0.208    1.217    1.431    0.502   \n",
       "5185    0.073    1.292    0.320    0.345   -0.207   -0.478    0.061    0.484   \n",
       "\n",
       "      wb_2091  wb_2092  wb_2093  wb_2094  wb_2095  wb_2096  wb_2097  wb_2098  \\\n",
       "3466    0.118    0.624    0.119    0.591   -1.823    1.085   -0.212    0.129   \n",
       "689     0.117    2.386    1.166    0.483   -0.683    0.311   -0.212    0.135   \n",
       "4148    1.342    0.469    1.025    0.407   -0.620    0.078   -0.212    0.135   \n",
       "2815    0.119    0.511    0.133    0.511   -0.184    1.765   -0.212    0.135   \n",
       "5185    0.534    0.591    0.424    0.678   -1.214    0.414   -0.754    1.112   \n",
       "\n",
       "      wb_2099  wb_2100  wb_2101  wb_2102  wb_2103  wb_2104  wb_2105  wb_2106  \\\n",
       "3466   -0.133   -2.021   -0.113   -0.391    0.439    0.341   -0.123   -0.298   \n",
       "689    -0.133   -0.183   -0.113   -0.005    0.191    0.113   -1.876   -0.344   \n",
       "4148   -0.133   -0.183   -0.113   -0.187    0.200    1.088   -0.123   -0.269   \n",
       "2815   -2.610   -0.183   -0.113   -0.298    1.217   -0.058   -0.124   -0.229   \n",
       "5185   -0.133   -0.602   -0.113    0.196    0.281    0.194   -0.123   -0.379   \n",
       "\n",
       "      wb_2107  wb_2108  wb_2109  wb_2110  wb_2111  wb_2112  wb_2113  wb_2114  \\\n",
       "3466    0.897   -0.092    0.537   -0.218    0.171    0.439   -0.133    0.500   \n",
       "689     1.351   -0.092    0.328   -1.652    0.531    0.292   -0.133    0.061   \n",
       "4148    0.187   -0.092    1.948   -0.118    0.353   -0.211   -0.133    1.193   \n",
       "2815    0.444   -0.092    1.471   -0.256    0.435    0.347   -0.133    0.338   \n",
       "5185    0.458   -0.092    0.134   -0.242    0.581    0.286   -0.133    0.353   \n",
       "\n",
       "      wb_2115  wb_2116  wb_2117  wb_2118  wb_2119  wb_2120  wb_2121  wb_2122  \\\n",
       "3466   -0.525   -0.750   -0.107   -0.558    1.650   -0.346   -0.567    0.426   \n",
       "689    -0.597   -0.372   -0.107   -0.836    0.535   -0.020   -1.039   -1.808   \n",
       "4148   -0.688   -0.363   -0.107   -1.416    3.490   -0.470   -0.220    0.082   \n",
       "2815    0.374   -0.633   -0.107   -0.422    0.456    0.238   -0.502   -0.395   \n",
       "5185    0.386   -0.491   -0.107   -0.047    0.560    0.471   -1.659   -0.365   \n",
       "\n",
       "      wb_2123  wb_2124  wb_2125  wb_2126  wb_2127  wb_2128  wb_2129  wb_2130  \\\n",
       "3466   -0.395   -1.122    0.000    0.168   -0.145   -0.296   -0.498   -0.403   \n",
       "689    -0.566   -0.523    0.000    2.265   -0.145   -0.411   -0.987   -0.843   \n",
       "4148   -0.133   -2.181    0.000    0.343   -0.140   -0.172   -0.474   -0.200   \n",
       "2815   -0.223   -0.038    0.000    2.916   -2.288   -0.162   -0.208   -0.215   \n",
       "5185   -0.249   -1.474    0.000    0.416   -0.145   -0.207   -0.162   -0.444   \n",
       "\n",
       "      wb_2131  wb_2132  wb_2133  wb_2134  wb_2135  wb_2136  wb_2137  wb_2138  \\\n",
       "3466    0.087    0.553   -1.485   -1.099    0.433   -0.246   -0.515    0.447   \n",
       "689     0.359    1.348   -1.305   -0.951   -0.291   -0.975   -1.267    0.262   \n",
       "4148    0.084    0.717   -0.049   -0.277   -0.687   -0.015    0.780    0.255   \n",
       "2815    0.090    0.448   -0.291   -0.419    0.258   -0.278   -0.397    0.364   \n",
       "5185    0.515    0.753   -0.594   -1.248    0.181   -0.283    0.446    0.476   \n",
       "\n",
       "      wb_2139  wb_2140  wb_2141  wb_2142  wb_2143  wb_2144  wb_2145  wb_2146  \\\n",
       "3466   -0.246   -0.092    0.278    0.920    0.628   -0.416    0.349    0.413   \n",
       "689    -0.199   -0.092    0.059    1.036   -0.858   -0.149    0.184    0.069   \n",
       "4148   -0.249   -0.092    0.099    0.624    0.233   -2.380    0.162   -1.960   \n",
       "2815   -0.235   -0.092    0.163    2.712    0.384   -0.279    0.116   -0.178   \n",
       "5185   -0.224   -0.457    0.165    0.378   -0.768   -0.585    0.219    0.332   \n",
       "\n",
       "      wb_2147  wb_2148  wb_2149  wb_2150  wb_2151  wb_2152  wb_2153  wb_2154  \\\n",
       "3466   -0.047   -0.747   -2.348   -0.964   -0.106    0.389    0.063    0.108   \n",
       "689    -0.908   -0.177   -0.191   -0.447   -0.106    0.219    0.467    0.108   \n",
       "4148   -1.241   -2.775   -2.636   -2.505   -0.106    0.152    0.061    0.108   \n",
       "2815   -0.369   -0.524   -2.207   -0.375   -0.106    0.203    0.064    0.108   \n",
       "5185   -0.668   -0.502   -0.765   -0.853   -0.106    0.215    0.887    0.108   \n",
       "\n",
       "      wb_2155  wb_2156  wb_2157  wb_2158  wb_2159  wb_2160  wb_2161  wb_2162  \\\n",
       "3466    1.289   -0.177   -1.670    0.067   -0.702   -0.006    0.591   -1.607   \n",
       "689     2.238   -0.177   -0.072    0.067   -0.482   -0.006    2.420   -1.730   \n",
       "4148    0.404   -2.621   -0.072    0.067   -0.340   -0.006    1.239   -2.434   \n",
       "2815    0.409   -0.170   -0.072    0.067   -0.454   -0.006    2.655    2.334   \n",
       "5185    1.982   -0.578   -0.072    0.067   -0.472   -0.001    1.063   -0.667   \n",
       "\n",
       "      wb_2163  wb_2164  wb_2165  wb_2166  wb_2167  wb_2168  wb_2169  wb_2170  \\\n",
       "3466   -0.203   -1.636    1.288    0.087    0.149    0.422    0.562    0.096   \n",
       "689    -0.203   -1.132    1.109    0.082    0.149    0.096    0.120   -0.006   \n",
       "4148   -0.203   -0.806    0.284    0.450    0.149    1.603    0.467   -0.052   \n",
       "2815   -0.203   -0.477    0.416    0.088    0.149    0.329    1.343   -0.208   \n",
       "5185   -0.203   -1.191    0.493    0.480    0.149    0.335    0.422   -0.187   \n",
       "\n",
       "      wb_2171  wb_2172  wb_2173  wb_2174  wb_2175  wb_2176  \n",
       "3466   -1.062   -0.427    0.121    1.140   -0.343   -0.238  \n",
       "689    -0.838   -1.020    0.133    0.790   -0.946    0.051  \n",
       "4148   -0.487   -2.400    2.469    0.346    0.191    0.167  \n",
       "2815   -0.316   -2.253    0.525    0.409    0.331    0.006  \n",
       "5185   -0.329   -0.352    1.037    0.508   -0.298   -0.252  \n",
       "\n",
       "[5 rows x 2225 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_valid.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:10.970350Z",
     "start_time": "2021-01-05T09:34:07.411246Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:50.007596Z",
     "iopub.status.busy": "2022-01-04T11:01:50.007286Z",
     "iopub.status.idle": "2022-01-04T11:01:50.257413Z",
     "shell.execute_reply": "2022-01-04T11:01:50.256804Z",
     "shell.execute_reply.started": "2022-01-04T11:01:50.007570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>split0</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>split6</th>\n",
       "      <th>split7</th>\n",
       "      <th>split8</th>\n",
       "      <th>split9</th>\n",
       "      <th>split10</th>\n",
       "      <th>split11</th>\n",
       "      <th>split12</th>\n",
       "      <th>split13</th>\n",
       "      <th>split14</th>\n",
       "      <th>lp0</th>\n",
       "      <th>lp1</th>\n",
       "      <th>lp2</th>\n",
       "      <th>lp3</th>\n",
       "      <th>lp4</th>\n",
       "      <th>lp5</th>\n",
       "      <th>lp6</th>\n",
       "      <th>lp7</th>\n",
       "      <th>lp8</th>\n",
       "      <th>lp9</th>\n",
       "      <th>lp10</th>\n",
       "      <th>lp11</th>\n",
       "      <th>lp12</th>\n",
       "      <th>lp13</th>\n",
       "      <th>lp14</th>\n",
       "      <th>lp15</th>\n",
       "      <th>wb_0</th>\n",
       "      <th>wb_1</th>\n",
       "      <th>wb_2</th>\n",
       "      <th>wb_3</th>\n",
       "      <th>wb_4</th>\n",
       "      <th>wb_5</th>\n",
       "      <th>wb_6</th>\n",
       "      <th>wb_7</th>\n",
       "      <th>wb_8</th>\n",
       "      <th>wb_9</th>\n",
       "      <th>wb_10</th>\n",
       "      <th>wb_11</th>\n",
       "      <th>wb_12</th>\n",
       "      <th>wb_13</th>\n",
       "      <th>wb_14</th>\n",
       "      <th>wb_15</th>\n",
       "      <th>wb_16</th>\n",
       "      <th>wb_17</th>\n",
       "      <th>wb_18</th>\n",
       "      <th>wb_19</th>\n",
       "      <th>wb_20</th>\n",
       "      <th>wb_21</th>\n",
       "      <th>wb_22</th>\n",
       "      <th>wb_23</th>\n",
       "      <th>wb_24</th>\n",
       "      <th>wb_25</th>\n",
       "      <th>wb_26</th>\n",
       "      <th>wb_27</th>\n",
       "      <th>wb_28</th>\n",
       "      <th>wb_29</th>\n",
       "      <th>wb_30</th>\n",
       "      <th>wb_31</th>\n",
       "      <th>wb_32</th>\n",
       "      <th>wb_33</th>\n",
       "      <th>wb_34</th>\n",
       "      <th>wb_35</th>\n",
       "      <th>wb_36</th>\n",
       "      <th>wb_37</th>\n",
       "      <th>wb_38</th>\n",
       "      <th>wb_39</th>\n",
       "      <th>wb_40</th>\n",
       "      <th>wb_41</th>\n",
       "      <th>wb_42</th>\n",
       "      <th>wb_43</th>\n",
       "      <th>wb_44</th>\n",
       "      <th>wb_45</th>\n",
       "      <th>wb_46</th>\n",
       "      <th>wb_47</th>\n",
       "      <th>wb_48</th>\n",
       "      <th>wb_49</th>\n",
       "      <th>wb_50</th>\n",
       "      <th>wb_51</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_2077</th>\n",
       "      <th>wb_2078</th>\n",
       "      <th>wb_2079</th>\n",
       "      <th>wb_2080</th>\n",
       "      <th>wb_2081</th>\n",
       "      <th>wb_2082</th>\n",
       "      <th>wb_2083</th>\n",
       "      <th>wb_2084</th>\n",
       "      <th>wb_2085</th>\n",
       "      <th>wb_2086</th>\n",
       "      <th>wb_2087</th>\n",
       "      <th>wb_2088</th>\n",
       "      <th>wb_2089</th>\n",
       "      <th>wb_2090</th>\n",
       "      <th>wb_2091</th>\n",
       "      <th>wb_2092</th>\n",
       "      <th>wb_2093</th>\n",
       "      <th>wb_2094</th>\n",
       "      <th>wb_2095</th>\n",
       "      <th>wb_2096</th>\n",
       "      <th>wb_2097</th>\n",
       "      <th>wb_2098</th>\n",
       "      <th>wb_2099</th>\n",
       "      <th>wb_2100</th>\n",
       "      <th>wb_2101</th>\n",
       "      <th>wb_2102</th>\n",
       "      <th>wb_2103</th>\n",
       "      <th>wb_2104</th>\n",
       "      <th>wb_2105</th>\n",
       "      <th>wb_2106</th>\n",
       "      <th>wb_2107</th>\n",
       "      <th>wb_2108</th>\n",
       "      <th>wb_2109</th>\n",
       "      <th>wb_2110</th>\n",
       "      <th>wb_2111</th>\n",
       "      <th>wb_2112</th>\n",
       "      <th>wb_2113</th>\n",
       "      <th>wb_2114</th>\n",
       "      <th>wb_2115</th>\n",
       "      <th>wb_2116</th>\n",
       "      <th>wb_2117</th>\n",
       "      <th>wb_2118</th>\n",
       "      <th>wb_2119</th>\n",
       "      <th>wb_2120</th>\n",
       "      <th>wb_2121</th>\n",
       "      <th>wb_2122</th>\n",
       "      <th>wb_2123</th>\n",
       "      <th>wb_2124</th>\n",
       "      <th>wb_2125</th>\n",
       "      <th>wb_2126</th>\n",
       "      <th>wb_2127</th>\n",
       "      <th>wb_2128</th>\n",
       "      <th>wb_2129</th>\n",
       "      <th>wb_2130</th>\n",
       "      <th>wb_2131</th>\n",
       "      <th>wb_2132</th>\n",
       "      <th>wb_2133</th>\n",
       "      <th>wb_2134</th>\n",
       "      <th>wb_2135</th>\n",
       "      <th>wb_2136</th>\n",
       "      <th>wb_2137</th>\n",
       "      <th>wb_2138</th>\n",
       "      <th>wb_2139</th>\n",
       "      <th>wb_2140</th>\n",
       "      <th>wb_2141</th>\n",
       "      <th>wb_2142</th>\n",
       "      <th>wb_2143</th>\n",
       "      <th>wb_2144</th>\n",
       "      <th>wb_2145</th>\n",
       "      <th>wb_2146</th>\n",
       "      <th>wb_2147</th>\n",
       "      <th>wb_2148</th>\n",
       "      <th>wb_2149</th>\n",
       "      <th>wb_2150</th>\n",
       "      <th>wb_2151</th>\n",
       "      <th>wb_2152</th>\n",
       "      <th>wb_2153</th>\n",
       "      <th>wb_2154</th>\n",
       "      <th>wb_2155</th>\n",
       "      <th>wb_2156</th>\n",
       "      <th>wb_2157</th>\n",
       "      <th>wb_2158</th>\n",
       "      <th>wb_2159</th>\n",
       "      <th>wb_2160</th>\n",
       "      <th>wb_2161</th>\n",
       "      <th>wb_2162</th>\n",
       "      <th>wb_2163</th>\n",
       "      <th>wb_2164</th>\n",
       "      <th>wb_2165</th>\n",
       "      <th>wb_2166</th>\n",
       "      <th>wb_2167</th>\n",
       "      <th>wb_2168</th>\n",
       "      <th>wb_2169</th>\n",
       "      <th>wb_2170</th>\n",
       "      <th>wb_2171</th>\n",
       "      <th>wb_2172</th>\n",
       "      <th>wb_2173</th>\n",
       "      <th>wb_2174</th>\n",
       "      <th>wb_2175</th>\n",
       "      <th>wb_2176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7217.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-1.651</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.358</td>\n",
       "      <td>2.074</td>\n",
       "      <td>0.133</td>\n",
       "      <td>2.126</td>\n",
       "      <td>-1.764</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>1.484</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-1.155</td>\n",
       "      <td>1.389</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.587</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-1.022</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.759</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-1.657</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.370</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-1.330</td>\n",
       "      <td>-1.097</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-1.508</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-1.506</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>2.383</td>\n",
       "      <td>-1.234</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.241</td>\n",
       "      <td>1.025</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-1.104</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-1.459</td>\n",
       "      <td>-0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>8291.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.475</td>\n",
       "      <td>2.029</td>\n",
       "      <td>2.184</td>\n",
       "      <td>2.741</td>\n",
       "      <td>0.421</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>1.469</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-2.250</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-1.826</td>\n",
       "      <td>-1.949</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-1.231</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-1.766</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.355</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-2.671</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>-1.941</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.370</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.775</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>1.361</td>\n",
       "      <td>0.066</td>\n",
       "      <td>2.012</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>1.608</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>3.748</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.446</td>\n",
       "      <td>-2.078</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>3.266</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-1.170</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.022</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.304</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-3.957</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.106</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.987</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.266</td>\n",
       "      <td>1.247</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-2.231</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.241</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.754</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.662</td>\n",
       "      <td>-1.379</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.456</td>\n",
       "      <td>1.251</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>5114.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>1.802</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>1.256</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.361</td>\n",
       "      <td>1.786</td>\n",
       "      <td>2.970</td>\n",
       "      <td>0.731</td>\n",
       "      <td>-2.667</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>2.866</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>2.004</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>2.613</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>1.792</td>\n",
       "      <td>0.999</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1.526</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-1.964</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.745</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>0.270</td>\n",
       "      <td>2.460</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>2.661</td>\n",
       "      <td>-3.527</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>-1.025</td>\n",
       "      <td>-0.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859.000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.728</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.867</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.547</td>\n",
       "      <td>0.253</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>3.018</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.073</td>\n",
       "      <td>2.461</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.736</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.170</td>\n",
       "      <td>3.530</td>\n",
       "      <td>0.319</td>\n",
       "      <td>2.756</td>\n",
       "      <td>1.080</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.619</td>\n",
       "      <td>-1.183</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>1.407</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.558</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-2.508</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-1.986</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-1.102</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.952</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>1.149</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-1.057</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2.391</td>\n",
       "      <td>1.433</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-3.186</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.103</td>\n",
       "      <td>1.216</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-2.615</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.108</td>\n",
       "      <td>1.403</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-1.037</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.823</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.403</td>\n",
       "      <td>2.316</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  seed  feat0  feat1  feat2  feat3  feat4  feat5  feat6  feat7  \\\n",
       "7217 7217.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "8291 8291.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4607 4607.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5114 5114.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1859 1859.000    42  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "      feat8  feat9  feat10  feat11  feat12  feat13  feat14  split0  split1  \\\n",
       "7217  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "8291  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "4607  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "5114  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "1859  0.000  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "\n",
       "      split2  split3  split4  split5  split6  split7  split8  split9  split10  \\\n",
       "7217   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "8291   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "4607   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "5114   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "1859   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000    0.000   \n",
       "\n",
       "      split11  split12  split13  split14   lp0   lp1   lp2   lp3   lp4   lp5  \\\n",
       "7217    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "8291    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "4607    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "5114    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "1859    0.000    0.000    0.000    0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "\n",
       "       lp6   lp7   lp8   lp9  lp10  lp11  lp12  lp13  lp14  lp15   wb_0  \\\n",
       "7217 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.096   \n",
       "8291 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.082   \n",
       "4607 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.043   \n",
       "5114 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.037   \n",
       "1859 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.148   \n",
       "\n",
       "       wb_1   wb_2   wb_3   wb_4   wb_5  wb_6   wb_7   wb_8   wb_9  wb_10  \\\n",
       "7217  0.165 -0.175 -0.039 -0.276 -0.072 0.104  0.352  0.052 -0.183  0.034   \n",
       "8291 -0.052  0.014 -0.114 -0.197  0.039 0.104 -0.125 -0.169 -0.183  0.114   \n",
       "4607  0.404 -0.186 -0.314  0.133  0.035 0.104  0.251 -0.173 -0.183 -0.093   \n",
       "5114 -0.120 -0.075 -0.087 -0.175  0.034 0.104 -0.147 -0.176 -0.183  0.057   \n",
       "1859  0.160  0.181 -0.220 -0.371  0.219 0.297 -0.188 -0.059 -0.183  0.259   \n",
       "\n",
       "      wb_11  wb_12  wb_13  wb_14  wb_15  wb_16  wb_17  wb_18  wb_19  wb_20  \\\n",
       "7217 -0.021  0.186 -0.371 -0.041  0.003  0.263  0.014  0.156 -0.217  0.126   \n",
       "8291 -0.039  0.069 -0.075  0.067  0.098 -0.015 -0.071  0.076 -0.087 -0.107   \n",
       "4607  0.111  0.376  0.188 -0.186  0.104 -0.005  0.136  0.399  0.177  0.124   \n",
       "5114  0.014 -0.108  0.008  0.067 -0.063 -0.187 -0.024  0.144 -0.003 -0.379   \n",
       "1859 -0.183  0.090 -0.092  0.051  0.299  0.177 -0.217 -0.364 -0.209 -0.243   \n",
       "\n",
       "      wb_21  wb_22  wb_23  wb_24  wb_25  wb_26  wb_27  wb_28  wb_29  wb_30  \\\n",
       "7217  0.088 -0.258 -0.175  0.003 -0.152 -0.154 -0.144 -0.153 -0.081  0.346   \n",
       "8291 -0.031  0.058 -0.040  0.107 -0.046 -0.014  0.042 -0.044  0.021  0.023   \n",
       "4607  0.238  0.455 -0.393 -0.431 -0.483  0.283 -0.183 -0.136 -0.437 -0.092   \n",
       "5114  0.034 -0.160 -0.169  0.108 -0.061  0.076 -0.035 -0.157  0.118  0.082   \n",
       "1859 -0.175 -0.162  0.145  0.728 -0.104 -0.131  0.110 -0.164  0.867 -0.143   \n",
       "\n",
       "      wb_31  wb_32  wb_33  wb_34  wb_35  wb_36  wb_37  wb_38  wb_39  wb_40  \\\n",
       "7217 -0.119  0.184 -0.043 -0.076  0.069  0.011  0.054 -0.105 -0.198 -0.124   \n",
       "8291  0.088  0.184  0.043 -0.076  0.069  0.007  0.132 -0.016 -0.207 -0.020   \n",
       "4607 -0.123  0.184 -0.234 -0.076  0.069 -0.205 -0.065 -0.196 -0.203 -0.566   \n",
       "5114  0.038  0.184 -0.009 -0.076  0.069 -0.070  0.095 -0.039 -0.203 -0.064   \n",
       "1859  0.270  0.184  0.236 -0.076  0.069 -0.547  0.253 -0.101 -0.198  0.168   \n",
       "\n",
       "      wb_41  wb_42  wb_43  wb_44  wb_45  wb_46  wb_47  wb_48  wb_49  wb_50  \\\n",
       "7217 -0.057  0.014  0.009  0.307  0.126  0.351 -0.366 -0.010 -0.202  0.128   \n",
       "8291 -0.095  0.116  0.005  0.105  0.210  0.113 -0.096  0.336 -0.207  0.128   \n",
       "4607  0.057 -0.354 -0.146 -0.242 -0.108 -0.185 -0.196 -0.126 -0.211  0.439   \n",
       "5114 -0.074 -0.217  0.024 -0.102 -0.175  0.032 -0.224  0.089 -0.212  0.128   \n",
       "1859  0.994  0.235  0.615  0.027  0.117  0.376 -0.180  0.379 -0.202  0.121   \n",
       "\n",
       "      wb_51  ...  wb_2077  wb_2078  wb_2079  wb_2080  wb_2081  wb_2082  \\\n",
       "7217 -0.126  ...    0.367   -1.651    0.648    0.194    0.338   -0.080   \n",
       "8291 -0.126  ...    0.025   -0.464    0.396    0.194    0.344   -0.080   \n",
       "4607 -0.126  ...    0.677   -0.077    0.495    0.194    0.775   -0.080   \n",
       "5114 -0.126  ...    1.802   -0.443    0.437    0.194    0.444   -0.080   \n",
       "1859 -0.126  ...    3.018   -0.399    0.371    0.194    0.233   -0.080   \n",
       "\n",
       "      wb_2083  wb_2084  wb_2085  wb_2086  wb_2087  wb_2088  wb_2089  wb_2090  \\\n",
       "7217    0.073    0.004    0.273    0.073   -0.208    0.389    0.272    0.316   \n",
       "8291    0.073    0.017    0.210    0.185   -0.203    0.234    0.993    0.475   \n",
       "4607    0.073    0.616    0.212    0.041   -0.203    1.361    0.066    2.012   \n",
       "5114    0.073    0.468    0.360    0.324   -0.203    1.256    0.801    0.899   \n",
       "1859    0.073    2.461    0.220    0.736   -0.208    0.170    3.530    0.319   \n",
       "\n",
       "      wb_2091  wb_2092  wb_2093  wb_2094  wb_2095  wb_2096  wb_2097  wb_2098  \\\n",
       "7217    0.358    2.074    0.133    2.126   -1.764    0.392   -0.212    0.135   \n",
       "8291    2.029    2.184    2.741    0.421   -1.070    1.469   -0.207    0.135   \n",
       "4607    0.516    0.669    0.599    0.703   -0.153    1.608   -0.203    3.748   \n",
       "5114    0.361    1.786    2.970    0.731   -2.667    0.096   -0.200    0.135   \n",
       "1859    2.756    1.080    0.126    0.619   -1.183    0.504   -0.212    0.128   \n",
       "\n",
       "      wb_2099  wb_2100  wb_2101  wb_2102  wb_2103  wb_2104  wb_2105  wb_2106  \\\n",
       "7217   -0.133   -0.183   -0.113   -0.288    0.332    0.187   -0.995   -0.211   \n",
       "8291   -0.133   -0.183   -0.113   -0.284    0.056    0.041   -0.123   -0.457   \n",
       "4607   -0.133   -0.183   -0.113   -0.002    0.207    0.446   -2.078   -0.254   \n",
       "5114   -0.133   -0.183   -0.113   -0.449    0.562    0.368   -0.587   -0.364   \n",
       "1859   -0.133   -0.183   -0.113   -0.892    1.407    0.180   -0.123   -0.381   \n",
       "\n",
       "      wb_2107  wb_2108  wb_2109  wb_2110  wb_2111  wb_2112  wb_2113  wb_2114  \\\n",
       "7217    1.484   -0.092    0.374   -1.155    1.389    0.374   -0.133    0.242   \n",
       "8291    0.411   -0.092    0.135   -0.900    0.223    0.280   -0.133   -0.305   \n",
       "4607    3.266   -0.092    0.142   -0.051    0.338   -0.741   -0.133    0.356   \n",
       "5114    2.866   -0.092    2.004   -0.325    2.613   -0.357   -0.133    1.792   \n",
       "1859    0.281   -0.092    0.558   -0.095    0.398   -2.508   -0.133   -0.213   \n",
       "\n",
       "      wb_2115  wb_2116  wb_2117  wb_2118  wb_2119  wb_2120  wb_2121  wb_2122  \\\n",
       "7217    0.272   -1.079   -0.107   -1.587    0.421    0.278   -0.395   -1.022   \n",
       "8291   -0.301   -0.112   -0.107   -0.350    0.467    0.512   -0.947   -0.368   \n",
       "4607   -1.170   -0.504   -0.107   -1.022    0.165   -0.787   -1.099    0.870   \n",
       "5114    0.999   -0.109   -0.107   -0.562    0.167    1.526   -0.423    0.435   \n",
       "1859   -0.240   -1.986   -0.107   -1.102    0.370    0.167   -0.335    0.471   \n",
       "\n",
       "      wb_2123  wb_2124  wb_2125  wb_2126  wb_2127  wb_2128  wb_2129  wb_2130  \\\n",
       "7217   -0.233   -0.603    0.000    0.170   -0.145   -0.183   -0.370   -0.309   \n",
       "8291   -0.399   -1.950   -1.002    0.482   -2.250   -0.283   -0.366   -0.628   \n",
       "4607   -0.248   -0.036    0.000    1.304   -0.141   -0.309   -0.341   -0.289   \n",
       "5114   -0.209   -0.029    0.000    0.164   -0.145    0.177   -0.403   -0.377   \n",
       "1859   -0.148   -0.323    0.000    2.952   -0.145   -0.005   -0.129   -0.050   \n",
       "\n",
       "      wb_2131  wb_2132  wb_2133  wb_2134  wb_2135  wb_2136  wb_2137  wb_2138  \\\n",
       "7217    0.464    0.625   -0.759   -0.874    0.138   -0.216   -1.657    0.211   \n",
       "8291    0.088   -1.826   -1.949   -0.850    0.306   -0.296   -1.231    0.237   \n",
       "4607    0.095    0.439   -3.957   -0.189    1.106   -0.246    0.877    0.987   \n",
       "5114    0.629   -1.964   -0.483   -0.422    0.190   -0.085    0.528    0.745   \n",
       "1859    1.149   -0.454   -0.275   -1.057   -0.006    0.646    2.391    1.433   \n",
       "\n",
       "      wb_2139  wb_2140  wb_2141  wb_2142  wb_2143  wb_2144  wb_2145  wb_2146  \\\n",
       "7217   -0.243   -0.092    0.103    0.408    0.301   -0.390    0.289    0.370   \n",
       "8291   -0.386   -0.092    0.169    0.339   -1.766   -0.085    0.088    0.355   \n",
       "4607   -0.174   -0.467    0.075    0.415    0.472   -0.310    0.266    1.247   \n",
       "5114   -0.300   -0.494    0.270    2.460   -0.505   -0.435    0.341    0.500   \n",
       "1859   -0.318   -3.186    0.004    0.037   -0.299   -0.420    0.103    1.216   \n",
       "\n",
       "      wb_2147  wb_2148  wb_2149  wb_2150  wb_2151  wb_2152  wb_2153  wb_2154  \\\n",
       "7217   -0.940   -1.330   -1.097   -0.572   -0.106    0.174    0.194    0.108   \n",
       "8291   -0.606   -2.671   -0.555   -1.941   -0.106    0.181    0.063    0.108   \n",
       "4607   -0.063   -0.177   -2.231   -0.442   -0.106    0.179    1.241    0.108   \n",
       "5114   -0.240   -0.184   -0.191   -0.519   -0.106    0.272    0.543    0.108   \n",
       "1859   -0.972   -2.615   -0.225   -0.393   -0.106    0.039    0.048    0.108   \n",
       "\n",
       "      wb_2155  wb_2156  wb_2157  wb_2158  wb_2159  wb_2160  wb_2161  wb_2162  \\\n",
       "7217    0.084   -1.508   -0.072    0.418   -1.506   -0.006    2.383   -1.234   \n",
       "8291    0.744   -0.176   -0.067    0.067   -0.062   -0.006    0.611    0.253   \n",
       "4607    0.093   -0.174   -0.067    0.067   -0.754   -0.006    0.662   -1.379   \n",
       "5114    0.095   -1.220   -0.067    0.067   -0.060   -0.006    2.661   -3.527   \n",
       "1859    1.403   -0.175   -0.066    0.067   -0.282   -0.006    3.013    0.021   \n",
       "\n",
       "      wb_2163  wb_2164  wb_2165  wb_2166  wb_2167  wb_2168  wb_2169  wb_2170  \\\n",
       "7217   -0.203   -1.095    0.382    0.086    0.149    0.241    1.025   -0.158   \n",
       "8291   -0.203   -0.471    0.452    0.086    0.149    1.370    0.374   -0.188   \n",
       "4607   -0.203   -0.765    0.456    1.251    0.149    0.154    0.812   -0.105   \n",
       "5114   -0.203   -0.112    1.250    0.087    0.149    0.370    0.538   -0.127   \n",
       "1859   -0.203   -1.037    0.187    0.084    0.149   -0.043    0.415   -0.071   \n",
       "\n",
       "      wb_2171  wb_2172  wb_2173  wb_2174  wb_2175  wb_2176  \n",
       "7217   -0.409   -1.104    0.427    0.432   -1.459   -0.106  \n",
       "8291   -0.372   -0.603    0.134    0.250    0.309    0.095  \n",
       "4607   -1.002   -0.082    0.127    0.897    0.416    0.046  \n",
       "5114   -0.335   -0.212    0.130   -0.903   -1.025   -0.294  \n",
       "1859   -0.823   -0.033    0.403    2.316   -0.921   -0.115  \n",
       "\n",
       "[5 rows x 2225 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_net_dataset_test.as_pandas(config).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:50.258565Z",
     "iopub.status.busy": "2022-01-04T11:01:50.258364Z",
     "iopub.status.idle": "2022-01-04T11:01:50.261538Z",
     "shell.execute_reply": "2022-01-04T11:01:50.260964Z",
     "shell.execute_reply.started": "2022-01-04T11:01:50.258539Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir data/logging/ --port=8811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:50.262583Z",
     "iopub.status.busy": "2022-01-04T11:01:50.262330Z",
     "iopub.status.idle": "2022-01-04T11:01:50.268023Z",
     "shell.execute_reply": "2022-01-04T11:01:50.267445Z",
     "shell.execute_reply.started": "2022-01-04T11:01:50.262558Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:01:50.269206Z",
     "iopub.status.busy": "2022-01-04T11:01:50.268819Z",
     "iopub.status.idle": "2022-01-04T11:42:13.041694Z",
     "shell.execute_reply": "2022-01-04T11:42:13.040290Z",
     "shell.execute_reply.started": "2022-01-04T11:01:50.269181Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------- TRAINING INTERPRETATION NET -----------------------------------------------\n",
      "Epoch 1/500\n",
      "35/35 - 44s - loss: 0.6898 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6905 - binary_accuracy_inet_decision_function_fv_metric: 0.5286 - val_loss: 0.6814 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6852 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5604\n",
      "Epoch 2/500\n",
      "35/35 - 15s - loss: 0.6804 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6839 - binary_accuracy_inet_decision_function_fv_metric: 0.5655 - val_loss: 0.6795 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6841 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5642\n",
      "Epoch 3/500\n",
      "35/35 - 15s - loss: 0.6779 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6822 - binary_accuracy_inet_decision_function_fv_metric: 0.5711 - val_loss: 0.6745 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6814 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5781\n",
      "Epoch 4/500\n",
      "35/35 - 15s - loss: 0.6756 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6806 - binary_accuracy_inet_decision_function_fv_metric: 0.5763 - val_loss: 0.6709 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6792 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5864\n",
      "Epoch 5/500\n",
      "35/35 - 15s - loss: 0.6718 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6780 - binary_accuracy_inet_decision_function_fv_metric: 0.5844 - val_loss: 0.6655 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6758 - val_binary_accuracy_inet_decision_function_fv_metric: 0.5962\n",
      "Epoch 6/500\n",
      "35/35 - 15s - loss: 0.6657 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6739 - binary_accuracy_inet_decision_function_fv_metric: 0.5951 - val_loss: 0.6609 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6731 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6020\n",
      "Epoch 7/500\n",
      "35/35 - 15s - loss: 0.6632 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6722 - binary_accuracy_inet_decision_function_fv_metric: 0.5996 - val_loss: 0.6597 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6726 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6048\n",
      "Epoch 8/500\n",
      "35/35 - 15s - loss: 0.6622 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6716 - binary_accuracy_inet_decision_function_fv_metric: 0.5997 - val_loss: 0.6577 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6709 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6068\n",
      "Epoch 9/500\n",
      "35/35 - 14s - loss: 0.6611 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6709 - binary_accuracy_inet_decision_function_fv_metric: 0.6028 - val_loss: 0.6573 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6705 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6070\n",
      "Epoch 10/500\n",
      "35/35 - 15s - loss: 0.6591 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6694 - binary_accuracy_inet_decision_function_fv_metric: 0.6055 - val_loss: 0.6557 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6695 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6102\n",
      "Epoch 11/500\n",
      "35/35 - 14s - loss: 0.6576 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6686 - binary_accuracy_inet_decision_function_fv_metric: 0.6079 - val_loss: 0.6537 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6683 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6126\n",
      "Epoch 12/500\n",
      "35/35 - 14s - loss: 0.6565 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6678 - binary_accuracy_inet_decision_function_fv_metric: 0.6093 - val_loss: 0.6540 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6683 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6122\n",
      "Epoch 13/500\n",
      "35/35 - 14s - loss: 0.6567 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6679 - binary_accuracy_inet_decision_function_fv_metric: 0.6096 - val_loss: 0.6547 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6692 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6112\n",
      "Epoch 14/500\n",
      "35/35 - 14s - loss: 0.6562 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6676 - binary_accuracy_inet_decision_function_fv_metric: 0.6100 - val_loss: 0.6538 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6679 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6132\n",
      "Epoch 15/500\n",
      "35/35 - 15s - loss: 0.6557 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6672 - binary_accuracy_inet_decision_function_fv_metric: 0.6117 - val_loss: 0.6528 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6678 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6173\n",
      "Epoch 16/500\n",
      "35/35 - 15s - loss: 0.6544 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6664 - binary_accuracy_inet_decision_function_fv_metric: 0.6135 - val_loss: 0.6526 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6678 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6149\n",
      "Epoch 17/500\n",
      "35/35 - 14s - loss: 0.6542 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6663 - binary_accuracy_inet_decision_function_fv_metric: 0.6136 - val_loss: 0.6518 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6670 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6181\n",
      "Epoch 18/500\n",
      "35/35 - 15s - loss: 0.6528 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6653 - binary_accuracy_inet_decision_function_fv_metric: 0.6162 - val_loss: 0.6515 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6667 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6178\n",
      "Epoch 19/500\n",
      "35/35 - 15s - loss: 0.6524 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6650 - binary_accuracy_inet_decision_function_fv_metric: 0.6175 - val_loss: 0.6506 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6662 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6193\n",
      "Epoch 20/500\n",
      "35/35 - 14s - loss: 0.6519 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6647 - binary_accuracy_inet_decision_function_fv_metric: 0.6182 - val_loss: 0.6507 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6666 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6199\n",
      "Epoch 21/500\n",
      "35/35 - 15s - loss: 0.6521 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6649 - binary_accuracy_inet_decision_function_fv_metric: 0.6181 - val_loss: 0.6506 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6663 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6188\n",
      "Epoch 22/500\n",
      "35/35 - 14s - loss: 0.6522 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6648 - binary_accuracy_inet_decision_function_fv_metric: 0.6184 - val_loss: 0.6507 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6661 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6195\n",
      "Epoch 23/500\n",
      "35/35 - 14s - loss: 0.6515 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6644 - binary_accuracy_inet_decision_function_fv_metric: 0.6184 - val_loss: 0.6501 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6658 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6193\n",
      "Epoch 24/500\n",
      "35/35 - 15s - loss: 0.6523 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6650 - binary_accuracy_inet_decision_function_fv_metric: 0.6176 - val_loss: 0.6511 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6668 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6194\n",
      "Epoch 25/500\n",
      "35/35 - 15s - loss: 0.6511 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6642 - binary_accuracy_inet_decision_function_fv_metric: 0.6193 - val_loss: 0.6504 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6663 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6211\n",
      "Epoch 26/500\n",
      "35/35 - 15s - loss: 0.6501 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6636 - binary_accuracy_inet_decision_function_fv_metric: 0.6206 - val_loss: 0.6502 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6661 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6204\n",
      "Epoch 27/500\n",
      "35/35 - 15s - loss: 0.6498 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6633 - binary_accuracy_inet_decision_function_fv_metric: 0.6214 - val_loss: 0.6478 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6645 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6244\n",
      "Epoch 28/500\n",
      "35/35 - 14s - loss: 0.6492 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6629 - binary_accuracy_inet_decision_function_fv_metric: 0.6218 - val_loss: 0.6485 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6648 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6239\n",
      "Epoch 29/500\n",
      "35/35 - 14s - loss: 0.6489 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6628 - binary_accuracy_inet_decision_function_fv_metric: 0.6227 - val_loss: 0.6472 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6644 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6258\n",
      "Epoch 30/500\n",
      "35/35 - 14s - loss: 0.6476 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6620 - binary_accuracy_inet_decision_function_fv_metric: 0.6242 - val_loss: 0.6454 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6629 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6276\n",
      "Epoch 31/500\n",
      "35/35 - 14s - loss: 0.6482 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6623 - binary_accuracy_inet_decision_function_fv_metric: 0.6239 - val_loss: 0.6459 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6630 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6258\n",
      "Epoch 32/500\n",
      "35/35 - 13s - loss: 0.6485 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6624 - binary_accuracy_inet_decision_function_fv_metric: 0.6230 - val_loss: 0.6462 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6633 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6263\n",
      "Epoch 33/500\n",
      "35/35 - 13s - loss: 0.6492 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6628 - binary_accuracy_inet_decision_function_fv_metric: 0.6232 - val_loss: 0.6462 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6635 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6263\n",
      "Epoch 34/500\n",
      "35/35 - 13s - loss: 0.6491 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6629 - binary_accuracy_inet_decision_function_fv_metric: 0.6229 - val_loss: 0.6457 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6630 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6271\n",
      "Epoch 35/500\n",
      "35/35 - 14s - loss: 0.6470 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6616 - binary_accuracy_inet_decision_function_fv_metric: 0.6253 - val_loss: 0.6442 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6618 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6297\n",
      "Epoch 36/500\n",
      "35/35 - 14s - loss: 0.6466 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6612 - binary_accuracy_inet_decision_function_fv_metric: 0.6262 - val_loss: 0.6430 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6612 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6325\n",
      "Epoch 37/500\n",
      "35/35 - 13s - loss: 0.6454 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6605 - binary_accuracy_inet_decision_function_fv_metric: 0.6279 - val_loss: 0.6441 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6624 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6316\n",
      "Epoch 38/500\n",
      "35/35 - 14s - loss: 0.6457 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6606 - binary_accuracy_inet_decision_function_fv_metric: 0.6273 - val_loss: 0.6450 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6628 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6310\n",
      "Epoch 39/500\n",
      "35/35 - 14s - loss: 0.6445 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6599 - binary_accuracy_inet_decision_function_fv_metric: 0.6287 - val_loss: 0.6428 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6617 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6319\n",
      "Epoch 40/500\n",
      "35/35 - 13s - loss: 0.6442 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6596 - binary_accuracy_inet_decision_function_fv_metric: 0.6291 - val_loss: 0.6426 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6611 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6336\n",
      "Epoch 41/500\n",
      "35/35 - 13s - loss: 0.6436 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6593 - binary_accuracy_inet_decision_function_fv_metric: 0.6294 - val_loss: 0.6425 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6611 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6291\n",
      "Epoch 42/500\n",
      "35/35 - 13s - loss: 0.6443 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6597 - binary_accuracy_inet_decision_function_fv_metric: 0.6289 - val_loss: 0.6425 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6609 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6314\n",
      "Epoch 43/500\n",
      "35/35 - 13s - loss: 0.6438 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6594 - binary_accuracy_inet_decision_function_fv_metric: 0.6293 - val_loss: 0.6417 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6605 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6313\n",
      "Epoch 44/500\n",
      "35/35 - 13s - loss: 0.6424 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6584 - binary_accuracy_inet_decision_function_fv_metric: 0.6312 - val_loss: 0.6415 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6607 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6326\n",
      "Epoch 45/500\n",
      "35/35 - 13s - loss: 0.6426 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6586 - binary_accuracy_inet_decision_function_fv_metric: 0.6304 - val_loss: 0.6414 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6605 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6321\n",
      "Epoch 46/500\n",
      "35/35 - 14s - loss: 0.6433 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6591 - binary_accuracy_inet_decision_function_fv_metric: 0.6295 - val_loss: 0.6418 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6612 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6330\n",
      "Epoch 47/500\n",
      "35/35 - 13s - loss: 0.6434 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6592 - binary_accuracy_inet_decision_function_fv_metric: 0.6300 - val_loss: 0.6419 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6613 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6340\n",
      "Epoch 48/500\n",
      "35/35 - 13s - loss: 0.6427 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6588 - binary_accuracy_inet_decision_function_fv_metric: 0.6302 - val_loss: 0.6394 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6591 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6358\n",
      "Epoch 49/500\n",
      "35/35 - 13s - loss: 0.6415 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6578 - binary_accuracy_inet_decision_function_fv_metric: 0.6327 - val_loss: 0.6393 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6590 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6357\n",
      "Epoch 50/500\n",
      "35/35 - 13s - loss: 0.6405 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6573 - binary_accuracy_inet_decision_function_fv_metric: 0.6328 - val_loss: 0.6390 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6592 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6365\n",
      "Epoch 51/500\n",
      "35/35 - 13s - loss: 0.6405 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6573 - binary_accuracy_inet_decision_function_fv_metric: 0.6329 - val_loss: 0.6411 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6606 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6329\n",
      "Epoch 52/500\n",
      "35/35 - 13s - loss: 0.6411 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6577 - binary_accuracy_inet_decision_function_fv_metric: 0.6320 - val_loss: 0.6401 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6601 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6343\n",
      "Epoch 53/500\n",
      "35/35 - 14s - loss: 0.6412 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6577 - binary_accuracy_inet_decision_function_fv_metric: 0.6326 - val_loss: 0.6409 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6606 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6333\n",
      "Epoch 54/500\n",
      "35/35 - 13s - loss: 0.6405 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6574 - binary_accuracy_inet_decision_function_fv_metric: 0.6329 - val_loss: 0.6386 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6590 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6379\n",
      "Epoch 55/500\n",
      "35/35 - 14s - loss: 0.6401 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6570 - binary_accuracy_inet_decision_function_fv_metric: 0.6345 - val_loss: 0.6383 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6590 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6388\n",
      "Epoch 56/500\n",
      "35/35 - 14s - loss: 0.6398 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6569 - binary_accuracy_inet_decision_function_fv_metric: 0.6354 - val_loss: 0.6382 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6589 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6386\n",
      "Epoch 57/500\n",
      "35/35 - 13s - loss: 0.6395 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6565 - binary_accuracy_inet_decision_function_fv_metric: 0.6354 - val_loss: 0.6393 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6595 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6376\n",
      "Epoch 58/500\n",
      "35/35 - 14s - loss: 0.6389 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6563 - binary_accuracy_inet_decision_function_fv_metric: 0.6362 - val_loss: 0.6367 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6577 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6410\n",
      "Epoch 59/500\n",
      "35/35 - 14s - loss: 0.6393 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6564 - binary_accuracy_inet_decision_function_fv_metric: 0.6360 - val_loss: 0.6383 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6585 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6401\n",
      "Epoch 60/500\n",
      "35/35 - 14s - loss: 0.6385 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6560 - binary_accuracy_inet_decision_function_fv_metric: 0.6368 - val_loss: 0.6365 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6576 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6407\n",
      "Epoch 61/500\n",
      "35/35 - 14s - loss: 0.6383 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6556 - binary_accuracy_inet_decision_function_fv_metric: 0.6382 - val_loss: 0.6364 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6574 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6396\n",
      "Epoch 62/500\n",
      "35/35 - 14s - loss: 0.6379 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6556 - binary_accuracy_inet_decision_function_fv_metric: 0.6380 - val_loss: 0.6367 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6578 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6411\n",
      "Epoch 63/500\n",
      "35/35 - 13s - loss: 0.6392 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6563 - binary_accuracy_inet_decision_function_fv_metric: 0.6364 - val_loss: 0.6379 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6586 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6384\n",
      "Epoch 64/500\n",
      "35/35 - 13s - loss: 0.6379 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6556 - binary_accuracy_inet_decision_function_fv_metric: 0.6376 - val_loss: 0.6355 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6565 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6420\n",
      "Epoch 65/500\n",
      "35/35 - 13s - loss: 0.6376 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6552 - binary_accuracy_inet_decision_function_fv_metric: 0.6389 - val_loss: 0.6369 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6578 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6408\n",
      "Epoch 66/500\n",
      "35/35 - 13s - loss: 0.6377 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6554 - binary_accuracy_inet_decision_function_fv_metric: 0.6392 - val_loss: 0.6344 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6560 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6437\n",
      "Epoch 67/500\n",
      "35/35 - 13s - loss: 0.6364 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6545 - binary_accuracy_inet_decision_function_fv_metric: 0.6408 - val_loss: 0.6344 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6563 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6465\n",
      "Epoch 68/500\n",
      "35/35 - 13s - loss: 0.6377 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6554 - binary_accuracy_inet_decision_function_fv_metric: 0.6384 - val_loss: 0.6354 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6571 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6456\n",
      "Epoch 69/500\n",
      "35/35 - 14s - loss: 0.6385 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6559 - binary_accuracy_inet_decision_function_fv_metric: 0.6384 - val_loss: 0.6361 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6571 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6431\n",
      "Epoch 70/500\n",
      "35/35 - 13s - loss: 0.6385 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6559 - binary_accuracy_inet_decision_function_fv_metric: 0.6375 - val_loss: 0.6362 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6579 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6441\n",
      "Epoch 71/500\n",
      "35/35 - 13s - loss: 0.6375 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6552 - binary_accuracy_inet_decision_function_fv_metric: 0.6387 - val_loss: 0.6346 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6564 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6428\n",
      "Epoch 72/500\n",
      "35/35 - 14s - loss: 0.6366 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6547 - binary_accuracy_inet_decision_function_fv_metric: 0.6402 - val_loss: 0.6346 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6563 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6449\n",
      "Epoch 73/500\n",
      "35/35 - 13s - loss: 0.6368 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6548 - binary_accuracy_inet_decision_function_fv_metric: 0.6390 - val_loss: 0.6352 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6567 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6415\n",
      "Epoch 74/500\n",
      "35/35 - 13s - loss: 0.6362 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - binary_accuracy_inet_decision_function_fv_metric: 0.6400 - val_loss: 0.6325 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6550 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6477\n",
      "Epoch 75/500\n",
      "35/35 - 13s - loss: 0.6364 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6545 - binary_accuracy_inet_decision_function_fv_metric: 0.6407 - val_loss: 0.6338 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6562 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6459\n",
      "Epoch 76/500\n",
      "35/35 - 14s - loss: 0.6359 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6542 - binary_accuracy_inet_decision_function_fv_metric: 0.6411 - val_loss: 0.6347 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6563 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6451\n",
      "Epoch 77/500\n",
      "35/35 - 13s - loss: 0.6356 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6540 - binary_accuracy_inet_decision_function_fv_metric: 0.6419 - val_loss: 0.6319 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6549 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6488\n",
      "Epoch 78/500\n",
      "35/35 - 13s - loss: 0.6353 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6538 - binary_accuracy_inet_decision_function_fv_metric: 0.6420 - val_loss: 0.6343 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6564 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6431\n",
      "Epoch 79/500\n",
      "35/35 - 13s - loss: 0.6350 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6536 - binary_accuracy_inet_decision_function_fv_metric: 0.6417 - val_loss: 0.6327 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6550 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6493\n",
      "Epoch 80/500\n",
      "35/35 - 13s - loss: 0.6348 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6535 - binary_accuracy_inet_decision_function_fv_metric: 0.6424 - val_loss: 0.6322 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6551 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6490\n",
      "Epoch 81/500\n",
      "35/35 - 13s - loss: 0.6348 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - binary_accuracy_inet_decision_function_fv_metric: 0.6427 - val_loss: 0.6317 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6549 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6477\n",
      "Epoch 82/500\n",
      "35/35 - 13s - loss: 0.6339 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6528 - binary_accuracy_inet_decision_function_fv_metric: 0.6442 - val_loss: 0.6341 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6562 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6455\n",
      "Epoch 83/500\n",
      "35/35 - 13s - loss: 0.6345 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - binary_accuracy_inet_decision_function_fv_metric: 0.6426 - val_loss: 0.6331 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6555 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6454\n",
      "Epoch 84/500\n",
      "35/35 - 13s - loss: 0.6347 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6533 - binary_accuracy_inet_decision_function_fv_metric: 0.6426 - val_loss: 0.6321 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6551 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6472\n",
      "Epoch 85/500\n",
      "35/35 - 14s - loss: 0.6346 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6532 - binary_accuracy_inet_decision_function_fv_metric: 0.6427 - val_loss: 0.6340 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6566 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6445\n",
      "Epoch 86/500\n",
      "35/35 - 13s - loss: 0.6340 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - binary_accuracy_inet_decision_function_fv_metric: 0.6428 - val_loss: 0.6320 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6549 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6461\n",
      "Epoch 87/500\n",
      "35/35 - 14s - loss: 0.6341 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - binary_accuracy_inet_decision_function_fv_metric: 0.6427 - val_loss: 0.6334 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6552 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6445\n",
      "Epoch 88/500\n",
      "35/35 - 13s - loss: 0.6342 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - binary_accuracy_inet_decision_function_fv_metric: 0.6429 - val_loss: 0.6323 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6549 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6479\n",
      "Epoch 89/500\n",
      "35/35 - 14s - loss: 0.6340 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6530 - binary_accuracy_inet_decision_function_fv_metric: 0.6435 - val_loss: 0.6312 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6546 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6496\n",
      "Epoch 90/500\n",
      "35/35 - 13s - loss: 0.6349 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - binary_accuracy_inet_decision_function_fv_metric: 0.6415 - val_loss: 0.6313 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6540 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6486\n",
      "Epoch 91/500\n",
      "35/35 - 13s - loss: 0.6343 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6532 - binary_accuracy_inet_decision_function_fv_metric: 0.6431 - val_loss: 0.6314 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6490\n",
      "Epoch 92/500\n",
      "35/35 - 14s - loss: 0.6334 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6527 - binary_accuracy_inet_decision_function_fv_metric: 0.6432 - val_loss: 0.6298 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6535 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6496\n",
      "Epoch 93/500\n",
      "35/35 - 13s - loss: 0.6334 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - binary_accuracy_inet_decision_function_fv_metric: 0.6436 - val_loss: 0.6305 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6541 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6492\n",
      "Epoch 94/500\n",
      "35/35 - 13s - loss: 0.6327 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6521 - binary_accuracy_inet_decision_function_fv_metric: 0.6441 - val_loss: 0.6311 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6546 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6495\n",
      "Epoch 95/500\n",
      "35/35 - 13s - loss: 0.6339 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6530 - binary_accuracy_inet_decision_function_fv_metric: 0.6429 - val_loss: 0.6302 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6539 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6498\n",
      "Epoch 96/500\n",
      "35/35 - 13s - loss: 0.6342 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - binary_accuracy_inet_decision_function_fv_metric: 0.6423 - val_loss: 0.6315 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6553 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6482\n",
      "Epoch 97/500\n",
      "35/35 - 13s - loss: 0.6334 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - binary_accuracy_inet_decision_function_fv_metric: 0.6442 - val_loss: 0.6312 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6548 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6483\n",
      "Epoch 98/500\n",
      "35/35 - 13s - loss: 0.6335 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - binary_accuracy_inet_decision_function_fv_metric: 0.6437 - val_loss: 0.6316 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6550 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6485\n",
      "Epoch 99/500\n",
      "35/35 - 13s - loss: 0.6339 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - binary_accuracy_inet_decision_function_fv_metric: 0.6434 - val_loss: 0.6311 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6546 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6493\n",
      "Epoch 100/500\n",
      "35/35 - 13s - loss: 0.6332 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6525 - binary_accuracy_inet_decision_function_fv_metric: 0.6440 - val_loss: 0.6303 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6502\n",
      "Epoch 101/500\n",
      "35/35 - 13s - loss: 0.6326 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6521 - binary_accuracy_inet_decision_function_fv_metric: 0.6450 - val_loss: 0.6314 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6541 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6463\n",
      "Epoch 102/500\n",
      "35/35 - 13s - loss: 0.6326 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6521 - binary_accuracy_inet_decision_function_fv_metric: 0.6445 - val_loss: 0.6303 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6538 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6490\n",
      "Epoch 103/500\n",
      "35/35 - 14s - loss: 0.6324 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6519 - binary_accuracy_inet_decision_function_fv_metric: 0.6451 - val_loss: 0.6291 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6510\n",
      "Epoch 104/500\n",
      "35/35 - 13s - loss: 0.6323 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6520 - binary_accuracy_inet_decision_function_fv_metric: 0.6444 - val_loss: 0.6306 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6540 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6503\n",
      "Epoch 105/500\n",
      "35/35 - 13s - loss: 0.6326 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6520 - binary_accuracy_inet_decision_function_fv_metric: 0.6447 - val_loss: 0.6302 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6542 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6506\n",
      "Epoch 106/500\n",
      "35/35 - 14s - loss: 0.6323 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6520 - binary_accuracy_inet_decision_function_fv_metric: 0.6448 - val_loss: 0.6300 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6540 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6496\n",
      "Epoch 107/500\n",
      "35/35 - 13s - loss: 0.6316 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6514 - binary_accuracy_inet_decision_function_fv_metric: 0.6458 - val_loss: 0.6323 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6553 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6476\n",
      "Epoch 108/500\n",
      "35/35 - 13s - loss: 0.6321 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - binary_accuracy_inet_decision_function_fv_metric: 0.6444 - val_loss: 0.6305 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6541 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6502\n",
      "Epoch 109/500\n",
      "35/35 - 13s - loss: 0.6319 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6517 - binary_accuracy_inet_decision_function_fv_metric: 0.6451 - val_loss: 0.6294 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6538 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6515\n",
      "Epoch 110/500\n",
      "35/35 - 13s - loss: 0.6321 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6519 - binary_accuracy_inet_decision_function_fv_metric: 0.6449 - val_loss: 0.6312 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6544 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6468\n",
      "Epoch 111/500\n",
      "35/35 - 13s - loss: 0.6321 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6517 - binary_accuracy_inet_decision_function_fv_metric: 0.6447 - val_loss: 0.6308 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6541 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6493\n",
      "Epoch 112/500\n",
      "35/35 - 14s - loss: 0.6322 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - binary_accuracy_inet_decision_function_fv_metric: 0.6447 - val_loss: 0.6306 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6493\n",
      "Epoch 113/500\n",
      "35/35 - 13s - loss: 0.6323 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6520 - binary_accuracy_inet_decision_function_fv_metric: 0.6441 - val_loss: 0.6288 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6533 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6520\n",
      "Epoch 114/500\n",
      "35/35 - 13s - loss: 0.6314 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6513 - binary_accuracy_inet_decision_function_fv_metric: 0.6452 - val_loss: 0.6308 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6545 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6485\n",
      "Epoch 115/500\n",
      "35/35 - 13s - loss: 0.6320 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6519 - binary_accuracy_inet_decision_function_fv_metric: 0.6442 - val_loss: 0.6288 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6532 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6510\n",
      "Epoch 116/500\n",
      "35/35 - 14s - loss: 0.6307 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6510 - binary_accuracy_inet_decision_function_fv_metric: 0.6459 - val_loss: 0.6282 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6518\n",
      "Epoch 117/500\n",
      "35/35 - 13s - loss: 0.6309 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6510 - binary_accuracy_inet_decision_function_fv_metric: 0.6460 - val_loss: 0.6300 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6536 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6497\n",
      "Epoch 118/500\n",
      "35/35 - 13s - loss: 0.6324 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6521 - binary_accuracy_inet_decision_function_fv_metric: 0.6442 - val_loss: 0.6293 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6506\n",
      "Epoch 119/500\n",
      "35/35 - 13s - loss: 0.6324 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6520 - binary_accuracy_inet_decision_function_fv_metric: 0.6439 - val_loss: 0.6303 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6539 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6515\n",
      "Epoch 120/500\n",
      "35/35 - 13s - loss: 0.6316 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6515 - binary_accuracy_inet_decision_function_fv_metric: 0.6457 - val_loss: 0.6299 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6532 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6510\n",
      "Epoch 121/500\n",
      "35/35 - 13s - loss: 0.6323 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6519 - binary_accuracy_inet_decision_function_fv_metric: 0.6437 - val_loss: 0.6302 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6541 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6496\n",
      "Epoch 122/500\n",
      "35/35 - 13s - loss: 0.6324 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6520 - binary_accuracy_inet_decision_function_fv_metric: 0.6436 - val_loss: 0.6298 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6538 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6492\n",
      "Epoch 123/500\n",
      "35/35 - 13s - loss: 0.6314 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6513 - binary_accuracy_inet_decision_function_fv_metric: 0.6450 - val_loss: 0.6295 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6539 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6508\n",
      "Epoch 124/500\n",
      "35/35 - 14s - loss: 0.6308 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6510 - binary_accuracy_inet_decision_function_fv_metric: 0.6455 - val_loss: 0.6288 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6536 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6517\n",
      "Epoch 125/500\n",
      "35/35 - 13s - loss: 0.6309 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6511 - binary_accuracy_inet_decision_function_fv_metric: 0.6460 - val_loss: 0.6269 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6521 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6538\n",
      "Epoch 126/500\n",
      "35/35 - 14s - loss: 0.6308 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6510 - binary_accuracy_inet_decision_function_fv_metric: 0.6460 - val_loss: 0.6288 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6505\n",
      "Epoch 127/500\n",
      "35/35 - 13s - loss: 0.6321 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - binary_accuracy_inet_decision_function_fv_metric: 0.6447 - val_loss: 0.6307 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6544 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6469\n",
      "Epoch 128/500\n",
      "35/35 - 13s - loss: 0.6322 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - binary_accuracy_inet_decision_function_fv_metric: 0.6448 - val_loss: 0.6291 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6536 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6511\n",
      "Epoch 129/500\n",
      "35/35 - 13s - loss: 0.6324 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6520 - binary_accuracy_inet_decision_function_fv_metric: 0.6439 - val_loss: 0.6291 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6535 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6508\n",
      "Epoch 130/500\n",
      "35/35 - 14s - loss: 0.6322 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6519 - binary_accuracy_inet_decision_function_fv_metric: 0.6450 - val_loss: 0.6291 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6533 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6490\n",
      "Epoch 131/500\n",
      "35/35 - 13s - loss: 0.6319 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6516 - binary_accuracy_inet_decision_function_fv_metric: 0.6448 - val_loss: 0.6284 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6516\n",
      "Epoch 132/500\n",
      "35/35 - 13s - loss: 0.6311 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6512 - binary_accuracy_inet_decision_function_fv_metric: 0.6456 - val_loss: 0.6284 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6530 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6530\n",
      "Epoch 133/500\n",
      "35/35 - 13s - loss: 0.6321 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - binary_accuracy_inet_decision_function_fv_metric: 0.6442 - val_loss: 0.6295 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6541 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6526\n",
      "Epoch 134/500\n",
      "35/35 - 13s - loss: 0.6315 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6515 - binary_accuracy_inet_decision_function_fv_metric: 0.6442 - val_loss: 0.6280 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6528\n",
      "Epoch 135/500\n",
      "35/35 - 13s - loss: 0.6313 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6513 - binary_accuracy_inet_decision_function_fv_metric: 0.6448 - val_loss: 0.6284 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6532 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6514\n",
      "Epoch 136/500\n",
      "35/35 - 13s - loss: 0.6330 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6524 - binary_accuracy_inet_decision_function_fv_metric: 0.6437 - val_loss: 0.6308 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6542 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6490\n",
      "Epoch 137/500\n",
      "35/35 - 13s - loss: 0.6312 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6512 - binary_accuracy_inet_decision_function_fv_metric: 0.6452 - val_loss: 0.6286 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6518\n",
      "Epoch 138/500\n",
      "35/35 - 13s - loss: 0.6326 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6521 - binary_accuracy_inet_decision_function_fv_metric: 0.6437 - val_loss: 0.6307 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6487\n",
      "Epoch 139/500\n",
      "35/35 - 13s - loss: 0.6313 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6513 - binary_accuracy_inet_decision_function_fv_metric: 0.6452 - val_loss: 0.6290 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6504\n",
      "Epoch 140/500\n",
      "35/35 - 13s - loss: 0.6314 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6512 - binary_accuracy_inet_decision_function_fv_metric: 0.6455 - val_loss: 0.6289 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6537 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6520\n",
      "Epoch 141/500\n",
      "35/35 - 14s - loss: 0.6309 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6512 - binary_accuracy_inet_decision_function_fv_metric: 0.6456 - val_loss: 0.6287 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6532 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6515\n",
      "Epoch 142/500\n",
      "35/35 - 13s - loss: 0.6298 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6502 - binary_accuracy_inet_decision_function_fv_metric: 0.6472 - val_loss: 0.6280 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6528 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6526\n",
      "Epoch 143/500\n",
      "35/35 - 13s - loss: 0.6306 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6509 - binary_accuracy_inet_decision_function_fv_metric: 0.6458 - val_loss: 0.6283 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6533 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6521\n",
      "Epoch 144/500\n",
      "35/35 - 13s - loss: 0.6293 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6502 - binary_accuracy_inet_decision_function_fv_metric: 0.6478 - val_loss: 0.6285 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6520\n",
      "Epoch 145/500\n",
      "35/35 - 13s - loss: 0.6297 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6503 - binary_accuracy_inet_decision_function_fv_metric: 0.6472 - val_loss: 0.6286 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6532 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6523\n",
      "Epoch 146/500\n",
      "35/35 - 13s - loss: 0.6301 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6506 - binary_accuracy_inet_decision_function_fv_metric: 0.6470 - val_loss: 0.6280 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6518\n",
      "Epoch 147/500\n",
      "35/35 - 14s - loss: 0.6301 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6505 - binary_accuracy_inet_decision_function_fv_metric: 0.6466 - val_loss: 0.6274 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6527 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6529\n",
      "Epoch 148/500\n",
      "35/35 - 14s - loss: 0.6314 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6514 - binary_accuracy_inet_decision_function_fv_metric: 0.6455 - val_loss: 0.6286 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6532 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6516\n",
      "Epoch 149/500\n",
      "35/35 - 13s - loss: 0.6313 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6514 - binary_accuracy_inet_decision_function_fv_metric: 0.6459 - val_loss: 0.6288 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6533 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6525\n",
      "Epoch 150/500\n",
      "35/35 - 13s - loss: 0.6303 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6506 - binary_accuracy_inet_decision_function_fv_metric: 0.6468 - val_loss: 0.6283 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6531 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6522\n",
      "Epoch 151/500\n",
      "35/35 - 13s - loss: 0.6305 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6509 - binary_accuracy_inet_decision_function_fv_metric: 0.6468 - val_loss: 0.6282 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6524\n",
      "Epoch 152/500\n",
      "35/35 - 13s - loss: 0.6301 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6506 - binary_accuracy_inet_decision_function_fv_metric: 0.6463 - val_loss: 0.6281 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6530 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6527\n",
      "Epoch 153/500\n",
      "35/35 - 14s - loss: 0.6300 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6504 - binary_accuracy_inet_decision_function_fv_metric: 0.6471 - val_loss: 0.6295 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6536 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6516\n",
      "Epoch 154/500\n",
      "35/35 - 13s - loss: 0.6302 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6507 - binary_accuracy_inet_decision_function_fv_metric: 0.6459 - val_loss: 0.6282 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6532\n",
      "Epoch 155/500\n",
      "35/35 - 13s - loss: 0.6302 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6507 - binary_accuracy_inet_decision_function_fv_metric: 0.6467 - val_loss: 0.6281 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6524 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6498\n",
      "Epoch 156/500\n",
      "35/35 - 13s - loss: 0.6318 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6516 - binary_accuracy_inet_decision_function_fv_metric: 0.6442 - val_loss: 0.6294 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6535 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6508\n",
      "Epoch 157/500\n",
      "35/35 - 13s - loss: 0.6311 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6511 - binary_accuracy_inet_decision_function_fv_metric: 0.6453 - val_loss: 0.6300 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6535 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6490\n",
      "Epoch 158/500\n",
      "35/35 - 13s - loss: 0.6316 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6515 - binary_accuracy_inet_decision_function_fv_metric: 0.6454 - val_loss: 0.6307 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6543 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6482\n",
      "Epoch 159/500\n",
      "35/35 - 13s - loss: 0.6308 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6510 - binary_accuracy_inet_decision_function_fv_metric: 0.6460 - val_loss: 0.6291 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6534 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6504\n",
      "Epoch 160/500\n",
      "35/35 - 13s - loss: 0.6314 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6514 - binary_accuracy_inet_decision_function_fv_metric: 0.6452 - val_loss: 0.6282 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6524 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6508\n",
      "Epoch 161/500\n",
      "35/35 - 13s - loss: 0.6305 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6509 - binary_accuracy_inet_decision_function_fv_metric: 0.6459 - val_loss: 0.6268 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6523 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6547\n",
      "Epoch 162/500\n",
      "35/35 - 13s - loss: 0.6298 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6504 - binary_accuracy_inet_decision_function_fv_metric: 0.6475 - val_loss: 0.6263 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6514 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6536\n",
      "Epoch 163/500\n",
      "35/35 - 13s - loss: 0.6299 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6504 - binary_accuracy_inet_decision_function_fv_metric: 0.6471 - val_loss: 0.6271 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6519 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6521\n",
      "Epoch 164/500\n",
      "35/35 - 13s - loss: 0.6299 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6504 - binary_accuracy_inet_decision_function_fv_metric: 0.6473 - val_loss: 0.6279 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6526 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6520\n",
      "Epoch 165/500\n",
      "35/35 - 13s - loss: 0.6300 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6505 - binary_accuracy_inet_decision_function_fv_metric: 0.6474 - val_loss: 0.6284 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6511\n",
      "Epoch 166/500\n",
      "35/35 - 13s - loss: 0.6300 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6505 - binary_accuracy_inet_decision_function_fv_metric: 0.6467 - val_loss: 0.6295 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6537 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6497\n",
      "Epoch 167/500\n",
      "35/35 - 13s - loss: 0.6305 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6508 - binary_accuracy_inet_decision_function_fv_metric: 0.6456 - val_loss: 0.6300 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6538 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6480\n",
      "Epoch 168/500\n",
      "35/35 - 13s - loss: 0.6312 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6513 - binary_accuracy_inet_decision_function_fv_metric: 0.6455 - val_loss: 0.6284 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6533 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6509\n",
      "Epoch 169/500\n",
      "35/35 - 13s - loss: 0.6300 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6506 - binary_accuracy_inet_decision_function_fv_metric: 0.6462 - val_loss: 0.6280 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6527 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6512\n",
      "Epoch 170/500\n",
      "35/35 - 14s - loss: 0.6294 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6502 - binary_accuracy_inet_decision_function_fv_metric: 0.6475 - val_loss: 0.6267 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6518 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6533\n",
      "Epoch 171/500\n",
      "35/35 - 13s - loss: 0.6299 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6505 - binary_accuracy_inet_decision_function_fv_metric: 0.6460 - val_loss: 0.6279 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6524 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6518\n",
      "Epoch 172/500\n",
      "35/35 - 13s - loss: 0.6299 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6503 - binary_accuracy_inet_decision_function_fv_metric: 0.6466 - val_loss: 0.6283 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6528 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6520\n",
      "Epoch 173/500\n",
      "35/35 - 13s - loss: 0.6307 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6509 - binary_accuracy_inet_decision_function_fv_metric: 0.6458 - val_loss: 0.6281 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6514\n",
      "Epoch 174/500\n",
      "35/35 - 13s - loss: 0.6295 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6502 - binary_accuracy_inet_decision_function_fv_metric: 0.6474 - val_loss: 0.6286 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6529 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6501\n",
      "Epoch 175/500\n",
      "35/35 - 13s - loss: 0.6302 - soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6508 - binary_accuracy_inet_decision_function_fv_metric: 0.6468 - val_loss: 0.6271 - val_soft_binary_crossentropy_inet_decision_function_fv_metric: 0.6523 - val_binary_accuracy_inet_decision_function_fv_metric: 0.6525\n",
      "Training Time: 0:40:18\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------ LOADING MODELS -----------------------------------------------------\n",
      "Loading Time: 0:00:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "((X_valid, y_valid), \n",
    " (X_test, y_test),\n",
    " \n",
    " history,\n",
    " loss_function,\n",
    " metrics,\n",
    " \n",
    " model,\n",
    " encoder_model) = interpretation_net_training(\n",
    "                                      lambda_net_dataset_train, \n",
    "                                      lambda_net_dataset_valid, \n",
    "                                      lambda_net_dataset_test,\n",
    "                                      config,\n",
    "                                      #callback_names=['tensorboard'] #plot_losses\n",
    "                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:42:13.043820Z",
     "iopub.status.busy": "2022-01-04T11:42:13.043584Z",
     "iopub.status.idle": "2022-01-04T11:42:13.487855Z",
     "shell.execute_reply": "2022-01-04T11:42:13.486928Z",
     "shell.execute_reply.started": "2022-01-04T11:42:13.043781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if nas:\n",
    "    for trial in history: \n",
    "        print(trial.summary())\n",
    "        \n",
    "    writepath_nas = './results_nas.csv'\n",
    "\n",
    "    if different_eval_data:\n",
    "        flat_config = flatten_dict(config_train)\n",
    "    else:\n",
    "        flat_config = flatten_dict(config)    \n",
    "\n",
    "    if not os.path.exists(writepath_nas):\n",
    "        with open(writepath_nas, 'w+') as text_file:       \n",
    "            for key in flat_config.keys():\n",
    "                text_file.write(key)\n",
    "                text_file.write(';')         \n",
    "\n",
    "            for hp in history[0].hyperparameters.values.keys():\n",
    "                text_file.write(hp + ';')    \n",
    "               \n",
    "            text_file.write('score')\n",
    "            \n",
    "            text_file.write('\\n')\n",
    "            \n",
    "            \n",
    "\n",
    "    with open(writepath_nas, 'a+') as text_file:  \n",
    "        for value in flat_config.values():\n",
    "            text_file.write(str(value))\n",
    "            text_file.write(';')\n",
    "\n",
    "        for hp, value in history[0].hyperparameters.values.items():\n",
    "            text_file.write(str(value) + ';')        \n",
    "\n",
    "        \n",
    "        text_file.write(str(history[0].score))\n",
    "            \n",
    "        text_file.write('\\n')            \n",
    "\n",
    "        text_file.close()      \n",
    "        \n",
    "else:\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:42:13.489656Z",
     "iopub.status.busy": "2022-01-04T11:42:13.489347Z",
     "iopub.status.idle": "2022-01-04T11:42:20.462554Z",
     "shell.execute_reply": "2022-01-04T11:42:20.461689Z",
     "shell.execute_reply.started": "2022-01-04T11:42:13.489629Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 3\n",
    "network_parameters = np.array([lambda_net_dataset_test.network_parameters_array[index]])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data(network_parameters, config, encoder_model)    \n",
    "dt_parameters = model.predict(network_parameters)[0]\n",
    "\n",
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(dt_parameters, config=config)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(dt_parameters, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:42:20.464989Z",
     "iopub.status.busy": "2022-01-04T11:42:20.464589Z",
     "iopub.status.idle": "2022-01-04T11:42:20.495477Z",
     "shell.execute_reply": "2022-01-04T11:42:20.494593Z",
     "shell.execute_reply.started": "2022-01-04T11:42:20.464953Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 2177)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_1024 (Dense)            (None, 1024)         2230272     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation1_relu (Activation)   (None, 1024)         0           hidden1_1024[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout1_0.3 (Dropout)          (None, 1024)         0           activation1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_1024 (Dense)            (None, 1024)         1049600     dropout1_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation2_relu (Activation)   (None, 1024)         0           hidden2_1024[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout2_0.3 (Dropout)          (None, 1024)         0           activation2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden3_256 (Dense)             (None, 256)          262400      dropout2_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation3_relu (Activation)   (None, 256)          0           hidden3_256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout3_0.3 (Dropout)          (None, 256)          0           activation3_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden4_2048 (Dense)            (None, 2048)         526336      dropout3_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation4_relu (Activation)   (None, 2048)         0           hidden4_2048[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout4_0.3 (Dropout)          (None, 2048)         0           activation4_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hidden5_2048 (Dense)            (None, 2048)         4196352     dropout4_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation5_relu (Activation)   (None, 2048)         0           hidden5_2048[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout5_0.3 (Dropout)          (None, 2048)         0           activation5_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_coeff_225 (Dense)        (None, 225)          461025      dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_1 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_2 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_3 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_4 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_5 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_6 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_7 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_8 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_9 (Dense)     (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_10 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_11 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_12 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_13 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_14 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_identifier_15 (Dense)    (None, 15)           30735       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_leaf_node_16 (Dense)     (None, 16)           32784       dropout5_0.3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_combined (Concatenate)   (None, 466)          0           output_coeff_225[0][0]           \n",
      "                                                                 output_identifier_1[0][0]        \n",
      "                                                                 output_identifier_2[0][0]        \n",
      "                                                                 output_identifier_3[0][0]        \n",
      "                                                                 output_identifier_4[0][0]        \n",
      "                                                                 output_identifier_5[0][0]        \n",
      "                                                                 output_identifier_6[0][0]        \n",
      "                                                                 output_identifier_7[0][0]        \n",
      "                                                                 output_identifier_8[0][0]        \n",
      "                                                                 output_identifier_9[0][0]        \n",
      "                                                                 output_identifier_10[0][0]       \n",
      "                                                                 output_identifier_11[0][0]       \n",
      "                                                                 output_identifier_12[0][0]       \n",
      "                                                                 output_identifier_13[0][0]       \n",
      "                                                                 output_identifier_14[0][0]       \n",
      "                                                                 output_identifier_15[0][0]       \n",
      "                                                                 output_leaf_node_16[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 9,219,794\n",
      "Trainable params: 9,219,794\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:42:20.497079Z",
     "iopub.status.busy": "2022-01-04T11:42:20.496773Z",
     "iopub.status.idle": "2022-01-04T11:43:52.108982Z",
     "shell.execute_reply": "2022-01-04T11:43:52.108138Z",
     "shell.execute_reply.started": "2022-01-04T11:42:20.497050Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=7)]: Done  11 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=7)]: Done  47 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=7)]: Done  58 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=7)]: Done  71 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=7)]: Done  84 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=7)]: Done  98 out of 100 | elapsed:  1.5min remaining:    1.9s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_train.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_train.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)   \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "    \n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=10, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_train.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_train.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_train = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_train == None:\n",
    "            inet_evaluation_result_dict_train = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_train = mergeDict(inet_evaluation_result_dict_train, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_train['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_train = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_train.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_train[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_train[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_train[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:43:52.111140Z",
     "iopub.status.busy": "2022-01-04T11:43:52.110900Z",
     "iopub.status.idle": "2022-01-04T11:43:52.131698Z",
     "shell.execute_reply": "2022-01-04T11:43:52.130960Z",
     "shell.execute_reply.started": "2022-01-04T11:43:52.111108Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA RESULTS\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|               Metric              | Distilled DT (Train/Random Data) | Distilled DT (Test Data) | I-Net DT (Test Data) |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|  Soft Binary Crossentropy (Mean)  |              0.526               |          0.535           |        0.649         |\n",
      "|     Binary Crossentropy (Mean)    |              0.405               |          0.443           |        0.623         |\n",
      "|          Accuracy (Mean)          |              0.814               |          0.795           |         0.65         |\n",
      "|          F1 Score (Mean)          |              0.808               |          0.789           |        0.611         |\n",
      "|           Runtime (Mean)          |              0.046               |          0.046           |        0.001         |\n",
      "| Soft Binary Crossentropy (Median) |              0.529               |          0.539           |        0.651         |\n",
      "|    Binary Crossentropy (Median)   |              0.415               |          0.454           |        0.628         |\n",
      "|         Accuracy (Median)         |              0.809               |          0.794           |        0.647         |\n",
      "|         F1 Score (Median)         |              0.818               |          0.804           |        0.656         |\n",
      "|          Runtime (Median)         |              0.047               |          0.047           |        0.001         |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:43:52.133167Z",
     "iopub.status.busy": "2022-01-04T11:43:52.132860Z",
     "iopub.status.idle": "2022-01-04T11:44:56.124232Z",
     "shell.execute_reply": "2022-01-04T11:44:56.123436Z",
     "shell.execute_reply.started": "2022-01-04T11:43:52.133142Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d408628cd33a4cec933c32d2ec58ee31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_train = np.round(np.mean(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "std_train = np.round(np.std(lambda_net_dataset_train.network_parameters_array, axis=0), 5)\n",
    "\n",
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_train.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_train = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_train = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_train = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_train = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_train = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_train = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:44:56.126266Z",
     "iopub.status.busy": "2022-01-04T11:44:56.126040Z",
     "iopub.status.idle": "2022-01-04T11:46:08.559099Z",
     "shell.execute_reply": "2022-01-04T11:46:08.558069Z",
     "shell.execute_reply.started": "2022-01-04T11:44:56.126235Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = min(lambda_net_dataset_valid.X_test_lambda_array.shape[0], 100)\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_valid.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)  \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_valid.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_valid.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_valid = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_valid == None:\n",
    "            inet_evaluation_result_dict_valid = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_valid = mergeDict(inet_evaluation_result_dict_valid, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_valid['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_valid = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_valid.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_valid[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_valid[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_valid[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:46:08.561549Z",
     "iopub.status.busy": "2022-01-04T11:46:08.561200Z",
     "iopub.status.idle": "2022-01-04T11:46:08.581834Z",
     "shell.execute_reply": "2022-01-04T11:46:08.581156Z",
     "shell.execute_reply.started": "2022-01-04T11:46:08.561501Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID DATA RESULTS\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|               Metric              | Distilled DT (Train/Random Data) | Distilled DT (Test Data) | I-Net DT (Test Data) |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|  Soft Binary Crossentropy (Mean)  |              0.526               |          0.535           |        0.655         |\n",
      "|     Binary Crossentropy (Mean)    |              0.405               |          0.444           |        0.633         |\n",
      "|          Accuracy (Mean)          |              0.814               |          0.795           |        0.649         |\n",
      "|          F1 Score (Mean)          |              0.808               |          0.789           |        0.617         |\n",
      "|           Runtime (Mean)          |              0.045               |          0.045           |        0.001         |\n",
      "| Soft Binary Crossentropy (Median) |              0.533               |           0.54           |        0.657         |\n",
      "|    Binary Crossentropy (Median)   |              0.418               |           0.45           |         0.64         |\n",
      "|         Accuracy (Median)         |              0.812               |          0.794           |        0.658         |\n",
      "|         F1 Score (Median)         |              0.815               |          0.793           |        0.661         |\n",
      "|          Runtime (Median)         |              0.047               |          0.047           |        0.001         |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "print('VALID DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:46:08.583175Z",
     "iopub.status.busy": "2022-01-04T11:46:08.582913Z",
     "iopub.status.idle": "2022-01-04T11:46:55.209772Z",
     "shell.execute_reply": "2022-01-04T11:46:55.208615Z",
     "shell.execute_reply.started": "2022-01-04T11:46:08.583149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6fde8b2b43492c9c1e397e262e15ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_valid.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_valid = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_valid = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_valid = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_valid = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_valid = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_valid = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:46:55.212562Z",
     "iopub.status.busy": "2022-01-04T11:46:55.212282Z",
     "iopub.status.idle": "2022-01-04T11:47:37.820911Z",
     "shell.execute_reply": "2022-01-04T11:47:37.819983Z",
     "shell.execute_reply.started": "2022-01-04T11:46:55.212513Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=7)]: Done  50 out of  50 | elapsed:   42.5s finished\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    number = lambda_net_dataset_test.X_test_lambda_array.shape[0]#10\n",
    "\n",
    "    start_inet = time.time() \n",
    "    \n",
    "    network_parameters = np.array(lambda_net_dataset_test.network_parameters_array[:number])\n",
    "    if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "        network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "    elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "        network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "    dt_inet_list = model.predict(network_parameters)  \n",
    "    \n",
    "    end_inet = time.time()     \n",
    "    inet_runtime = (end_inet - start_inet)    \n",
    "\n",
    "\n",
    "    parallel_inet_evaluation = Parallel(n_jobs=n_jobs, verbose=1, backend='loky') #loky #sequential multiprocessing\n",
    "    inet_evaluation_results_with_dt = parallel_inet_evaluation(delayed(evaluate_interpretation_net_prediction_single_sample)(lambda_net_parameters, \n",
    "                                                                                                                   dt_inet,\n",
    "                                                                                                                   X_test_lambda, \n",
    "                                                                                                                   #y_test_lambda,\n",
    "                                                                                                                   config) for lambda_net_parameters, \n",
    "                                                                                                                               dt_inet, \n",
    "                                                                                                                               X_test_lambda in zip(lambda_net_dataset_test.network_parameters_array[:number], \n",
    "                                                                                                                                                    dt_inet_list, \n",
    "                                                                                                                                                    lambda_net_dataset_test.X_test_lambda_array[:number]))      \n",
    "\n",
    "    del parallel_inet_evaluation\n",
    "\n",
    "    inet_evaluation_results = [entry[0] for entry in inet_evaluation_results_with_dt]\n",
    "    dt_distilled_list = [entry[1] for entry in inet_evaluation_results_with_dt]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_test = None\n",
    "    for some_dict in inet_evaluation_results:\n",
    "        if inet_evaluation_result_dict_test == None:\n",
    "            inet_evaluation_result_dict_test = some_dict\n",
    "        else:\n",
    "            inet_evaluation_result_dict_test = mergeDict(inet_evaluation_result_dict_test, some_dict)\n",
    "\n",
    "    inet_evaluation_result_dict_test['inet_scores']['runtime'] = [inet_runtime/number for _ in range(number)]\n",
    "\n",
    "\n",
    "    inet_evaluation_result_dict_mean_test = {}\n",
    "\n",
    "    for key_l1, values_l1 in inet_evaluation_result_dict_test.items():\n",
    "        if key_l1 != 'function_values':\n",
    "            if isinstance(values_l1, dict):\n",
    "                inet_evaluation_result_dict_mean_test[key_l1] = {}\n",
    "                for key_l2, values_l2 in values_l1.items():\n",
    "                    inet_evaluation_result_dict_mean_test[key_l1][key_l2] = np.mean(values_l2)\n",
    "                    inet_evaluation_result_dict_mean_test[key_l1][key_l2 + '_median'] = np.median(values_l2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:47:37.822977Z",
     "iopub.status.busy": "2022-01-04T11:47:37.822753Z",
     "iopub.status.idle": "2022-01-04T11:47:37.843967Z",
     "shell.execute_reply": "2022-01-04T11:47:37.843384Z",
     "shell.execute_reply.started": "2022-01-04T11:47:37.822947Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA RESULTS\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|               Metric              | Distilled DT (Train/Random Data) | Distilled DT (Test Data) | I-Net DT (Test Data) |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n",
      "|  Soft Binary Crossentropy (Mean)  |              0.525               |          0.534           |        0.653         |\n",
      "|     Binary Crossentropy (Mean)    |              0.404               |          0.444           |        0.629         |\n",
      "|          Accuracy (Mean)          |              0.815               |          0.795           |        0.646         |\n",
      "|          F1 Score (Mean)          |              0.805               |          0.785           |        0.608         |\n",
      "|           Runtime (Mean)          |              0.039               |          0.039           |        0.002         |\n",
      "| Soft Binary Crossentropy (Median) |              0.529               |          0.538           |        0.656         |\n",
      "|    Binary Crossentropy (Median)   |              0.411               |          0.452           |        0.634         |\n",
      "|         Accuracy (Median)         |              0.815               |          0.794           |        0.659         |\n",
      "|         F1 Score (Median)         |              0.807               |          0.786           |        0.659         |\n",
      "|          Runtime (Median)         |              0.037               |          0.037           |        0.002         |\n",
      "+-----------------------------------+----------------------------------+--------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "print('TEST DATA RESULTS')\n",
    "\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Soft Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:47:37.845409Z",
     "iopub.status.busy": "2022-01-04T11:47:37.845144Z",
     "iopub.status.idle": "2022-01-04T11:48:00.665315Z",
     "shell.execute_reply": "2022-01-04T11:48:00.664295Z",
     "shell.execute_reply.started": "2022-01-04T11:47:37.845375Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13645d9fb30140ba9fcfe700f9a7666c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_score_aggregate_list = []\n",
    "distance_to_initialization_aggregate_list = []\n",
    "distance_to_sample_average_list = []\n",
    "distance_to_sample_min_list = []\n",
    "max_distance_to_neuron_average_list = []\n",
    "max_distance_to_neuron_min_list = []\n",
    "\n",
    "for network in tqdm(lambda_net_dataset_test.network_parameters_array[:100]):\n",
    "    (z_score_aggregate, \n",
    "     distance_to_initialization_aggregate, \n",
    "     distance_to_sample_average, \n",
    "     distance_to_sample_min, \n",
    "     max_distance_to_neuron_average,\n",
    "     max_distance_to_neuron_min) = calculate_network_distance(mean=mean_train, \n",
    "                                                               std=std_train, \n",
    "                                                               network_parameters=network, \n",
    "                                                               lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                               config=config)    \n",
    "    z_score_aggregate_list.append(z_score_aggregate)\n",
    "    distance_to_initialization_aggregate_list.append(distance_to_initialization_aggregate)\n",
    "    distance_to_sample_average_list.append(distance_to_sample_average)\n",
    "    distance_to_sample_min_list.append(distance_to_sample_min)  \n",
    "    max_distance_to_neuron_average_list.append(max_distance_to_neuron_average)\n",
    "    max_distance_to_neuron_min_list.append(max_distance_to_neuron_min)\n",
    "    \n",
    "z_score_average_test = np.mean(z_score_aggregate_list)\n",
    "distance_to_initialization_average_test = np.mean(distance_to_initialization_aggregate_list)\n",
    "\n",
    "distance_to_sample_average_average_test = np.mean(distance_to_sample_average_list)\n",
    "distance_to_sample_min_average_test = np.mean(distance_to_sample_min_list)\n",
    "\n",
    "max_distance_to_neuron_average_average_test = np.mean(max_distance_to_neuron_average_list)\n",
    "max_distance_to_neuron_min_average_test = np.mean(max_distance_to_neuron_min_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:00.669224Z",
     "iopub.status.busy": "2022-01-04T11:48:00.668710Z",
     "iopub.status.idle": "2022-01-04T11:48:00.724412Z",
     "shell.execute_reply": "2022-01-04T11:48:00.723751Z",
     "shell.execute_reply.started": "2022-01-04T11:48:00.669182Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+----------------+--------+---------+----------------+--------+---------+----------------+-------+--------+\n",
      "|               Metric              |     Train      | Train  |  Train  |     Valid      | Valid  |  Valid  |      Test      | Test  |  Test  |\n",
      "+-----------------------------------+----------------+--------+---------+----------------+--------+---------+----------------+-------+--------+\n",
      "|               Metric              | Dist. (Random) | Dist.  |  I-Net  | Dist. (Random) | Dist.  |  I-Net  | Dist. (Random) | Dist. | I-Net  |\n",
      "|  Soft Binary Crossentropy (Mean)  |     0.526      | 0.535  |  0.649  |     0.526      | 0.535  |  0.655  |     0.525      | 0.534 | 0.653  |\n",
      "|     Binary Crossentropy (Mean)    |     0.405      | 0.443  |  0.623  |     0.405      | 0.444  |  0.633  |     0.404      | 0.444 | 0.629  |\n",
      "|          Accuracy (Mean)          |     0.814      | 0.795  |   0.65  |     0.814      | 0.795  |  0.649  |     0.815      | 0.795 | 0.646  |\n",
      "|          F1 Score (Mean)          |     0.808      | 0.789  |  0.611  |     0.808      | 0.789  |  0.617  |     0.805      | 0.785 | 0.608  |\n",
      "|           Runtime (Mean)          |     0.046      | 0.046  |  0.001  |     0.045      | 0.045  |  0.001  |     0.039      | 0.039 | 0.002  |\n",
      "| Soft Binary Crossentropy (Median) |     0.529      | 0.539  |  0.651  |     0.533      |  0.54  |  0.657  |     0.529      | 0.538 | 0.656  |\n",
      "|    Binary Crossentropy (Median)   |     0.415      | 0.454  |  0.628  |     0.418      |  0.45  |   0.64  |     0.411      | 0.452 | 0.634  |\n",
      "|         Accuracy (Median)         |     0.809      | 0.794  |  0.647  |     0.812      | 0.794  |  0.658  |     0.815      | 0.794 | 0.659  |\n",
      "|         F1 Score (Median)         |     0.818      | 0.804  |  0.656  |     0.815      | 0.793  |  0.661  |     0.807      | 0.786 | 0.659  |\n",
      "|          Runtime (Median)         |     0.047      | 0.047  |  0.001  |     0.047      | 0.047  |  0.001  |     0.037      | 0.037 | 0.002  |\n",
      "+-----------------------------------+----------------+--------+---------+----------------+--------+---------+----------------+-------+--------+\n"
     ]
    }
   ],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', 'Train', 'Train ', ' Train ', 'Valid', 'Valid ', ' Valid ', 'Test', 'Test ', ' Test ']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Metric', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net', \n",
    "         'Dist. (Random)', 'Dist.', 'I-Net'],\n",
    "        ['Soft Binary Crossentropy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "        ['Binary Crossentropy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy'], 3)],\n",
    "        ['Accuracy (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy'], 3)],\n",
    "        ['F1 Score (Mean)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score'], 3)],\n",
    "        ['Runtime (Mean)',  \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime'], 3)],\n",
    "        ['Soft Binary Crossentropy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['soft_binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['soft_binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['soft_binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['soft_binary_crossentropy_median'], 3)],\n",
    "        ['Binary Crossentropy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['binary_crossentropy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['binary_crossentropy_median'], 3),\n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['binary_crossentropy_median'], 3)],\n",
    "        ['Accuracy (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['accuracy_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['accuracy_median'], 3)],\n",
    "        ['F1 Score (Median)', \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_data_random_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['f1_score_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['f1_score_median'], 3)],\n",
    "        ['Runtime (Median)',  \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_train['inet_scores']['runtime_median'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_valid['inet_scores']['runtime_median'], 3),  \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['dt_scores']['runtime_median'], 3), \n",
    "         np.round(inet_evaluation_result_dict_mean_test['inet_scores']['runtime_median'], 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:00.725731Z",
     "iopub.status.busy": "2022-01-04T11:48:00.725495Z",
     "iopub.status.idle": "2022-01-04T11:48:00.740376Z",
     "shell.execute_reply": "2022-01-04T11:48:00.739722Z",
     "shell.execute_reply.started": "2022-01-04T11:48:00.725706Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------+------------+------------+-----------+\n",
      "|                    Measure                    | Train Data | Valid Data | Test Data |\n",
      "+-----------------------------------------------+------------+------------+-----------+\n",
      "|     Average Z-Score (Sample to Train Data)    |  1345.061  |  1323.282  |  1352.215 |\n",
      "|       Average Distance to Initialization      |  278.299   |  268.358   |  271.382  |\n",
      "|      Average Mean Distance to Train Data      |  393.152   |  386.734   |  389.171  |\n",
      "| Average Distance to closest Train Data Sample |    0.0     |  264.991   |  267.449  |\n",
      "|   Average Biggest Distance for Single Neuron  |    3.58    |   3.453    |   3.489   |\n",
      "|   Minimum Biggest Distance for Single Neuron  |    0.0     |   1.955    |   1.969   |\n",
      "+-----------------------------------------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3)],\n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATA EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:00.741621Z",
     "iopub.status.busy": "2022-01-04T11:48:00.741380Z",
     "iopub.status.idle": "2022-01-04T11:48:02.844928Z",
     "shell.execute_reply": "2022-01-04T11:48:02.843878Z",
     "shell.execute_reply.started": "2022-01-04T11:48:00.741596Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>capital_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age          Workclass  fnlwgt   Education  Education-Num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        Marital Status          Occupation    Relationship    Race      Sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   Capital Gain  Capital Loss  Hours per week         Country capital_gain  \n",
       "0          2174             0              40   United-States        <=50K  \n",
       "1             0             0              13   United-States        <=50K  \n",
       "2             0             0              40   United-States        <=50K  \n",
       "3             0             0              40   United-States        <=50K  \n",
       "4             0             0              40            Cuba        <=50K  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = [\n",
    "                 \"Age\", #0\n",
    "                 \"Workclass\",  #1\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Race\",  #8\n",
    "                 \"Sex\",  #9\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 \"Country\", #13\n",
    "                 \"capital_gain\" #14\n",
    "                ] \n",
    "\n",
    "\n",
    "\n",
    "adult_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, index_col=False)\n",
    "\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:02.847060Z",
     "iopub.status.busy": "2022-01-04T11:48:02.846725Z",
     "iopub.status.idle": "2022-01-04T11:48:02.885297Z",
     "shell.execute_reply": "2022-01-04T11:48:02.884552Z",
     "shell.execute_reply.started": "2022-01-04T11:48:02.847016Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000</td>\n",
       "      <td>32561.000</td>\n",
       "      <td>32561.000</td>\n",
       "      <td>32561.000</td>\n",
       "      <td>32561.000</td>\n",
       "      <td>32561.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.582</td>\n",
       "      <td>189778.367</td>\n",
       "      <td>10.081</td>\n",
       "      <td>1077.649</td>\n",
       "      <td>87.304</td>\n",
       "      <td>40.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640</td>\n",
       "      <td>105549.978</td>\n",
       "      <td>2.573</td>\n",
       "      <td>7385.292</td>\n",
       "      <td>402.960</td>\n",
       "      <td>12.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000</td>\n",
       "      <td>12285.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000</td>\n",
       "      <td>117827.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000</td>\n",
       "      <td>178356.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000</td>\n",
       "      <td>237051.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000</td>\n",
       "      <td>1484705.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>99999.000</td>\n",
       "      <td>4356.000</td>\n",
       "      <td>99.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age      fnlwgt  Education-Num  Capital Gain  Capital Loss  \\\n",
       "count 32561.000   32561.000      32561.000     32561.000     32561.000   \n",
       "mean     38.582  189778.367         10.081      1077.649        87.304   \n",
       "std      13.640  105549.978          2.573      7385.292       402.960   \n",
       "min      17.000   12285.000          1.000         0.000         0.000   \n",
       "25%      28.000  117827.000          9.000         0.000         0.000   \n",
       "50%      37.000  178356.000         10.000         0.000         0.000   \n",
       "75%      48.000  237051.000         12.000         0.000         0.000   \n",
       "max      90.000 1484705.000         16.000     99999.000      4356.000   \n",
       "\n",
       "       Hours per week  \n",
       "count       32561.000  \n",
       "mean           40.437  \n",
       "std            12.347  \n",
       "min             1.000  \n",
       "25%            40.000  \n",
       "50%            40.000  \n",
       "75%            45.000  \n",
       "max            99.000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:02.886625Z",
     "iopub.status.busy": "2022-01-04T11:48:02.886361Z",
     "iopub.status.idle": "2022-01-04T11:48:02.916270Z",
     "shell.execute_reply": "2022-01-04T11:48:02.915450Z",
     "shell.execute_reply.started": "2022-01-04T11:48:02.886598Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Age             32561 non-null  int64 \n",
      " 1   Workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   Education       32561 non-null  object\n",
      " 4   Education-Num   32561 non-null  int64 \n",
      " 5   Marital Status  32561 non-null  object\n",
      " 6   Occupation      32561 non-null  object\n",
      " 7   Relationship    32561 non-null  object\n",
      " 8   Race            32561 non-null  object\n",
      " 9   Sex             32561 non-null  object\n",
      " 10  Capital Gain    32561 non-null  int64 \n",
      " 11  Capital Loss    32561 non-null  int64 \n",
      " 12  Hours per week  32561 non-null  int64 \n",
      " 13  Country         32561 non-null  object\n",
      " 14  capital_gain    32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:02.917647Z",
     "iopub.status.busy": "2022-01-04T11:48:02.917403Z",
     "iopub.status.idle": "2022-01-04T11:48:02.922172Z",
     "shell.execute_reply": "2022-01-04T11:48:02.921466Z",
     "shell.execute_reply.started": "2022-01-04T11:48:02.917620Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adult_data['Workclass'][adult_data['Workclass'] != ' Private'] = 'Other'\n",
    "#adult_data['Race'][adult_data['Race'] != ' White'] = 'Other'\n",
    "\n",
    "#adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:02.923477Z",
     "iopub.status.busy": "2022-01-04T11:48:02.923174Z",
     "iopub.status.idle": "2022-01-04T11:48:03.882905Z",
     "shell.execute_reply": "2022-01-04T11:48:03.882130Z",
     "shell.execute_reply.started": "2022-01-04T11:48:02.923452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__x0_ Amer-Indian-Eskimo</th>\n",
       "      <th>cat__x0_ Asian-Pac-Islander</th>\n",
       "      <th>cat__x0_ Black</th>\n",
       "      <th>cat__x0_ Other</th>\n",
       "      <th>cat__x0_ White</th>\n",
       "      <th>cat__x1_ ?</th>\n",
       "      <th>cat__x1_ Federal-gov</th>\n",
       "      <th>cat__x1_ Local-gov</th>\n",
       "      <th>cat__x1_ Never-worked</th>\n",
       "      <th>cat__x1_ Private</th>\n",
       "      <th>cat__x1_ Self-emp-inc</th>\n",
       "      <th>cat__x1_ Self-emp-not-inc</th>\n",
       "      <th>cat__x1_ State-gov</th>\n",
       "      <th>cat__x1_ Without-pay</th>\n",
       "      <th>cat__x2_ 10th</th>\n",
       "      <th>cat__x2_ 11th</th>\n",
       "      <th>cat__x2_ 12th</th>\n",
       "      <th>cat__x2_ 1st-4th</th>\n",
       "      <th>cat__x2_ 5th-6th</th>\n",
       "      <th>cat__x2_ 7th-8th</th>\n",
       "      <th>cat__x2_ 9th</th>\n",
       "      <th>cat__x2_ Assoc-acdm</th>\n",
       "      <th>cat__x2_ Assoc-voc</th>\n",
       "      <th>cat__x2_ Bachelors</th>\n",
       "      <th>cat__x2_ Doctorate</th>\n",
       "      <th>cat__x2_ HS-grad</th>\n",
       "      <th>cat__x2_ Masters</th>\n",
       "      <th>cat__x2_ Preschool</th>\n",
       "      <th>cat__x2_ Prof-school</th>\n",
       "      <th>cat__x2_ Some-college</th>\n",
       "      <th>cat__x3_ Divorced</th>\n",
       "      <th>cat__x3_ Married-AF-spouse</th>\n",
       "      <th>cat__x3_ Married-civ-spouse</th>\n",
       "      <th>cat__x3_ Married-spouse-absent</th>\n",
       "      <th>cat__x3_ Never-married</th>\n",
       "      <th>cat__x3_ Separated</th>\n",
       "      <th>cat__x3_ Widowed</th>\n",
       "      <th>cat__x4_ ?</th>\n",
       "      <th>cat__x4_ Adm-clerical</th>\n",
       "      <th>cat__x4_ Armed-Forces</th>\n",
       "      <th>cat__x4_ Craft-repair</th>\n",
       "      <th>cat__x4_ Exec-managerial</th>\n",
       "      <th>cat__x4_ Farming-fishing</th>\n",
       "      <th>cat__x4_ Handlers-cleaners</th>\n",
       "      <th>cat__x4_ Machine-op-inspct</th>\n",
       "      <th>cat__x4_ Other-service</th>\n",
       "      <th>cat__x4_ Priv-house-serv</th>\n",
       "      <th>cat__x4_ Prof-specialty</th>\n",
       "      <th>cat__x4_ Protective-serv</th>\n",
       "      <th>cat__x4_ Sales</th>\n",
       "      <th>cat__x4_ Tech-support</th>\n",
       "      <th>cat__x4_ Transport-moving</th>\n",
       "      <th>cat__x5_ Husband</th>\n",
       "      <th>cat__x5_ Not-in-family</th>\n",
       "      <th>cat__x5_ Other-relative</th>\n",
       "      <th>cat__x5_ Own-child</th>\n",
       "      <th>cat__x5_ Unmarried</th>\n",
       "      <th>cat__x5_ Wife</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>77516.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>2174.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>83311.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>215646.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>234721.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>338409.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat__x0_ Amer-Indian-Eskimo  cat__x0_ Asian-Pac-Islander  cat__x0_ Black  \\\n",
       "0                        0.000                        0.000           0.000   \n",
       "1                        0.000                        0.000           0.000   \n",
       "2                        0.000                        0.000           0.000   \n",
       "3                        0.000                        0.000           1.000   \n",
       "4                        0.000                        0.000           1.000   \n",
       "\n",
       "   cat__x0_ Other  cat__x0_ White  cat__x1_ ?  cat__x1_ Federal-gov  \\\n",
       "0           0.000           1.000       0.000                 0.000   \n",
       "1           0.000           1.000       0.000                 0.000   \n",
       "2           0.000           1.000       0.000                 0.000   \n",
       "3           0.000           0.000       0.000                 0.000   \n",
       "4           0.000           0.000       0.000                 0.000   \n",
       "\n",
       "   cat__x1_ Local-gov  cat__x1_ Never-worked  cat__x1_ Private  \\\n",
       "0               0.000                  0.000             0.000   \n",
       "1               0.000                  0.000             0.000   \n",
       "2               0.000                  0.000             1.000   \n",
       "3               0.000                  0.000             1.000   \n",
       "4               0.000                  0.000             1.000   \n",
       "\n",
       "   cat__x1_ Self-emp-inc  cat__x1_ Self-emp-not-inc  cat__x1_ State-gov  \\\n",
       "0                  0.000                      0.000               1.000   \n",
       "1                  0.000                      1.000               0.000   \n",
       "2                  0.000                      0.000               0.000   \n",
       "3                  0.000                      0.000               0.000   \n",
       "4                  0.000                      0.000               0.000   \n",
       "\n",
       "   cat__x1_ Without-pay  cat__x2_ 10th  cat__x2_ 11th  cat__x2_ 12th  \\\n",
       "0                 0.000          0.000          0.000          0.000   \n",
       "1                 0.000          0.000          0.000          0.000   \n",
       "2                 0.000          0.000          0.000          0.000   \n",
       "3                 0.000          0.000          1.000          0.000   \n",
       "4                 0.000          0.000          0.000          0.000   \n",
       "\n",
       "   cat__x2_ 1st-4th  cat__x2_ 5th-6th  cat__x2_ 7th-8th  cat__x2_ 9th  \\\n",
       "0             0.000             0.000             0.000         0.000   \n",
       "1             0.000             0.000             0.000         0.000   \n",
       "2             0.000             0.000             0.000         0.000   \n",
       "3             0.000             0.000             0.000         0.000   \n",
       "4             0.000             0.000             0.000         0.000   \n",
       "\n",
       "   cat__x2_ Assoc-acdm  cat__x2_ Assoc-voc  cat__x2_ Bachelors  \\\n",
       "0                0.000               0.000               1.000   \n",
       "1                0.000               0.000               1.000   \n",
       "2                0.000               0.000               0.000   \n",
       "3                0.000               0.000               0.000   \n",
       "4                0.000               0.000               1.000   \n",
       "\n",
       "   cat__x2_ Doctorate  cat__x2_ HS-grad  cat__x2_ Masters  cat__x2_ Preschool  \\\n",
       "0               0.000             0.000             0.000               0.000   \n",
       "1               0.000             0.000             0.000               0.000   \n",
       "2               0.000             1.000             0.000               0.000   \n",
       "3               0.000             0.000             0.000               0.000   \n",
       "4               0.000             0.000             0.000               0.000   \n",
       "\n",
       "   cat__x2_ Prof-school  cat__x2_ Some-college  cat__x3_ Divorced  \\\n",
       "0                 0.000                  0.000              0.000   \n",
       "1                 0.000                  0.000              0.000   \n",
       "2                 0.000                  0.000              1.000   \n",
       "3                 0.000                  0.000              0.000   \n",
       "4                 0.000                  0.000              0.000   \n",
       "\n",
       "   cat__x3_ Married-AF-spouse  cat__x3_ Married-civ-spouse  \\\n",
       "0                       0.000                        0.000   \n",
       "1                       0.000                        1.000   \n",
       "2                       0.000                        0.000   \n",
       "3                       0.000                        1.000   \n",
       "4                       0.000                        1.000   \n",
       "\n",
       "   cat__x3_ Married-spouse-absent  cat__x3_ Never-married  cat__x3_ Separated  \\\n",
       "0                           0.000                   1.000               0.000   \n",
       "1                           0.000                   0.000               0.000   \n",
       "2                           0.000                   0.000               0.000   \n",
       "3                           0.000                   0.000               0.000   \n",
       "4                           0.000                   0.000               0.000   \n",
       "\n",
       "   cat__x3_ Widowed  cat__x4_ ?  cat__x4_ Adm-clerical  cat__x4_ Armed-Forces  \\\n",
       "0             0.000       0.000                  1.000                  0.000   \n",
       "1             0.000       0.000                  0.000                  0.000   \n",
       "2             0.000       0.000                  0.000                  0.000   \n",
       "3             0.000       0.000                  0.000                  0.000   \n",
       "4             0.000       0.000                  0.000                  0.000   \n",
       "\n",
       "   cat__x4_ Craft-repair  cat__x4_ Exec-managerial  cat__x4_ Farming-fishing  \\\n",
       "0                  0.000                     0.000                     0.000   \n",
       "1                  0.000                     1.000                     0.000   \n",
       "2                  0.000                     0.000                     0.000   \n",
       "3                  0.000                     0.000                     0.000   \n",
       "4                  0.000                     0.000                     0.000   \n",
       "\n",
       "   cat__x4_ Handlers-cleaners  cat__x4_ Machine-op-inspct  \\\n",
       "0                       0.000                       0.000   \n",
       "1                       0.000                       0.000   \n",
       "2                       1.000                       0.000   \n",
       "3                       1.000                       0.000   \n",
       "4                       0.000                       0.000   \n",
       "\n",
       "   cat__x4_ Other-service  cat__x4_ Priv-house-serv  cat__x4_ Prof-specialty  \\\n",
       "0                   0.000                     0.000                    0.000   \n",
       "1                   0.000                     0.000                    0.000   \n",
       "2                   0.000                     0.000                    0.000   \n",
       "3                   0.000                     0.000                    0.000   \n",
       "4                   0.000                     0.000                    1.000   \n",
       "\n",
       "   cat__x4_ Protective-serv  cat__x4_ Sales  cat__x4_ Tech-support  \\\n",
       "0                     0.000           0.000                  0.000   \n",
       "1                     0.000           0.000                  0.000   \n",
       "2                     0.000           0.000                  0.000   \n",
       "3                     0.000           0.000                  0.000   \n",
       "4                     0.000           0.000                  0.000   \n",
       "\n",
       "   cat__x4_ Transport-moving  cat__x5_ Husband  cat__x5_ Not-in-family  \\\n",
       "0                      0.000             0.000                   1.000   \n",
       "1                      0.000             1.000                   0.000   \n",
       "2                      0.000             0.000                   1.000   \n",
       "3                      0.000             1.000                   0.000   \n",
       "4                      0.000             0.000                   0.000   \n",
       "\n",
       "   cat__x5_ Other-relative  cat__x5_ Own-child  cat__x5_ Unmarried  \\\n",
       "0                    0.000               0.000               0.000   \n",
       "1                    0.000               0.000               0.000   \n",
       "2                    0.000               0.000               0.000   \n",
       "3                    0.000               0.000               0.000   \n",
       "4                    0.000               0.000               0.000   \n",
       "\n",
       "   cat__x5_ Wife   Sex    Age     fnlwgt  Education-Num  Capital Gain  \\\n",
       "0          0.000 1.000 39.000  77516.000         13.000      2174.000   \n",
       "1          0.000 1.000 50.000  83311.000         13.000         0.000   \n",
       "2          0.000 1.000 38.000 215646.000          9.000         0.000   \n",
       "3          0.000 1.000 53.000 234721.000          7.000         0.000   \n",
       "4          1.000 0.000 28.000 338409.000         13.000         0.000   \n",
       "\n",
       "   Capital Loss  Hours per week  \n",
       "0         0.000          40.000  \n",
       "1         0.000          13.000  \n",
       "2         0.000          40.000  \n",
       "3         0.000          40.000  \n",
       "4         0.000          40.000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_select = [\n",
    "                 \"Sex\",  #9 \n",
    "                 \"Race\",  #8\n",
    "                 \"Workclass\",  #1\n",
    "                 \"Age\", #0\n",
    "                 \"fnlwgt\",  #2\n",
    "                 \"Education\",  #3\n",
    "                 \"Education-Num\",  #4\n",
    "                 \"Marital Status\", #5\n",
    "                 \"Occupation\",  #6\n",
    "                 \"Relationship\",  #7\n",
    "                 \"Capital Gain\",  #10\n",
    "                 \"Capital Loss\", #11\n",
    "                 \"Hours per week\",  #12\n",
    "                 #\"Country\", #13 \n",
    "                 'capital_gain'\n",
    "                  ]\n",
    "\n",
    "adult_data = adult_data[features_select]\n",
    "\n",
    "categorical_features = ['Race', 'Workclass', 'Education', \"Marital Status\", \"Occupation\", \"Relationship\"]#[1, 2, 7]\n",
    "ordinal_features = ['Sex', 'capital_gain']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(adult_data)\n",
    "\n",
    "adult_data = transformer.transform(adult_data)\n",
    "adult_data = pd.DataFrame(adult_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    adult_data[ordinal_feature] = OrdinalEncoder().fit_transform(adult_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "adult_data = adult_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_adult = adult_data.drop(['capital_gain'], axis = 1)\n",
    "\n",
    "y_data_adult = adult_data['capital_gain']\n",
    "\n",
    "print(X_data_adult.shape)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:03.884383Z",
     "iopub.status.busy": "2022-01-04T11:48:03.884158Z",
     "iopub.status.idle": "2022-01-04T11:48:08.767627Z",
     "shell.execute_reply": "2022-01-04T11:48:08.766504Z",
     "shell.execute_reply.started": "2022-01-04T11:48:03.884353Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__x2_ Bachelors</th>\n",
       "      <th>cat__x3_ Married-civ-spouse</th>\n",
       "      <th>cat__x3_ Never-married</th>\n",
       "      <th>cat__x4_ Exec-managerial</th>\n",
       "      <th>cat__x4_ Prof-specialty</th>\n",
       "      <th>cat__x5_ Husband</th>\n",
       "      <th>cat__x5_ Not-in-family</th>\n",
       "      <th>cat__x5_ Own-child</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>77516.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>2174.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>83311.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>215646.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>234721.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>338409.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat__x2_ Bachelors  cat__x3_ Married-civ-spouse  cat__x3_ Never-married  \\\n",
       "0               1.000                        0.000                   1.000   \n",
       "1               1.000                        1.000                   0.000   \n",
       "2               0.000                        0.000                   0.000   \n",
       "3               0.000                        1.000                   0.000   \n",
       "4               1.000                        1.000                   0.000   \n",
       "\n",
       "   cat__x4_ Exec-managerial  cat__x4_ Prof-specialty  cat__x5_ Husband  \\\n",
       "0                     0.000                    0.000             0.000   \n",
       "1                     1.000                    0.000             1.000   \n",
       "2                     0.000                    0.000             0.000   \n",
       "3                     0.000                    0.000             1.000   \n",
       "4                     0.000                    1.000             0.000   \n",
       "\n",
       "   cat__x5_ Not-in-family  cat__x5_ Own-child   Sex    Age     fnlwgt  \\\n",
       "0                   1.000               0.000 1.000 39.000  77516.000   \n",
       "1                   0.000               0.000 1.000 50.000  83311.000   \n",
       "2                   1.000               0.000 1.000 38.000 215646.000   \n",
       "3                   0.000               0.000 1.000 53.000 234721.000   \n",
       "4                   0.000               0.000 0.000 28.000 338409.000   \n",
       "\n",
       "   Education-Num  Capital Gain  Capital Loss  Hours per week  \n",
       "0         13.000      2174.000         0.000          40.000  \n",
       "1         13.000         0.000         0.000          13.000  \n",
       "2          9.000         0.000         0.000          40.000  \n",
       "3          7.000         0.000         0.000          40.000  \n",
       "4         13.000         0.000         0.000          40.000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if X_data_adult.shape[1] > number_of_variables:\n",
    "    #X_data_adult = X_data_adult.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_adult = ExtraTreesClassifier(n_estimators=100,\n",
    "                                      random_state=RANDOM_SEED)\n",
    "    clf_adult = clf_adult.fit(X_data_adult, y_data_adult)\n",
    "\n",
    "    selector_adult = SelectFromModel(clf_adult, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_adult.get_support()   \n",
    "    X_data_adult = X_data_adult.loc[:,feature_idx]\n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_adult.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_adult[column_name] = np.zeros(X_data_adult.shape[0])\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:08.778991Z",
     "iopub.status.busy": "2022-01-04T11:48:08.778764Z",
     "iopub.status.idle": "2022-01-04T11:48:08.809324Z",
     "shell.execute_reply": "2022-01-04T11:48:08.808341Z",
     "shell.execute_reply.started": "2022-01-04T11:48:08.778961Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__x2_ Bachelors</th>\n",
       "      <th>cat__x3_ Married-civ-spouse</th>\n",
       "      <th>cat__x3_ Never-married</th>\n",
       "      <th>cat__x4_ Exec-managerial</th>\n",
       "      <th>cat__x4_ Prof-specialty</th>\n",
       "      <th>cat__x5_ Husband</th>\n",
       "      <th>cat__x5_ Not-in-family</th>\n",
       "      <th>cat__x5_ Own-child</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat__x2_ Bachelors  cat__x3_ Married-civ-spouse  cat__x3_ Never-married  \\\n",
       "0               1.000                        0.000                   1.000   \n",
       "1               1.000                        1.000                   0.000   \n",
       "2               0.000                        0.000                   0.000   \n",
       "3               0.000                        1.000                   0.000   \n",
       "4               1.000                        1.000                   0.000   \n",
       "\n",
       "   cat__x4_ Exec-managerial  cat__x4_ Prof-specialty  cat__x5_ Husband  \\\n",
       "0                     0.000                    0.000             0.000   \n",
       "1                     1.000                    0.000             1.000   \n",
       "2                     0.000                    0.000             0.000   \n",
       "3                     0.000                    0.000             1.000   \n",
       "4                     0.000                    1.000             0.000   \n",
       "\n",
       "   cat__x5_ Not-in-family  cat__x5_ Own-child   Sex   Age  fnlwgt  \\\n",
       "0                   1.000               0.000 1.000 0.301   0.044   \n",
       "1                   0.000               0.000 1.000 0.452   0.048   \n",
       "2                   1.000               0.000 1.000 0.288   0.138   \n",
       "3                   0.000               0.000 1.000 0.493   0.151   \n",
       "4                   0.000               0.000 0.000 0.151   0.221   \n",
       "\n",
       "   Education-Num  Capital Gain  Capital Loss  Hours per week  \n",
       "0          0.800         0.022         0.000           0.398  \n",
       "1          0.800         0.000         0.000           0.122  \n",
       "2          0.533         0.000         0.000           0.398  \n",
       "3          0.400         0.000         0.000           0.398  \n",
       "4          0.800         0.000         0.000           0.398  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_adult:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_adult[column_name].values.reshape(-1, 1))\n",
    "    X_data_adult[column_name] = scaler.transform(X_data_adult[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:08.810772Z",
     "iopub.status.busy": "2022-01-04T11:48:08.810517Z",
     "iopub.status.idle": "2022-01-04T11:48:08.817634Z",
     "shell.execute_reply": "2022-01-04T11:48:08.817035Z",
     "shell.execute_reply.started": "2022-01-04T11:48:08.810747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000\n",
       "1       0.000\n",
       "2       0.000\n",
       "3       0.000\n",
       "4       0.000\n",
       "         ... \n",
       "32556   0.000\n",
       "32557   1.000\n",
       "32558   0.000\n",
       "32559   0.000\n",
       "32560   1.000\n",
       "Name: capital_gain, Length: 32561, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:08.818962Z",
     "iopub.status.busy": "2022-01-04T11:48:08.818599Z",
     "iopub.status.idle": "2022-01-04T11:48:08.838770Z",
     "shell.execute_reply": "2022-01-04T11:48:08.838134Z",
     "shell.execute_reply.started": "2022-01-04T11:48:08.818939Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20838, 15) (20838,)\n",
      "(5210, 15) (5210,)\n",
      "(6513, 15) (6513,)\n"
     ]
    }
   ],
   "source": [
    "X_train_adult_with_valid, X_test_adult, y_train_adult_with_valid, y_test_adult = train_test_split(X_data_adult, y_data_adult, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_adult, X_valid_adult, y_train_adult, y_valid_adult = train_test_split(X_train_adult_with_valid, y_train_adult_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_adult.shape, y_train_adult.shape)\n",
    "print(X_valid_adult.shape, y_valid_adult.shape)\n",
    "print(X_test_adult.shape, y_test_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:08.839956Z",
     "iopub.status.busy": "2022-01-04T11:48:08.839761Z",
     "iopub.status.idle": "2022-01-04T11:48:08.846298Z",
     "shell.execute_reply": "2022-01-04T11:48:08.845707Z",
     "shell.execute_reply.started": "2022-01-04T11:48:08.839932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Ratio:  0.24301756406564928\n"
     ]
    }
   ],
   "source": [
    "true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:08.847423Z",
     "iopub.status.busy": "2022-01-04T11:48:08.847157Z",
     "iopub.status.idle": "2022-01-04T11:48:08.993935Z",
     "shell.execute_reply": "2022-01-04T11:48:08.993087Z",
     "shell.execute_reply.started": "2022-01-04T11:48:08.847398Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Ratio:  0.5\n"
     ]
    }
   ],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_adult, y_train_adult = oversample.fit_resample(X_train_adult, y_train_adult)\n",
    "\n",
    "    true_labels = len(y_train_adult[y_train_adult >= 0.5 ]) \n",
    "    false_labels = len(y_train_adult[y_train_adult < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T11:48:08.996166Z",
     "iopub.status.busy": "2022-01-04T11:48:08.995467Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_accuracy\n",
      "\ttraining         \t (min:    0.767, max:    0.823, cur:    0.823)\n",
      "\tvalidation       \t (min:    0.761, max:    0.817, cur:    0.800)\n",
      "Loss\n",
      "\ttraining         \t (min:    0.378, max:    0.478, cur:    0.378)\n",
      "\tvalidation       \t (min:    0.369, max:    0.456, cur:    0.390)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_adult = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_adult.fit(X_train_adult,\n",
    "                                      y_train_adult, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_adult, y_valid_adult),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_adult_parameters = shaped_network_parameters_to_array(test_network_adult.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_adult_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_adult_dt_inet = model.predict(network_parameters)[0]    \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size_list = [1_000, 10_000, 100_000, 1_000_000, 'TRAIN_DATA']\n",
    "    \n",
    "results_adult_list = []\n",
    "dt_distilled_adult_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_adult.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_adult, dt_distilled_adult = evaluate_interpretation_net_prediction_single_sample(test_network_adult_parameters, \n",
    "                                                                           test_network_adult_dt_inet,\n",
    "                                                                           X_test_adult.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_adult['inet_scores']['runtime'] = inet_runtime\n",
    "    results_adult_list.append(results_adult)\n",
    "    dt_distilled_adult_list.append(dt_distilled_adult)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_adult['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy',  np.round(results_adult['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_adult['dt_scores']['binary_crossentropy'], 3), np.round(results_adult['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_adult['dt_scores']['accuracy_data_random'], 3), np.round(results_adult['dt_scores']['accuracy'], 3), np.round(results_adult['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_adult['dt_scores']['f1_score_data_random'], 3), np.round(results_adult['dt_scores']['f1_score'], 3), np.round(results_adult['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['dt_scores']['runtime'], 3), np.round(results_adult['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n",
    "        \n",
    "adult_evaluation_result_dict = None\n",
    "for some_dict in results_adult_list:\n",
    "    if adult_evaluation_result_dict == None:\n",
    "        adult_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        adult_evaluation_result_dict = mergeDict(adult_evaluation_result_dict, some_dict)\n",
    "\n",
    "#adult_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_adult_list],\n",
    "                      np.round(results_adult['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_adult, \n",
    " distance_to_initialization_aggregate_adult, \n",
    " distance_to_sample_average_adult, \n",
    " distance_to_sample_min_adult,\n",
    " max_distance_to_neuron_average_adult,\n",
    " max_distance_to_neuron_min_adult) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_adult_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3)],           \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_adult_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_adult_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_adult, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_adult.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"./real_world_datasets/Titanic/train.csv\")\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.drop([\n",
    "                                    'Cabin', \n",
    "                                    'Ticket', \n",
    "                                    'Name', \n",
    "                                    'PassengerId'\n",
    "                                ], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace = True)\n",
    "titanic_data['Fare'].fillna(titanic_data['Fare'].mean(), inplace = True)\n",
    "    \n",
    "titanic_data['Embarked'].fillna('S', inplace = True)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                    'Sex',    \n",
    "                    'Embarked',\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'SibSp',    \n",
    "                    'Parch',\n",
    "                    'Fare',    \n",
    "                    'Survived',    \n",
    "                  ]\n",
    "\n",
    "titanic_data = titanic_data[features_select]\n",
    "\n",
    "categorical_features = ['Embarked']#[1, 2, 7]\n",
    "ordinal_features = ['Sex']\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(titanic_data)\n",
    "\n",
    "titanic_data = transformer.transform(titanic_data)\n",
    "titanic_data = pd.DataFrame(titanic_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    titanic_data[ordinal_feature] = OrdinalEncoder().fit_transform(titanic_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "titanic_data = titanic_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_titanic = titanic_data.drop(['Survived'], axis = 1)\n",
    "y_data_titanic = titanic_data['Survived']\n",
    "\n",
    "print(X_data_titanic.shape)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    survival\tSurvival\t0 = No, 1 = Yes\n",
    "    pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex\tSex\t\n",
    "    Age\tAge in years\t\n",
    "    sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "    parch\t# of parents / children aboard the Titanic\t\n",
    "    ticket\tTicket number\t\n",
    "    fare\tPassenger fare\t\n",
    "    cabin\tCabin number\t\n",
    "    embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_titanic.shape[1] > number_of_variables:\n",
    "    #X_data_titanic = X_data_titanic.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_titanic = ExtraTreesClassifier(n_estimators=100,\n",
    "                                      random_state=RANDOM_SEED)\n",
    "    clf_titanic = clf_titanic.fit(X_data_titanic, y_data_titanic)\n",
    "\n",
    "    selector_titanic = SelectFromModel(clf_titanic, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_titanic.get_support()   \n",
    "    X_data_titanic = X_data_titanic.loc[:,feature_idx]    \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_titanic.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_titanic[column_name] = np.zeros(X_data_titanic.shape[0])\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_titanic:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_titanic[column_name].values.reshape(-1, 1))\n",
    "    X_data_titanic[column_name] = scaler.transform(X_data_titanic[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_titanic_with_valid, X_test_titanic, y_train_titanic_with_valid, y_test_titanic = train_test_split(X_data_titanic, y_data_titanic, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_titanic, X_valid_titanic, y_train_titanic, y_valid_titanic = train_test_split(X_train_titanic_with_valid, y_train_titanic_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_titanic.shape, y_train_titanic.shape)\n",
    "print(X_valid_titanic.shape, y_valid_titanic.shape)\n",
    "print(X_test_titanic.shape, y_test_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_titanic, y_train_titanic = oversample.fit_resample(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    true_labels = len(y_train_titanic[y_train_titanic >= 0.5 ]) \n",
    "    false_labels = len(y_train_titanic[y_train_titanic < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_titanic = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_titanic.fit(X_train_titanic,\n",
    "                                          y_train_titanic, \n",
    "                                          epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                          batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                          callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                          validation_data=(X_valid_titanic, y_valid_titanic),\n",
    "                                          verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_titanic_parameters = shaped_network_parameters_to_array(test_network_titanic.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_titanic_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_titanic_dt_inet = model.predict(network_parameters)[0]    \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_titanic_list = []\n",
    "dt_distilled_titanic_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_titanic.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_titanic, dt_distilled_titanic = evaluate_interpretation_net_prediction_single_sample(test_network_titanic_parameters, \n",
    "                                                                           test_network_titanic_dt_inet,\n",
    "                                                                           X_test_titanic.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_titanic['inet_scores']['runtime'] = inet_runtime\n",
    "    results_titanic_list.append(results_titanic)\n",
    "    dt_distilled_titanic_list.append(dt_distilled_titanic)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_titanic['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_titanic['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_titanic['dt_scores']['binary_crossentropy'], 3), np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_titanic['dt_scores']['accuracy_data_random'], 3), np.round(results_titanic['dt_scores']['accuracy'], 3), np.round(results_titanic['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_titanic['dt_scores']['f1_score_data_random'], 3), np.round(results_titanic['dt_scores']['f1_score'], 3), np.round(results_titanic['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime',  np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['dt_scores']['runtime'], 3), np.round(results_titanic['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "        \n",
    "titanic_evaluation_result_dict = None\n",
    "for some_dict in results_titanic_list:\n",
    "    if titanic_evaluation_result_dict == None:\n",
    "        titanic_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        titanic_evaluation_result_dict = mergeDict(titanic_evaluation_result_dict, some_dict)\n",
    "\n",
    "#titanic_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_titanic_list],\n",
    "                      np.round(results_titanic['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_titanic, \n",
    " distance_to_initialization_aggregate_titanic, \n",
    " distance_to_sample_average_titanic, \n",
    " distance_to_sample_min_titanic,\n",
    " max_distance_to_neuron_average_titanic,\n",
    " max_distance_to_neuron_min_titanic) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_titanic_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data', 'Titanic Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3), np.round(z_score_aggregate_titanic, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3), np.round(distance_to_initialization_aggregate_titanic, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3), np.round(distance_to_sample_average_titanic, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3), np.round(distance_to_sample_min_titanic, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3), np.round(max_distance_to_neuron_average_titanic, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3), np.round(max_distance_to_neuron_min_titanic, 3)],           \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_titanic_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_titanic_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_titanic, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_titanic.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absenteeism at Work Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data = pd.read_csv('real_world_datasets/Absenteeism/absenteeism.csv', delimiter=';')\n",
    "\n",
    "absenteeism_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "absenteeism_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_select = [\n",
    "                           'Disciplinary failure', #CATEGORICAL\n",
    "                           'Social drinker', #CATEGORICAL\n",
    "                           'Social smoker', #CATEGORICAL\n",
    "                           'Transportation expense', \n",
    "                           'Distance from Residence to Work',\n",
    "                           'Service time', \n",
    "                           'Age', \n",
    "                           'Work load Average/day ', \n",
    "                           'Hit target',\n",
    "                           'Education', \n",
    "                           'Son', \n",
    "                           'Pet', \n",
    "                           'Weight', \n",
    "                           'Height', \n",
    "                           'Body mass index', \n",
    "                           'Absenteeism time in hours'\n",
    "                        ]\n",
    "\n",
    "absenteeism_data = absenteeism_data[features_select]\n",
    "\n",
    "categorical_features = []#[1, 2, 7]\n",
    "ordinal_features = []\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), categorical_features)], remainder='passthrough', sparse_threshold=0)\n",
    "transformer.fit(absenteeism_data)\n",
    "\n",
    "absenteeism_data = transformer.transform(absenteeism_data)\n",
    "absenteeism_data = pd.DataFrame(absenteeism_data, columns=transformer.get_feature_names())\n",
    "\n",
    "for ordinal_feature in ordinal_features:\n",
    "    absenteeism_data[ordinal_feature] = OrdinalEncoder().fit_transform(absenteeism_data[ordinal_feature].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "absenteeism_data = absenteeism_data.astype(np.float64)\n",
    "\n",
    "    \n",
    "X_data_absenteeism = absenteeism_data.drop(['Absenteeism time in hours'], axis = 1)\n",
    "y_data_absenteeism = ((absenteeism_data['Absenteeism time in hours'] > 4) * 1) #absenteeism_data['Absenteeism time in hours']\n",
    "\n",
    "print(X_data_absenteeism.shape)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Month of absence\n",
    "    4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "    5. Seasons (summer (1), autumn (2), winter (3), spring (4))\n",
    "    6. Transportation expense\n",
    "    7. Distance from Residence to Work (kilometers)\n",
    "    8. Service time\n",
    "    9. Age\n",
    "    10. Work load Average/day\n",
    "    11. Hit target\n",
    "    12. Disciplinary failure (yes=1; no=0)\n",
    "    13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "    14. Son (number of children)\n",
    "    15. Social drinker (yes=1; no=0)\n",
    "    16. Social smoker (yes=1; no=0)\n",
    "    17. Pet (number of pet)\n",
    "    18. Weight\n",
    "    19. Height\n",
    "    20. Body mass index\n",
    "    21. Absenteeism time in hours (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X_data_absenteeism.shape[1] > number_of_variables:\n",
    "    #X_data_absenteeism = X_data_absenteeism.sample(n=number_of_variables,axis='columns')\n",
    "    \n",
    "    clf_absenteeism = ExtraTreesClassifier(n_estimators=100,\n",
    "                                          random_state=RANDOM_SEED)\n",
    "    clf_absenteeism = clf_absenteeism.fit(X_data_absenteeism, y_data_absenteeism)\n",
    "\n",
    "    selector_absenteeism = SelectFromModel(clf_absenteeism, \n",
    "                                     prefit=True,\n",
    "                                     threshold=-np.inf,\n",
    "                                     max_features=number_of_variables)\n",
    "    feature_idx = selector_absenteeism.get_support()   \n",
    "    X_data_absenteeism = X_data_absenteeism.loc[:,feature_idx]        \n",
    "else:\n",
    "    for i in range(number_of_variables-X_data_absenteeism.shape[1]):\n",
    "        column_name = 'zero_dummy_' + str(i+1)\n",
    "        X_data_absenteeism[column_name] = np.zeros(X_data_absenteeism.shape[0])\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_list = []\n",
    "for column_name in X_data_absenteeism:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_data_absenteeism[column_name].values.reshape(-1, 1))\n",
    "    X_data_absenteeism[column_name] = scaler.transform(X_data_absenteeism[column_name].values.reshape(-1, 1)).ravel()\n",
    "    normalizer_list.append(scaler)\n",
    "X_data_absenteeism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data_absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_absenteeism_with_valid, X_test_absenteeism, y_train_absenteeism_with_valid, y_test_absenteeism = train_test_split(X_data_absenteeism, y_data_absenteeism, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_train_absenteeism, X_valid_absenteeism, y_train_absenteeism, y_valid_absenteeism = train_test_split(X_train_absenteeism_with_valid, y_train_absenteeism_with_valid, train_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train_absenteeism.shape, y_train_absenteeism.shape)\n",
    "print(X_valid_absenteeism.shape, y_valid_absenteeism.shape)\n",
    "print(X_test_absenteeism.shape, y_test_absenteeism.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "true_ratio = true_labels/(true_labels+false_labels)\n",
    "\n",
    "print('True Ratio: ', str(true_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if true_ratio <= 0.3 or true_ratio >= 0.7:\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM_SEED)\n",
    "\n",
    "    X_train_absenteeism, y_train_absenteeism = oversample.fit_resample(X_train_absenteeism, y_train_absenteeism)\n",
    "\n",
    "    true_labels = len(y_train_absenteeism[y_train_absenteeism >= 0.5 ]) \n",
    "    false_labels = len(y_train_absenteeism[y_train_absenteeism < 0.5 ]) \n",
    "\n",
    "    print('True Ratio: ', str(true_labels/(true_labels+false_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    if int(tf.__version__[0]) >= 2:\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "    else:\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    test_network_absenteeism = generate_lambda_net_from_config(config, seed=RANDOM_SEED)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=50, \n",
    "                                                      min_delta=0.001, \n",
    "                                                      verbose=0, \n",
    "                                                      mode='min', \n",
    "                                                      restore_best_weights=False)\n",
    "\n",
    "    model_history = test_network_absenteeism.fit(X_train_absenteeism,\n",
    "                                      y_train_absenteeism, \n",
    "                                      epochs=config['lambda_net']['epochs_lambda'], \n",
    "                                      batch_size=config['lambda_net']['batch_lambda'], \n",
    "                                      callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "                                      validation_data=(X_valid_absenteeism, y_valid_absenteeism),\n",
    "                                      verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_network_absenteeism_parameters = shaped_network_parameters_to_array(test_network_absenteeism.get_weights(), config)\n",
    "\n",
    "start_inet = time.time() \n",
    "\n",
    "network_parameters = np.array([test_network_absenteeism_parameters])\n",
    "if config['i_net']['data_reshape_version'] == 1 or config['i_net']['data_reshape_version'] == 2:\n",
    "    network_parameters, network_parameters_flat = restructure_data_cnn_lstm(network_parameters, config, subsequences=None)\n",
    "elif config['i_net']['data_reshape_version'] == 3: #autoencoder\n",
    "    network_parameters, network_parameters_flat, _ = autoencode_data([network_parameters], config, encoder_model)    \n",
    "test_network_absenteeism_dt_inet = model.predict(network_parameters)[0]  \n",
    "\n",
    "end_inet = time.time()     \n",
    "inet_runtime = (end_inet - start_inet)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_absenteeism_list = []\n",
    "dt_distilled_absenteeism_list = []\n",
    "for dataset_size in dataset_size_list:\n",
    "    \n",
    "    if dataset_size == 'TRAIN_DATA': \n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config,\n",
    "                                                                           train_data=X_train_absenteeism.values)\n",
    "    \n",
    "    else:\n",
    "        config_test = deepcopy(config)\n",
    "        config_test['evaluation']['per_network_optimization_dataset_size'] = dataset_size\n",
    "\n",
    "        results_absenteeism, dt_distilled_absenteeism = evaluate_interpretation_net_prediction_single_sample(test_network_absenteeism_parameters, \n",
    "                                                                           test_network_absenteeism_dt_inet,\n",
    "                                                                           X_test_absenteeism.values, \n",
    "                                                                           #y_test_lambda,\n",
    "                                                                           config_test)\n",
    "\n",
    "        \n",
    "    results_absenteeism['inet_scores']['runtime'] = inet_runtime\n",
    "    results_absenteeism_list.append(results_absenteeism)\n",
    "    dt_distilled_absenteeism_list.append(dt_distilled_absenteeism)\n",
    "    \n",
    "    print('Dataset Size:\\t\\t', dataset_size)\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = ['Metric', 'Distilled DT (Train/Random Data)', 'Distilled DT (Test Data)', 'I-Net DT (Test Data)']\n",
    "    tab.add_rows(\n",
    "        [\n",
    "            ['Soft Binary Crossentropy', np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['soft_binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['soft_binary_crossentropy'], 3)],\n",
    "            ['Binary Crossentropy', np.round(results_absenteeism['dt_scores']['binary_crossentropy_data_random'], 3), np.round(results_absenteeism['dt_scores']['binary_crossentropy'], 3), np.round(results_absenteeism['inet_scores']['binary_crossentropy'], 3)],\n",
    "            ['Accuracy', np.round(results_absenteeism['dt_scores']['accuracy_data_random'], 3), np.round(results_absenteeism['dt_scores']['accuracy'], 3), np.round(results_absenteeism['inet_scores']['accuracy'], 3)],\n",
    "            ['F1 Score', np.round(results_absenteeism['dt_scores']['f1_score_data_random'], 3), np.round(results_absenteeism['dt_scores']['f1_score'], 3), np.round(results_absenteeism['inet_scores']['f1_score'], 3)],\n",
    "            ['Runtime', np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['dt_scores']['runtime'], 3), np.round(results_absenteeism['inet_scores']['runtime'], 3)],\n",
    "        ]    \n",
    "    )\n",
    "    print(tab)\n",
    "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')        \n",
    "\n",
    "    \n",
    "absenteeism_evaluation_result_dict = None\n",
    "for some_dict in results_absenteeism_list:\n",
    "    if absenteeism_evaluation_result_dict == None:\n",
    "        absenteeism_evaluation_result_dict = some_dict\n",
    "    else:\n",
    "        absenteeism_evaluation_result_dict = mergeDict(absenteeism_evaluation_result_dict, some_dict)\n",
    "\n",
    "#absenteeism_evaluation_result_dict['dataset_size'] = dataset_size_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = flatten_list(['Metric', [['Dist. (Random) ' + str(size), 'Dist. ' + str(size)] for size in dataset_size_list], 'I-Net'])\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft Binary Crossentropy', \n",
    "                      [[np.round(result_dict['dt_scores']['soft_binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['soft_binary_crossentropy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['soft_binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Binary Crossentropy',  \n",
    "                      [[np.round(result_dict['dt_scores']['binary_crossentropy_data_random'], 3), np.round(result_dict['dt_scores']['binary_crossentropy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['binary_crossentropy'], 3)]),\n",
    "        flatten_list(['Accuracy', \n",
    "                      [[np.round(result_dict['dt_scores']['accuracy_data_random'], 3), np.round(result_dict['dt_scores']['accuracy'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['accuracy'], 3)]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      [[np.round(result_dict['dt_scores']['f1_score_data_random'], 3), np.round(result_dict['dt_scores']['f1_score'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['f1_score'], 3)]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      [[np.round(result_dict['dt_scores']['runtime'], 3), np.round(result_dict['dt_scores']['runtime'], 3)] for result_dict in results_absenteeism_list],\n",
    "                      np.round(results_titanic['inet_scores']['runtime'], 3)])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(z_score_aggregate_absenteeism, \n",
    " distance_to_initialization_aggregate_absenteeism, \n",
    " distance_to_sample_average_absenteeism, \n",
    " distance_to_sample_min_absenteeism,\n",
    " max_distance_to_neuron_average_absenteeism,\n",
    " max_distance_to_neuron_min_absenteeism) = calculate_network_distance(mean=mean_train, \n",
    "                                                       std=std_train, \n",
    "                                                       network_parameters=test_network_absenteeism_parameters, \n",
    "                                                       lambda_net_parameters_train=lambda_net_dataset_train.network_parameters_array, \n",
    "                                                       config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = PrettyTable()\n",
    "tab.field_names = ['Measure', 'Train Data', 'Valid Data', 'Test Data', 'Adult Data', 'Titanic Data', 'Absenteeism Data']\n",
    "tab.add_rows(\n",
    "    [\n",
    "        ['Average Z-Score (Sample to Train Data)', np.round(z_score_average_train, 3), np.round(z_score_average_valid, 3), np.round(z_score_average_test, 3), np.round(z_score_aggregate_adult, 3), np.round(z_score_aggregate_titanic, 3), np.round(z_score_aggregate_absenteeism, 3)],\n",
    "        ['Average Distance to Initialization', np.round(distance_to_initialization_average_train, 3), np.round(distance_to_initialization_average_valid, 3), np.round(distance_to_initialization_average_test, 3), np.round(distance_to_initialization_aggregate_adult, 3), np.round(distance_to_initialization_aggregate_titanic, 3), np.round(distance_to_initialization_aggregate_absenteeism, 3)],\n",
    "        ['Average Mean Distance to Train Data', np.round(distance_to_sample_average_average_train, 3), np.round(distance_to_sample_average_average_valid, 3), np.round(distance_to_sample_average_average_test, 3), np.round(distance_to_sample_average_adult, 3), np.round(distance_to_sample_average_titanic, 3), np.round(distance_to_sample_average_absenteeism, 3)],\n",
    "        ['Average Distance to closest Train Data Sample', np.round(distance_to_sample_min_average_train, 3), np.round(distance_to_sample_min_average_valid, 3), np.round(distance_to_sample_min_average_test, 3), np.round(distance_to_sample_min_adult, 3), np.round(distance_to_sample_min_titanic, 3), np.round(distance_to_sample_min_absenteeism, 3)],\n",
    "        ['Average Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_average_average_train, 3), np.round(max_distance_to_neuron_average_average_valid, 3), np.round(max_distance_to_neuron_average_average_test, 3), np.round(max_distance_to_neuron_average_adult, 3), np.round(max_distance_to_neuron_average_titanic, 3), np.round(max_distance_to_neuron_average_absenteeism, 3)],\n",
    "        ['Minimum Biggest Distance for Single Neuron', np.round(max_distance_to_neuron_min_average_train, 3), np.round(max_distance_to_neuron_min_average_valid, 3), np.round(max_distance_to_neuron_min_average_test, 3), np.round(max_distance_to_neuron_min_adult, 3), np.round(max_distance_to_neuron_min_titanic, 3), np.round(max_distance_to_neuron_min_absenteeism, 3)],        \n",
    "    ]    \n",
    ")\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    image, nodes = anytree_decision_tree_from_parameters(test_network_absenteeism_dt_inet, config=config, normalizer_list=normalizer_list)\n",
    "else:\n",
    "    tree = generate_random_decision_tree(config)\n",
    "    tree.initialize_from_parameter_array(test_network_absenteeism_dt_inet, reshape=True, config=config)\n",
    "    image = tree.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['function_family']['dt_type'] == 'vanilla':\n",
    "    plt.figure(figsize=(24,12))  # set plot size (denoted in inches)\n",
    "    plot_tree(dt_distilled_absenteeism, fontsize=12)\n",
    "    image = plt.show()\n",
    "else:\n",
    "    image = dt_distilled_absenteeism.plot_tree()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size = 10000\n",
    "\n",
    "print('Dataset Size:\\t\\t', dataset_size)\n",
    "tab = PrettyTable()\n",
    "tab.field_names = ['Metric', \n",
    "                   #'Dist. (Random) Adult', \n",
    "                   'Dist. Adult', \n",
    "                   'I-Net Adult',\n",
    "                   #'Dist. (Random) Titanic', \n",
    "                   'Dist. Titanic', \n",
    "                   'I-Net Titanic',                   \n",
    "                   #'Dist. (Random) Absent.', \n",
    "                   'Dist. Absent.', \n",
    "                   'I-Net Absent.',\n",
    "                  ]\n",
    "tab.add_rows(\n",
    "    [\n",
    "        #flatten_list(['Metric', [[fill('Distilled DT (Train/Random Data) ' + str(size), width=10), fill('Distilled DT (Test Data) ' + str(size), width=10)] for size in dataset_size_list_adult], fill('I-Net DT (Test Data)', width=10)]),\n",
    "        flatten_list(['Soft BC', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['soft_binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['soft_binary_crossentropy'], 3),                      \n",
    "                      ]),\n",
    "        flatten_list(['BC',  \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['binary_crossentropy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['binary_crossentropy'], 3),                       \n",
    "                     ]),\n",
    "        flatten_list(['Acc', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['accuracy'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['accuracy'], 3),      \n",
    "                     ]),\n",
    "        flatten_list(['F1 Score', \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score_data_random'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['f1_score'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['f1_score'], 3),                            \n",
    "                     ]),\n",
    "        flatten_list(['Runtime',  \n",
    "                      #np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_adult_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                                      \n",
    "                      #np.round(results_titanic_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3), \n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['dt_scores']['runtime'], 3),\n",
    "                      np.round(results_absenteeism_list[dataset_size_list.index(dataset_size)]['inet_scores']['runtime'], 3),                            \n",
    "                     ])\n",
    "    ]    \n",
    ")\n",
    "print(tab)\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writepath_complete = './results_complete.csv'\n",
    "writepath_summary = './results_summary.csv'\n",
    "\n",
    "#TODO: ADD COMPLEXITY FOR DTS\n",
    "\n",
    "if different_eval_data:\n",
    "    flat_config = flatten_dict(config_train)\n",
    "else:\n",
    "    flat_config = flatten_dict(config)    \n",
    "\n",
    "flat_dict_train = flatten_dict(inet_evaluation_result_dict_train)\n",
    "flat_dict_valid = flatten_dict(inet_evaluation_result_dict_valid)\n",
    "flat_dict_test = flatten_dict(inet_evaluation_result_dict_test)\n",
    "\n",
    "\n",
    "#TODO ADD FUNCTION VALUES FOR EACH DATASET SIZE (IN SEPARATE FILE?)\n",
    "#    - COLLECT ERRORS PER NETWORK / FIND FILE WHERE SAVED\n",
    "\n",
    "if not os.path.exists(writepath_complete):\n",
    "    with open(writepath_complete, 'w+') as text_file:       \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key)\n",
    "            text_file.write(';')      \n",
    "        \n",
    "        number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_train.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_train_' + str(i) + ';')    \n",
    "                    \n",
    "        number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_valid.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_valid_' + str(i) + ';')       \n",
    "                    \n",
    "        number_of_evaluated_networks = np.array(flat_dict_test['inet_scores_binary_crossentropy']).shape[0]\n",
    "        for key in flat_dict_test.keys():\n",
    "            if 'function_values' not in key:\n",
    "                for i in range(number_of_evaluated_networks):\n",
    "                    text_file.write(key + '_test_' + str(i) + ';')        \n",
    "        \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_complete, 'a+') as text_file:  \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value))\n",
    "        text_file.write(';')\n",
    "            \n",
    "        \n",
    "    number_of_evaluated_networks = np.array(flat_dict_train['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_train.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_valid['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_valid.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "\n",
    "    number_of_evaluated_networks = np.array(flat_dict_test['inet_scores_binary_crossentropy']).shape[0]\n",
    "    for key, values in flat_dict_test.items():\n",
    "        if 'function_values' not in key:\n",
    "            for score in values:\n",
    "                text_file.write(str(score) + ';')   \n",
    "                    \n",
    "    text_file.write('\\n')            \n",
    "\n",
    "    text_file.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inet_evaluation_result_dict_mean_train_flat = flatten_dict(inet_evaluation_result_dict_mean_train)\n",
    "inet_evaluation_result_dict_mean_valid_flat = flatten_dict(inet_evaluation_result_dict_mean_valid)\n",
    "inet_evaluation_result_dict_mean_test_flat = flatten_dict(inet_evaluation_result_dict_mean_test)\n",
    "    \n",
    "results_adult_flat = flatten_dict(results_adult)\n",
    "del results_adult_flat['function_values_y_test_inet_dt']\n",
    "del results_adult_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "results_titanic_flat = flatten_dict(results_titanic)\n",
    "del results_titanic_flat['function_values_y_test_inet_dt']\n",
    "del results_titanic_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "results_absenteeism_flat = flatten_dict(results_absenteeism)\n",
    "del results_absenteeism_flat['function_values_y_test_inet_dt']\n",
    "del results_absenteeism_flat['function_values_y_test_distilled_dt']\n",
    "\n",
    "adult_evaluation_result_dict_flat = flatten_dict(adult_evaluation_result_dict)\n",
    "del adult_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del adult_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del adult_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "titanic_evaluation_result_dict_flat = flatten_dict(titanic_evaluation_result_dict)\n",
    "del titanic_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del titanic_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del titanic_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "absenteeism_evaluation_result_dict_flat = flatten_dict(absenteeism_evaluation_result_dict)\n",
    "del absenteeism_evaluation_result_dict_flat['function_values_y_test_inet_dt']\n",
    "del absenteeism_evaluation_result_dict_flat['function_values_y_test_distilled_dt']\n",
    "#del absenteeism_evaluation_result_dict_flat['dataset_size']\n",
    "\n",
    "\n",
    "if not os.path.exists(writepath_summary):\n",
    "    with open(writepath_summary, 'w+') as text_file: \n",
    "            \n",
    "        for key in flat_config.keys():\n",
    "            text_file.write(key + ';')\n",
    "         \n",
    "        for key in inet_evaluation_result_dict_mean_train_flat.keys():\n",
    "            text_file.write('train_' + key + ';')\n",
    "        for key in inet_evaluation_result_dict_mean_valid_flat.keys():\n",
    "            text_file.write('valid_' + key + ';')            \n",
    "        for key in inet_evaluation_result_dict_mean_test_flat.keys():\n",
    "            text_file.write('test_' + key + ';')\n",
    "        \n",
    "        for dataset_size in dataset_size_list:\n",
    "            for key in results_adult_flat.keys():\n",
    "                text_file.write(key + '_adult_' + str(dataset_size) + ';')\n",
    "        \n",
    "            for key in results_titanic_flat.keys():\n",
    "                text_file.write(key + '_titanic_' + str(dataset_size) + ';')\n",
    "                \n",
    "            for key in results_absenteeism_flat.keys():\n",
    "                text_file.write(key + '_absenteeism_' + str(dataset_size) + ';')    \n",
    "         \n",
    "        text_file.write('z-score_train' + ';')    \n",
    "        text_file.write('z-score_valid' + ';')    \n",
    "        text_file.write('z-score_test' + ';')    \n",
    "        text_file.write('z-score_adult' + ';')    \n",
    "        text_file.write('z-score_titanic' + ';')    \n",
    "        text_file.write('z-score_absenteeism' + ';')    \n",
    "\n",
    "        text_file.write('dist_to_init_train' + ';')    \n",
    "        text_file.write('dist_to_init_valid' + ';')    \n",
    "        text_file.write('dist_to_init_test' + ';')    \n",
    "        text_file.write('dist_to_init_adult' + ';')    \n",
    "        text_file.write('dist_to_init_titanic' + ';')    \n",
    "        text_file.write('dist_to_init_absenteeism' + ';')    \n",
    "        \n",
    "        text_file.write('avg_dist_to_train_train' + ';')    \n",
    "        text_file.write('avg_dist_to_train_valid' + ';')    \n",
    "        text_file.write('avg_dist_to_train_test' + ';')    \n",
    "        text_file.write('avg_dist_to_train_adult' + ';')    \n",
    "        text_file.write('avg_dist_to_train_titanic' + ';')    \n",
    "        text_file.write('avg_dist_to_train_absenteeism' + ';')    \n",
    "        \n",
    "        text_file.write('min_dist_to_train_sample_train' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_valid' + ';')    \n",
    "        text_file.write('min_dist_to_train_samplee_test' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_adult' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_titanic' + ';')    \n",
    "        text_file.write('min_dist_to_train_sample_absenteeism')    \n",
    "        \n",
    "        text_file.write('\\n')\n",
    "    \n",
    "with open(writepath_summary, 'a+') as text_file: \n",
    "    \n",
    "    for value in flat_config.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "        \n",
    "    for value in inet_evaluation_result_dict_mean_train_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "    for value in inet_evaluation_result_dict_mean_valid_flat.values():\n",
    "        text_file.write(str(value) + ';')            \n",
    "    for value in inet_evaluation_result_dict_mean_test_flat.values():\n",
    "        text_file.write(str(value) + ';')\n",
    "\n",
    "    for i in range(len(dataset_size_list)):\n",
    "        for values in adult_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "\n",
    "        for values in titanic_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "\n",
    "        for values in absenteeism_evaluation_result_dict_flat.values():\n",
    "            text_file.write(str(values[i]) + ';')            \n",
    "    \n",
    "    text_file.write(str(z_score_average_train) + ';')    \n",
    "    text_file.write(str(z_score_average_valid) + ';')    \n",
    "    text_file.write(str(z_score_average_test) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_adult) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_titanic) + ';')    \n",
    "    text_file.write(str(z_score_aggregate_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_initialization_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_adult) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_initialization_aggregate_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_sample_average_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_adult) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_sample_average_absenteeism) + ';')    \n",
    "\n",
    "    text_file.write(str(distance_to_sample_min_average_train) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_average_valid) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_average_test) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_adult) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_titanic) + ';')    \n",
    "    text_file.write(str(distance_to_sample_min_absenteeism))       \n",
    "    \n",
    "    text_file.write('\\n')\n",
    "\n",
    "    text_file.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
